[12/13 18:27:05] detectron2 INFO: Rank of current process: 0. World size: 2
[12/13 18:27:09] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/13 18:27:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/13 18:27:09] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 和原始一致，测试不缩放
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: True
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train",)
  TEST: ("my_dataset_test",)
SOLVER:
  MAX_ITER: 46368 
  BASE_LR: 0.01     ### 
  STEPS: (25000, 35000)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/13 18:27:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: True
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 46368
  MOMENTUM: 0.9
  STEPS: (25000, 35000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/13 18:27:09] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/13 18:27:09] d2.utils.env INFO: Using a generated random seed 9626906
[12/13 18:27:12] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/13 18:27:12] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0004999.pth
[12/13 18:28:21] detectron2 INFO: Rank of current process: 0. World size: 2
[12/13 18:28:25] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/13 18:28:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/13 18:28:25] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 和原始一致，测试不缩放
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: True
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train",)
  TEST: ("my_dataset_test",)
SOLVER:
  MAX_ITER: 46368 
  BASE_LR: 0.01     ### 
  STEPS: (25000, 35000)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/13 18:28:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: True
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 46368
  MOMENTUM: 0.9
  STEPS: (25000, 35000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/13 18:28:25] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/13 18:28:25] d2.utils.env INFO: Using a generated random seed 25810764
[12/13 18:28:28] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/13 18:28:28] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_final.pth
[12/13 18:30:39] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/13 18:30:39] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/13 18:30:40] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/13 18:30:40] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/13 18:31:34] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4845 s / img. ETA=2:15:40
[12/13 18:31:58] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4837 s / img. ETA=2:15:01
[12/13 18:32:22] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4832 s / img. ETA=2:14:28
[12/13 18:32:46] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4840 s / img. ETA=2:14:18
[12/13 18:33:10] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4841 s / img. ETA=2:13:56
[12/13 18:33:34] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4834 s / img. ETA=2:13:20
[12/13 18:33:59] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4833 s / img. ETA=2:12:54
[12/13 18:34:23] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4832 s / img. ETA=2:12:28
[12/13 18:34:47] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4830 s / img. ETA=2:12:01
[12/13 18:35:11] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4832 s / img. ETA=2:11:40
[12/13 18:35:35] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4831 s / img. ETA=2:11:13
[12/13 18:35:59] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4829 s / img. ETA=2:10:47
[12/13 18:36:23] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4828 s / img. ETA=2:10:21
[12/13 18:36:47] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4827 s / img. ETA=2:09:56
[12/13 18:37:11] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4828 s / img. ETA=2:09:32
[12/13 18:37:36] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4828 s / img. ETA=2:09:08
[12/13 18:38:00] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4828 s / img. ETA=2:08:44
[12/13 18:38:24] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4826 s / img. ETA=2:08:17
[12/13 18:38:48] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4826 s / img. ETA=2:07:52
[12/13 18:39:12] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4825 s / img. ETA=2:07:28
[12/13 18:39:36] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4825 s / img. ETA=2:07:04
[12/13 18:40:00] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4825 s / img. ETA=2:06:39
[12/13 18:40:24] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4824 s / img. ETA=2:06:13
[12/13 18:40:48] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4823 s / img. ETA=2:05:48
[12/13 18:41:12] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4823 s / img. ETA=2:05:24
[12/13 18:41:37] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4824 s / img. ETA=2:05:01
[12/13 18:42:01] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4824 s / img. ETA=2:04:37
[12/13 18:42:25] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4824 s / img. ETA=2:04:13
[12/13 18:42:49] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4824 s / img. ETA=2:03:48
[12/13 18:43:13] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4823 s / img. ETA=2:03:24
[12/13 18:43:37] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4823 s / img. ETA=2:02:59
[12/13 18:44:01] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4823 s / img. ETA=2:02:35
[12/13 18:44:25] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4823 s / img. ETA=2:02:10
[12/13 18:44:49] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4823 s / img. ETA=2:01:46
[12/13 18:45:13] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4823 s / img. ETA=2:01:22
[12/13 18:45:37] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4822 s / img. ETA=2:00:57
[12/13 18:46:01] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4822 s / img. ETA=2:00:32
[12/13 18:46:26] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4821 s / img. ETA=2:00:08
[12/13 18:46:50] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4822 s / img. ETA=1:59:44
[12/13 18:47:14] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4821 s / img. ETA=1:59:19
[12/13 18:47:38] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4821 s / img. ETA=1:58:54
[12/13 18:48:02] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4821 s / img. ETA=1:58:31
[12/13 18:48:26] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4821 s / img. ETA=1:58:06
[12/13 18:48:50] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4821 s / img. ETA=1:57:42
[12/13 18:49:14] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4821 s / img. ETA=1:57:19
[12/13 18:49:38] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4821 s / img. ETA=1:56:54
[12/13 18:50:02] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4821 s / img. ETA=1:56:30
[12/13 18:50:26] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4821 s / img. ETA=1:56:05
[12/13 18:50:50] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4820 s / img. ETA=1:55:41
[12/13 18:51:15] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4821 s / img. ETA=1:55:17
[12/13 18:51:39] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4821 s / img. ETA=1:54:53
[12/13 18:52:03] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4821 s / img. ETA=1:54:30
[12/13 18:52:27] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4821 s / img. ETA=1:54:06
[12/13 18:52:51] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4821 s / img. ETA=1:53:41
[12/13 18:53:15] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4821 s / img. ETA=1:53:17
[12/13 18:53:39] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4821 s / img. ETA=1:52:53
[12/13 18:54:03] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4821 s / img. ETA=1:52:28
[12/13 18:54:28] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4821 s / img. ETA=1:52:05
[12/13 18:54:52] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4821 s / img. ETA=1:51:40
[12/13 18:55:16] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4820 s / img. ETA=1:51:16
[12/13 18:55:42] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4827 s / img. ETA=1:51:00
[12/13 18:56:06] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4827 s / img. ETA=1:50:36
[12/13 18:56:30] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4827 s / img. ETA=1:50:12
[12/13 18:56:54] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4827 s / img. ETA=1:49:48
[12/13 18:57:18] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4826 s / img. ETA=1:49:23
[12/13 18:57:42] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4826 s / img. ETA=1:48:59
[12/13 18:58:06] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4826 s / img. ETA=1:48:35
[12/13 18:58:30] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4826 s / img. ETA=1:48:11
[12/13 18:58:54] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4826 s / img. ETA=1:47:47
[12/13 18:59:19] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4826 s / img. ETA=1:47:22
[12/13 18:59:42] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4825 s / img. ETA=1:46:57
[12/13 19:00:07] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4825 s / img. ETA=1:46:33
[12/13 19:00:31] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4825 s / img. ETA=1:46:08
[12/13 19:00:55] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4825 s / img. ETA=1:45:44
[12/13 19:01:19] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4825 s / img. ETA=1:45:21
[12/13 19:01:43] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4825 s / img. ETA=1:44:56
[12/13 19:02:07] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4824 s / img. ETA=1:44:31
[12/13 19:02:31] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4824 s / img. ETA=1:44:06
[12/13 19:02:55] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4824 s / img. ETA=1:43:42
[12/13 19:03:19] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4823 s / img. ETA=1:43:17
[12/13 19:03:43] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4823 s / img. ETA=1:42:53
[12/13 19:04:07] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4823 s / img. ETA=1:42:29
[12/13 19:04:31] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4823 s / img. ETA=1:42:05
[12/13 19:04:55] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4823 s / img. ETA=1:41:40
[12/13 19:05:19] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4822 s / img. ETA=1:41:16
[12/13 19:05:43] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4822 s / img. ETA=1:40:51
[12/13 19:06:07] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4822 s / img. ETA=1:40:27
[12/13 19:06:31] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4822 s / img. ETA=1:40:03
[12/13 19:06:55] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4822 s / img. ETA=1:39:39
[12/13 19:07:19] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4822 s / img. ETA=1:39:14
[12/13 19:07:43] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4822 s / img. ETA=1:38:50
[12/13 19:08:07] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4822 s / img. ETA=1:38:26
[12/13 19:08:31] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4822 s / img. ETA=1:38:02
[12/13 19:08:56] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4822 s / img. ETA=1:37:38
[12/13 19:09:20] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4821 s / img. ETA=1:37:13
[12/13 19:09:44] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4821 s / img. ETA=1:36:49
[12/13 19:10:08] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4821 s / img. ETA=1:36:25
[12/13 19:10:32] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4822 s / img. ETA=1:36:01
[12/13 19:10:56] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4822 s / img. ETA=1:35:38
[12/13 19:11:21] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4822 s / img. ETA=1:35:14
[12/13 19:11:45] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4823 s / img. ETA=1:34:50
[12/13 19:12:09] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4823 s / img. ETA=1:34:26
[12/13 19:12:33] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4823 s / img. ETA=1:34:02
[12/13 19:12:57] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4823 s / img. ETA=1:33:38
[12/13 19:13:21] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4823 s / img. ETA=1:33:14
[12/13 19:13:45] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4823 s / img. ETA=1:32:49
[12/13 19:14:09] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4822 s / img. ETA=1:32:25
[12/13 19:14:33] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4822 s / img. ETA=1:32:01
[12/13 19:14:57] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4822 s / img. ETA=1:31:36
[12/13 19:15:21] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4822 s / img. ETA=1:31:12
[12/13 19:15:46] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4822 s / img. ETA=1:30:48
[12/13 19:16:10] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4822 s / img. ETA=1:30:24
[12/13 19:16:33] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4821 s / img. ETA=1:29:59
[12/13 19:16:58] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4821 s / img. ETA=1:29:35
[12/13 19:17:22] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4821 s / img. ETA=1:29:11
[12/13 19:17:46] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4821 s / img. ETA=1:28:47
[12/13 19:18:10] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4821 s / img. ETA=1:28:22
[12/13 19:18:34] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4821 s / img. ETA=1:27:58
[12/13 19:18:58] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4821 s / img. ETA=1:27:34
[12/13 19:19:22] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4820 s / img. ETA=1:27:10
[12/13 19:19:46] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4820 s / img. ETA=1:26:45
[12/13 19:20:10] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4820 s / img. ETA=1:26:21
[12/13 19:20:34] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4820 s / img. ETA=1:25:57
[12/13 19:20:58] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4820 s / img. ETA=1:25:33
[12/13 19:21:22] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4820 s / img. ETA=1:25:09
[12/13 19:21:46] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4820 s / img. ETA=1:24:45
[12/13 19:22:10] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4820 s / img. ETA=1:24:21
[12/13 19:22:34] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4820 s / img. ETA=1:23:56
[12/13 19:22:58] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4820 s / img. ETA=1:23:32
[12/13 19:23:22] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4820 s / img. ETA=1:23:08
[12/13 19:23:46] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4819 s / img. ETA=1:22:44
[12/13 19:24:10] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4819 s / img. ETA=1:22:19
[12/13 19:24:34] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4819 s / img. ETA=1:21:55
[12/13 19:24:58] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4819 s / img. ETA=1:21:31
[12/13 19:25:22] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4819 s / img. ETA=1:21:07
[12/13 19:25:47] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4820 s / img. ETA=1:20:43
[12/13 19:26:11] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4820 s / img. ETA=1:20:20
[12/13 19:26:35] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4820 s / img. ETA=1:19:55
[12/13 19:26:59] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4820 s / img. ETA=1:19:31
[12/13 19:27:23] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4820 s / img. ETA=1:19:07
[12/13 19:27:47] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4820 s / img. ETA=1:18:43
[12/13 19:28:12] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4820 s / img. ETA=1:18:19
[12/13 19:28:36] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4820 s / img. ETA=1:17:55
[12/13 19:29:00] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4820 s / img. ETA=1:17:30
[12/13 19:29:24] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4819 s / img. ETA=1:17:06
[12/13 19:29:48] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4819 s / img. ETA=1:16:42
[12/13 19:30:12] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4819 s / img. ETA=1:16:18
[12/13 19:30:36] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4819 s / img. ETA=1:15:54
[12/13 19:31:00] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4819 s / img. ETA=1:15:29
[12/13 19:31:24] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4819 s / img. ETA=1:15:05
[12/13 19:31:48] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4819 s / img. ETA=1:14:41
[12/13 19:32:12] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4819 s / img. ETA=1:14:17
[12/13 19:32:36] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4819 s / img. ETA=1:13:53
[12/13 19:33:00] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4819 s / img. ETA=1:13:29
[12/13 19:33:24] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4819 s / img. ETA=1:13:05
[12/13 19:33:48] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4819 s / img. ETA=1:12:41
[12/13 19:34:12] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4819 s / img. ETA=1:12:16
[12/13 19:34:36] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4819 s / img. ETA=1:11:52
[12/13 19:35:00] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4819 s / img. ETA=1:11:28
[12/13 19:35:24] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4818 s / img. ETA=1:11:04
[12/13 19:35:48] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4818 s / img. ETA=1:10:40
[12/13 19:36:12] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4818 s / img. ETA=1:10:15
[12/13 19:36:36] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4818 s / img. ETA=1:09:51
[12/13 19:37:00] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4818 s / img. ETA=1:09:27
[12/13 19:37:24] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4818 s / img. ETA=1:09:03
[12/13 19:37:48] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4818 s / img. ETA=1:08:38
[12/13 19:38:12] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4818 s / img. ETA=1:08:14
[12/13 19:38:36] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4818 s / img. ETA=1:07:50
[12/13 19:39:00] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4817 s / img. ETA=1:07:26
[12/13 19:39:24] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4817 s / img. ETA=1:07:02
[12/13 19:39:48] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4817 s / img. ETA=1:06:38
[12/13 19:40:12] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4817 s / img. ETA=1:06:14
[12/13 19:40:36] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4817 s / img. ETA=1:05:50
[12/13 19:41:00] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4817 s / img. ETA=1:05:26
[12/13 19:41:24] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4817 s / img. ETA=1:05:01
[12/13 19:41:48] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4817 s / img. ETA=1:04:37
[12/13 19:42:13] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4817 s / img. ETA=1:04:13
[12/13 19:42:37] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4817 s / img. ETA=1:03:49
[12/13 19:43:01] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4818 s / img. ETA=1:03:25
[12/13 19:43:25] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4817 s / img. ETA=1:03:01
[12/13 19:43:49] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4817 s / img. ETA=1:02:37
[12/13 19:44:13] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4817 s / img. ETA=1:02:13
[12/13 19:44:37] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4817 s / img. ETA=1:01:49
[12/13 19:45:01] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4817 s / img. ETA=1:01:25
[12/13 19:45:25] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4817 s / img. ETA=1:01:01
[12/13 19:45:49] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4817 s / img. ETA=1:00:36
[12/13 19:46:13] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4817 s / img. ETA=1:00:12
[12/13 19:46:38] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4817 s / img. ETA=0:59:48
[12/13 19:47:01] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4817 s / img. ETA=0:59:24
[12/13 19:47:25] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4817 s / img. ETA=0:59:00
[12/13 19:47:50] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4817 s / img. ETA=0:58:36
[12/13 19:48:14] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4817 s / img. ETA=0:58:12
[12/13 19:48:38] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4817 s / img. ETA=0:57:48
[12/13 19:49:02] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4817 s / img. ETA=0:57:24
[12/13 19:49:26] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4817 s / img. ETA=0:56:59
[12/13 19:49:50] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4817 s / img. ETA=0:56:35
[12/13 19:50:14] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4817 s / img. ETA=0:56:11
[12/13 19:50:38] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4816 s / img. ETA=0:55:47
[12/13 19:51:02] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4816 s / img. ETA=0:55:23
[12/13 19:51:26] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4816 s / img. ETA=0:54:59
[12/13 19:51:50] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4816 s / img. ETA=0:54:35
[12/13 19:52:14] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4816 s / img. ETA=0:54:11
[12/13 19:52:38] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4816 s / img. ETA=0:53:47
[12/13 19:53:02] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4817 s / img. ETA=0:53:23
[12/13 19:53:26] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4817 s / img. ETA=0:52:58
[12/13 19:53:51] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4817 s / img. ETA=0:52:34
[12/13 19:54:15] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4817 s / img. ETA=0:52:10
[12/13 19:54:39] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4817 s / img. ETA=0:51:46
[12/13 19:55:03] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4817 s / img. ETA=0:51:22
[12/13 19:55:27] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4817 s / img. ETA=0:50:58
[12/13 19:55:53] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4819 s / img. ETA=0:50:35
[12/13 19:56:17] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4819 s / img. ETA=0:50:11
[12/13 19:56:41] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4819 s / img. ETA=0:49:47
[12/13 19:57:05] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4819 s / img. ETA=0:49:23
[12/13 19:57:29] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4819 s / img. ETA=0:48:59
[12/13 19:57:53] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4818 s / img. ETA=0:48:35
[12/13 19:58:17] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4818 s / img. ETA=0:48:10
[12/13 19:58:41] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4818 s / img. ETA=0:47:46
[12/13 19:59:05] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4818 s / img. ETA=0:47:22
[12/13 19:59:29] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4818 s / img. ETA=0:46:58
[12/13 19:59:53] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4818 s / img. ETA=0:46:34
[12/13 20:00:17] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4818 s / img. ETA=0:46:10
[12/13 20:00:41] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4818 s / img. ETA=0:45:46
[12/13 20:01:05] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4818 s / img. ETA=0:45:22
[12/13 20:01:29] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4818 s / img. ETA=0:44:57
[12/13 20:01:53] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4818 s / img. ETA=0:44:33
[12/13 20:02:18] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4818 s / img. ETA=0:44:09
[12/13 20:02:42] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4818 s / img. ETA=0:43:45
[12/13 20:03:06] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4818 s / img. ETA=0:43:21
[12/13 20:03:30] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4818 s / img. ETA=0:42:57
[12/13 20:03:54] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4818 s / img. ETA=0:42:33
[12/13 20:04:19] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4818 s / img. ETA=0:42:09
[12/13 20:04:43] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4818 s / img. ETA=0:41:45
[12/13 20:05:07] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4818 s / img. ETA=0:41:21
[12/13 20:05:31] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4818 s / img. ETA=0:40:57
[12/13 20:05:55] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4818 s / img. ETA=0:40:33
[12/13 20:06:19] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4818 s / img. ETA=0:40:08
[12/13 20:06:43] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4818 s / img. ETA=0:39:44
[12/13 20:07:07] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4818 s / img. ETA=0:39:20
[12/13 20:07:31] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4818 s / img. ETA=0:38:56
[12/13 20:07:55] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4818 s / img. ETA=0:38:32
[12/13 20:08:19] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4818 s / img. ETA=0:38:08
[12/13 20:08:43] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4818 s / img. ETA=0:37:44
[12/13 20:09:07] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4818 s / img. ETA=0:37:20
[12/13 20:09:32] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4818 s / img. ETA=0:36:56
[12/13 20:09:56] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4818 s / img. ETA=0:36:32
[12/13 20:10:20] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4818 s / img. ETA=0:36:08
[12/13 20:10:44] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4818 s / img. ETA=0:35:44
[12/13 20:11:08] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4818 s / img. ETA=0:35:19
[12/13 20:11:32] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4818 s / img. ETA=0:34:55
[12/13 20:11:56] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4818 s / img. ETA=0:34:31
[12/13 20:12:20] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4818 s / img. ETA=0:34:07
[12/13 20:12:44] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4818 s / img. ETA=0:33:43
[12/13 20:13:08] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4818 s / img. ETA=0:33:19
[12/13 20:13:32] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4818 s / img. ETA=0:32:55
[12/13 20:13:56] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4818 s / img. ETA=0:32:31
[12/13 20:14:20] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4818 s / img. ETA=0:32:07
[12/13 20:14:44] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4818 s / img. ETA=0:31:43
[12/13 20:15:08] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4818 s / img. ETA=0:31:18
[12/13 20:15:32] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4818 s / img. ETA=0:30:54
[12/13 20:15:56] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4818 s / img. ETA=0:30:30
[12/13 20:16:20] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4818 s / img. ETA=0:30:06
[12/13 20:16:44] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4818 s / img. ETA=0:29:42
[12/13 20:17:09] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4818 s / img. ETA=0:29:18
[12/13 20:17:33] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4818 s / img. ETA=0:28:54
[12/13 20:17:57] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4818 s / img. ETA=0:28:30
[12/13 20:18:21] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4818 s / img. ETA=0:28:06
[12/13 20:18:45] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4818 s / img. ETA=0:27:42
[12/13 20:19:09] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4818 s / img. ETA=0:27:18
[12/13 20:19:33] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4818 s / img. ETA=0:26:53
[12/13 20:19:57] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4818 s / img. ETA=0:26:29
[12/13 20:20:21] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4817 s / img. ETA=0:26:05
[12/13 20:20:45] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4817 s / img. ETA=0:25:41
[12/13 20:21:09] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4817 s / img. ETA=0:25:17
[12/13 20:21:33] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4817 s / img. ETA=0:24:53
[12/13 20:21:57] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4817 s / img. ETA=0:24:29
[12/13 20:22:21] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4817 s / img. ETA=0:24:05
[12/13 20:22:45] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4817 s / img. ETA=0:23:41
[12/13 20:23:09] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4817 s / img. ETA=0:23:16
[12/13 20:23:33] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4817 s / img. ETA=0:22:52
[12/13 20:23:57] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4817 s / img. ETA=0:22:28
[12/13 20:24:21] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4817 s / img. ETA=0:22:04
[12/13 20:24:45] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4817 s / img. ETA=0:21:40
[12/13 20:25:09] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4817 s / img. ETA=0:21:16
[12/13 20:25:33] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4817 s / img. ETA=0:20:52
[12/13 20:25:57] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4817 s / img. ETA=0:20:28
[12/13 20:26:21] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4817 s / img. ETA=0:20:04
[12/13 20:26:45] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4817 s / img. ETA=0:19:40
[12/13 20:27:09] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4817 s / img. ETA=0:19:15
[12/13 20:27:33] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4816 s / img. ETA=0:18:51
[12/13 20:27:57] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4816 s / img. ETA=0:18:27
[12/13 20:28:21] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4816 s / img. ETA=0:18:03
[12/13 20:28:45] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4816 s / img. ETA=0:17:39
[12/13 20:29:09] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4816 s / img. ETA=0:17:15
[12/13 20:29:33] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4816 s / img. ETA=0:16:51
[12/13 20:29:57] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4816 s / img. ETA=0:16:27
[12/13 20:30:21] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4816 s / img. ETA=0:16:03
[12/13 20:30:45] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4816 s / img. ETA=0:15:39
[12/13 20:31:09] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4816 s / img. ETA=0:15:15
[12/13 20:31:34] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4816 s / img. ETA=0:14:50
[12/13 20:31:58] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4816 s / img. ETA=0:14:26
[12/13 20:32:21] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4816 s / img. ETA=0:14:02
[12/13 20:32:45] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4816 s / img. ETA=0:13:38
[12/13 20:33:09] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4816 s / img. ETA=0:13:14
[12/13 20:33:33] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4816 s / img. ETA=0:12:50
[12/13 20:33:57] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4816 s / img. ETA=0:12:26
[12/13 20:34:21] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4816 s / img. ETA=0:12:02
[12/13 20:34:45] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4815 s / img. ETA=0:11:38
[12/13 20:35:09] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4815 s / img. ETA=0:11:14
[12/13 20:35:33] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4815 s / img. ETA=0:10:50
[12/13 20:35:57] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4815 s / img. ETA=0:10:25
[12/13 20:36:21] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4815 s / img. ETA=0:10:01
[12/13 20:36:45] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4815 s / img. ETA=0:09:37
[12/13 20:37:09] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4815 s / img. ETA=0:09:13
[12/13 20:37:33] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4815 s / img. ETA=0:08:49
[12/13 20:37:57] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4815 s / img. ETA=0:08:25
[12/13 20:38:21] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4815 s / img. ETA=0:08:01
[12/13 20:38:45] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4815 s / img. ETA=0:07:37
[12/13 20:39:09] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4815 s / img. ETA=0:07:13
[12/13 20:39:33] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4815 s / img. ETA=0:06:49
[12/13 20:39:57] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4815 s / img. ETA=0:06:25
[12/13 20:40:21] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4815 s / img. ETA=0:06:01
[12/13 20:40:45] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4815 s / img. ETA=0:05:37
[12/13 20:41:09] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4815 s / img. ETA=0:05:12
[12/13 20:41:33] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4815 s / img. ETA=0:04:48
[12/13 20:41:57] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4815 s / img. ETA=0:04:24
[12/13 20:42:21] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4815 s / img. ETA=0:04:00
[12/13 20:42:45] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4814 s / img. ETA=0:03:36
[12/13 20:43:09] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4814 s / img. ETA=0:03:12
[12/13 20:43:33] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4814 s / img. ETA=0:02:48
[12/13 20:43:57] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4814 s / img. ETA=0:02:24
[12/13 20:44:21] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4814 s / img. ETA=0:02:00
[12/13 20:44:45] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4814 s / img. ETA=0:01:36
[12/13 20:45:09] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4814 s / img. ETA=0:01:12
[12/13 20:45:34] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4814 s / img. ETA=0:00:48
[12/13 20:45:58] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4814 s / img. ETA=0:00:24
[12/13 20:46:22] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4814 s / img. ETA=0:00:00
[12/13 20:46:22] d2.evaluation.evaluator INFO: Total inference time: 2:15:10 (0.481449 s / img per device, on 2 devices)
[12/13 20:46:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:19 (0.478463 s / img per device, on 2 devices)
[12/13 20:46:25] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/13 20:46:25] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/13 20:46:27] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/13 20:47:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/13 20:47:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/13 20:47:02] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/13 20:47:02] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/13 20:47:02] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/13 20:47:02] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/14 09:28:58] detectron2 INFO: Rank of current process: 0. World size: 2
[12/14 09:29:02] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/14 09:29:02] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/14 09:29:02] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1200 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: True
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train",)
  TEST: ("my_dataset_test",)
SOLVER:
  MAX_ITER: 46368 
  BASE_LR: 0.01     ### 
  STEPS: (25000, 35000)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/14 09:29:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: True
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1200
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 46368
  MOMENTUM: 0.9
  STEPS: (25000, 35000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/14 09:29:02] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/14 09:29:02] d2.utils.env INFO: Using a generated random seed 3015895
[12/14 09:29:06] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/14 09:29:06] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_final.pth
[12/14 09:29:09] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/14 09:29:09] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/14 09:29:10] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/14 09:29:10] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/14 09:30:03] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4804 s / img. ETA=2:14:29
[12/14 09:30:27] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4814 s / img. ETA=2:14:23
[12/14 09:30:51] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4812 s / img. ETA=2:13:55
[12/14 09:31:15] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4812 s / img. ETA=2:13:32
[12/14 09:31:39] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4810 s / img. ETA=2:13:04
[12/14 09:32:03] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4810 s / img. ETA=2:12:41
[12/14 09:32:28] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4811 s / img. ETA=2:12:18
[12/14 09:32:52] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4813 s / img. ETA=2:11:57
[12/14 09:33:16] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4813 s / img. ETA=2:11:33
[12/14 09:33:40] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4813 s / img. ETA=2:11:09
[12/14 09:34:04] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4813 s / img. ETA=2:10:45
[12/14 09:34:28] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4814 s / img. ETA=2:10:22
[12/14 09:34:52] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4814 s / img. ETA=2:09:58
[12/14 09:35:16] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4814 s / img. ETA=2:09:34
[12/14 09:35:40] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4815 s / img. ETA=2:09:11
[12/14 09:36:04] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4815 s / img. ETA=2:08:47
[12/14 09:36:28] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4814 s / img. ETA=2:08:23
[12/14 09:36:52] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4814 s / img. ETA=2:07:58
[12/14 09:37:16] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4814 s / img. ETA=2:07:34
[12/14 09:37:41] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4814 s / img. ETA=2:07:10
[12/14 09:38:05] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4814 s / img. ETA=2:06:45
[12/14 09:38:29] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4814 s / img. ETA=2:06:22
[12/14 09:38:53] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4814 s / img. ETA=2:05:57
[12/14 09:39:17] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4814 s / img. ETA=2:05:33
[12/14 09:39:41] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4813 s / img. ETA=2:05:08
[12/14 09:40:05] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4813 s / img. ETA=2:04:44
[12/14 09:40:29] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4813 s / img. ETA=2:04:20
[12/14 09:40:53] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4814 s / img. ETA=2:03:57
[12/14 09:41:17] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4814 s / img. ETA=2:03:32
[12/14 09:41:41] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4814 s / img. ETA=2:03:08
[12/14 09:42:05] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4814 s / img. ETA=2:02:44
[12/14 09:42:29] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4813 s / img. ETA=2:02:20
[12/14 09:42:53] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4813 s / img. ETA=2:01:56
[12/14 09:43:17] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4814 s / img. ETA=2:01:32
[12/14 09:43:41] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4813 s / img. ETA=2:01:08
[12/14 09:44:05] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4813 s / img. ETA=2:00:43
[12/14 09:44:30] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4813 s / img. ETA=2:00:19
[12/14 09:44:54] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4813 s / img. ETA=1:59:55
[12/14 09:45:18] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4813 s / img. ETA=1:59:31
[12/14 09:45:42] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4813 s / img. ETA=1:59:07
[12/14 09:46:06] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4812 s / img. ETA=1:58:42
[12/14 09:46:30] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4812 s / img. ETA=1:58:18
[12/14 09:46:54] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4812 s / img. ETA=1:57:54
[12/14 09:47:18] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4813 s / img. ETA=1:57:30
[12/14 09:47:42] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4813 s / img. ETA=1:57:06
[12/14 09:48:06] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4813 s / img. ETA=1:56:43
[12/14 09:48:30] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4813 s / img. ETA=1:56:19
[12/14 09:48:54] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4813 s / img. ETA=1:55:55
[12/14 09:49:18] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4813 s / img. ETA=1:55:31
[12/14 09:49:42] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4813 s / img. ETA=1:55:07
[12/14 09:50:06] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4813 s / img. ETA=1:54:42
[12/14 09:50:31] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4813 s / img. ETA=1:54:18
[12/14 09:50:55] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4813 s / img. ETA=1:53:54
[12/14 09:51:19] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4813 s / img. ETA=1:53:30
[12/14 09:51:43] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4813 s / img. ETA=1:53:06
[12/14 09:52:07] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4813 s / img. ETA=1:52:42
[12/14 09:52:31] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4813 s / img. ETA=1:52:18
[12/14 09:52:55] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4813 s / img. ETA=1:51:54
[12/14 09:53:19] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4813 s / img. ETA=1:51:29
[12/14 09:53:43] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4812 s / img. ETA=1:51:05
[12/14 09:54:07] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4813 s / img. ETA=1:50:41
[12/14 09:54:31] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4813 s / img. ETA=1:50:17
[12/14 09:54:55] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4813 s / img. ETA=1:49:53
[12/14 09:55:19] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4813 s / img. ETA=1:49:29
[12/14 09:55:45] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4819 s / img. ETA=1:49:14
[12/14 09:56:09] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4819 s / img. ETA=1:48:50
[12/14 09:56:34] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4819 s / img. ETA=1:48:26
[12/14 09:56:58] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4819 s / img. ETA=1:48:01
[12/14 09:57:22] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4819 s / img. ETA=1:47:37
[12/14 09:57:46] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4819 s / img. ETA=1:47:12
[12/14 09:58:10] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4818 s / img. ETA=1:46:48
[12/14 09:58:34] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4818 s / img. ETA=1:46:24
[12/14 09:58:58] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4818 s / img. ETA=1:45:59
[12/14 09:59:22] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4818 s / img. ETA=1:45:35
[12/14 09:59:46] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4817 s / img. ETA=1:45:10
[12/14 10:00:10] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4817 s / img. ETA=1:44:46
[12/14 10:00:34] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4817 s / img. ETA=1:44:22
[12/14 10:00:58] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4817 s / img. ETA=1:43:58
[12/14 10:01:22] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4817 s / img. ETA=1:43:33
[12/14 10:01:46] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4817 s / img. ETA=1:43:09
[12/14 10:02:10] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4817 s / img. ETA=1:42:45
[12/14 10:02:34] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4817 s / img. ETA=1:42:21
[12/14 10:02:58] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4817 s / img. ETA=1:41:57
[12/14 10:03:22] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4816 s / img. ETA=1:41:32
[12/14 10:03:46] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4816 s / img. ETA=1:41:08
[12/14 10:04:10] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4816 s / img. ETA=1:40:44
[12/14 10:04:34] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4816 s / img. ETA=1:40:19
[12/14 10:04:58] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4816 s / img. ETA=1:39:55
[12/14 10:05:22] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4816 s / img. ETA=1:39:31
[12/14 10:05:46] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4816 s / img. ETA=1:39:07
[12/14 10:06:10] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4815 s / img. ETA=1:38:42
[12/14 10:06:34] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4815 s / img. ETA=1:38:18
[12/14 10:06:58] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4815 s / img. ETA=1:37:54
[12/14 10:07:22] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4815 s / img. ETA=1:37:30
[12/14 10:07:46] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4815 s / img. ETA=1:37:06
[12/14 10:08:10] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4815 s / img. ETA=1:36:41
[12/14 10:08:34] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4815 s / img. ETA=1:36:17
[12/14 10:08:58] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4815 s / img. ETA=1:35:53
[12/14 10:09:22] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4815 s / img. ETA=1:35:29
[12/14 10:09:46] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4814 s / img. ETA=1:35:05
[12/14 10:10:10] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4814 s / img. ETA=1:34:40
[12/14 10:10:34] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4814 s / img. ETA=1:34:16
[12/14 10:10:58] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4814 s / img. ETA=1:33:52
[12/14 10:11:22] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4814 s / img. ETA=1:33:28
[12/14 10:11:46] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4814 s / img. ETA=1:33:04
[12/14 10:12:10] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4814 s / img. ETA=1:32:39
[12/14 10:12:34] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4814 s / img. ETA=1:32:15
[12/14 10:12:58] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4813 s / img. ETA=1:31:51
[12/14 10:13:22] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4813 s / img. ETA=1:31:27
[12/14 10:13:46] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4813 s / img. ETA=1:31:03
[12/14 10:14:10] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4813 s / img. ETA=1:30:38
[12/14 10:14:34] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4813 s / img. ETA=1:30:14
[12/14 10:14:58] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4813 s / img. ETA=1:29:50
[12/14 10:15:22] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4813 s / img. ETA=1:29:26
[12/14 10:15:46] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4813 s / img. ETA=1:29:02
[12/14 10:16:10] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4813 s / img. ETA=1:28:37
[12/14 10:16:34] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4813 s / img. ETA=1:28:13
[12/14 10:16:58] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4812 s / img. ETA=1:27:49
[12/14 10:17:22] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4812 s / img. ETA=1:27:25
[12/14 10:17:46] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4812 s / img. ETA=1:27:01
[12/14 10:18:10] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4812 s / img. ETA=1:26:36
[12/14 10:18:34] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4812 s / img. ETA=1:26:12
[12/14 10:18:58] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4812 s / img. ETA=1:25:48
[12/14 10:19:22] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4811 s / img. ETA=1:25:24
[12/14 10:19:46] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4811 s / img. ETA=1:25:00
[12/14 10:20:10] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4811 s / img. ETA=1:24:36
[12/14 10:20:34] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4811 s / img. ETA=1:24:11
[12/14 10:20:58] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4811 s / img. ETA=1:23:47
[12/14 10:21:22] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4811 s / img. ETA=1:23:23
[12/14 10:21:46] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4811 s / img. ETA=1:22:59
[12/14 10:22:10] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4811 s / img. ETA=1:22:35
[12/14 10:22:34] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4811 s / img. ETA=1:22:10
[12/14 10:22:58] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4811 s / img. ETA=1:21:46
[12/14 10:23:22] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4811 s / img. ETA=1:21:22
[12/14 10:23:46] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4811 s / img. ETA=1:20:58
[12/14 10:24:10] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4811 s / img. ETA=1:20:34
[12/14 10:24:34] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4811 s / img. ETA=1:20:10
[12/14 10:24:58] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4811 s / img. ETA=1:19:46
[12/14 10:25:22] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4811 s / img. ETA=1:19:22
[12/14 10:25:46] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4810 s / img. ETA=1:18:58
[12/14 10:26:10] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4810 s / img. ETA=1:18:34
[12/14 10:26:34] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4810 s / img. ETA=1:18:10
[12/14 10:26:58] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4810 s / img. ETA=1:17:45
[12/14 10:27:22] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4810 s / img. ETA=1:17:21
[12/14 10:27:46] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4810 s / img. ETA=1:16:57
[12/14 10:28:10] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4810 s / img. ETA=1:16:33
[12/14 10:28:34] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4810 s / img. ETA=1:16:09
[12/14 10:28:58] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4810 s / img. ETA=1:15:45
[12/14 10:29:22] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4810 s / img. ETA=1:15:21
[12/14 10:29:46] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4810 s / img. ETA=1:14:57
[12/14 10:30:10] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4810 s / img. ETA=1:14:32
[12/14 10:30:34] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4810 s / img. ETA=1:14:08
[12/14 10:30:58] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4810 s / img. ETA=1:13:44
[12/14 10:31:22] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4810 s / img. ETA=1:13:20
[12/14 10:31:46] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4810 s / img. ETA=1:12:56
[12/14 10:32:11] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4809 s / img. ETA=1:12:32
[12/14 10:32:34] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4809 s / img. ETA=1:12:08
[12/14 10:32:58] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4809 s / img. ETA=1:11:44
[12/14 10:33:22] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4809 s / img. ETA=1:11:20
[12/14 10:33:46] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4809 s / img. ETA=1:10:56
[12/14 10:34:10] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4809 s / img. ETA=1:10:32
[12/14 10:34:34] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4809 s / img. ETA=1:10:07
[12/14 10:34:58] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4809 s / img. ETA=1:09:43
[12/14 10:35:22] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4809 s / img. ETA=1:09:19
[12/14 10:35:46] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4809 s / img. ETA=1:08:55
[12/14 10:36:10] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4809 s / img. ETA=1:08:31
[12/14 10:36:34] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4809 s / img. ETA=1:08:07
[12/14 10:36:58] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4808 s / img. ETA=1:07:43
[12/14 10:37:22] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4808 s / img. ETA=1:07:18
[12/14 10:37:46] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4808 s / img. ETA=1:06:54
[12/14 10:38:10] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4808 s / img. ETA=1:06:30
[12/14 10:38:34] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4808 s / img. ETA=1:06:06
[12/14 10:38:58] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4808 s / img. ETA=1:05:42
[12/14 10:39:22] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4808 s / img. ETA=1:05:18
[12/14 10:39:46] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4808 s / img. ETA=1:04:54
[12/14 10:40:10] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4808 s / img. ETA=1:04:30
[12/14 10:40:34] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4808 s / img. ETA=1:04:06
[12/14 10:40:58] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4808 s / img. ETA=1:03:42
[12/14 10:41:22] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4808 s / img. ETA=1:03:18
[12/14 10:41:46] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4808 s / img. ETA=1:02:54
[12/14 10:42:10] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4808 s / img. ETA=1:02:29
[12/14 10:42:34] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4808 s / img. ETA=1:02:05
[12/14 10:42:58] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4808 s / img. ETA=1:01:41
[12/14 10:43:22] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4808 s / img. ETA=1:01:17
[12/14 10:43:46] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4808 s / img. ETA=1:00:53
[12/14 10:44:10] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4807 s / img. ETA=1:00:29
[12/14 10:44:34] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4807 s / img. ETA=1:00:05
[12/14 10:44:58] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4807 s / img. ETA=0:59:41
[12/14 10:45:22] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4807 s / img. ETA=0:59:17
[12/14 10:45:46] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4807 s / img. ETA=0:58:53
[12/14 10:46:10] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4808 s / img. ETA=0:58:29
[12/14 10:46:34] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4808 s / img. ETA=0:58:05
[12/14 10:46:58] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4808 s / img. ETA=0:57:41
[12/14 10:47:22] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4807 s / img. ETA=0:57:17
[12/14 10:47:46] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4807 s / img. ETA=0:56:53
[12/14 10:48:10] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4807 s / img. ETA=0:56:29
[12/14 10:48:34] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4807 s / img. ETA=0:56:04
[12/14 10:48:58] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4807 s / img. ETA=0:55:40
[12/14 10:49:22] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4807 s / img. ETA=0:55:16
[12/14 10:49:46] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4807 s / img. ETA=0:54:52
[12/14 10:50:10] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4807 s / img. ETA=0:54:28
[12/14 10:50:34] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4807 s / img. ETA=0:54:04
[12/14 10:50:58] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4807 s / img. ETA=0:53:40
[12/14 10:51:22] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4806 s / img. ETA=0:53:16
[12/14 10:51:46] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4806 s / img. ETA=0:52:52
[12/14 10:52:10] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4806 s / img. ETA=0:52:28
[12/14 10:52:34] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4806 s / img. ETA=0:52:04
[12/14 10:52:58] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4806 s / img. ETA=0:51:40
[12/14 10:53:22] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4806 s / img. ETA=0:51:16
[12/14 10:53:46] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4806 s / img. ETA=0:50:52
[12/14 10:54:10] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4806 s / img. ETA=0:50:28
[12/14 10:54:34] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4806 s / img. ETA=0:50:03
[12/14 10:54:58] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4806 s / img. ETA=0:49:39
[12/14 10:55:22] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4806 s / img. ETA=0:49:15
[12/14 10:55:48] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4808 s / img. ETA=0:48:52
[12/14 10:56:12] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4808 s / img. ETA=0:48:28
[12/14 10:56:36] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4808 s / img. ETA=0:48:04
[12/14 10:56:59] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4808 s / img. ETA=0:47:40
[12/14 10:57:23] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4808 s / img. ETA=0:47:16
[12/14 10:57:47] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4807 s / img. ETA=0:46:52
[12/14 10:58:11] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4807 s / img. ETA=0:46:28
[12/14 10:58:35] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4807 s / img. ETA=0:46:04
[12/14 10:58:59] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4807 s / img. ETA=0:45:40
[12/14 10:59:23] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4807 s / img. ETA=0:45:16
[12/14 10:59:47] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4807 s / img. ETA=0:44:52
[12/14 11:00:11] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4807 s / img. ETA=0:44:27
[12/14 11:00:35] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4807 s / img. ETA=0:44:03
[12/14 11:00:59] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4807 s / img. ETA=0:43:39
[12/14 11:01:23] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4807 s / img. ETA=0:43:15
[12/14 11:01:47] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4807 s / img. ETA=0:42:51
[12/14 11:02:11] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4807 s / img. ETA=0:42:27
[12/14 11:02:35] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4807 s / img. ETA=0:42:03
[12/14 11:02:59] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4807 s / img. ETA=0:41:39
[12/14 11:03:23] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4807 s / img. ETA=0:41:15
[12/14 11:03:47] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4807 s / img. ETA=0:40:51
[12/14 11:04:11] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4807 s / img. ETA=0:40:27
[12/14 11:04:35] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4807 s / img. ETA=0:40:03
[12/14 11:04:59] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4807 s / img. ETA=0:39:39
[12/14 11:05:23] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4807 s / img. ETA=0:39:15
[12/14 11:05:47] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4807 s / img. ETA=0:38:51
[12/14 11:06:11] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4807 s / img. ETA=0:38:27
[12/14 11:06:35] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4807 s / img. ETA=0:38:03
[12/14 11:06:59] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4807 s / img. ETA=0:37:39
[12/14 11:07:23] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4807 s / img. ETA=0:37:15
[12/14 11:07:47] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4806 s / img. ETA=0:36:50
[12/14 11:08:11] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4806 s / img. ETA=0:36:26
[12/14 11:08:35] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4806 s / img. ETA=0:36:02
[12/14 11:08:59] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4806 s / img. ETA=0:35:38
[12/14 11:09:23] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4806 s / img. ETA=0:35:14
[12/14 11:09:47] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4806 s / img. ETA=0:34:50
[12/14 11:10:11] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4806 s / img. ETA=0:34:26
[12/14 11:10:35] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4806 s / img. ETA=0:34:02
[12/14 11:10:59] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4806 s / img. ETA=0:33:38
[12/14 11:11:23] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4806 s / img. ETA=0:33:14
[12/14 11:11:47] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4806 s / img. ETA=0:32:50
[12/14 11:12:11] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4806 s / img. ETA=0:32:26
[12/14 11:12:35] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4806 s / img. ETA=0:32:02
[12/14 11:12:59] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4806 s / img. ETA=0:31:38
[12/14 11:13:23] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4806 s / img. ETA=0:31:14
[12/14 11:13:47] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4806 s / img. ETA=0:30:50
[12/14 11:14:11] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4806 s / img. ETA=0:30:26
[12/14 11:14:35] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4806 s / img. ETA=0:30:02
[12/14 11:14:59] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4806 s / img. ETA=0:29:38
[12/14 11:15:23] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4806 s / img. ETA=0:29:14
[12/14 11:15:46] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4806 s / img. ETA=0:28:50
[12/14 11:16:10] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4806 s / img. ETA=0:28:25
[12/14 11:16:34] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4805 s / img. ETA=0:28:01
[12/14 11:16:58] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4805 s / img. ETA=0:27:37
[12/14 11:17:22] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4805 s / img. ETA=0:27:13
[12/14 11:17:46] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4805 s / img. ETA=0:26:49
[12/14 11:18:10] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4805 s / img. ETA=0:26:25
[12/14 11:18:34] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4805 s / img. ETA=0:26:01
[12/14 11:18:58] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4805 s / img. ETA=0:25:37
[12/14 11:19:22] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4805 s / img. ETA=0:25:13
[12/14 11:19:46] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4805 s / img. ETA=0:24:49
[12/14 11:20:10] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4805 s / img. ETA=0:24:25
[12/14 11:20:34] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4805 s / img. ETA=0:24:01
[12/14 11:20:58] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4805 s / img. ETA=0:23:37
[12/14 11:21:22] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4805 s / img. ETA=0:23:13
[12/14 11:21:46] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4805 s / img. ETA=0:22:49
[12/14 11:22:10] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4805 s / img. ETA=0:22:25
[12/14 11:22:34] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4805 s / img. ETA=0:22:01
[12/14 11:22:58] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4805 s / img. ETA=0:21:37
[12/14 11:23:22] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4805 s / img. ETA=0:21:13
[12/14 11:23:46] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4805 s / img. ETA=0:20:49
[12/14 11:24:10] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4805 s / img. ETA=0:20:25
[12/14 11:24:34] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4805 s / img. ETA=0:20:01
[12/14 11:24:58] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4805 s / img. ETA=0:19:37
[12/14 11:25:22] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4805 s / img. ETA=0:19:13
[12/14 11:25:46] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4805 s / img. ETA=0:18:49
[12/14 11:26:10] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4805 s / img. ETA=0:18:25
[12/14 11:26:34] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4805 s / img. ETA=0:18:01
[12/14 11:26:58] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4805 s / img. ETA=0:17:37
[12/14 11:27:22] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4805 s / img. ETA=0:17:12
[12/14 11:27:46] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4805 s / img. ETA=0:16:48
[12/14 11:28:10] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4805 s / img. ETA=0:16:24
[12/14 11:28:34] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4805 s / img. ETA=0:16:00
[12/14 11:28:58] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4805 s / img. ETA=0:15:36
[12/14 11:29:22] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4805 s / img. ETA=0:15:12
[12/14 11:29:46] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4804 s / img. ETA=0:14:48
[12/14 11:30:10] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4805 s / img. ETA=0:14:24
[12/14 11:30:34] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4804 s / img. ETA=0:14:00
[12/14 11:30:58] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4804 s / img. ETA=0:13:36
[12/14 11:31:22] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4804 s / img. ETA=0:13:12
[12/14 11:31:46] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4804 s / img. ETA=0:12:48
[12/14 11:32:10] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4804 s / img. ETA=0:12:24
[12/14 11:32:34] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4804 s / img. ETA=0:12:00
[12/14 11:32:57] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4804 s / img. ETA=0:11:36
[12/14 11:33:21] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4804 s / img. ETA=0:11:12
[12/14 11:33:45] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4804 s / img. ETA=0:10:48
[12/14 11:34:09] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4804 s / img. ETA=0:10:24
[12/14 11:34:33] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4804 s / img. ETA=0:10:00
[12/14 11:34:57] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4804 s / img. ETA=0:09:36
[12/14 11:35:21] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4804 s / img. ETA=0:09:12
[12/14 11:35:45] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4804 s / img. ETA=0:08:48
[12/14 11:36:09] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4804 s / img. ETA=0:08:24
[12/14 11:36:33] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4804 s / img. ETA=0:08:00
[12/14 11:36:57] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4804 s / img. ETA=0:07:36
[12/14 11:37:21] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4804 s / img. ETA=0:07:12
[12/14 11:37:45] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4804 s / img. ETA=0:06:48
[12/14 11:38:10] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4804 s / img. ETA=0:06:24
[12/14 11:38:34] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4804 s / img. ETA=0:06:00
[12/14 11:38:58] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4804 s / img. ETA=0:05:36
[12/14 11:39:22] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4804 s / img. ETA=0:05:12
[12/14 11:39:46] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4804 s / img. ETA=0:04:48
[12/14 11:40:09] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4804 s / img. ETA=0:04:24
[12/14 11:40:33] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4804 s / img. ETA=0:04:00
[12/14 11:40:57] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4804 s / img. ETA=0:03:36
[12/14 11:41:21] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4804 s / img. ETA=0:03:12
[12/14 11:41:45] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4804 s / img. ETA=0:02:48
[12/14 11:42:09] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4804 s / img. ETA=0:02:24
[12/14 11:42:33] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4804 s / img. ETA=0:02:00
[12/14 11:42:57] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4804 s / img. ETA=0:01:36
[12/14 11:43:21] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4804 s / img. ETA=0:01:12
[12/14 11:43:45] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4804 s / img. ETA=0:00:48
[12/14 11:44:10] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4804 s / img. ETA=0:00:24
[12/14 11:44:34] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4804 s / img. ETA=0:00:00
[12/14 11:44:34] d2.evaluation.evaluator INFO: Total inference time: 2:14:52 (0.480380 s / img per device, on 2 devices)
[12/14 11:44:34] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:01 (0.477374 s / img per device, on 2 devices)
[12/14 11:44:37] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/14 11:44:37] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/14 11:44:38] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/14 11:45:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/14 11:45:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/14 11:45:14] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/14 11:45:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/14 11:45:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/14 11:45:14] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/26 17:10:17] detectron2 INFO: Rank of current process: 0. World size: 2
[12/26 17:10:23] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/26 17:10:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/26 17:10:23] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_val_light",)  #my_dataset_val_light my_dataset_test
SOLVER:
  MAX_ITER: 74368 
  BASE_LR: 0.01     ### 
  STEPS: (74100, 74300)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/26 17:10:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_light',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 74368
  MOMENTUM: 0.9
  STEPS: (74100, 74300)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/26 17:10:23] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/26 17:10:23] d2.utils.env INFO: Using a generated random seed 23445900
[12/26 17:10:26] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/26 17:10:27] d2.data.datasets.coco INFO: Loaded 14085 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_light.json
[12/26 17:10:27] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 4488         |   ASC-US   | 4583         |    HSIL     | 2030         |
|    LSIL    | 2603         |  Candida   | 1199         | Trichomonas | 7163         |
|            |              |            |              |             |              |
|   total    | 22066        |            |              |             |              |[0m
[12/26 17:10:27] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[12/26 17:10:27] d2.data.build INFO: Using training sampler TrainingSampler
[12/26 17:11:42] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0046368.pth
[12/26 17:11:48] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0046368.pth
[12/26 17:11:48] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0046368.pth
[12/26 17:11:48] d2.engine.train_loop INFO: Starting training from iteration 46368
[12/26 17:11:52] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/26 17:30:27] detectron2 INFO: Rank of current process: 0. World size: 2
[12/26 17:30:31] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/26 17:30:31] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/26 17:30:31] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_val_light",)  #my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 74368 
  BASE_LR: 0.01     ### 
  STEPS: (74100, 74300)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/26 17:30:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_light',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 74368
  MOMENTUM: 0.9
  STEPS: (74100, 74300)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/26 17:30:31] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/26 17:30:31] d2.utils.env INFO: Using a generated random seed 31635927
[12/26 17:30:34] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/26 17:30:35] d2.data.datasets.coco INFO: Loaded 14085 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_light.json
[12/26 17:30:35] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 4485         |   ASC-US   | 4590         |    HSIL     | 1983         |
|    LSIL    | 2574         |  Candida   | 1198         | Trichomonas | 7388         |
|            |              |            |              |             |              |
|   total    | 22218        |            |              |             |              |[0m
[12/26 17:30:35] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[12/26 17:30:35] d2.data.build INFO: Using training sampler TrainingSampler
[12/26 17:31:34] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0046368.pth
[12/26 17:31:35] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0046368.pth
[12/26 17:31:36] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0046368.pth
[12/26 17:31:36] d2.engine.train_loop INFO: Starting training from iteration 46368
[12/26 17:32:13] d2.utils.events INFO: eta: 1 day, 0:21:12  iter: 46379  total_loss: 0.648  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.1133  data_time: 0.0036  lr: 0.000100  max_mem: 8580M
[12/26 17:33:12] d2.utils.events INFO: eta: 23:38:43  iter: 46399  total_loss: 0.480  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 2.9938  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 17:34:14] d2.utils.events INFO: eta: 23:37:45  iter: 46419  total_loss: 0.594  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0196  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 17:35:14] d2.utils.events INFO: eta: 23:35:08  iter: 46439  total_loss: 0.777  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0139  data_time: 0.0021  lr: 0.000100  max_mem: 8580M
[12/26 17:36:15] d2.utils.events INFO: eta: 23:33:27  iter: 46459  total_loss: 0.438  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0215  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 17:37:16] d2.utils.events INFO: eta: 23:33:06  iter: 46479  total_loss: 0.738  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0340  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 17:38:17] d2.utils.events INFO: eta: 23:32:07  iter: 46499  total_loss: 0.481  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.004  loss_rpn_loc: 0.002  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 17:39:18] d2.utils.events INFO: eta: 23:32:10  iter: 46519  total_loss: 0.648  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0361  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 17:40:19] d2.utils.events INFO: eta: 23:31:10  iter: 46539  total_loss: 0.749  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0382  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 17:41:20] d2.utils.events INFO: eta: 23:30:09  iter: 46559  total_loss: 0.474  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.124  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0031  lr: 0.000100  max_mem: 8580M
[12/26 17:42:20] d2.utils.events INFO: eta: 23:29:08  iter: 46579  total_loss: 0.687  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0363  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 17:43:21] d2.utils.events INFO: eta: 23:27:16  iter: 46599  total_loss: 0.712  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0335  data_time: 0.0023  lr: 0.000100  max_mem: 8580M
[12/26 17:44:21] d2.utils.events INFO: eta: 23:27:06  iter: 46619  total_loss: 0.534  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0334  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 17:45:22] d2.utils.events INFO: eta: 23:25:43  iter: 46639  total_loss: 0.547  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 17:46:22] d2.utils.events INFO: eta: 23:24:14  iter: 46659  total_loss: 0.644  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0019  lr: 0.000100  max_mem: 8580M
[12/26 17:47:21] d2.utils.events INFO: eta: 23:23:07  iter: 46679  total_loss: 0.369  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.079  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.125  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0256  data_time: 0.0028  lr: 0.000100  max_mem: 8580M
[12/26 17:48:21] d2.utils.events INFO: eta: 23:22:12  iter: 46699  total_loss: 0.499  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0245  data_time: 0.0025  lr: 0.000100  max_mem: 8580M
[12/26 17:49:22] d2.utils.events INFO: eta: 23:20:59  iter: 46719  total_loss: 0.487  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0244  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 17:50:21] d2.utils.events INFO: eta: 23:19:16  iter: 46739  total_loss: 0.363  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.028  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.064  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.105  loss_rpn_cls: 0.001  loss_rpn_loc: 0.001  time: 3.0205  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 17:51:23] d2.utils.events INFO: eta: 23:19:04  iter: 46759  total_loss: 0.598  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0255  data_time: 0.0035  lr: 0.000100  max_mem: 8580M
[12/26 17:52:25] d2.utils.events INFO: eta: 23:19:50  iter: 46779  total_loss: 0.896  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0297  data_time: 0.0028  lr: 0.000100  max_mem: 8580M
[12/26 17:53:26] d2.utils.events INFO: eta: 23:18:49  iter: 46799  total_loss: 0.627  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 17:54:28] d2.utils.events INFO: eta: 23:18:16  iter: 46819  total_loss: 0.736  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 8580M
[12/26 17:55:27] d2.utils.events INFO: eta: 23:17:01  iter: 46839  total_loss: 0.832  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0293  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 17:56:31] d2.utils.events INFO: eta: 23:16:16  iter: 46859  total_loss: 0.696  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  time: 3.0355  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 17:57:34] d2.utils.events INFO: eta: 23:15:32  iter: 46879  total_loss: 0.585  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0398  data_time: 0.0025  lr: 0.000100  max_mem: 8580M
[12/26 17:58:33] d2.utils.events INFO: eta: 23:14:14  iter: 46899  total_loss: 0.642  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0365  data_time: 0.0028  lr: 0.000100  max_mem: 8580M
[12/26 17:59:33] d2.utils.events INFO: eta: 23:13:13  iter: 46919  total_loss: 0.499  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0362  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:00:33] d2.utils.events INFO: eta: 23:12:03  iter: 46939  total_loss: 0.525  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0352  data_time: 0.0025  lr: 0.000100  max_mem: 8580M
[12/26 18:01:35] d2.utils.events INFO: eta: 23:11:14  iter: 46959  total_loss: 0.611  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0363  data_time: 0.0035  lr: 0.000100  max_mem: 8580M
[12/26 18:02:34] d2.utils.events INFO: eta: 23:10:07  iter: 46979  total_loss: 0.784  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0338  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:03:34] d2.utils.events INFO: eta: 23:09:06  iter: 46999  total_loss: 0.604  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0330  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:04:35] d2.utils.events INFO: eta: 23:08:09  iter: 47019  total_loss: 0.590  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:05:37] d2.utils.events INFO: eta: 23:07:17  iter: 47039  total_loss: 0.635  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:06:38] d2.utils.events INFO: eta: 23:06:31  iter: 47059  total_loss: 0.649  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0361  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:07:40] d2.utils.events INFO: eta: 23:05:33  iter: 47079  total_loss: 0.604  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0368  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:08:41] d2.utils.events INFO: eta: 23:04:32  iter: 47099  total_loss: 0.749  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0375  data_time: 0.0028  lr: 0.000100  max_mem: 8580M
[12/26 18:09:42] d2.utils.events INFO: eta: 23:03:34  iter: 47119  total_loss: 0.639  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0376  data_time: 0.0031  lr: 0.000100  max_mem: 8580M
[12/26 18:10:42] d2.utils.events INFO: eta: 23:02:30  iter: 47139  total_loss: 0.693  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0365  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:11:43] d2.utils.events INFO: eta: 23:01:29  iter: 47159  total_loss: 0.734  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0366  data_time: 0.0031  lr: 0.000100  max_mem: 8580M
[12/26 18:12:44] d2.utils.events INFO: eta: 23:00:34  iter: 47179  total_loss: 0.519  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0375  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:13:45] d2.utils.events INFO: eta: 22:59:33  iter: 47199  total_loss: 0.542  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0375  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:14:46] d2.utils.events INFO: eta: 22:58:32  iter: 47219  total_loss: 0.498  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0374  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 18:15:45] d2.utils.events INFO: eta: 22:57:25  iter: 47239  total_loss: 0.786  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0364  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:16:46] d2.utils.events INFO: eta: 22:56:28  iter: 47259  total_loss: 0.419  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0362  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 18:17:47] d2.utils.events INFO: eta: 22:55:22  iter: 47279  total_loss: 0.850  loss_cls_stage0: 0.078  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0361  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 18:18:48] d2.utils.events INFO: eta: 22:54:21  iter: 47299  total_loss: 0.518  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0362  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 18:19:49] d2.utils.events INFO: eta: 22:53:28  iter: 47319  total_loss: 0.763  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0367  data_time: 0.0025  lr: 0.000100  max_mem: 8580M
[12/26 18:20:50] d2.utils.events INFO: eta: 22:52:24  iter: 47339  total_loss: 0.674  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0369  data_time: 0.0025  lr: 0.000100  max_mem: 8580M
[12/26 18:21:49] d2.utils.events INFO: eta: 22:51:18  iter: 47359  total_loss: 0.580  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0358  data_time: 0.0023  lr: 0.000100  max_mem: 8580M
[12/26 18:22:52] d2.utils.events INFO: eta: 22:50:16  iter: 47379  total_loss: 0.457  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0374  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:23:51] d2.utils.events INFO: eta: 22:49:16  iter: 47399  total_loss: 0.626  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0364  data_time: 0.0031  lr: 0.000100  max_mem: 8580M
[12/26 18:24:52] d2.utils.events INFO: eta: 22:48:04  iter: 47419  total_loss: 0.621  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0359  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:25:51] d2.utils.events INFO: eta: 22:47:00  iter: 47439  total_loss: 0.438  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:26:52] d2.utils.events INFO: eta: 22:46:02  iter: 47459  total_loss: 0.369  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.080  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.098  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0345  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:27:52] d2.utils.events INFO: eta: 22:44:57  iter: 47479  total_loss: 0.563  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:28:52] d2.utils.events INFO: eta: 22:43:51  iter: 47499  total_loss: 0.395  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0338  data_time: 0.0028  lr: 0.000100  max_mem: 8580M
[12/26 18:29:51] d2.utils.events INFO: eta: 22:42:42  iter: 47519  total_loss: 0.500  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0023  lr: 0.000100  max_mem: 8580M
[12/26 18:30:52] d2.utils.events INFO: eta: 22:41:43  iter: 47539  total_loss: 0.445  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:31:54] d2.utils.events INFO: eta: 22:40:45  iter: 47559  total_loss: 0.574  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0335  data_time: 0.0031  lr: 0.000100  max_mem: 8580M
[12/26 18:32:53] d2.utils.events INFO: eta: 22:39:42  iter: 47579  total_loss: 0.485  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.003  loss_rpn_loc: 0.002  time: 3.0322  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:33:54] d2.utils.events INFO: eta: 22:38:42  iter: 47599  total_loss: 0.533  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 18:34:55] d2.utils.events INFO: eta: 22:37:40  iter: 47619  total_loss: 0.700  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0324  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 18:35:57] d2.utils.events INFO: eta: 22:36:44  iter: 47639  total_loss: 0.582  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 18:36:57] d2.utils.events INFO: eta: 22:35:40  iter: 47659  total_loss: 0.841  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0329  data_time: 0.0029  lr: 0.000100  max_mem: 8580M
[12/26 18:37:57] d2.utils.events INFO: eta: 22:34:49  iter: 47679  total_loss: 0.793  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0326  data_time: 0.0027  lr: 0.000100  max_mem: 8580M
[12/26 18:38:58] d2.utils.events INFO: eta: 22:33:41  iter: 47699  total_loss: 0.716  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0328  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:39:59] d2.utils.events INFO: eta: 22:32:52  iter: 47719  total_loss: 0.748  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0330  data_time: 0.0030  lr: 0.000100  max_mem: 8580M
[12/26 18:40:58] d2.utils.events INFO: eta: 22:31:49  iter: 47739  total_loss: 0.334  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.028  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.073  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.003  loss_rpn_loc: 0.002  time: 3.0320  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:41:59] d2.utils.events INFO: eta: 22:30:36  iter: 47759  total_loss: 0.704  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.006  loss_rpn_loc: 0.005  time: 3.0321  data_time: 0.0028  lr: 0.000100  max_mem: 8580M
[12/26 18:43:01] d2.utils.events INFO: eta: 22:29:33  iter: 47779  total_loss: 0.642  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0331  data_time: 0.0026  lr: 0.000100  max_mem: 8580M
[12/26 18:44:01] d2.utils.events INFO: eta: 22:28:29  iter: 47799  total_loss: 0.450  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0024  lr: 0.000100  max_mem: 8580M
[12/26 18:45:02] d2.utils.events INFO: eta: 22:27:18  iter: 47819  total_loss: 0.474  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 8580M
[12/26 18:46:04] d2.utils.events INFO: eta: 22:26:31  iter: 47839  total_loss: 0.662  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0335  data_time: 0.0029  lr: 0.000100  max_mem: 9149M
[12/26 18:47:05] d2.utils.events INFO: eta: 22:25:23  iter: 47859  total_loss: 0.435  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.122  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0338  data_time: 0.0025  lr: 0.000100  max_mem: 9149M
[12/26 18:48:06] d2.utils.events INFO: eta: 22:24:04  iter: 47879  total_loss: 0.822  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.109  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0338  data_time: 0.0024  lr: 0.000100  max_mem: 9149M
[12/26 18:49:07] d2.utils.events INFO: eta: 22:23:25  iter: 47899  total_loss: 0.516  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0026  lr: 0.000100  max_mem: 9149M
[12/26 18:50:07] d2.utils.events INFO: eta: 22:22:14  iter: 47919  total_loss: 0.368  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.090  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.097  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0336  data_time: 0.0028  lr: 0.000100  max_mem: 9149M
[12/26 18:51:08] d2.utils.events INFO: eta: 22:21:28  iter: 47939  total_loss: 0.643  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.087  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0026  lr: 0.000100  max_mem: 9149M
[12/26 18:52:09] d2.utils.events INFO: eta: 22:20:13  iter: 47959  total_loss: 0.768  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0340  data_time: 0.0028  lr: 0.000100  max_mem: 9149M
[12/26 18:53:10] d2.utils.events INFO: eta: 22:19:22  iter: 47979  total_loss: 0.570  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0027  lr: 0.000100  max_mem: 9149M
[12/26 18:54:12] d2.utils.events INFO: eta: 22:18:25  iter: 47999  total_loss: 0.789  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0351  data_time: 0.0038  lr: 0.000100  max_mem: 9149M
[12/26 18:55:13] d2.utils.events INFO: eta: 22:17:16  iter: 48019  total_loss: 0.752  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.087  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0352  data_time: 0.0032  lr: 0.000100  max_mem: 9149M
[12/26 18:56:14] d2.utils.events INFO: eta: 22:16:04  iter: 48039  total_loss: 0.412  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.072  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.117  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0351  data_time: 0.0020  lr: 0.000100  max_mem: 9149M
[12/26 18:57:15] d2.utils.events INFO: eta: 22:14:56  iter: 48059  total_loss: 0.623  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0356  data_time: 0.0028  lr: 0.000100  max_mem: 9149M
[12/26 18:58:16] d2.utils.events INFO: eta: 22:13:53  iter: 48079  total_loss: 0.820  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0354  data_time: 0.0028  lr: 0.000100  max_mem: 9149M
[12/26 18:59:16] d2.utils.events INFO: eta: 22:12:51  iter: 48099  total_loss: 0.475  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0353  data_time: 0.0029  lr: 0.000100  max_mem: 9149M
[12/26 19:00:19] d2.utils.events INFO: eta: 22:11:51  iter: 48119  total_loss: 0.727  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.097  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0363  data_time: 0.0029  lr: 0.000100  max_mem: 9149M
[12/26 19:01:19] d2.utils.events INFO: eta: 22:10:45  iter: 48139  total_loss: 0.676  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0360  data_time: 0.0031  lr: 0.000100  max_mem: 9149M
[12/26 19:02:19] d2.utils.events INFO: eta: 22:09:38  iter: 48159  total_loss: 0.939  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0354  data_time: 0.0023  lr: 0.000100  max_mem: 9149M
[12/26 19:03:18] d2.utils.events INFO: eta: 22:08:14  iter: 48179  total_loss: 0.490  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0348  data_time: 0.0025  lr: 0.000100  max_mem: 9149M
[12/26 19:04:20] d2.utils.events INFO: eta: 22:07:29  iter: 48199  total_loss: 0.713  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0355  data_time: 0.0023  lr: 0.000100  max_mem: 9149M
[12/26 19:05:22] d2.utils.events INFO: eta: 22:06:11  iter: 48219  total_loss: 0.544  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0358  data_time: 0.0025  lr: 0.000100  max_mem: 9149M
[12/26 19:06:21] d2.utils.events INFO: eta: 22:04:58  iter: 48239  total_loss: 0.629  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0030  lr: 0.000100  max_mem: 9149M
[12/26 19:07:23] d2.utils.events INFO: eta: 22:04:00  iter: 48259  total_loss: 0.565  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0032  lr: 0.000100  max_mem: 9149M
[12/26 19:08:25] d2.utils.events INFO: eta: 22:03:09  iter: 48279  total_loss: 0.500  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0364  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 19:09:24] d2.utils.events INFO: eta: 22:01:53  iter: 48299  total_loss: 0.474  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0355  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/26 19:10:23] d2.utils.events INFO: eta: 22:00:26  iter: 48319  total_loss: 0.660  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:11:23] d2.utils.events INFO: eta: 21:58:50  iter: 48339  total_loss: 0.635  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0036  lr: 0.000100  max_mem: 9404M
[12/26 19:12:24] d2.utils.events INFO: eta: 21:57:47  iter: 48359  total_loss: 0.738  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0342  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 19:13:25] d2.utils.events INFO: eta: 21:56:48  iter: 48379  total_loss: 0.701  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:14:25] d2.utils.events INFO: eta: 21:55:50  iter: 48399  total_loss: 0.515  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0344  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:15:25] d2.utils.events INFO: eta: 21:54:56  iter: 48419  total_loss: 0.572  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:16:26] d2.utils.events INFO: eta: 21:54:03  iter: 48439  total_loss: 0.431  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0338  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 19:17:26] d2.utils.events INFO: eta: 21:52:54  iter: 48459  total_loss: 0.565  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0337  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 19:18:27] d2.utils.events INFO: eta: 21:52:01  iter: 48479  total_loss: 0.550  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0339  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 19:19:30] d2.utils.events INFO: eta: 21:51:29  iter: 48499  total_loss: 0.641  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:20:29] d2.utils.events INFO: eta: 21:50:42  iter: 48519  total_loss: 0.545  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0341  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:21:29] d2.utils.events INFO: eta: 21:49:25  iter: 48539  total_loss: 0.639  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0336  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 19:22:30] d2.utils.events INFO: eta: 21:48:20  iter: 48559  total_loss: 0.545  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0337  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:23:31] d2.utils.events INFO: eta: 21:47:23  iter: 48579  total_loss: 0.530  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:24:32] d2.utils.events INFO: eta: 21:46:42  iter: 48599  total_loss: 0.737  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0341  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 19:25:31] d2.utils.events INFO: eta: 21:45:24  iter: 48619  total_loss: 0.591  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:26:33] d2.utils.events INFO: eta: 21:44:23  iter: 48639  total_loss: 0.594  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 19:27:34] d2.utils.events INFO: eta: 21:43:22  iter: 48659  total_loss: 0.629  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0339  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:28:35] d2.utils.events INFO: eta: 21:42:34  iter: 48679  total_loss: 0.476  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0341  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/26 19:29:36] d2.utils.events INFO: eta: 21:41:39  iter: 48699  total_loss: 0.610  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0341  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:30:37] d2.utils.events INFO: eta: 21:40:50  iter: 48719  total_loss: 0.658  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0346  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 19:31:37] d2.utils.events INFO: eta: 21:40:04  iter: 48739  total_loss: 0.465  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:32:38] d2.utils.events INFO: eta: 21:39:06  iter: 48759  total_loss: 0.454  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0344  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 19:33:38] d2.utils.events INFO: eta: 21:37:48  iter: 48779  total_loss: 0.622  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:34:39] d2.utils.events INFO: eta: 21:36:43  iter: 48799  total_loss: 0.468  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/26 19:35:40] d2.utils.events INFO: eta: 21:35:49  iter: 48819  total_loss: 0.586  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0041  lr: 0.000100  max_mem: 9404M
[12/26 19:36:41] d2.utils.events INFO: eta: 21:34:54  iter: 48839  total_loss: 0.685  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:37:42] d2.utils.events INFO: eta: 21:33:47  iter: 48859  total_loss: 0.621  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0344  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 19:38:41] d2.utils.events INFO: eta: 21:32:38  iter: 48879  total_loss: 0.652  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0339  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:39:43] d2.utils.events INFO: eta: 21:31:37  iter: 48899  total_loss: 0.659  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:40:45] d2.utils.events INFO: eta: 21:30:59  iter: 48919  total_loss: 0.697  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 19:41:44] d2.utils.events INFO: eta: 21:29:35  iter: 48939  total_loss: 0.558  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 19:42:45] d2.utils.events INFO: eta: 21:28:27  iter: 48959  total_loss: 0.616  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 19:43:45] d2.utils.events INFO: eta: 21:27:27  iter: 48979  total_loss: 0.611  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 19:44:46] d2.utils.events INFO: eta: 21:26:39  iter: 48999  total_loss: 0.761  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 19:45:48] d2.utils.events INFO: eta: 21:25:38  iter: 49019  total_loss: 0.724  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:46:49] d2.utils.events INFO: eta: 21:24:39  iter: 49039  total_loss: 0.627  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0344  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:47:49] d2.utils.events INFO: eta: 21:23:31  iter: 49059  total_loss: 0.655  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 19:48:49] d2.utils.events INFO: eta: 21:22:23  iter: 49079  total_loss: 0.419  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:49:48] d2.utils.events INFO: eta: 21:21:11  iter: 49099  total_loss: 0.404  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.077  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.115  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:50:48] d2.utils.events INFO: eta: 21:19:44  iter: 49119  total_loss: 0.501  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 19:51:50] d2.utils.events INFO: eta: 21:19:19  iter: 49139  total_loss: 0.820  loss_cls_stage0: 0.083  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.099  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.101  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0335  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:52:49] d2.utils.events INFO: eta: 21:18:16  iter: 49159  total_loss: 0.502  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 19:53:49] d2.utils.events INFO: eta: 21:17:19  iter: 49179  total_loss: 0.453  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0329  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 19:54:48] d2.utils.events INFO: eta: 21:15:35  iter: 49199  total_loss: 0.610  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 19:55:50] d2.utils.events INFO: eta: 21:14:48  iter: 49219  total_loss: 0.588  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0327  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:56:51] d2.utils.events INFO: eta: 21:14:12  iter: 49239  total_loss: 0.552  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 19:57:51] d2.utils.events INFO: eta: 21:12:56  iter: 49259  total_loss: 0.731  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0325  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 19:58:52] d2.utils.events INFO: eta: 21:12:03  iter: 49279  total_loss: 0.605  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 19:59:52] d2.utils.events INFO: eta: 21:11:11  iter: 49299  total_loss: 0.575  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/26 20:00:54] d2.utils.events INFO: eta: 21:10:29  iter: 49319  total_loss: 0.769  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0327  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 20:01:55] d2.utils.events INFO: eta: 21:09:53  iter: 49339  total_loss: 0.838  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0329  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:02:55] d2.utils.events INFO: eta: 21:08:47  iter: 49359  total_loss: 0.563  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 20:03:55] d2.utils.events INFO: eta: 21:07:26  iter: 49379  total_loss: 0.539  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 20:04:56] d2.utils.events INFO: eta: 21:06:26  iter: 49399  total_loss: 0.701  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:05:56] d2.utils.events INFO: eta: 21:05:39  iter: 49419  total_loss: 0.442  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:06:57] d2.utils.events INFO: eta: 21:04:30  iter: 49439  total_loss: 0.530  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 20:07:59] d2.utils.events INFO: eta: 21:03:45  iter: 49459  total_loss: 0.461  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:09:00] d2.utils.events INFO: eta: 21:02:52  iter: 49479  total_loss: 0.606  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0329  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 20:10:01] d2.utils.events INFO: eta: 21:01:48  iter: 49499  total_loss: 0.642  loss_cls_stage0: 0.080  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.098  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0331  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/26 20:11:01] d2.utils.events INFO: eta: 21:00:49  iter: 49519  total_loss: 0.551  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0330  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 20:12:02] d2.utils.events INFO: eta: 20:59:56  iter: 49539  total_loss: 0.602  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 20:13:04] d2.utils.events INFO: eta: 20:59:00  iter: 49559  total_loss: 0.455  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0334  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/26 20:14:05] d2.utils.events INFO: eta: 20:57:56  iter: 49579  total_loss: 0.652  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0334  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 20:15:06] d2.utils.events INFO: eta: 20:56:49  iter: 49599  total_loss: 0.632  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0335  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:16:07] d2.utils.events INFO: eta: 20:55:54  iter: 49619  total_loss: 0.546  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0337  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:17:09] d2.utils.events INFO: eta: 20:54:46  iter: 49639  total_loss: 0.501  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:18:10] d2.utils.events INFO: eta: 20:53:50  iter: 49659  total_loss: 0.644  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:19:11] d2.utils.events INFO: eta: 20:52:45  iter: 49679  total_loss: 0.863  loss_cls_stage0: 0.077  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0341  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:20:12] d2.utils.events INFO: eta: 20:51:48  iter: 49699  total_loss: 0.513  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0344  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 20:21:12] d2.utils.events INFO: eta: 20:50:32  iter: 49719  total_loss: 0.489  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 20:22:13] d2.utils.events INFO: eta: 20:49:31  iter: 49739  total_loss: 0.553  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0344  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 20:23:14] d2.utils.events INFO: eta: 20:47:56  iter: 49759  total_loss: 0.641  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:24:15] d2.utils.events INFO: eta: 20:47:16  iter: 49779  total_loss: 0.691  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 20:25:15] d2.utils.events INFO: eta: 20:46:12  iter: 49799  total_loss: 0.663  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0343  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 20:26:17] d2.utils.events INFO: eta: 20:44:53  iter: 49819  total_loss: 0.569  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/26 20:27:17] d2.utils.events INFO: eta: 20:43:48  iter: 49839  total_loss: 0.691  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 20:28:19] d2.utils.events INFO: eta: 20:42:48  iter: 49859  total_loss: 0.655  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0346  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 20:29:19] d2.utils.events INFO: eta: 20:41:51  iter: 49879  total_loss: 0.587  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:30:20] d2.utils.events INFO: eta: 20:40:48  iter: 49899  total_loss: 0.634  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:31:20] d2.utils.events INFO: eta: 20:39:34  iter: 49919  total_loss: 0.548  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0344  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:32:21] d2.utils.events INFO: eta: 20:38:44  iter: 49939  total_loss: 0.606  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:33:22] d2.utils.events INFO: eta: 20:38:06  iter: 49959  total_loss: 0.736  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:34:24] d2.utils.events INFO: eta: 20:37:21  iter: 49979  total_loss: 0.596  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 20:35:24] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0049999.pth
[12/26 20:35:31] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/26 20:35:31] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 760          |   ASC-US   | 760          |    HSIL     | 365          |
|    LSIL    | 416          |  Candida   | 197          | Trichomonas | 1144         |
|            |              |            |              |             |              |
|   total    | 3642         |            |              |             |              |[0m
[12/26 20:35:31] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/26 20:36:38] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4830 s / img. ETA=0:09:02
[12/26 20:37:02] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4827 s / img. ETA=0:08:38
[12/26 20:37:26] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4822 s / img. ETA=0:08:13
[12/26 20:37:50] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4820 s / img. ETA=0:07:49
[12/26 20:38:14] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4819 s / img. ETA=0:07:25
[12/26 20:38:38] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4817 s / img. ETA=0:07:01
[12/26 20:39:02] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4818 s / img. ETA=0:06:36
[12/26 20:39:26] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4819 s / img. ETA=0:06:13
[12/26 20:39:50] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4819 s / img. ETA=0:05:48
[12/26 20:40:14] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4819 s / img. ETA=0:05:24
[12/26 20:40:38] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4818 s / img. ETA=0:05:00
[12/26 20:41:03] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4819 s / img. ETA=0:04:36
[12/26 20:41:27] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4818 s / img. ETA=0:04:12
[12/26 20:41:51] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4820 s / img. ETA=0:03:48
[12/26 20:42:15] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4822 s / img. ETA=0:03:24
[12/26 20:42:39] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4823 s / img. ETA=0:03:00
[12/26 20:43:03] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4822 s / img. ETA=0:02:36
[12/26 20:43:27] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4822 s / img. ETA=0:02:12
[12/26 20:43:52] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4822 s / img. ETA=0:01:48
[12/26 20:44:16] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4822 s / img. ETA=0:01:23
[12/26 20:44:40] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4821 s / img. ETA=0:00:59
[12/26 20:45:04] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4821 s / img. ETA=0:00:35
[12/26 20:45:28] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4822 s / img. ETA=0:00:11
[12/26 20:45:40] d2.evaluation.evaluator INFO: Total inference time: 0:09:23 (0.481608 s / img per device, on 2 devices)
[12/26 20:45:40] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:20 (0.479111 s / img per device, on 2 devices)
[12/26 20:45:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/26 20:45:40] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/26 20:45:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/26 20:45:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.756 | 71.214 | 55.357 | 24.471 | 42.986 | 50.973 |
[12/26 20:45:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 53.240 | ASC-US     | 49.404 | HSIL        | 65.609 |
| LSIL       | 62.533 | Candida    | 46.882 | Trichomonas | 20.866 |
[12/26 20:45:45] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/26 20:45:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/26 20:45:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/26 20:45:45] d2.evaluation.testing INFO: copypaste: 49.7555,71.2139,55.3567,24.4706,42.9864,50.9729
[12/26 20:45:45] d2.utils.events INFO: eta: 20:36:04  iter: 49999  total_loss: 0.709  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0348  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 20:46:45] d2.utils.events INFO: eta: 20:35:01  iter: 50019  total_loss: 0.699  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 20:47:46] d2.utils.events INFO: eta: 20:33:41  iter: 50039  total_loss: 0.649  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 20:48:46] d2.utils.events INFO: eta: 20:32:38  iter: 50059  total_loss: 0.566  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0345  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:49:48] d2.utils.events INFO: eta: 20:32:02  iter: 50079  total_loss: 0.734  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 20:50:50] d2.utils.events INFO: eta: 20:31:24  iter: 50099  total_loss: 0.668  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/26 20:51:50] d2.utils.events INFO: eta: 20:30:24  iter: 50119  total_loss: 0.567  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0351  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 20:52:50] d2.utils.events INFO: eta: 20:29:23  iter: 50139  total_loss: 0.608  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 20:53:49] d2.utils.events INFO: eta: 20:28:18  iter: 50159  total_loss: 0.310  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.082  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.088  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0342  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:54:48] d2.utils.events INFO: eta: 20:27:14  iter: 50179  total_loss: 0.634  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0339  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 20:55:47] d2.utils.events INFO: eta: 20:26:16  iter: 50199  total_loss: 0.477  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.063  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.088  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0336  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 20:56:48] d2.utils.events INFO: eta: 20:25:15  iter: 50219  total_loss: 0.689  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0334  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 20:57:48] d2.utils.events INFO: eta: 20:24:17  iter: 50239  total_loss: 0.905  loss_cls_stage0: 0.093  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.099  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0334  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 20:58:49] d2.utils.events INFO: eta: 20:23:23  iter: 50259  total_loss: 0.665  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0335  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 20:59:49] d2.utils.events INFO: eta: 20:22:05  iter: 50279  total_loss: 0.546  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:00:48] d2.utils.events INFO: eta: 20:21:07  iter: 50299  total_loss: 0.549  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0329  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:01:49] d2.utils.events INFO: eta: 20:19:55  iter: 50319  total_loss: 0.543  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0330  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:02:50] d2.utils.events INFO: eta: 20:18:54  iter: 50339  total_loss: 0.671  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0329  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 21:03:50] d2.utils.events INFO: eta: 20:18:05  iter: 50359  total_loss: 0.462  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:04:49] d2.utils.events INFO: eta: 20:17:05  iter: 50379  total_loss: 0.521  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:05:50] d2.utils.events INFO: eta: 20:16:12  iter: 50399  total_loss: 0.619  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0324  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 21:06:49] d2.utils.events INFO: eta: 20:14:55  iter: 50419  total_loss: 0.603  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:07:51] d2.utils.events INFO: eta: 20:13:58  iter: 50439  total_loss: 0.714  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:08:53] d2.utils.events INFO: eta: 20:13:06  iter: 50459  total_loss: 0.639  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:09:53] d2.utils.events INFO: eta: 20:12:00  iter: 50479  total_loss: 0.821  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:10:52] d2.utils.events INFO: eta: 20:10:44  iter: 50499  total_loss: 0.682  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.103  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.100  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0321  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:11:52] d2.utils.events INFO: eta: 20:09:43  iter: 50519  total_loss: 0.542  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 21:12:53] d2.utils.events INFO: eta: 20:08:42  iter: 50539  total_loss: 0.661  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:13:53] d2.utils.events INFO: eta: 20:07:36  iter: 50559  total_loss: 0.568  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:14:52] d2.utils.events INFO: eta: 20:06:32  iter: 50579  total_loss: 0.445  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:15:54] d2.utils.events INFO: eta: 20:05:23  iter: 50599  total_loss: 0.612  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 21:16:53] d2.utils.events INFO: eta: 20:04:11  iter: 50619  total_loss: 0.673  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 21:17:55] d2.utils.events INFO: eta: 20:03:22  iter: 50639  total_loss: 0.758  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:18:56] d2.utils.events INFO: eta: 20:02:21  iter: 50659  total_loss: 0.493  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0318  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:19:57] d2.utils.events INFO: eta: 20:01:34  iter: 50679  total_loss: 0.525  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 21:20:59] d2.utils.events INFO: eta: 20:00:35  iter: 50699  total_loss: 0.540  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:22:00] d2.utils.events INFO: eta: 19:59:39  iter: 50719  total_loss: 0.730  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 21:23:00] d2.utils.events INFO: eta: 19:58:28  iter: 50739  total_loss: 0.406  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 21:24:01] d2.utils.events INFO: eta: 19:57:27  iter: 50759  total_loss: 0.725  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:25:00] d2.utils.events INFO: eta: 19:56:22  iter: 50779  total_loss: 0.649  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:26:02] d2.utils.events INFO: eta: 19:55:21  iter: 50799  total_loss: 0.820  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 21:27:02] d2.utils.events INFO: eta: 19:54:11  iter: 50819  total_loss: 0.434  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:28:03] d2.utils.events INFO: eta: 19:53:10  iter: 50839  total_loss: 0.621  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 21:29:04] d2.utils.events INFO: eta: 19:52:04  iter: 50859  total_loss: 0.689  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:30:04] d2.utils.events INFO: eta: 19:51:03  iter: 50879  total_loss: 0.623  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:31:04] d2.utils.events INFO: eta: 19:49:45  iter: 50899  total_loss: 0.579  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:32:05] d2.utils.events INFO: eta: 19:48:53  iter: 50919  total_loss: 0.743  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:33:06] d2.utils.events INFO: eta: 19:47:52  iter: 50939  total_loss: 0.537  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:34:07] d2.utils.events INFO: eta: 19:46:39  iter: 50959  total_loss: 0.510  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:35:06] d2.utils.events INFO: eta: 19:45:14  iter: 50979  total_loss: 0.644  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0317  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 21:36:08] d2.utils.events INFO: eta: 19:44:05  iter: 50999  total_loss: 0.711  loss_cls_stage0: 0.078  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 21:37:08] d2.utils.events INFO: eta: 19:42:57  iter: 51019  total_loss: 0.645  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 21:38:08] d2.utils.events INFO: eta: 19:41:56  iter: 51039  total_loss: 0.788  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 21:39:07] d2.utils.events INFO: eta: 19:40:42  iter: 51059  total_loss: 0.451  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:40:08] d2.utils.events INFO: eta: 19:38:20  iter: 51079  total_loss: 0.763  loss_cls_stage0: 0.081  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 21:41:09] d2.utils.events INFO: eta: 19:36:54  iter: 51099  total_loss: 0.497  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:42:08] d2.utils.events INFO: eta: 19:35:53  iter: 51119  total_loss: 0.580  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:43:08] d2.utils.events INFO: eta: 19:34:42  iter: 51139  total_loss: 0.461  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 21:44:08] d2.utils.events INFO: eta: 19:33:51  iter: 51159  total_loss: 0.668  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:45:09] d2.utils.events INFO: eta: 19:33:17  iter: 51179  total_loss: 0.594  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 21:46:10] d2.utils.events INFO: eta: 19:33:51  iter: 51199  total_loss: 0.754  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:47:12] d2.utils.events INFO: eta: 19:32:51  iter: 51219  total_loss: 0.574  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:48:14] d2.utils.events INFO: eta: 19:32:14  iter: 51239  total_loss: 0.514  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:49:15] d2.utils.events INFO: eta: 19:31:14  iter: 51259  total_loss: 0.598  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:50:13] d2.utils.events INFO: eta: 19:30:13  iter: 51279  total_loss: 0.527  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0019  lr: 0.000100  max_mem: 9404M
[12/26 21:51:14] d2.utils.events INFO: eta: 19:29:19  iter: 51299  total_loss: 0.536  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.137  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0312  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:52:14] d2.utils.events INFO: eta: 19:28:13  iter: 51319  total_loss: 0.704  loss_cls_stage0: 0.078  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0311  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 21:53:13] d2.utils.events INFO: eta: 19:26:45  iter: 51339  total_loss: 0.623  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:54:15] d2.utils.events INFO: eta: 19:26:05  iter: 51359  total_loss: 0.660  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:55:16] d2.utils.events INFO: eta: 19:25:09  iter: 51379  total_loss: 0.719  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 21:56:18] d2.utils.events INFO: eta: 19:24:10  iter: 51399  total_loss: 0.628  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 21:57:18] d2.utils.events INFO: eta: 19:23:20  iter: 51419  total_loss: 0.641  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 21:58:18] d2.utils.events INFO: eta: 19:22:08  iter: 51439  total_loss: 0.601  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 21:59:18] d2.utils.events INFO: eta: 19:20:41  iter: 51459  total_loss: 0.941  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 3.0308  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 22:00:17] d2.utils.events INFO: eta: 19:17:54  iter: 51479  total_loss: 0.512  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:01:17] d2.utils.events INFO: eta: 19:17:10  iter: 51499  total_loss: 0.584  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:02:17] d2.utils.events INFO: eta: 19:15:55  iter: 51519  total_loss: 0.821  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 22:03:19] d2.utils.events INFO: eta: 19:14:58  iter: 51539  total_loss: 0.740  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 22:04:19] d2.utils.events INFO: eta: 19:14:24  iter: 51559  total_loss: 0.651  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 22:05:20] d2.utils.events INFO: eta: 19:14:17  iter: 51579  total_loss: 0.637  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:06:20] d2.utils.events INFO: eta: 19:11:57  iter: 51599  total_loss: 0.491  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 22:07:19] d2.utils.events INFO: eta: 19:11:22  iter: 51619  total_loss: 0.668  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:08:18] d2.utils.events INFO: eta: 19:09:47  iter: 51639  total_loss: 0.515  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 22:09:19] d2.utils.events INFO: eta: 19:08:22  iter: 51659  total_loss: 0.666  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 22:10:19] d2.utils.events INFO: eta: 19:06:52  iter: 51679  total_loss: 0.674  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 22:11:20] d2.utils.events INFO: eta: 19:05:48  iter: 51699  total_loss: 0.763  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.093  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:12:22] d2.utils.events INFO: eta: 19:05:03  iter: 51719  total_loss: 0.777  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:13:23] d2.utils.events INFO: eta: 19:04:14  iter: 51739  total_loss: 0.675  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 22:14:24] d2.utils.events INFO: eta: 19:03:13  iter: 51759  total_loss: 0.543  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 22:15:25] d2.utils.events INFO: eta: 19:02:18  iter: 51779  total_loss: 0.584  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 22:16:25] d2.utils.events INFO: eta: 19:01:12  iter: 51799  total_loss: 0.548  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:17:27] d2.utils.events INFO: eta: 19:00:46  iter: 51819  total_loss: 0.662  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 22:18:27] d2.utils.events INFO: eta: 18:59:16  iter: 51839  total_loss: 0.512  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:19:28] d2.utils.events INFO: eta: 18:58:44  iter: 51859  total_loss: 0.634  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 22:20:30] d2.utils.events INFO: eta: 18:58:03  iter: 51879  total_loss: 0.521  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 22:21:30] d2.utils.events INFO: eta: 18:56:56  iter: 51899  total_loss: 0.532  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 22:22:29] d2.utils.events INFO: eta: 18:55:49  iter: 51919  total_loss: 0.528  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:23:30] d2.utils.events INFO: eta: 18:54:44  iter: 51939  total_loss: 0.789  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:24:31] d2.utils.events INFO: eta: 18:53:48  iter: 51959  total_loss: 0.584  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:25:31] d2.utils.events INFO: eta: 18:52:47  iter: 51979  total_loss: 0.594  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 22:26:31] d2.utils.events INFO: eta: 18:51:39  iter: 51999  total_loss: 0.478  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 22:27:29] d2.utils.events INFO: eta: 18:50:08  iter: 52019  total_loss: 0.808  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0296  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/26 22:28:30] d2.utils.events INFO: eta: 18:49:38  iter: 52039  total_loss: 0.736  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 22:29:31] d2.utils.events INFO: eta: 18:49:17  iter: 52059  total_loss: 0.552  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:30:33] d2.utils.events INFO: eta: 18:48:35  iter: 52079  total_loss: 0.849  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.099  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 22:31:35] d2.utils.events INFO: eta: 18:48:33  iter: 52099  total_loss: 0.544  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.137  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 22:32:35] d2.utils.events INFO: eta: 18:47:26  iter: 52119  total_loss: 0.520  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 22:33:35] d2.utils.events INFO: eta: 18:46:32  iter: 52139  total_loss: 0.464  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:34:37] d2.utils.events INFO: eta: 18:45:41  iter: 52159  total_loss: 0.886  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 22:35:39] d2.utils.events INFO: eta: 18:44:42  iter: 52179  total_loss: 1.003  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 22:36:38] d2.utils.events INFO: eta: 18:43:00  iter: 52199  total_loss: 0.675  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:37:41] d2.utils.events INFO: eta: 18:42:38  iter: 52219  total_loss: 0.731  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:38:43] d2.utils.events INFO: eta: 18:41:21  iter: 52239  total_loss: 0.652  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 22:39:42] d2.utils.events INFO: eta: 18:39:37  iter: 52259  total_loss: 0.505  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:40:43] d2.utils.events INFO: eta: 18:38:39  iter: 52279  total_loss: 0.434  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:41:45] d2.utils.events INFO: eta: 18:37:56  iter: 52299  total_loss: 0.705  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/26 22:42:45] d2.utils.events INFO: eta: 18:37:17  iter: 52319  total_loss: 0.648  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/26 22:43:46] d2.utils.events INFO: eta: 18:36:36  iter: 52339  total_loss: 0.540  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 22:44:48] d2.utils.events INFO: eta: 18:35:40  iter: 52359  total_loss: 0.870  loss_cls_stage0: 0.088  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.105  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.106  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0311  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 22:45:48] d2.utils.events INFO: eta: 18:34:33  iter: 52379  total_loss: 0.595  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 22:46:48] d2.utils.events INFO: eta: 18:33:12  iter: 52399  total_loss: 0.663  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 22:47:49] d2.utils.events INFO: eta: 18:32:29  iter: 52419  total_loss: 0.772  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 22:48:50] d2.utils.events INFO: eta: 18:31:37  iter: 52439  total_loss: 0.548  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/26 22:49:51] d2.utils.events INFO: eta: 18:30:52  iter: 52459  total_loss: 0.613  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:50:52] d2.utils.events INFO: eta: 18:30:05  iter: 52479  total_loss: 0.581  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:51:53] d2.utils.events INFO: eta: 18:29:08  iter: 52499  total_loss: 0.687  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0310  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:52:53] d2.utils.events INFO: eta: 18:28:05  iter: 52519  total_loss: 0.626  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 22:53:52] d2.utils.events INFO: eta: 18:26:58  iter: 52539  total_loss: 0.655  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 22:54:54] d2.utils.events INFO: eta: 18:26:02  iter: 52559  total_loss: 0.588  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 22:55:53] d2.utils.events INFO: eta: 18:24:50  iter: 52579  total_loss: 0.481  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:56:54] d2.utils.events INFO: eta: 18:23:56  iter: 52599  total_loss: 0.614  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 22:57:54] d2.utils.events INFO: eta: 18:22:57  iter: 52619  total_loss: 0.561  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 22:58:55] d2.utils.events INFO: eta: 18:22:02  iter: 52639  total_loss: 0.645  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 22:59:56] d2.utils.events INFO: eta: 18:21:03  iter: 52659  total_loss: 0.773  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:00:58] d2.utils.events INFO: eta: 18:20:11  iter: 52679  total_loss: 0.771  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/26 23:01:59] d2.utils.events INFO: eta: 18:19:09  iter: 52699  total_loss: 0.593  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0310  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 23:03:02] d2.utils.events INFO: eta: 18:18:19  iter: 52719  total_loss: 0.640  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0314  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:04:01] d2.utils.events INFO: eta: 18:17:09  iter: 52739  total_loss: 0.371  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.075  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.092  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/26 23:05:03] d2.utils.events INFO: eta: 18:16:17  iter: 52759  total_loss: 0.671  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0313  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 23:06:03] d2.utils.events INFO: eta: 18:15:02  iter: 52779  total_loss: 0.791  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/26 23:07:05] d2.utils.events INFO: eta: 18:14:06  iter: 52799  total_loss: 0.510  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:08:08] d2.utils.events INFO: eta: 18:13:06  iter: 52819  total_loss: 0.754  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0317  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/26 23:09:08] d2.utils.events INFO: eta: 18:12:05  iter: 52839  total_loss: 0.693  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 23:10:08] d2.utils.events INFO: eta: 18:11:00  iter: 52859  total_loss: 0.495  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 23:11:09] d2.utils.events INFO: eta: 18:09:59  iter: 52879  total_loss: 0.545  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:12:09] d2.utils.events INFO: eta: 18:09:05  iter: 52899  total_loss: 0.738  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 23:13:11] d2.utils.events INFO: eta: 18:08:19  iter: 52919  total_loss: 0.760  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:14:11] d2.utils.events INFO: eta: 18:07:03  iter: 52939  total_loss: 0.691  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:15:11] d2.utils.events INFO: eta: 18:06:02  iter: 52959  total_loss: 0.570  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:16:12] d2.utils.events INFO: eta: 18:05:14  iter: 52979  total_loss: 0.637  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 23:17:12] d2.utils.events INFO: eta: 18:04:17  iter: 52999  total_loss: 0.737  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:18:14] d2.utils.events INFO: eta: 18:03:27  iter: 53019  total_loss: 0.628  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 23:19:14] d2.utils.events INFO: eta: 18:02:22  iter: 53039  total_loss: 0.564  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:20:14] d2.utils.events INFO: eta: 18:01:17  iter: 53059  total_loss: 0.619  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:21:14] d2.utils.events INFO: eta: 18:00:15  iter: 53079  total_loss: 0.590  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0314  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 23:22:16] d2.utils.events INFO: eta: 17:59:11  iter: 53099  total_loss: 0.966  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.097  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:23:17] d2.utils.events INFO: eta: 17:58:11  iter: 53119  total_loss: 0.633  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:24:17] d2.utils.events INFO: eta: 17:57:12  iter: 53139  total_loss: 0.508  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:25:18] d2.utils.events INFO: eta: 17:56:07  iter: 53159  total_loss: 0.654  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:26:19] d2.utils.events INFO: eta: 17:55:06  iter: 53179  total_loss: 0.773  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:27:19] d2.utils.events INFO: eta: 17:54:07  iter: 53199  total_loss: 0.640  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 23:28:21] d2.utils.events INFO: eta: 17:53:05  iter: 53219  total_loss: 0.558  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:29:22] d2.utils.events INFO: eta: 17:52:05  iter: 53239  total_loss: 0.638  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:30:21] d2.utils.events INFO: eta: 17:51:09  iter: 53259  total_loss: 0.611  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 23:31:23] d2.utils.events INFO: eta: 17:50:07  iter: 53279  total_loss: 0.526  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:32:24] d2.utils.events INFO: eta: 17:49:06  iter: 53299  total_loss: 0.576  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:33:25] d2.utils.events INFO: eta: 17:48:08  iter: 53319  total_loss: 0.556  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:34:26] d2.utils.events INFO: eta: 17:47:04  iter: 53339  total_loss: 0.591  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:35:26] d2.utils.events INFO: eta: 17:45:57  iter: 53359  total_loss: 0.488  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:36:27] d2.utils.events INFO: eta: 17:44:58  iter: 53379  total_loss: 0.434  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 23:37:27] d2.utils.events INFO: eta: 17:43:57  iter: 53399  total_loss: 0.708  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/26 23:38:27] d2.utils.events INFO: eta: 17:42:50  iter: 53419  total_loss: 0.798  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 23:39:28] d2.utils.events INFO: eta: 17:41:45  iter: 53439  total_loss: 0.725  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:40:28] d2.utils.events INFO: eta: 17:40:39  iter: 53459  total_loss: 0.828  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/26 23:41:28] d2.utils.events INFO: eta: 17:39:28  iter: 53479  total_loss: 0.538  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/26 23:42:29] d2.utils.events INFO: eta: 17:38:27  iter: 53499  total_loss: 0.609  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:43:30] d2.utils.events INFO: eta: 17:37:32  iter: 53519  total_loss: 0.718  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:44:30] d2.utils.events INFO: eta: 17:36:31  iter: 53539  total_loss: 0.377  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.107  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/26 23:45:30] d2.utils.events INFO: eta: 17:35:27  iter: 53559  total_loss: 0.575  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:46:31] d2.utils.events INFO: eta: 17:34:33  iter: 53579  total_loss: 0.675  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:47:31] d2.utils.events INFO: eta: 17:33:26  iter: 53599  total_loss: 0.493  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/26 23:48:31] d2.utils.events INFO: eta: 17:32:32  iter: 53619  total_loss: 0.574  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0312  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:49:31] d2.utils.events INFO: eta: 17:31:26  iter: 53639  total_loss: 0.663  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/26 23:50:32] d2.utils.events INFO: eta: 17:30:39  iter: 53659  total_loss: 0.599  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0312  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:51:33] d2.utils.events INFO: eta: 17:29:36  iter: 53679  total_loss: 0.579  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0312  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/26 23:52:32] d2.utils.events INFO: eta: 17:28:34  iter: 53699  total_loss: 0.625  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:53:33] d2.utils.events INFO: eta: 17:27:14  iter: 53719  total_loss: 0.757  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/26 23:54:34] d2.utils.events INFO: eta: 17:26:17  iter: 53739  total_loss: 0.582  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:55:33] d2.utils.events INFO: eta: 17:24:59  iter: 53759  total_loss: 0.413  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:56:36] d2.utils.events INFO: eta: 17:24:20  iter: 53779  total_loss: 0.742  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0312  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/26 23:57:35] d2.utils.events INFO: eta: 17:23:11  iter: 53799  total_loss: 0.615  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/26 23:58:36] d2.utils.events INFO: eta: 17:22:07  iter: 53819  total_loss: 0.584  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/26 23:59:37] d2.utils.events INFO: eta: 17:21:09  iter: 53839  total_loss: 0.821  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0312  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:00:38] d2.utils.events INFO: eta: 17:20:12  iter: 53859  total_loss: 0.661  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0312  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:01:38] d2.utils.events INFO: eta: 17:19:02  iter: 53879  total_loss: 0.689  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:02:38] d2.utils.events INFO: eta: 17:17:58  iter: 53899  total_loss: 0.482  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:03:39] d2.utils.events INFO: eta: 17:16:50  iter: 53919  total_loss: 0.799  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 00:04:41] d2.utils.events INFO: eta: 17:16:14  iter: 53939  total_loss: 0.565  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0312  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 00:05:41] d2.utils.events INFO: eta: 17:15:10  iter: 53959  total_loss: 0.576  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0312  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:06:42] d2.utils.events INFO: eta: 17:14:12  iter: 53979  total_loss: 0.431  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:07:42] d2.utils.events INFO: eta: 17:13:12  iter: 53999  total_loss: 0.594  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0310  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 00:08:43] d2.utils.events INFO: eta: 17:12:01  iter: 54019  total_loss: 0.755  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 00:09:44] d2.utils.events INFO: eta: 17:11:10  iter: 54039  total_loss: 0.584  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:10:44] d2.utils.events INFO: eta: 17:10:04  iter: 54059  total_loss: 0.666  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:11:43] d2.utils.events INFO: eta: 17:08:59  iter: 54079  total_loss: 0.820  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:12:43] d2.utils.events INFO: eta: 17:07:40  iter: 54099  total_loss: 0.475  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.077  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 00:13:44] d2.utils.events INFO: eta: 17:06:39  iter: 54119  total_loss: 0.579  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:14:45] d2.utils.events INFO: eta: 17:05:38  iter: 54139  total_loss: 0.487  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 00:15:44] d2.utils.events INFO: eta: 17:04:31  iter: 54159  total_loss: 0.630  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 00:16:43] d2.utils.events INFO: eta: 17:03:13  iter: 54179  total_loss: 0.723  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:17:44] d2.utils.events INFO: eta: 17:02:12  iter: 54199  total_loss: 0.492  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:18:44] d2.utils.events INFO: eta: 17:00:50  iter: 54219  total_loss: 0.537  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:19:44] d2.utils.events INFO: eta: 16:59:30  iter: 54239  total_loss: 0.530  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:20:44] d2.utils.events INFO: eta: 16:58:22  iter: 54259  total_loss: 0.801  loss_cls_stage0: 0.085  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:21:45] d2.utils.events INFO: eta: 16:58:01  iter: 54279  total_loss: 0.728  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:22:44] d2.utils.events INFO: eta: 16:55:46  iter: 54299  total_loss: 0.556  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 00:23:45] d2.utils.events INFO: eta: 16:55:02  iter: 54319  total_loss: 0.704  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/27 00:24:45] d2.utils.events INFO: eta: 16:53:29  iter: 54339  total_loss: 0.535  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 00:25:46] d2.utils.events INFO: eta: 16:52:47  iter: 54359  total_loss: 0.672  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:26:46] d2.utils.events INFO: eta: 16:51:46  iter: 54379  total_loss: 0.374  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 00:27:47] d2.utils.events INFO: eta: 16:51:24  iter: 54399  total_loss: 0.565  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:28:49] d2.utils.events INFO: eta: 16:50:42  iter: 54419  total_loss: 0.645  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 00:29:50] d2.utils.events INFO: eta: 16:50:00  iter: 54439  total_loss: 0.643  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 00:30:51] d2.utils.events INFO: eta: 16:49:13  iter: 54459  total_loss: 0.588  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:31:52] d2.utils.events INFO: eta: 16:48:24  iter: 54479  total_loss: 0.566  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:32:52] d2.utils.events INFO: eta: 16:47:05  iter: 54499  total_loss: 0.747  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:33:53] d2.utils.events INFO: eta: 16:46:11  iter: 54519  total_loss: 0.542  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:34:54] d2.utils.events INFO: eta: 16:45:36  iter: 54539  total_loss: 0.764  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:35:55] d2.utils.events INFO: eta: 16:44:38  iter: 54559  total_loss: 0.444  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 00:36:55] d2.utils.events INFO: eta: 16:43:34  iter: 54579  total_loss: 0.529  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 00:37:56] d2.utils.events INFO: eta: 16:42:39  iter: 54599  total_loss: 0.553  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:38:57] d2.utils.events INFO: eta: 16:41:38  iter: 54619  total_loss: 0.717  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:39:58] d2.utils.events INFO: eta: 16:40:34  iter: 54639  total_loss: 0.590  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:40:58] d2.utils.events INFO: eta: 16:39:20  iter: 54659  total_loss: 0.640  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0303  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 00:41:58] d2.utils.events INFO: eta: 16:38:15  iter: 54679  total_loss: 0.564  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 00:42:59] d2.utils.events INFO: eta: 16:37:27  iter: 54699  total_loss: 0.599  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:44:00] d2.utils.events INFO: eta: 16:36:18  iter: 54719  total_loss: 0.650  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:45:01] d2.utils.events INFO: eta: 16:35:17  iter: 54739  total_loss: 0.649  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 00:46:01] d2.utils.events INFO: eta: 16:34:20  iter: 54759  total_loss: 0.488  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:47:02] d2.utils.events INFO: eta: 16:31:58  iter: 54779  total_loss: 0.780  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:48:01] d2.utils.events INFO: eta: 16:30:57  iter: 54799  total_loss: 0.440  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.001  loss_rpn_loc: 0.001  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:48:59] d2.utils.events INFO: eta: 16:29:39  iter: 54819  total_loss: 0.507  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:50:01] d2.utils.events INFO: eta: 16:28:48  iter: 54839  total_loss: 0.717  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:51:01] d2.utils.events INFO: eta: 16:27:49  iter: 54859  total_loss: 0.699  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:52:04] d2.utils.events INFO: eta: 16:26:54  iter: 54879  total_loss: 0.593  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 00:53:05] d2.utils.events INFO: eta: 16:27:06  iter: 54899  total_loss: 0.584  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 00:54:05] d2.utils.events INFO: eta: 16:24:55  iter: 54919  total_loss: 0.658  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:55:04] d2.utils.events INFO: eta: 16:23:44  iter: 54939  total_loss: 0.695  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 00:56:06] d2.utils.events INFO: eta: 16:22:43  iter: 54959  total_loss: 0.568  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/27 00:57:08] d2.utils.events INFO: eta: 16:21:42  iter: 54979  total_loss: 0.477  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 00:58:08] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0054999.pth
[12/27 00:58:14] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/27 00:58:14] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/27 00:59:20] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4807 s / img. ETA=0:09:00
[12/27 00:59:44] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4806 s / img. ETA=0:08:36
[12/27 01:00:08] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4806 s / img. ETA=0:08:12
[12/27 01:00:32] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4806 s / img. ETA=0:07:48
[12/27 01:00:56] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4805 s / img. ETA=0:07:23
[12/27 01:01:20] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4803 s / img. ETA=0:06:59
[12/27 01:01:44] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4803 s / img. ETA=0:06:35
[12/27 01:02:08] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4803 s / img. ETA=0:06:11
[12/27 01:02:32] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4803 s / img. ETA=0:05:47
[12/27 01:02:56] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4804 s / img. ETA=0:05:23
[12/27 01:03:20] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4804 s / img. ETA=0:04:59
[12/27 01:03:44] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4804 s / img. ETA=0:04:35
[12/27 01:04:08] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4804 s / img. ETA=0:04:11
[12/27 01:04:32] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4804 s / img. ETA=0:03:47
[12/27 01:04:56] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4804 s / img. ETA=0:03:23
[12/27 01:05:20] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4804 s / img. ETA=0:02:59
[12/27 01:05:44] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4805 s / img. ETA=0:02:35
[12/27 01:06:09] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4808 s / img. ETA=0:02:11
[12/27 01:06:33] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4809 s / img. ETA=0:01:47
[12/27 01:06:57] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4809 s / img. ETA=0:01:23
[12/27 01:07:21] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4809 s / img. ETA=0:00:59
[12/27 01:07:45] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4809 s / img. ETA=0:00:35
[12/27 01:08:09] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4809 s / img. ETA=0:00:11
[12/27 01:08:21] d2.evaluation.evaluator INFO: Total inference time: 0:09:22 (0.480753 s / img per device, on 2 devices)
[12/27 01:08:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:18 (0.477844 s / img per device, on 2 devices)
[12/27 01:08:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/27 01:08:21] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/27 01:08:21] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/27 01:08:26] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 50.504 | 72.051 | 56.297 | 23.665 | 43.449 | 51.799 |
[12/27 01:08:26] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 54.265 | ASC-US     | 49.922 | HSIL        | 66.159 |
| LSIL       | 63.916 | Candida    | 48.037 | Trichomonas | 20.727 |
[12/27 01:08:26] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/27 01:08:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/27 01:08:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/27 01:08:26] d2.evaluation.testing INFO: copypaste: 50.5043,72.0506,56.2973,23.6655,43.4488,51.7990
[12/27 01:08:26] d2.utils.events INFO: eta: 16:20:42  iter: 54999  total_loss: 0.643  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:09:27] d2.utils.events INFO: eta: 16:19:44  iter: 55019  total_loss: 0.597  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 01:10:28] d2.utils.events INFO: eta: 16:18:45  iter: 55039  total_loss: 0.601  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:11:30] d2.utils.events INFO: eta: 16:19:03  iter: 55059  total_loss: 0.558  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 01:12:29] d2.utils.events INFO: eta: 16:17:24  iter: 55079  total_loss: 0.731  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 01:13:31] d2.utils.events INFO: eta: 16:17:06  iter: 55099  total_loss: 0.675  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:14:30] d2.utils.events INFO: eta: 16:16:02  iter: 55119  total_loss: 0.555  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:15:30] d2.utils.events INFO: eta: 16:13:47  iter: 55139  total_loss: 0.339  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.001  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:16:29] d2.utils.events INFO: eta: 16:12:47  iter: 55159  total_loss: 0.463  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.108  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:17:31] d2.utils.events INFO: eta: 16:13:00  iter: 55179  total_loss: 0.664  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:18:32] d2.utils.events INFO: eta: 16:11:59  iter: 55199  total_loss: 0.613  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:19:30] d2.utils.events INFO: eta: 16:09:40  iter: 55219  total_loss: 0.476  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 01:20:32] d2.utils.events INFO: eta: 16:08:42  iter: 55239  total_loss: 0.577  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:21:32] d2.utils.events INFO: eta: 16:07:39  iter: 55259  total_loss: 0.381  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:22:32] d2.utils.events INFO: eta: 16:06:34  iter: 55279  total_loss: 0.556  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:23:33] d2.utils.events INFO: eta: 16:05:47  iter: 55299  total_loss: 0.642  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 01:24:34] d2.utils.events INFO: eta: 16:04:43  iter: 55319  total_loss: 0.746  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 01:25:35] d2.utils.events INFO: eta: 16:04:57  iter: 55339  total_loss: 0.598  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 01:26:35] d2.utils.events INFO: eta: 16:02:45  iter: 55359  total_loss: 0.487  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 01:27:36] d2.utils.events INFO: eta: 16:02:51  iter: 55379  total_loss: 0.680  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 01:28:36] d2.utils.events INFO: eta: 16:01:42  iter: 55399  total_loss: 0.503  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:29:36] d2.utils.events INFO: eta: 15:59:39  iter: 55419  total_loss: 0.527  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 01:30:38] d2.utils.events INFO: eta: 15:59:08  iter: 55439  total_loss: 0.727  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:31:39] d2.utils.events INFO: eta: 15:57:37  iter: 55459  total_loss: 0.827  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.095  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.101  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:32:38] d2.utils.events INFO: eta: 15:56:33  iter: 55479  total_loss: 0.703  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 01:33:39] d2.utils.events INFO: eta: 15:56:06  iter: 55499  total_loss: 0.451  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.109  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:34:38] d2.utils.events INFO: eta: 15:54:30  iter: 55519  total_loss: 0.519  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:35:39] d2.utils.events INFO: eta: 15:53:08  iter: 55539  total_loss: 0.590  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 01:36:39] d2.utils.events INFO: eta: 15:52:00  iter: 55559  total_loss: 0.583  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:37:41] d2.utils.events INFO: eta: 15:51:22  iter: 55579  total_loss: 0.619  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:38:42] d2.utils.events INFO: eta: 15:50:19  iter: 55599  total_loss: 0.594  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:39:43] d2.utils.events INFO: eta: 15:49:20  iter: 55619  total_loss: 0.707  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 01:40:44] d2.utils.events INFO: eta: 15:48:23  iter: 55639  total_loss: 0.556  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/27 01:41:45] d2.utils.events INFO: eta: 15:47:30  iter: 55659  total_loss: 0.604  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:42:47] d2.utils.events INFO: eta: 15:46:48  iter: 55679  total_loss: 0.764  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:43:48] d2.utils.events INFO: eta: 15:45:47  iter: 55699  total_loss: 0.595  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 01:44:48] d2.utils.events INFO: eta: 15:45:19  iter: 55719  total_loss: 0.640  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:45:49] d2.utils.events INFO: eta: 15:44:27  iter: 55739  total_loss: 0.737  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 01:46:49] d2.utils.events INFO: eta: 15:43:37  iter: 55759  total_loss: 0.674  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:47:50] d2.utils.events INFO: eta: 15:42:41  iter: 55779  total_loss: 0.495  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 01:48:52] d2.utils.events INFO: eta: 15:41:55  iter: 55799  total_loss: 0.578  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/27 01:49:52] d2.utils.events INFO: eta: 15:40:59  iter: 55819  total_loss: 0.722  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:50:53] d2.utils.events INFO: eta: 15:39:58  iter: 55839  total_loss: 0.356  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 01:51:54] d2.utils.events INFO: eta: 15:38:55  iter: 55859  total_loss: 0.583  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 01:52:55] d2.utils.events INFO: eta: 15:37:51  iter: 55879  total_loss: 0.663  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 01:53:56] d2.utils.events INFO: eta: 15:36:39  iter: 55899  total_loss: 0.749  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 01:54:56] d2.utils.events INFO: eta: 15:35:45  iter: 55919  total_loss: 0.680  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 01:55:58] d2.utils.events INFO: eta: 15:34:48  iter: 55939  total_loss: 0.479  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0401  lr: 0.000100  max_mem: 9404M
[12/27 01:57:01] d2.utils.events INFO: eta: 15:33:53  iter: 55959  total_loss: 0.493  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 01:58:02] d2.utils.events INFO: eta: 15:32:52  iter: 55979  total_loss: 0.507  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 01:59:02] d2.utils.events INFO: eta: 15:31:51  iter: 55999  total_loss: 0.620  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:00:02] d2.utils.events INFO: eta: 15:30:45  iter: 56019  total_loss: 0.591  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:01:02] d2.utils.events INFO: eta: 15:29:44  iter: 56039  total_loss: 0.606  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:02:04] d2.utils.events INFO: eta: 15:28:45  iter: 56059  total_loss: 0.610  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:03:04] d2.utils.events INFO: eta: 15:27:47  iter: 56079  total_loss: 0.614  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:04:03] d2.utils.events INFO: eta: 15:26:44  iter: 56099  total_loss: 0.532  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 02:05:02] d2.utils.events INFO: eta: 15:25:38  iter: 56119  total_loss: 0.508  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:06:03] d2.utils.events INFO: eta: 15:24:42  iter: 56139  total_loss: 0.688  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 02:07:03] d2.utils.events INFO: eta: 15:23:39  iter: 56159  total_loss: 0.676  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:08:04] d2.utils.events INFO: eta: 15:22:38  iter: 56179  total_loss: 0.573  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:09:04] d2.utils.events INFO: eta: 15:21:35  iter: 56199  total_loss: 0.628  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:10:05] d2.utils.events INFO: eta: 15:20:42  iter: 56219  total_loss: 0.631  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:11:05] d2.utils.events INFO: eta: 15:19:38  iter: 56239  total_loss: 0.534  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:12:06] d2.utils.events INFO: eta: 15:18:40  iter: 56259  total_loss: 0.458  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:13:06] d2.utils.events INFO: eta: 15:17:39  iter: 56279  total_loss: 0.536  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:14:05] d2.utils.events INFO: eta: 15:16:28  iter: 56299  total_loss: 0.540  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:15:06] d2.utils.events INFO: eta: 15:15:32  iter: 56319  total_loss: 0.594  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:16:06] d2.utils.events INFO: eta: 15:14:21  iter: 56339  total_loss: 0.461  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:17:07] d2.utils.events INFO: eta: 15:13:31  iter: 56359  total_loss: 0.547  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:18:06] d2.utils.events INFO: eta: 15:12:25  iter: 56379  total_loss: 0.594  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:19:07] d2.utils.events INFO: eta: 15:11:15  iter: 56399  total_loss: 0.570  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:20:07] d2.utils.events INFO: eta: 15:10:14  iter: 56419  total_loss: 0.426  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:21:08] d2.utils.events INFO: eta: 15:09:10  iter: 56439  total_loss: 0.592  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:22:08] d2.utils.events INFO: eta: 15:08:15  iter: 56459  total_loss: 0.554  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 02:23:10] d2.utils.events INFO: eta: 15:07:14  iter: 56479  total_loss: 0.981  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:24:11] d2.utils.events INFO: eta: 15:06:11  iter: 56499  total_loss: 0.742  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:25:12] d2.utils.events INFO: eta: 15:05:05  iter: 56519  total_loss: 0.607  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:26:11] d2.utils.events INFO: eta: 15:04:03  iter: 56539  total_loss: 0.802  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0299  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:27:11] d2.utils.events INFO: eta: 15:03:02  iter: 56559  total_loss: 0.498  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:28:13] d2.utils.events INFO: eta: 15:01:56  iter: 56579  total_loss: 0.758  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:29:15] d2.utils.events INFO: eta: 15:01:06  iter: 56599  total_loss: 0.659  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 02:30:15] d2.utils.events INFO: eta: 14:59:55  iter: 56619  total_loss: 0.689  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:31:15] d2.utils.events INFO: eta: 14:58:46  iter: 56639  total_loss: 0.489  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 02:32:15] d2.utils.events INFO: eta: 14:57:33  iter: 56659  total_loss: 0.615  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:33:18] d2.utils.events INFO: eta: 14:56:17  iter: 56679  total_loss: 0.699  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:34:18] d2.utils.events INFO: eta: 14:54:55  iter: 56699  total_loss: 0.632  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:35:20] d2.utils.events INFO: eta: 14:54:08  iter: 56719  total_loss: 0.691  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:36:22] d2.utils.events INFO: eta: 14:53:30  iter: 56739  total_loss: 0.591  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:37:22] d2.utils.events INFO: eta: 14:52:24  iter: 56759  total_loss: 0.985  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.092  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:38:22] d2.utils.events INFO: eta: 14:50:55  iter: 56779  total_loss: 0.987  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:39:22] d2.utils.events INFO: eta: 14:49:26  iter: 56799  total_loss: 0.693  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:40:21] d2.utils.events INFO: eta: 14:48:05  iter: 56819  total_loss: 0.460  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.128  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 02:41:21] d2.utils.events INFO: eta: 14:46:53  iter: 56839  total_loss: 0.608  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:42:21] d2.utils.events INFO: eta: 14:45:55  iter: 56859  total_loss: 0.566  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:43:21] d2.utils.events INFO: eta: 14:44:52  iter: 56879  total_loss: 0.721  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 02:44:22] d2.utils.events INFO: eta: 14:43:42  iter: 56899  total_loss: 0.599  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 02:45:23] d2.utils.events INFO: eta: 14:42:56  iter: 56919  total_loss: 0.479  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0035  lr: 0.000100  max_mem: 9404M
[12/27 02:46:24] d2.utils.events INFO: eta: 14:42:00  iter: 56939  total_loss: 0.588  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 02:47:24] d2.utils.events INFO: eta: 14:40:33  iter: 56959  total_loss: 0.598  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 02:48:25] d2.utils.events INFO: eta: 14:39:27  iter: 56979  total_loss: 0.553  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 02:49:25] d2.utils.events INFO: eta: 14:38:26  iter: 56999  total_loss: 0.838  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.108  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0299  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 02:50:26] d2.utils.events INFO: eta: 14:37:28  iter: 57019  total_loss: 0.813  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0037  lr: 0.000100  max_mem: 9404M
[12/27 02:51:27] d2.utils.events INFO: eta: 14:36:27  iter: 57039  total_loss: 0.704  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 02:52:28] d2.utils.events INFO: eta: 14:35:11  iter: 57059  total_loss: 0.696  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 02:53:31] d2.utils.events INFO: eta: 14:34:32  iter: 57079  total_loss: 0.448  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 02:54:32] d2.utils.events INFO: eta: 14:33:41  iter: 57099  total_loss: 0.701  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 02:55:32] d2.utils.events INFO: eta: 14:32:56  iter: 57119  total_loss: 0.746  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:56:35] d2.utils.events INFO: eta: 14:31:55  iter: 57139  total_loss: 0.649  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:57:37] d2.utils.events INFO: eta: 14:31:40  iter: 57159  total_loss: 0.702  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 02:58:37] d2.utils.events INFO: eta: 14:30:28  iter: 57179  total_loss: 0.505  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 02:59:38] d2.utils.events INFO: eta: 14:29:19  iter: 57199  total_loss: 0.565  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:00:38] d2.utils.events INFO: eta: 14:28:15  iter: 57219  total_loss: 0.478  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:01:39] d2.utils.events INFO: eta: 14:27:14  iter: 57239  total_loss: 0.609  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:02:39] d2.utils.events INFO: eta: 14:26:13  iter: 57259  total_loss: 0.543  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:03:39] d2.utils.events INFO: eta: 14:25:12  iter: 57279  total_loss: 0.781  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:04:41] d2.utils.events INFO: eta: 14:25:18  iter: 57299  total_loss: 0.929  loss_cls_stage0: 0.078  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:05:40] d2.utils.events INFO: eta: 14:23:34  iter: 57319  total_loss: 0.487  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:06:41] d2.utils.events INFO: eta: 14:22:49  iter: 57339  total_loss: 0.531  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:07:41] d2.utils.events INFO: eta: 14:21:58  iter: 57359  total_loss: 0.721  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 03:08:40] d2.utils.events INFO: eta: 14:20:48  iter: 57379  total_loss: 0.562  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:09:38] d2.utils.events INFO: eta: 14:19:31  iter: 57399  total_loss: 0.518  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0299  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:10:40] d2.utils.events INFO: eta: 14:19:18  iter: 57419  total_loss: 0.790  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:11:41] d2.utils.events INFO: eta: 14:18:02  iter: 57439  total_loss: 0.701  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:12:42] d2.utils.events INFO: eta: 14:17:01  iter: 57459  total_loss: 0.795  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 03:13:41] d2.utils.events INFO: eta: 14:15:44  iter: 57479  total_loss: 0.409  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 03:14:42] d2.utils.events INFO: eta: 14:14:59  iter: 57499  total_loss: 0.707  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 03:15:43] d2.utils.events INFO: eta: 14:14:23  iter: 57519  total_loss: 0.516  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.005  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:16:44] d2.utils.events INFO: eta: 14:13:37  iter: 57539  total_loss: 0.782  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:17:46] d2.utils.events INFO: eta: 14:12:44  iter: 57559  total_loss: 0.709  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 03:18:47] d2.utils.events INFO: eta: 14:11:38  iter: 57579  total_loss: 0.519  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:19:47] d2.utils.events INFO: eta: 14:10:37  iter: 57599  total_loss: 0.701  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 03:20:46] d2.utils.events INFO: eta: 14:09:40  iter: 57619  total_loss: 0.764  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.010  loss_rpn_loc: 0.007  time: 3.0300  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 03:21:46] d2.utils.events INFO: eta: 14:08:38  iter: 57639  total_loss: 0.590  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 03:22:46] d2.utils.events INFO: eta: 14:07:37  iter: 57659  total_loss: 0.607  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 03:23:47] d2.utils.events INFO: eta: 14:06:34  iter: 57679  total_loss: 0.516  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0299  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 03:24:47] d2.utils.events INFO: eta: 14:05:37  iter: 57699  total_loss: 0.477  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:25:49] d2.utils.events INFO: eta: 14:04:42  iter: 57719  total_loss: 0.709  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:26:49] d2.utils.events INFO: eta: 14:03:38  iter: 57739  total_loss: 0.446  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:27:49] d2.utils.events INFO: eta: 14:02:33  iter: 57759  total_loss: 0.563  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:28:50] d2.utils.events INFO: eta: 14:01:37  iter: 57779  total_loss: 0.604  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 03:29:52] d2.utils.events INFO: eta: 14:00:45  iter: 57799  total_loss: 0.617  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 03:30:53] d2.utils.events INFO: eta: 13:59:49  iter: 57819  total_loss: 0.773  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 03:31:54] d2.utils.events INFO: eta: 13:58:48  iter: 57839  total_loss: 0.646  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:32:54] d2.utils.events INFO: eta: 13:57:44  iter: 57859  total_loss: 0.534  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:33:53] d2.utils.events INFO: eta: 13:56:41  iter: 57879  total_loss: 0.579  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:34:53] d2.utils.events INFO: eta: 13:55:42  iter: 57899  total_loss: 0.593  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 03:35:55] d2.utils.events INFO: eta: 13:54:37  iter: 57919  total_loss: 0.711  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:36:54] d2.utils.events INFO: eta: 13:53:27  iter: 57939  total_loss: 0.556  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 03:37:56] d2.utils.events INFO: eta: 13:52:33  iter: 57959  total_loss: 0.684  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:38:55] d2.utils.events INFO: eta: 13:51:31  iter: 57979  total_loss: 0.429  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0298  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 03:39:56] d2.utils.events INFO: eta: 13:50:34  iter: 57999  total_loss: 0.432  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:40:58] d2.utils.events INFO: eta: 13:49:37  iter: 58019  total_loss: 0.715  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 03:41:58] d2.utils.events INFO: eta: 13:48:35  iter: 58039  total_loss: 0.623  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:42:57] d2.utils.events INFO: eta: 13:47:28  iter: 58059  total_loss: 0.623  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 03:43:57] d2.utils.events INFO: eta: 13:46:14  iter: 58079  total_loss: 0.520  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:44:58] d2.utils.events INFO: eta: 13:45:13  iter: 58099  total_loss: 0.528  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:45:59] d2.utils.events INFO: eta: 13:44:12  iter: 58119  total_loss: 0.654  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:47:00] d2.utils.events INFO: eta: 13:43:12  iter: 58139  total_loss: 0.930  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0298  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:48:01] d2.utils.events INFO: eta: 13:42:10  iter: 58159  total_loss: 0.719  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:49:02] d2.utils.events INFO: eta: 13:41:09  iter: 58179  total_loss: 0.642  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:50:02] d2.utils.events INFO: eta: 13:40:08  iter: 58199  total_loss: 0.569  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0298  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 03:51:03] d2.utils.events INFO: eta: 13:39:09  iter: 58219  total_loss: 0.529  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 03:52:03] d2.utils.events INFO: eta: 13:38:12  iter: 58239  total_loss: 0.500  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 03:53:04] d2.utils.events INFO: eta: 13:37:06  iter: 58259  total_loss: 0.650  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 03:54:04] d2.utils.events INFO: eta: 13:36:05  iter: 58279  total_loss: 0.603  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0297  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:55:05] d2.utils.events INFO: eta: 13:34:49  iter: 58299  total_loss: 0.750  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 03:56:08] d2.utils.events INFO: eta: 13:34:07  iter: 58319  total_loss: 0.746  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 03:57:09] d2.utils.events INFO: eta: 13:33:06  iter: 58339  total_loss: 0.844  loss_cls_stage0: 0.077  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 03:58:10] d2.utils.events INFO: eta: 13:31:55  iter: 58359  total_loss: 0.621  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 03:59:12] d2.utils.events INFO: eta: 13:31:00  iter: 58379  total_loss: 0.591  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 04:00:12] d2.utils.events INFO: eta: 13:30:00  iter: 58399  total_loss: 0.502  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 04:01:13] d2.utils.events INFO: eta: 13:28:56  iter: 58419  total_loss: 0.677  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:02:15] d2.utils.events INFO: eta: 13:27:59  iter: 58439  total_loss: 0.750  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:03:17] d2.utils.events INFO: eta: 13:27:01  iter: 58459  total_loss: 0.514  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:04:17] d2.utils.events INFO: eta: 13:26:09  iter: 58479  total_loss: 0.521  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:05:17] d2.utils.events INFO: eta: 13:24:59  iter: 58499  total_loss: 0.679  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:06:18] d2.utils.events INFO: eta: 13:23:49  iter: 58519  total_loss: 0.982  loss_cls_stage0: 0.086  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.093  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:07:20] d2.utils.events INFO: eta: 13:22:48  iter: 58539  total_loss: 0.780  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 04:08:21] d2.utils.events INFO: eta: 13:21:38  iter: 58559  total_loss: 0.583  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 04:09:22] d2.utils.events INFO: eta: 13:20:36  iter: 58579  total_loss: 0.492  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 04:10:21] d2.utils.events INFO: eta: 13:19:28  iter: 58599  total_loss: 0.542  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:11:22] d2.utils.events INFO: eta: 13:18:27  iter: 58619  total_loss: 0.669  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:12:24] d2.utils.events INFO: eta: 13:17:34  iter: 58639  total_loss: 0.559  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:13:25] d2.utils.events INFO: eta: 13:16:34  iter: 58659  total_loss: 0.559  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:14:25] d2.utils.events INFO: eta: 13:15:32  iter: 58679  total_loss: 0.816  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:15:27] d2.utils.events INFO: eta: 13:14:34  iter: 58699  total_loss: 0.654  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 04:16:28] d2.utils.events INFO: eta: 13:13:28  iter: 58719  total_loss: 0.490  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/27 04:17:28] d2.utils.events INFO: eta: 13:12:27  iter: 58739  total_loss: 0.621  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 04:18:28] d2.utils.events INFO: eta: 13:11:28  iter: 58759  total_loss: 0.397  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:19:28] d2.utils.events INFO: eta: 13:10:28  iter: 58779  total_loss: 0.607  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 04:20:30] d2.utils.events INFO: eta: 13:09:27  iter: 58799  total_loss: 0.549  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0035  lr: 0.000100  max_mem: 9404M
[12/27 04:21:31] d2.utils.events INFO: eta: 13:08:27  iter: 58819  total_loss: 0.629  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:22:31] d2.utils.events INFO: eta: 13:07:26  iter: 58839  total_loss: 0.622  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:23:31] d2.utils.events INFO: eta: 13:06:25  iter: 58859  total_loss: 0.611  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 04:24:31] d2.utils.events INFO: eta: 13:05:32  iter: 58879  total_loss: 0.473  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:25:31] d2.utils.events INFO: eta: 13:04:29  iter: 58899  total_loss: 0.439  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:26:31] d2.utils.events INFO: eta: 13:03:23  iter: 58919  total_loss: 0.515  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 04:27:33] d2.utils.events INFO: eta: 13:02:33  iter: 58939  total_loss: 0.755  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 04:28:34] d2.utils.events INFO: eta: 13:01:32  iter: 58959  total_loss: 0.433  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:29:34] d2.utils.events INFO: eta: 13:00:29  iter: 58979  total_loss: 0.445  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.005  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 04:30:35] d2.utils.events INFO: eta: 12:59:24  iter: 58999  total_loss: 0.602  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 04:31:38] d2.utils.events INFO: eta: 12:58:27  iter: 59019  total_loss: 0.608  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:32:39] d2.utils.events INFO: eta: 12:57:28  iter: 59039  total_loss: 0.612  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:33:39] d2.utils.events INFO: eta: 12:56:28  iter: 59059  total_loss: 0.585  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:34:39] d2.utils.events INFO: eta: 12:55:27  iter: 59079  total_loss: 0.580  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:35:40] d2.utils.events INFO: eta: 12:54:25  iter: 59099  total_loss: 0.676  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 04:36:42] d2.utils.events INFO: eta: 12:53:25  iter: 59119  total_loss: 0.575  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 04:37:43] d2.utils.events INFO: eta: 12:52:22  iter: 59139  total_loss: 0.915  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.105  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 04:38:44] d2.utils.events INFO: eta: 12:51:20  iter: 59159  total_loss: 0.776  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:39:45] d2.utils.events INFO: eta: 12:50:20  iter: 59179  total_loss: 0.656  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:40:45] d2.utils.events INFO: eta: 12:49:21  iter: 59199  total_loss: 0.507  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 04:41:46] d2.utils.events INFO: eta: 12:48:21  iter: 59219  total_loss: 0.557  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:42:47] d2.utils.events INFO: eta: 12:47:22  iter: 59239  total_loss: 0.546  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.095  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/27 04:43:48] d2.utils.events INFO: eta: 12:46:26  iter: 59259  total_loss: 0.446  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:44:49] d2.utils.events INFO: eta: 12:45:30  iter: 59279  total_loss: 0.510  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:45:50] d2.utils.events INFO: eta: 12:44:36  iter: 59299  total_loss: 0.888  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 04:46:51] d2.utils.events INFO: eta: 12:43:28  iter: 59319  total_loss: 0.471  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 04:47:49] d2.utils.events INFO: eta: 12:42:20  iter: 59339  total_loss: 0.564  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:48:50] d2.utils.events INFO: eta: 12:41:26  iter: 59359  total_loss: 0.665  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:49:52] d2.utils.events INFO: eta: 12:40:27  iter: 59379  total_loss: 0.682  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 04:50:53] d2.utils.events INFO: eta: 12:39:31  iter: 59399  total_loss: 0.665  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 04:51:54] d2.utils.events INFO: eta: 12:38:32  iter: 59419  total_loss: 0.641  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:52:54] d2.utils.events INFO: eta: 12:37:24  iter: 59439  total_loss: 0.588  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0308  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:53:54] d2.utils.events INFO: eta: 12:36:18  iter: 59459  total_loss: 0.696  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 04:54:54] d2.utils.events INFO: eta: 12:35:17  iter: 59479  total_loss: 0.640  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 04:55:56] d2.utils.events INFO: eta: 12:34:19  iter: 59499  total_loss: 0.569  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 04:56:56] d2.utils.events INFO: eta: 12:33:19  iter: 59519  total_loss: 0.671  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 04:57:55] d2.utils.events INFO: eta: 12:32:07  iter: 59539  total_loss: 0.390  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 04:58:55] d2.utils.events INFO: eta: 12:31:05  iter: 59559  total_loss: 0.727  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 04:59:56] d2.utils.events INFO: eta: 12:30:07  iter: 59579  total_loss: 0.505  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:00:58] d2.utils.events INFO: eta: 12:29:11  iter: 59599  total_loss: 0.559  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:01:59] d2.utils.events INFO: eta: 12:28:14  iter: 59619  total_loss: 0.716  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0308  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 05:03:00] d2.utils.events INFO: eta: 12:27:04  iter: 59639  total_loss: 0.617  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 05:03:59] d2.utils.events INFO: eta: 12:26:02  iter: 59659  total_loss: 0.523  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 05:04:58] d2.utils.events INFO: eta: 12:25:03  iter: 59679  total_loss: 0.598  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 05:05:59] d2.utils.events INFO: eta: 12:23:55  iter: 59699  total_loss: 0.523  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:07:00] d2.utils.events INFO: eta: 12:22:55  iter: 59719  total_loss: 0.631  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:08:00] d2.utils.events INFO: eta: 12:21:57  iter: 59739  total_loss: 0.562  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:09:00] d2.utils.events INFO: eta: 12:20:58  iter: 59759  total_loss: 0.572  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:09:59] d2.utils.events INFO: eta: 12:19:48  iter: 59779  total_loss: 0.604  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:11:00] d2.utils.events INFO: eta: 12:18:46  iter: 59799  total_loss: 0.432  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.080  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:12:01] d2.utils.events INFO: eta: 12:17:38  iter: 59819  total_loss: 0.707  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 05:13:01] d2.utils.events INFO: eta: 12:16:33  iter: 59839  total_loss: 0.645  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:14:02] d2.utils.events INFO: eta: 12:15:40  iter: 59859  total_loss: 0.660  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:15:02] d2.utils.events INFO: eta: 12:14:31  iter: 59879  total_loss: 0.772  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 05:16:04] d2.utils.events INFO: eta: 12:13:42  iter: 59899  total_loss: 0.526  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:17:05] d2.utils.events INFO: eta: 12:12:39  iter: 59919  total_loss: 0.516  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 05:18:05] d2.utils.events INFO: eta: 12:11:31  iter: 59939  total_loss: 0.580  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 05:19:05] d2.utils.events INFO: eta: 12:10:28  iter: 59959  total_loss: 0.747  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 05:20:07] d2.utils.events INFO: eta: 12:09:40  iter: 59979  total_loss: 0.541  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 05:21:07] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0059999.pth
[12/27 05:21:14] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/27 05:21:14] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/27 05:22:20] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4803 s / img. ETA=0:08:59
[12/27 05:22:44] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4799 s / img. ETA=0:08:35
[12/27 05:23:08] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4798 s / img. ETA=0:08:11
[12/27 05:23:32] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4799 s / img. ETA=0:07:47
[12/27 05:23:56] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4800 s / img. ETA=0:07:23
[12/27 05:24:20] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4801 s / img. ETA=0:06:59
[12/27 05:24:44] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4801 s / img. ETA=0:06:35
[12/27 05:25:08] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4802 s / img. ETA=0:06:11
[12/27 05:25:32] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4802 s / img. ETA=0:05:47
[12/27 05:25:56] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4802 s / img. ETA=0:05:23
[12/27 05:26:20] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4802 s / img. ETA=0:04:59
[12/27 05:26:44] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4802 s / img. ETA=0:04:35
[12/27 05:27:08] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4802 s / img. ETA=0:04:11
[12/27 05:27:32] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4801 s / img. ETA=0:03:47
[12/27 05:27:56] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4802 s / img. ETA=0:03:23
[12/27 05:28:20] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4803 s / img. ETA=0:02:59
[12/27 05:28:44] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4804 s / img. ETA=0:02:35
[12/27 05:29:08] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4804 s / img. ETA=0:02:11
[12/27 05:29:32] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4806 s / img. ETA=0:01:47
[12/27 05:29:56] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4806 s / img. ETA=0:01:23
[12/27 05:30:21] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4806 s / img. ETA=0:00:59
[12/27 05:30:45] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4807 s / img. ETA=0:00:35
[12/27 05:31:09] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4808 s / img. ETA=0:00:11
[12/27 05:31:21] d2.evaluation.evaluator INFO: Total inference time: 0:09:22 (0.480753 s / img per device, on 2 devices)
[12/27 05:31:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:18 (0.477680 s / img per device, on 2 devices)
[12/27 05:31:21] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/27 05:31:21] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/27 05:31:21] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/27 05:31:25] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.855 | 70.796 | 55.668 | 25.350 | 42.801 | 51.292 |
[12/27 05:31:25] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 53.900 | ASC-US     | 48.976 | HSIL        | 65.226 |
| LSIL       | 63.490 | Candida    | 47.353 | Trichomonas | 20.185 |
[12/27 05:31:25] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/27 05:31:25] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/27 05:31:25] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/27 05:31:25] d2.evaluation.testing INFO: copypaste: 49.8550,70.7955,55.6685,25.3502,42.8013,51.2916
[12/27 05:31:25] d2.utils.events INFO: eta: 12:08:38  iter: 59999  total_loss: 0.759  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:32:26] d2.utils.events INFO: eta: 12:07:24  iter: 60019  total_loss: 0.441  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:33:27] d2.utils.events INFO: eta: 12:06:29  iter: 60039  total_loss: 0.794  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:34:28] d2.utils.events INFO: eta: 12:05:34  iter: 60059  total_loss: 0.584  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:35:30] d2.utils.events INFO: eta: 12:04:52  iter: 60079  total_loss: 0.723  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:36:30] d2.utils.events INFO: eta: 12:03:53  iter: 60099  total_loss: 0.759  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 05:37:30] d2.utils.events INFO: eta: 12:02:44  iter: 60119  total_loss: 0.586  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:38:31] d2.utils.events INFO: eta: 12:01:36  iter: 60139  total_loss: 0.642  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:39:33] d2.utils.events INFO: eta: 12:00:48  iter: 60159  total_loss: 0.485  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 05:40:33] d2.utils.events INFO: eta: 11:59:47  iter: 60179  total_loss: 0.632  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 05:41:34] d2.utils.events INFO: eta: 11:58:47  iter: 60199  total_loss: 0.582  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:42:35] d2.utils.events INFO: eta: 11:57:47  iter: 60219  total_loss: 0.754  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.095  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 05:43:35] d2.utils.events INFO: eta: 11:56:33  iter: 60239  total_loss: 0.701  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 05:44:34] d2.utils.events INFO: eta: 11:55:23  iter: 60259  total_loss: 0.446  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 05:45:35] d2.utils.events INFO: eta: 11:54:19  iter: 60279  total_loss: 0.611  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:46:37] d2.utils.events INFO: eta: 11:53:11  iter: 60299  total_loss: 0.558  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 05:47:36] d2.utils.events INFO: eta: 11:52:17  iter: 60319  total_loss: 0.693  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 05:48:38] d2.utils.events INFO: eta: 11:51:23  iter: 60339  total_loss: 0.634  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:49:37] d2.utils.events INFO: eta: 11:50:14  iter: 60359  total_loss: 0.604  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 05:50:39] d2.utils.events INFO: eta: 11:49:18  iter: 60379  total_loss: 0.657  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 05:51:42] d2.utils.events INFO: eta: 11:48:21  iter: 60399  total_loss: 0.571  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 05:52:42] d2.utils.events INFO: eta: 11:47:15  iter: 60419  total_loss: 0.738  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 05:53:43] d2.utils.events INFO: eta: 11:46:14  iter: 60439  total_loss: 0.512  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 05:54:44] d2.utils.events INFO: eta: 11:45:24  iter: 60459  total_loss: 0.686  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 05:55:47] d2.utils.events INFO: eta: 11:44:35  iter: 60479  total_loss: 0.694  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0309  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 05:56:48] d2.utils.events INFO: eta: 11:43:35  iter: 60499  total_loss: 0.596  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 05:57:48] d2.utils.events INFO: eta: 11:42:35  iter: 60519  total_loss: 0.549  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 05:58:49] d2.utils.events INFO: eta: 11:41:40  iter: 60539  total_loss: 0.699  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 05:59:49] d2.utils.events INFO: eta: 11:40:40  iter: 60559  total_loss: 0.855  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 06:00:49] d2.utils.events INFO: eta: 11:39:39  iter: 60579  total_loss: 0.551  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:01:49] d2.utils.events INFO: eta: 11:38:38  iter: 60599  total_loss: 0.718  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0308  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 06:02:50] d2.utils.events INFO: eta: 11:37:36  iter: 60619  total_loss: 0.629  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:03:52] d2.utils.events INFO: eta: 11:36:36  iter: 60639  total_loss: 0.591  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 06:04:53] d2.utils.events INFO: eta: 11:35:37  iter: 60659  total_loss: 0.700  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 06:05:52] d2.utils.events INFO: eta: 11:34:35  iter: 60679  total_loss: 0.590  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 06:06:52] d2.utils.events INFO: eta: 11:33:36  iter: 60699  total_loss: 0.637  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:07:51] d2.utils.events INFO: eta: 11:32:32  iter: 60719  total_loss: 0.373  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.082  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:08:52] d2.utils.events INFO: eta: 11:31:32  iter: 60739  total_loss: 0.578  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:09:53] d2.utils.events INFO: eta: 11:30:30  iter: 60759  total_loss: 0.507  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 06:10:53] d2.utils.events INFO: eta: 11:29:30  iter: 60779  total_loss: 0.684  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 06:11:53] d2.utils.events INFO: eta: 11:28:29  iter: 60799  total_loss: 0.387  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:12:53] d2.utils.events INFO: eta: 11:27:27  iter: 60819  total_loss: 0.797  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:13:54] d2.utils.events INFO: eta: 11:26:27  iter: 60839  total_loss: 0.976  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 06:14:53] d2.utils.events INFO: eta: 11:25:22  iter: 60859  total_loss: 0.840  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.096  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.107  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:15:54] d2.utils.events INFO: eta: 11:24:21  iter: 60879  total_loss: 0.535  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 06:16:55] d2.utils.events INFO: eta: 11:23:11  iter: 60899  total_loss: 0.511  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:17:55] d2.utils.events INFO: eta: 11:22:16  iter: 60919  total_loss: 0.672  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:18:55] d2.utils.events INFO: eta: 11:21:15  iter: 60939  total_loss: 0.595  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 06:19:56] d2.utils.events INFO: eta: 11:20:14  iter: 60959  total_loss: 0.442  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:20:58] d2.utils.events INFO: eta: 11:19:14  iter: 60979  total_loss: 0.586  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:21:57] d2.utils.events INFO: eta: 11:17:52  iter: 60999  total_loss: 0.443  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:22:59] d2.utils.events INFO: eta: 11:17:07  iter: 61019  total_loss: 0.542  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:24:01] d2.utils.events INFO: eta: 11:16:06  iter: 61039  total_loss: 0.599  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:25:02] d2.utils.events INFO: eta: 11:14:54  iter: 61059  total_loss: 0.538  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 06:26:03] d2.utils.events INFO: eta: 11:13:47  iter: 61079  total_loss: 0.625  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:27:04] d2.utils.events INFO: eta: 11:12:47  iter: 61099  total_loss: 0.492  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:28:04] d2.utils.events INFO: eta: 11:11:46  iter: 61119  total_loss: 0.644  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:29:04] d2.utils.events INFO: eta: 11:10:45  iter: 61139  total_loss: 0.558  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 06:30:04] d2.utils.events INFO: eta: 11:09:41  iter: 61159  total_loss: 0.676  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:31:05] d2.utils.events INFO: eta: 11:08:40  iter: 61179  total_loss: 0.861  loss_cls_stage0: 0.077  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.097  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.095  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:32:06] d2.utils.events INFO: eta: 11:07:39  iter: 61199  total_loss: 0.645  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 06:33:07] d2.utils.events INFO: eta: 11:06:42  iter: 61219  total_loss: 0.660  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 06:34:06] d2.utils.events INFO: eta: 11:05:41  iter: 61239  total_loss: 0.276  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.022  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.048  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.090  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:35:07] d2.utils.events INFO: eta: 11:04:43  iter: 61259  total_loss: 0.571  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 06:36:06] d2.utils.events INFO: eta: 11:03:42  iter: 61279  total_loss: 0.531  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 06:37:07] d2.utils.events INFO: eta: 11:02:40  iter: 61299  total_loss: 0.510  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 06:38:09] d2.utils.events INFO: eta: 11:01:38  iter: 61319  total_loss: 0.723  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:39:09] d2.utils.events INFO: eta: 11:00:35  iter: 61339  total_loss: 0.746  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:40:10] d2.utils.events INFO: eta: 10:59:42  iter: 61359  total_loss: 0.697  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 06:41:10] d2.utils.events INFO: eta: 10:58:30  iter: 61379  total_loss: 0.660  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:42:11] d2.utils.events INFO: eta: 10:57:29  iter: 61399  total_loss: 0.755  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 06:43:14] d2.utils.events INFO: eta: 10:56:35  iter: 61419  total_loss: 0.634  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:44:14] d2.utils.events INFO: eta: 10:55:33  iter: 61439  total_loss: 0.697  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:45:14] d2.utils.events INFO: eta: 10:54:32  iter: 61459  total_loss: 0.553  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:46:15] d2.utils.events INFO: eta: 10:53:26  iter: 61479  total_loss: 0.400  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.081  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:47:15] d2.utils.events INFO: eta: 10:52:04  iter: 61499  total_loss: 0.664  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:48:14] d2.utils.events INFO: eta: 10:50:59  iter: 61519  total_loss: 0.712  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 06:49:15] d2.utils.events INFO: eta: 10:49:57  iter: 61539  total_loss: 0.853  loss_cls_stage0: 0.080  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.087  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 06:50:17] d2.utils.events INFO: eta: 10:48:58  iter: 61559  total_loss: 0.529  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.071  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 06:51:17] d2.utils.events INFO: eta: 10:47:52  iter: 61579  total_loss: 0.657  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0019  lr: 0.000100  max_mem: 9404M
[12/27 06:52:18] d2.utils.events INFO: eta: 10:46:57  iter: 61599  total_loss: 0.754  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 06:53:18] d2.utils.events INFO: eta: 10:45:56  iter: 61619  total_loss: 0.664  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 06:54:19] d2.utils.events INFO: eta: 10:44:47  iter: 61639  total_loss: 0.467  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 06:55:17] d2.utils.events INFO: eta: 10:43:30  iter: 61659  total_loss: 0.598  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:56:20] d2.utils.events INFO: eta: 10:42:41  iter: 61679  total_loss: 0.764  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 06:57:20] d2.utils.events INFO: eta: 10:41:47  iter: 61699  total_loss: 0.503  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 06:58:21] d2.utils.events INFO: eta: 10:41:01  iter: 61719  total_loss: 0.592  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 06:59:20] d2.utils.events INFO: eta: 10:39:58  iter: 61739  total_loss: 0.590  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 07:00:21] d2.utils.events INFO: eta: 10:38:57  iter: 61759  total_loss: 0.526  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:01:21] d2.utils.events INFO: eta: 10:37:59  iter: 61779  total_loss: 0.497  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/27 07:02:24] d2.utils.events INFO: eta: 10:37:13  iter: 61799  total_loss: 0.799  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:03:25] d2.utils.events INFO: eta: 10:36:17  iter: 61819  total_loss: 0.722  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 07:04:25] d2.utils.events INFO: eta: 10:35:15  iter: 61839  total_loss: 0.610  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:05:26] d2.utils.events INFO: eta: 10:34:24  iter: 61859  total_loss: 0.671  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:06:26] d2.utils.events INFO: eta: 10:33:19  iter: 61879  total_loss: 0.483  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 07:07:28] d2.utils.events INFO: eta: 10:32:26  iter: 61899  total_loss: 0.478  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:08:30] d2.utils.events INFO: eta: 10:31:30  iter: 61919  total_loss: 0.730  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:09:29] d2.utils.events INFO: eta: 10:30:28  iter: 61939  total_loss: 0.499  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:10:31] d2.utils.events INFO: eta: 10:29:27  iter: 61959  total_loss: 0.716  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0037  lr: 0.000100  max_mem: 9404M
[12/27 07:11:31] d2.utils.events INFO: eta: 10:28:22  iter: 61979  total_loss: 0.498  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 07:12:30] d2.utils.events INFO: eta: 10:27:23  iter: 61999  total_loss: 0.594  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:13:32] d2.utils.events INFO: eta: 10:26:22  iter: 62019  total_loss: 0.610  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 07:14:32] d2.utils.events INFO: eta: 10:25:14  iter: 62039  total_loss: 0.550  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:15:31] d2.utils.events INFO: eta: 10:24:09  iter: 62059  total_loss: 0.673  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:16:31] d2.utils.events INFO: eta: 10:23:06  iter: 62079  total_loss: 0.486  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:17:32] d2.utils.events INFO: eta: 10:21:56  iter: 62099  total_loss: 0.489  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 07:18:31] d2.utils.events INFO: eta: 10:20:57  iter: 62119  total_loss: 0.614  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 07:19:31] d2.utils.events INFO: eta: 10:19:51  iter: 62139  total_loss: 0.461  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:20:31] d2.utils.events INFO: eta: 10:18:46  iter: 62159  total_loss: 0.613  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:21:31] d2.utils.events INFO: eta: 10:17:42  iter: 62179  total_loss: 0.437  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 07:22:32] d2.utils.events INFO: eta: 10:16:45  iter: 62199  total_loss: 0.814  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 07:23:33] d2.utils.events INFO: eta: 10:15:35  iter: 62219  total_loss: 0.646  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:24:33] d2.utils.events INFO: eta: 10:14:38  iter: 62239  total_loss: 0.635  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:25:34] d2.utils.events INFO: eta: 10:13:42  iter: 62259  total_loss: 0.625  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:26:36] d2.utils.events INFO: eta: 10:12:47  iter: 62279  total_loss: 0.572  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:27:36] d2.utils.events INFO: eta: 10:11:41  iter: 62299  total_loss: 0.739  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:28:36] d2.utils.events INFO: eta: 10:10:40  iter: 62319  total_loss: 0.676  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 07:29:36] d2.utils.events INFO: eta: 10:09:46  iter: 62339  total_loss: 0.434  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:30:37] d2.utils.events INFO: eta: 10:08:53  iter: 62359  total_loss: 0.514  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:31:36] d2.utils.events INFO: eta: 10:07:57  iter: 62379  total_loss: 0.571  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 07:32:38] d2.utils.events INFO: eta: 10:06:56  iter: 62399  total_loss: 0.357  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.003  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 07:33:37] d2.utils.events INFO: eta: 10:05:32  iter: 62419  total_loss: 0.579  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:34:38] d2.utils.events INFO: eta: 10:04:29  iter: 62439  total_loss: 0.578  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 07:35:38] d2.utils.events INFO: eta: 10:03:30  iter: 62459  total_loss: 0.551  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:36:40] d2.utils.events INFO: eta: 10:02:48  iter: 62479  total_loss: 0.559  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 07:37:41] d2.utils.events INFO: eta: 10:01:59  iter: 62499  total_loss: 0.685  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 07:38:42] d2.utils.events INFO: eta: 10:01:05  iter: 62519  total_loss: 0.535  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:39:41] d2.utils.events INFO: eta: 9:59:59  iter: 62539  total_loss: 0.640  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:40:42] d2.utils.events INFO: eta: 9:58:58  iter: 62559  total_loss: 0.621  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 07:41:42] d2.utils.events INFO: eta: 9:57:57  iter: 62579  total_loss: 0.633  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:42:43] d2.utils.events INFO: eta: 9:56:54  iter: 62599  total_loss: 0.639  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 07:43:45] d2.utils.events INFO: eta: 9:55:54  iter: 62619  total_loss: 0.639  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:44:45] d2.utils.events INFO: eta: 9:54:53  iter: 62639  total_loss: 0.682  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 07:45:45] d2.utils.events INFO: eta: 9:53:54  iter: 62659  total_loss: 0.602  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:46:46] d2.utils.events INFO: eta: 9:52:52  iter: 62679  total_loss: 0.515  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 07:47:48] d2.utils.events INFO: eta: 9:51:51  iter: 62699  total_loss: 0.745  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:48:49] d2.utils.events INFO: eta: 9:50:49  iter: 62719  total_loss: 0.666  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 07:49:50] d2.utils.events INFO: eta: 9:49:49  iter: 62739  total_loss: 0.941  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 07:50:50] d2.utils.events INFO: eta: 9:48:48  iter: 62759  total_loss: 0.479  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:51:52] d2.utils.events INFO: eta: 9:47:50  iter: 62779  total_loss: 0.585  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:52:52] d2.utils.events INFO: eta: 9:46:46  iter: 62799  total_loss: 0.483  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:53:52] d2.utils.events INFO: eta: 9:45:42  iter: 62819  total_loss: 0.649  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 07:54:53] d2.utils.events INFO: eta: 9:44:44  iter: 62839  total_loss: 0.843  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.100  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 07:55:56] d2.utils.events INFO: eta: 9:43:43  iter: 62859  total_loss: 0.607  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 07:56:56] d2.utils.events INFO: eta: 9:42:43  iter: 62879  total_loss: 0.458  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 07:57:56] d2.utils.events INFO: eta: 9:41:40  iter: 62899  total_loss: 0.480  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 07:58:55] d2.utils.events INFO: eta: 9:40:36  iter: 62919  total_loss: 0.400  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 07:59:57] d2.utils.events INFO: eta: 9:39:40  iter: 62939  total_loss: 0.549  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:00:57] d2.utils.events INFO: eta: 9:38:37  iter: 62959  total_loss: 0.862  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:01:59] d2.utils.events INFO: eta: 9:37:37  iter: 62979  total_loss: 0.584  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 08:02:58] d2.utils.events INFO: eta: 9:36:39  iter: 62999  total_loss: 0.527  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:04:00] d2.utils.events INFO: eta: 9:35:38  iter: 63019  total_loss: 0.562  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 08:05:01] d2.utils.events INFO: eta: 9:34:37  iter: 63039  total_loss: 0.660  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:06:02] d2.utils.events INFO: eta: 9:33:41  iter: 63059  total_loss: 0.742  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 08:07:03] d2.utils.events INFO: eta: 9:32:42  iter: 63079  total_loss: 0.600  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 08:08:05] d2.utils.events INFO: eta: 9:31:47  iter: 63099  total_loss: 0.579  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:09:06] d2.utils.events INFO: eta: 9:30:46  iter: 63119  total_loss: 0.675  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:10:06] d2.utils.events INFO: eta: 9:29:49  iter: 63139  total_loss: 0.764  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:11:06] d2.utils.events INFO: eta: 9:28:44  iter: 63159  total_loss: 0.590  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:12:06] d2.utils.events INFO: eta: 9:27:43  iter: 63179  total_loss: 0.502  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:13:07] d2.utils.events INFO: eta: 9:26:42  iter: 63199  total_loss: 0.685  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 08:14:08] d2.utils.events INFO: eta: 9:25:43  iter: 63219  total_loss: 0.739  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:15:09] d2.utils.events INFO: eta: 9:24:42  iter: 63239  total_loss: 0.622  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/27 08:16:10] d2.utils.events INFO: eta: 9:23:41  iter: 63259  total_loss: 0.758  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:17:09] d2.utils.events INFO: eta: 9:22:38  iter: 63279  total_loss: 0.428  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 08:18:09] d2.utils.events INFO: eta: 9:21:39  iter: 63299  total_loss: 0.748  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 08:19:11] d2.utils.events INFO: eta: 9:20:42  iter: 63319  total_loss: 0.704  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:20:12] d2.utils.events INFO: eta: 9:19:45  iter: 63339  total_loss: 0.719  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:21:13] d2.utils.events INFO: eta: 9:18:41  iter: 63359  total_loss: 0.703  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:22:13] d2.utils.events INFO: eta: 9:17:43  iter: 63379  total_loss: 0.719  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:23:13] d2.utils.events INFO: eta: 9:16:37  iter: 63399  total_loss: 0.718  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:24:13] d2.utils.events INFO: eta: 9:15:34  iter: 63419  total_loss: 0.516  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 08:25:13] d2.utils.events INFO: eta: 9:14:34  iter: 63439  total_loss: 0.568  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:26:13] d2.utils.events INFO: eta: 9:13:34  iter: 63459  total_loss: 0.618  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 08:27:13] d2.utils.events INFO: eta: 9:12:31  iter: 63479  total_loss: 0.806  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 08:28:13] d2.utils.events INFO: eta: 9:11:25  iter: 63499  total_loss: 0.551  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:29:14] d2.utils.events INFO: eta: 9:10:22  iter: 63519  total_loss: 0.574  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:30:15] d2.utils.events INFO: eta: 9:09:25  iter: 63539  total_loss: 0.386  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:31:14] d2.utils.events INFO: eta: 9:08:22  iter: 63559  total_loss: 0.270  loss_cls_stage0: 0.015  loss_box_reg_stage0: 0.021  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.056  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.083  loss_rpn_cls: 0.002  loss_rpn_loc: 0.001  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:32:15] d2.utils.events INFO: eta: 9:07:24  iter: 63579  total_loss: 0.644  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:33:17] d2.utils.events INFO: eta: 9:06:25  iter: 63599  total_loss: 0.432  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.003  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 08:34:18] d2.utils.events INFO: eta: 9:05:20  iter: 63619  total_loss: 0.521  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 08:35:19] d2.utils.events INFO: eta: 9:04:23  iter: 63639  total_loss: 0.639  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:36:22] d2.utils.events INFO: eta: 9:03:28  iter: 63659  total_loss: 0.419  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0033  lr: 0.000100  max_mem: 9404M
[12/27 08:37:22] d2.utils.events INFO: eta: 9:02:27  iter: 63679  total_loss: 0.457  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:38:24] d2.utils.events INFO: eta: 9:01:29  iter: 63699  total_loss: 0.701  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 08:39:25] d2.utils.events INFO: eta: 9:00:28  iter: 63719  total_loss: 0.606  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 08:40:26] d2.utils.events INFO: eta: 8:59:21  iter: 63739  total_loss: 0.726  loss_cls_stage0: 0.086  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.098  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.007  loss_rpn_loc: 0.011  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:41:26] d2.utils.events INFO: eta: 8:58:27  iter: 63759  total_loss: 0.575  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:42:26] d2.utils.events INFO: eta: 8:57:22  iter: 63779  total_loss: 0.672  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 08:43:27] d2.utils.events INFO: eta: 8:56:21  iter: 63799  total_loss: 0.661  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 08:44:28] d2.utils.events INFO: eta: 8:55:25  iter: 63819  total_loss: 0.724  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 08:45:28] d2.utils.events INFO: eta: 8:54:22  iter: 63839  total_loss: 0.609  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 08:46:29] d2.utils.events INFO: eta: 8:53:21  iter: 63859  total_loss: 0.580  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 08:47:29] d2.utils.events INFO: eta: 8:52:21  iter: 63879  total_loss: 0.674  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:48:31] d2.utils.events INFO: eta: 8:51:23  iter: 63899  total_loss: 0.659  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 08:49:31] d2.utils.events INFO: eta: 8:50:22  iter: 63919  total_loss: 0.591  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:50:33] d2.utils.events INFO: eta: 8:49:21  iter: 63939  total_loss: 0.597  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:51:33] d2.utils.events INFO: eta: 8:48:20  iter: 63959  total_loss: 0.584  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:52:33] d2.utils.events INFO: eta: 8:47:18  iter: 63979  total_loss: 0.785  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 08:53:34] d2.utils.events INFO: eta: 8:46:18  iter: 63999  total_loss: 0.597  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 08:54:34] d2.utils.events INFO: eta: 8:45:17  iter: 64019  total_loss: 0.515  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 08:55:35] d2.utils.events INFO: eta: 8:44:13  iter: 64039  total_loss: 0.462  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 08:56:36] d2.utils.events INFO: eta: 8:43:13  iter: 64059  total_loss: 0.526  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 08:57:37] d2.utils.events INFO: eta: 8:42:15  iter: 64079  total_loss: 0.705  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 08:58:36] d2.utils.events INFO: eta: 8:41:04  iter: 64099  total_loss: 0.610  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 08:59:36] d2.utils.events INFO: eta: 8:40:02  iter: 64119  total_loss: 0.799  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 09:00:38] d2.utils.events INFO: eta: 8:39:01  iter: 64139  total_loss: 0.547  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 09:01:40] d2.utils.events INFO: eta: 8:38:11  iter: 64159  total_loss: 0.671  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:02:41] d2.utils.events INFO: eta: 8:37:10  iter: 64179  total_loss: 0.767  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:03:43] d2.utils.events INFO: eta: 8:36:10  iter: 64199  total_loss: 0.712  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:04:42] d2.utils.events INFO: eta: 8:35:08  iter: 64219  total_loss: 0.666  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:05:42] d2.utils.events INFO: eta: 8:34:07  iter: 64239  total_loss: 0.485  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 09:06:42] d2.utils.events INFO: eta: 8:33:01  iter: 64259  total_loss: 0.731  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 09:07:40] d2.utils.events INFO: eta: 8:31:58  iter: 64279  total_loss: 0.431  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.137  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 09:08:40] d2.utils.events INFO: eta: 8:30:53  iter: 64299  total_loss: 0.589  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:09:40] d2.utils.events INFO: eta: 8:29:49  iter: 64319  total_loss: 0.446  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:10:41] d2.utils.events INFO: eta: 8:28:45  iter: 64339  total_loss: 0.673  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 09:11:42] d2.utils.events INFO: eta: 8:27:43  iter: 64359  total_loss: 0.547  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 09:12:41] d2.utils.events INFO: eta: 8:26:40  iter: 64379  total_loss: 0.773  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 09:13:42] d2.utils.events INFO: eta: 8:25:41  iter: 64399  total_loss: 0.540  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:14:43] d2.utils.events INFO: eta: 8:24:41  iter: 64419  total_loss: 0.580  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:15:43] d2.utils.events INFO: eta: 8:23:39  iter: 64439  total_loss: 0.428  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/27 09:16:42] d2.utils.events INFO: eta: 8:22:29  iter: 64459  total_loss: 0.400  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 09:17:43] d2.utils.events INFO: eta: 8:21:28  iter: 64479  total_loss: 0.592  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 09:18:43] d2.utils.events INFO: eta: 8:20:32  iter: 64499  total_loss: 0.594  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:19:44] d2.utils.events INFO: eta: 8:19:28  iter: 64519  total_loss: 0.613  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 09:20:45] d2.utils.events INFO: eta: 8:18:27  iter: 64539  total_loss: 0.610  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 09:21:45] d2.utils.events INFO: eta: 8:17:28  iter: 64559  total_loss: 0.573  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 09:22:46] d2.utils.events INFO: eta: 8:16:31  iter: 64579  total_loss: 0.639  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 09:23:46] d2.utils.events INFO: eta: 8:15:23  iter: 64599  total_loss: 0.721  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 09:24:47] d2.utils.events INFO: eta: 8:14:23  iter: 64619  total_loss: 0.756  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 09:25:48] d2.utils.events INFO: eta: 8:13:29  iter: 64639  total_loss: 0.494  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 09:26:50] d2.utils.events INFO: eta: 8:12:20  iter: 64659  total_loss: 0.714  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 09:27:49] d2.utils.events INFO: eta: 8:11:14  iter: 64679  total_loss: 0.665  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0019  lr: 0.000100  max_mem: 9404M
[12/27 09:28:51] d2.utils.events INFO: eta: 8:10:09  iter: 64699  total_loss: 0.559  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 09:29:52] d2.utils.events INFO: eta: 8:09:07  iter: 64719  total_loss: 0.539  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 09:30:53] d2.utils.events INFO: eta: 8:08:09  iter: 64739  total_loss: 0.717  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:31:54] d2.utils.events INFO: eta: 8:07:02  iter: 64759  total_loss: 0.437  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 09:32:54] d2.utils.events INFO: eta: 8:06:02  iter: 64779  total_loss: 0.689  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 09:33:55] d2.utils.events INFO: eta: 8:05:01  iter: 64799  total_loss: 0.638  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:34:54] d2.utils.events INFO: eta: 8:03:31  iter: 64819  total_loss: 0.533  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:35:54] d2.utils.events INFO: eta: 8:02:31  iter: 64839  total_loss: 0.652  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 09:36:53] d2.utils.events INFO: eta: 8:01:27  iter: 64859  total_loss: 0.519  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 09:37:53] d2.utils.events INFO: eta: 8:00:15  iter: 64879  total_loss: 0.457  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 09:38:54] d2.utils.events INFO: eta: 7:59:10  iter: 64899  total_loss: 0.768  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:39:56] d2.utils.events INFO: eta: 7:58:09  iter: 64919  total_loss: 0.562  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:40:57] d2.utils.events INFO: eta: 7:56:53  iter: 64939  total_loss: 0.647  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 09:41:56] d2.utils.events INFO: eta: 7:55:52  iter: 64959  total_loss: 0.737  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 09:42:58] d2.utils.events INFO: eta: 7:54:48  iter: 64979  total_loss: 0.808  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 09:44:01] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0064999.pth
[12/27 09:44:08] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/27 09:44:08] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/27 09:45:13] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4795 s / img. ETA=0:08:58
[12/27 09:45:37] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4795 s / img. ETA=0:08:34
[12/27 09:46:01] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4800 s / img. ETA=0:08:11
[12/27 09:46:25] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4805 s / img. ETA=0:07:47
[12/27 09:46:49] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4807 s / img. ETA=0:07:24
[12/27 09:47:13] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4806 s / img. ETA=0:07:00
[12/27 09:47:37] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4805 s / img. ETA=0:06:35
[12/27 09:48:01] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4804 s / img. ETA=0:06:11
[12/27 09:48:25] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4803 s / img. ETA=0:05:47
[12/27 09:48:49] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4803 s / img. ETA=0:05:23
[12/27 09:49:13] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4802 s / img. ETA=0:04:59
[12/27 09:49:37] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4802 s / img. ETA=0:04:35
[12/27 09:50:01] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4802 s / img. ETA=0:04:11
[12/27 09:50:25] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4802 s / img. ETA=0:03:47
[12/27 09:50:49] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4802 s / img. ETA=0:03:23
[12/27 09:51:13] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4802 s / img. ETA=0:02:59
[12/27 09:51:37] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4802 s / img. ETA=0:02:35
[12/27 09:52:01] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4803 s / img. ETA=0:02:11
[12/27 09:52:25] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4803 s / img. ETA=0:01:47
[12/27 09:52:49] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4803 s / img. ETA=0:01:23
[12/27 09:53:13] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4803 s / img. ETA=0:00:59
[12/27 09:53:37] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4803 s / img. ETA=0:00:35
[12/27 09:54:01] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4803 s / img. ETA=0:00:11
[12/27 09:54:13] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/27 09:54:13] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:17 (0.477123 s / img per device, on 2 devices)
[12/27 09:54:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/27 09:54:14] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/27 09:54:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/27 09:54:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.780 | 70.994 | 55.393 | 25.179 | 42.780 | 50.907 |
[12/27 09:54:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 53.810 | ASC-US     | 49.184 | HSIL        | 64.975 |
| LSIL       | 62.356 | Candida    | 47.630 | Trichomonas | 20.727 |
[12/27 09:54:18] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/27 09:54:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/27 09:54:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/27 09:54:18] d2.evaluation.testing INFO: copypaste: 49.7804,70.9939,55.3928,25.1791,42.7797,50.9068
[12/27 09:54:18] d2.utils.events INFO: eta: 7:54:01  iter: 64999  total_loss: 0.707  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0302  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/27 09:55:18] d2.utils.events INFO: eta: 7:53:00  iter: 65019  total_loss: 0.565  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:56:20] d2.utils.events INFO: eta: 7:52:14  iter: 65039  total_loss: 0.517  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:57:22] d2.utils.events INFO: eta: 7:51:16  iter: 65059  total_loss: 0.550  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 09:58:22] d2.utils.events INFO: eta: 7:50:08  iter: 65079  total_loss: 0.804  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.099  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 09:59:21] d2.utils.events INFO: eta: 7:49:04  iter: 65099  total_loss: 0.572  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 10:00:22] d2.utils.events INFO: eta: 7:48:11  iter: 65119  total_loss: 0.633  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:01:24] d2.utils.events INFO: eta: 7:47:13  iter: 65139  total_loss: 0.669  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:02:24] d2.utils.events INFO: eta: 7:46:05  iter: 65159  total_loss: 0.621  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:03:25] d2.utils.events INFO: eta: 7:45:00  iter: 65179  total_loss: 0.755  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:04:25] d2.utils.events INFO: eta: 7:43:54  iter: 65199  total_loss: 0.529  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:05:24] d2.utils.events INFO: eta: 7:42:51  iter: 65219  total_loss: 0.461  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.132  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:06:25] d2.utils.events INFO: eta: 7:41:52  iter: 65239  total_loss: 0.628  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:07:26] d2.utils.events INFO: eta: 7:40:56  iter: 65259  total_loss: 0.859  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 10:08:27] d2.utils.events INFO: eta: 7:40:05  iter: 65279  total_loss: 0.761  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.099  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:09:26] d2.utils.events INFO: eta: 7:39:08  iter: 65299  total_loss: 0.590  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:10:26] d2.utils.events INFO: eta: 7:38:04  iter: 65319  total_loss: 0.547  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:11:28] d2.utils.events INFO: eta: 7:37:14  iter: 65339  total_loss: 0.790  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:12:29] d2.utils.events INFO: eta: 7:36:21  iter: 65359  total_loss: 0.567  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:13:31] d2.utils.events INFO: eta: 7:35:27  iter: 65379  total_loss: 0.604  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:14:30] d2.utils.events INFO: eta: 7:34:11  iter: 65399  total_loss: 0.474  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:15:31] d2.utils.events INFO: eta: 7:33:26  iter: 65419  total_loss: 0.740  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:16:33] d2.utils.events INFO: eta: 7:32:35  iter: 65439  total_loss: 0.603  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:17:32] d2.utils.events INFO: eta: 7:31:35  iter: 65459  total_loss: 0.697  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:18:33] d2.utils.events INFO: eta: 7:30:33  iter: 65479  total_loss: 0.541  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:19:34] d2.utils.events INFO: eta: 7:29:30  iter: 65499  total_loss: 0.702  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 10:20:35] d2.utils.events INFO: eta: 7:28:31  iter: 65519  total_loss: 0.595  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.089  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:21:34] d2.utils.events INFO: eta: 7:27:25  iter: 65539  total_loss: 0.424  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:22:36] d2.utils.events INFO: eta: 7:26:22  iter: 65559  total_loss: 0.565  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 10:23:38] d2.utils.events INFO: eta: 7:25:25  iter: 65579  total_loss: 0.543  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:24:40] d2.utils.events INFO: eta: 7:24:31  iter: 65599  total_loss: 0.428  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 10:25:40] d2.utils.events INFO: eta: 7:23:28  iter: 65619  total_loss: 0.734  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:26:40] d2.utils.events INFO: eta: 7:22:05  iter: 65639  total_loss: 0.566  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 10:27:41] d2.utils.events INFO: eta: 7:21:05  iter: 65659  total_loss: 0.653  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:28:41] d2.utils.events INFO: eta: 7:20:13  iter: 65679  total_loss: 0.650  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:29:42] d2.utils.events INFO: eta: 7:19:12  iter: 65699  total_loss: 0.592  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 10:30:42] d2.utils.events INFO: eta: 7:18:14  iter: 65719  total_loss: 0.739  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:31:43] d2.utils.events INFO: eta: 7:17:13  iter: 65739  total_loss: 0.557  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:32:45] d2.utils.events INFO: eta: 7:16:19  iter: 65759  total_loss: 0.835  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:33:45] d2.utils.events INFO: eta: 7:15:16  iter: 65779  total_loss: 0.494  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:34:44] d2.utils.events INFO: eta: 7:14:11  iter: 65799  total_loss: 0.721  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:35:46] d2.utils.events INFO: eta: 7:13:22  iter: 65819  total_loss: 0.700  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:36:47] d2.utils.events INFO: eta: 7:12:25  iter: 65839  total_loss: 0.583  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:37:46] d2.utils.events INFO: eta: 7:11:17  iter: 65859  total_loss: 0.545  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:38:46] d2.utils.events INFO: eta: 7:10:23  iter: 65879  total_loss: 0.714  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 10:39:47] d2.utils.events INFO: eta: 7:09:21  iter: 65899  total_loss: 0.520  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 10:40:49] d2.utils.events INFO: eta: 7:08:20  iter: 65919  total_loss: 0.594  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:41:50] d2.utils.events INFO: eta: 7:07:21  iter: 65939  total_loss: 0.536  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:42:49] d2.utils.events INFO: eta: 7:06:20  iter: 65959  total_loss: 0.576  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:43:49] d2.utils.events INFO: eta: 7:05:19  iter: 65979  total_loss: 0.514  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 10:44:51] d2.utils.events INFO: eta: 7:04:11  iter: 65999  total_loss: 0.438  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 10:45:51] d2.utils.events INFO: eta: 7:03:09  iter: 66019  total_loss: 0.683  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:46:51] d2.utils.events INFO: eta: 7:02:04  iter: 66039  total_loss: 0.549  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:47:53] d2.utils.events INFO: eta: 7:01:04  iter: 66059  total_loss: 0.630  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 10:48:53] d2.utils.events INFO: eta: 7:00:07  iter: 66079  total_loss: 0.466  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:49:52] d2.utils.events INFO: eta: 6:59:14  iter: 66099  total_loss: 0.605  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:50:53] d2.utils.events INFO: eta: 6:58:13  iter: 66119  total_loss: 0.520  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 10:51:54] d2.utils.events INFO: eta: 6:57:12  iter: 66139  total_loss: 0.570  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 10:52:55] d2.utils.events INFO: eta: 6:56:10  iter: 66159  total_loss: 0.570  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 10:53:56] d2.utils.events INFO: eta: 6:55:12  iter: 66179  total_loss: 0.576  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 10:54:58] d2.utils.events INFO: eta: 6:54:16  iter: 66199  total_loss: 0.751  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 10:56:01] d2.utils.events INFO: eta: 6:53:23  iter: 66219  total_loss: 0.672  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 10:57:03] d2.utils.events INFO: eta: 6:52:24  iter: 66239  total_loss: 0.814  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 10:58:02] d2.utils.events INFO: eta: 6:51:21  iter: 66259  total_loss: 0.593  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 10:59:02] d2.utils.events INFO: eta: 6:50:19  iter: 66279  total_loss: 0.596  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:00:02] d2.utils.events INFO: eta: 6:49:18  iter: 66299  total_loss: 0.831  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:01:04] d2.utils.events INFO: eta: 6:48:19  iter: 66319  total_loss: 0.879  loss_cls_stage0: 0.081  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:02:06] d2.utils.events INFO: eta: 6:47:18  iter: 66339  total_loss: 0.699  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 11:03:07] d2.utils.events INFO: eta: 6:46:19  iter: 66359  total_loss: 0.702  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.102  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:04:07] d2.utils.events INFO: eta: 6:45:16  iter: 66379  total_loss: 0.527  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:05:07] d2.utils.events INFO: eta: 6:44:19  iter: 66399  total_loss: 0.463  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 11:06:10] d2.utils.events INFO: eta: 6:43:18  iter: 66419  total_loss: 0.579  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:07:11] d2.utils.events INFO: eta: 6:42:13  iter: 66439  total_loss: 0.396  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 11:08:12] d2.utils.events INFO: eta: 6:41:13  iter: 66459  total_loss: 0.628  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:09:12] d2.utils.events INFO: eta: 6:40:12  iter: 66479  total_loss: 0.490  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:10:13] d2.utils.events INFO: eta: 6:39:15  iter: 66499  total_loss: 0.583  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:11:14] d2.utils.events INFO: eta: 6:38:13  iter: 66519  total_loss: 0.653  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 11:12:15] d2.utils.events INFO: eta: 6:37:13  iter: 66539  total_loss: 0.399  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:13:15] d2.utils.events INFO: eta: 6:36:12  iter: 66559  total_loss: 0.614  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 11:14:14] d2.utils.events INFO: eta: 6:35:07  iter: 66579  total_loss: 0.709  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:15:15] d2.utils.events INFO: eta: 6:34:05  iter: 66599  total_loss: 0.765  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 11:16:17] d2.utils.events INFO: eta: 6:33:06  iter: 66619  total_loss: 0.528  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:17:18] d2.utils.events INFO: eta: 6:32:10  iter: 66639  total_loss: 0.724  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:18:20] d2.utils.events INFO: eta: 6:31:11  iter: 66659  total_loss: 0.671  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:19:20] d2.utils.events INFO: eta: 6:30:10  iter: 66679  total_loss: 0.564  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:20:21] d2.utils.events INFO: eta: 6:29:09  iter: 66699  total_loss: 0.706  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 11:21:20] d2.utils.events INFO: eta: 6:28:07  iter: 66719  total_loss: 0.520  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 11:22:21] d2.utils.events INFO: eta: 6:27:06  iter: 66739  total_loss: 0.692  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 11:23:21] d2.utils.events INFO: eta: 6:26:04  iter: 66759  total_loss: 0.761  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 11:24:21] d2.utils.events INFO: eta: 6:25:03  iter: 66779  total_loss: 0.735  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:25:22] d2.utils.events INFO: eta: 6:24:03  iter: 66799  total_loss: 0.636  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:26:23] d2.utils.events INFO: eta: 6:23:01  iter: 66819  total_loss: 0.813  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:27:24] d2.utils.events INFO: eta: 6:22:00  iter: 66839  total_loss: 0.653  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:28:25] d2.utils.events INFO: eta: 6:21:04  iter: 66859  total_loss: 0.651  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:29:26] d2.utils.events INFO: eta: 6:20:04  iter: 66879  total_loss: 0.644  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:30:27] d2.utils.events INFO: eta: 6:19:02  iter: 66899  total_loss: 0.581  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:31:28] d2.utils.events INFO: eta: 6:17:59  iter: 66919  total_loss: 0.778  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 11:32:30] d2.utils.events INFO: eta: 6:16:58  iter: 66939  total_loss: 0.626  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:33:32] d2.utils.events INFO: eta: 6:16:01  iter: 66959  total_loss: 0.587  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:34:33] d2.utils.events INFO: eta: 6:14:59  iter: 66979  total_loss: 0.841  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:35:33] d2.utils.events INFO: eta: 6:13:58  iter: 66999  total_loss: 0.674  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0308  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 11:36:33] d2.utils.events INFO: eta: 6:12:58  iter: 67019  total_loss: 0.612  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 11:37:33] d2.utils.events INFO: eta: 6:11:58  iter: 67039  total_loss: 0.603  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:38:33] d2.utils.events INFO: eta: 6:10:55  iter: 67059  total_loss: 0.719  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:39:34] d2.utils.events INFO: eta: 6:09:53  iter: 67079  total_loss: 0.495  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:40:33] d2.utils.events INFO: eta: 6:08:51  iter: 67099  total_loss: 0.622  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:41:33] d2.utils.events INFO: eta: 6:07:50  iter: 67119  total_loss: 0.667  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:42:35] d2.utils.events INFO: eta: 6:06:48  iter: 67139  total_loss: 0.381  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:43:35] d2.utils.events INFO: eta: 6:05:47  iter: 67159  total_loss: 0.502  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:44:37] d2.utils.events INFO: eta: 6:04:47  iter: 67179  total_loss: 0.554  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 11:45:38] d2.utils.events INFO: eta: 6:03:44  iter: 67199  total_loss: 0.649  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:46:38] d2.utils.events INFO: eta: 6:02:40  iter: 67219  total_loss: 0.586  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:47:40] d2.utils.events INFO: eta: 6:01:40  iter: 67239  total_loss: 0.721  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:48:39] d2.utils.events INFO: eta: 6:00:36  iter: 67259  total_loss: 0.555  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:49:37] d2.utils.events INFO: eta: 5:59:33  iter: 67279  total_loss: 0.530  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 11:50:38] d2.utils.events INFO: eta: 5:58:35  iter: 67299  total_loss: 0.527  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 11:51:38] d2.utils.events INFO: eta: 5:57:31  iter: 67319  total_loss: 0.817  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.087  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:52:38] d2.utils.events INFO: eta: 5:56:26  iter: 67339  total_loss: 0.645  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 11:53:38] d2.utils.events INFO: eta: 5:55:21  iter: 67359  total_loss: 0.665  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:54:39] d2.utils.events INFO: eta: 5:54:24  iter: 67379  total_loss: 0.475  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 11:55:41] d2.utils.events INFO: eta: 5:53:24  iter: 67399  total_loss: 0.620  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 11:56:41] d2.utils.events INFO: eta: 5:52:19  iter: 67419  total_loss: 0.583  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 11:57:42] d2.utils.events INFO: eta: 5:51:20  iter: 67439  total_loss: 0.352  loss_cls_stage0: 0.021  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.080  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 11:58:42] d2.utils.events INFO: eta: 5:50:20  iter: 67459  total_loss: 0.707  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 11:59:43] d2.utils.events INFO: eta: 5:49:19  iter: 67479  total_loss: 0.398  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 12:00:43] d2.utils.events INFO: eta: 5:48:15  iter: 67499  total_loss: 0.411  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:01:44] d2.utils.events INFO: eta: 5:47:15  iter: 67519  total_loss: 0.523  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:02:44] d2.utils.events INFO: eta: 5:46:13  iter: 67539  total_loss: 0.546  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:03:45] d2.utils.events INFO: eta: 5:45:12  iter: 67559  total_loss: 0.561  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 12:04:46] d2.utils.events INFO: eta: 5:44:15  iter: 67579  total_loss: 0.478  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 12:05:47] d2.utils.events INFO: eta: 5:43:14  iter: 67599  total_loss: 0.617  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 12:06:48] d2.utils.events INFO: eta: 5:42:10  iter: 67619  total_loss: 0.532  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:07:50] d2.utils.events INFO: eta: 5:41:09  iter: 67639  total_loss: 0.538  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 12:08:52] d2.utils.events INFO: eta: 5:40:11  iter: 67659  total_loss: 0.711  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:09:53] d2.utils.events INFO: eta: 5:39:12  iter: 67679  total_loss: 0.608  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0035  lr: 0.000100  max_mem: 9404M
[12/27 12:10:54] d2.utils.events INFO: eta: 5:38:12  iter: 67699  total_loss: 0.613  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 12:11:54] d2.utils.events INFO: eta: 5:37:12  iter: 67719  total_loss: 0.785  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:12:54] d2.utils.events INFO: eta: 5:36:09  iter: 67739  total_loss: 0.425  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:13:54] d2.utils.events INFO: eta: 5:35:07  iter: 67759  total_loss: 0.481  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:14:54] d2.utils.events INFO: eta: 5:34:07  iter: 67779  total_loss: 0.546  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:15:55] d2.utils.events INFO: eta: 5:33:07  iter: 67799  total_loss: 0.591  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:16:55] d2.utils.events INFO: eta: 5:32:03  iter: 67819  total_loss: 0.702  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:17:56] d2.utils.events INFO: eta: 5:31:00  iter: 67839  total_loss: 0.663  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:18:56] d2.utils.events INFO: eta: 5:30:03  iter: 67859  total_loss: 0.637  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 12:19:57] d2.utils.events INFO: eta: 5:29:03  iter: 67879  total_loss: 0.449  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:20:55] d2.utils.events INFO: eta: 5:27:57  iter: 67899  total_loss: 0.601  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 12:21:56] d2.utils.events INFO: eta: 5:26:54  iter: 67919  total_loss: 0.650  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:22:57] d2.utils.events INFO: eta: 5:25:51  iter: 67939  total_loss: 0.451  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0031  lr: 0.000100  max_mem: 9404M
[12/27 12:23:58] d2.utils.events INFO: eta: 5:24:48  iter: 67959  total_loss: 0.485  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 12:24:58] d2.utils.events INFO: eta: 5:23:46  iter: 67979  total_loss: 0.569  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:25:59] d2.utils.events INFO: eta: 5:22:51  iter: 67999  total_loss: 0.608  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0032  lr: 0.000100  max_mem: 9404M
[12/27 12:26:59] d2.utils.events INFO: eta: 5:21:47  iter: 68019  total_loss: 0.933  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 12:28:00] d2.utils.events INFO: eta: 5:20:46  iter: 68039  total_loss: 0.604  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:29:00] d2.utils.events INFO: eta: 5:19:46  iter: 68059  total_loss: 0.675  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:30:01] d2.utils.events INFO: eta: 5:18:44  iter: 68079  total_loss: 0.695  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:31:02] d2.utils.events INFO: eta: 5:17:51  iter: 68099  total_loss: 0.482  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 12:32:03] d2.utils.events INFO: eta: 5:16:50  iter: 68119  total_loss: 0.670  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0036  lr: 0.000100  max_mem: 9404M
[12/27 12:33:03] d2.utils.events INFO: eta: 5:15:44  iter: 68139  total_loss: 0.426  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:34:03] d2.utils.events INFO: eta: 5:14:47  iter: 68159  total_loss: 0.368  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.081  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.105  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 12:35:03] d2.utils.events INFO: eta: 5:13:40  iter: 68179  total_loss: 0.554  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:36:05] d2.utils.events INFO: eta: 5:12:45  iter: 68199  total_loss: 0.576  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 12:37:05] d2.utils.events INFO: eta: 5:11:44  iter: 68219  total_loss: 0.706  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:38:06] d2.utils.events INFO: eta: 5:10:45  iter: 68239  total_loss: 0.530  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:39:07] d2.utils.events INFO: eta: 5:09:49  iter: 68259  total_loss: 0.526  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:40:07] d2.utils.events INFO: eta: 5:08:49  iter: 68279  total_loss: 0.645  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 12:41:09] d2.utils.events INFO: eta: 5:07:50  iter: 68299  total_loss: 0.821  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:42:09] d2.utils.events INFO: eta: 5:06:51  iter: 68319  total_loss: 0.520  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:43:10] d2.utils.events INFO: eta: 5:05:52  iter: 68339  total_loss: 0.621  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 12:44:12] d2.utils.events INFO: eta: 5:04:54  iter: 68359  total_loss: 0.615  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 12:45:13] d2.utils.events INFO: eta: 5:03:54  iter: 68379  total_loss: 0.678  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:46:13] d2.utils.events INFO: eta: 5:02:51  iter: 68399  total_loss: 0.514  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 12:47:14] d2.utils.events INFO: eta: 5:01:52  iter: 68419  total_loss: 0.566  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:48:14] d2.utils.events INFO: eta: 5:00:49  iter: 68439  total_loss: 0.595  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:49:15] d2.utils.events INFO: eta: 4:59:50  iter: 68459  total_loss: 0.715  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 12:50:16] d2.utils.events INFO: eta: 4:58:49  iter: 68479  total_loss: 0.617  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 12:51:17] d2.utils.events INFO: eta: 4:57:49  iter: 68499  total_loss: 0.754  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 12:52:18] d2.utils.events INFO: eta: 4:56:48  iter: 68519  total_loss: 0.591  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 12:53:19] d2.utils.events INFO: eta: 4:55:47  iter: 68539  total_loss: 0.590  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 12:54:18] d2.utils.events INFO: eta: 4:54:45  iter: 68559  total_loss: 0.488  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 12:55:18] d2.utils.events INFO: eta: 4:53:43  iter: 68579  total_loss: 0.493  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:56:17] d2.utils.events INFO: eta: 4:52:42  iter: 68599  total_loss: 0.127  loss_cls_stage0: 0.009  loss_box_reg_stage0: 0.011  loss_cls_stage1: 0.010  loss_box_reg_stage1: 0.033  loss_cls_stage2: 0.009  loss_box_reg_stage2: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:57:19] d2.utils.events INFO: eta: 4:51:42  iter: 68619  total_loss: 0.739  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:58:19] d2.utils.events INFO: eta: 4:50:36  iter: 68639  total_loss: 0.591  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 12:59:20] d2.utils.events INFO: eta: 4:49:35  iter: 68659  total_loss: 0.642  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:00:20] d2.utils.events INFO: eta: 4:48:30  iter: 68679  total_loss: 0.680  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 13:01:21] d2.utils.events INFO: eta: 4:47:28  iter: 68699  total_loss: 0.675  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:02:20] d2.utils.events INFO: eta: 4:46:23  iter: 68719  total_loss: 0.480  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:03:21] d2.utils.events INFO: eta: 4:45:24  iter: 68739  total_loss: 0.630  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 13:04:21] d2.utils.events INFO: eta: 4:44:25  iter: 68759  total_loss: 0.811  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:05:20] d2.utils.events INFO: eta: 4:43:21  iter: 68779  total_loss: 0.354  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.074  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.115  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:06:19] d2.utils.events INFO: eta: 4:42:12  iter: 68799  total_loss: 0.444  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:07:18] d2.utils.events INFO: eta: 4:41:12  iter: 68819  total_loss: 0.577  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 13:08:18] d2.utils.events INFO: eta: 4:40:08  iter: 68839  total_loss: 0.832  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:09:17] d2.utils.events INFO: eta: 4:39:02  iter: 68859  total_loss: 0.635  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 13:10:17] d2.utils.events INFO: eta: 4:37:53  iter: 68879  total_loss: 0.502  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 13:11:16] d2.utils.events INFO: eta: 4:36:53  iter: 68899  total_loss: 0.527  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 13:12:18] d2.utils.events INFO: eta: 4:36:00  iter: 68919  total_loss: 0.729  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:13:19] d2.utils.events INFO: eta: 4:34:57  iter: 68939  total_loss: 0.568  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.130  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 13:14:19] d2.utils.events INFO: eta: 4:33:51  iter: 68959  total_loss: 0.558  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:15:20] d2.utils.events INFO: eta: 4:32:50  iter: 68979  total_loss: 0.645  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:16:20] d2.utils.events INFO: eta: 4:31:46  iter: 68999  total_loss: 0.625  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 13:17:22] d2.utils.events INFO: eta: 4:30:45  iter: 69019  total_loss: 0.884  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 13:18:23] d2.utils.events INFO: eta: 4:29:45  iter: 69039  total_loss: 0.678  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:19:23] d2.utils.events INFO: eta: 4:28:46  iter: 69059  total_loss: 0.625  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 13:20:24] d2.utils.events INFO: eta: 4:27:57  iter: 69079  total_loss: 0.664  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:21:26] d2.utils.events INFO: eta: 4:26:58  iter: 69099  total_loss: 0.869  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:22:27] d2.utils.events INFO: eta: 4:25:59  iter: 69119  total_loss: 0.502  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 13:23:29] d2.utils.events INFO: eta: 4:25:07  iter: 69139  total_loss: 0.567  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.128  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:24:30] d2.utils.events INFO: eta: 4:24:07  iter: 69159  total_loss: 0.484  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 13:25:30] d2.utils.events INFO: eta: 4:23:10  iter: 69179  total_loss: 0.548  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:26:30] d2.utils.events INFO: eta: 4:21:56  iter: 69199  total_loss: 0.581  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:27:31] d2.utils.events INFO: eta: 4:21:00  iter: 69219  total_loss: 0.757  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 13:28:30] d2.utils.events INFO: eta: 4:19:47  iter: 69239  total_loss: 0.473  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9404M
[12/27 13:29:30] d2.utils.events INFO: eta: 4:18:49  iter: 69259  total_loss: 1.016  loss_cls_stage0: 0.080  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.259  loss_cls_stage2: 0.100  loss_box_reg_stage2: 0.364  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0301  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 13:30:31] d2.utils.events INFO: eta: 4:17:51  iter: 69279  total_loss: 0.547  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:31:31] d2.utils.events INFO: eta: 4:16:43  iter: 69299  total_loss: 0.320  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.069  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:32:33] d2.utils.events INFO: eta: 4:15:44  iter: 69319  total_loss: 0.562  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:33:34] d2.utils.events INFO: eta: 4:14:50  iter: 69339  total_loss: 0.624  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:34:34] d2.utils.events INFO: eta: 4:13:42  iter: 69359  total_loss: 0.559  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.003  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 13:35:34] d2.utils.events INFO: eta: 4:12:36  iter: 69379  total_loss: 0.427  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.125  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 13:36:35] d2.utils.events INFO: eta: 4:11:38  iter: 69399  total_loss: 0.445  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 13:37:36] d2.utils.events INFO: eta: 4:10:32  iter: 69419  total_loss: 0.647  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:38:36] d2.utils.events INFO: eta: 4:09:34  iter: 69439  total_loss: 0.648  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:39:36] d2.utils.events INFO: eta: 4:08:31  iter: 69459  total_loss: 0.543  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:40:37] d2.utils.events INFO: eta: 4:07:31  iter: 69479  total_loss: 0.544  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:41:37] d2.utils.events INFO: eta: 4:06:30  iter: 69499  total_loss: 0.566  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:42:37] d2.utils.events INFO: eta: 4:05:27  iter: 69519  total_loss: 0.457  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:43:37] d2.utils.events INFO: eta: 4:04:25  iter: 69539  total_loss: 0.512  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:44:37] d2.utils.events INFO: eta: 4:03:27  iter: 69559  total_loss: 0.615  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:45:38] d2.utils.events INFO: eta: 4:02:26  iter: 69579  total_loss: 0.542  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:46:39] d2.utils.events INFO: eta: 4:01:30  iter: 69599  total_loss: 0.659  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 13:47:40] d2.utils.events INFO: eta: 4:00:24  iter: 69619  total_loss: 0.611  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:48:40] d2.utils.events INFO: eta: 3:59:28  iter: 69639  total_loss: 0.619  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 13:49:40] d2.utils.events INFO: eta: 3:58:20  iter: 69659  total_loss: 0.821  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/27 13:50:40] d2.utils.events INFO: eta: 3:57:17  iter: 69679  total_loss: 0.639  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:51:40] d2.utils.events INFO: eta: 3:56:15  iter: 69699  total_loss: 0.447  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:52:40] d2.utils.events INFO: eta: 3:55:15  iter: 69719  total_loss: 0.621  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:53:40] d2.utils.events INFO: eta: 3:54:14  iter: 69739  total_loss: 0.549  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:54:41] d2.utils.events INFO: eta: 3:53:14  iter: 69759  total_loss: 0.599  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 13:55:41] d2.utils.events INFO: eta: 3:52:17  iter: 69779  total_loss: 0.458  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.137  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:56:43] d2.utils.events INFO: eta: 3:51:27  iter: 69799  total_loss: 0.554  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 13:57:43] d2.utils.events INFO: eta: 3:50:29  iter: 69819  total_loss: 0.603  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0298  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 13:58:42] d2.utils.events INFO: eta: 3:49:26  iter: 69839  total_loss: 0.480  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 13:59:42] d2.utils.events INFO: eta: 3:48:22  iter: 69859  total_loss: 0.577  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 14:00:42] d2.utils.events INFO: eta: 3:47:21  iter: 69879  total_loss: 0.635  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0297  data_time: 0.0034  lr: 0.000100  max_mem: 9404M
[12/27 14:01:43] d2.utils.events INFO: eta: 3:46:29  iter: 69899  total_loss: 0.861  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.369  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0297  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 14:02:42] d2.utils.events INFO: eta: 3:45:17  iter: 69919  total_loss: 0.438  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 14:03:44] d2.utils.events INFO: eta: 3:44:28  iter: 69939  total_loss: 0.562  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 14:04:45] d2.utils.events INFO: eta: 3:43:28  iter: 69959  total_loss: 0.517  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 14:05:45] d2.utils.events INFO: eta: 3:42:22  iter: 69979  total_loss: 0.567  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0297  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 14:06:47] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0069999.pth
[12/27 14:06:52] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/27 14:06:52] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/27 14:07:58] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4798 s / img. ETA=0:08:59
[12/27 14:08:22] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4803 s / img. ETA=0:08:35
[12/27 14:08:46] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4804 s / img. ETA=0:08:11
[12/27 14:09:10] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4803 s / img. ETA=0:07:47
[12/27 14:09:34] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4802 s / img. ETA=0:07:23
[12/27 14:09:58] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4803 s / img. ETA=0:06:59
[12/27 14:10:22] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4803 s / img. ETA=0:06:35
[12/27 14:10:46] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4802 s / img. ETA=0:06:11
[12/27 14:11:10] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4801 s / img. ETA=0:05:47
[12/27 14:11:34] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4802 s / img. ETA=0:05:23
[12/27 14:11:58] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4804 s / img. ETA=0:04:59
[12/27 14:12:22] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4803 s / img. ETA=0:04:35
[12/27 14:12:46] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4803 s / img. ETA=0:04:11
[12/27 14:13:10] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4803 s / img. ETA=0:03:47
[12/27 14:13:34] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4803 s / img. ETA=0:03:23
[12/27 14:13:59] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4803 s / img. ETA=0:02:59
[12/27 14:14:23] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4804 s / img. ETA=0:02:35
[12/27 14:14:47] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4804 s / img. ETA=0:02:11
[12/27 14:15:11] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4804 s / img. ETA=0:01:47
[12/27 14:15:35] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4805 s / img. ETA=0:01:23
[12/27 14:15:59] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4805 s / img. ETA=0:00:59
[12/27 14:16:23] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4805 s / img. ETA=0:00:35
[12/27 14:16:47] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4805 s / img. ETA=0:00:11
[12/27 14:16:59] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/27 14:16:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:18 (0.477359 s / img per device, on 2 devices)
[12/27 14:16:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/27 14:16:59] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/27 14:16:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/27 14:17:03] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.539 | 70.648 | 55.529 | 23.966 | 42.605 | 50.765 |
[12/27 14:17:03] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 53.303 | ASC-US     | 48.060 | HSIL        | 66.070 |
| LSIL       | 62.576 | Candida    | 46.735 | Trichomonas | 20.491 |
[12/27 14:17:03] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/27 14:17:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/27 14:17:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/27 14:17:03] d2.evaluation.testing INFO: copypaste: 49.5391,70.6479,55.5289,23.9661,42.6049,50.7647
[12/27 14:17:03] d2.utils.events INFO: eta: 3:41:16  iter: 69999  total_loss: 0.819  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0297  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 14:18:04] d2.utils.events INFO: eta: 3:40:18  iter: 70019  total_loss: 0.625  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 14:19:03] d2.utils.events INFO: eta: 3:39:09  iter: 70039  total_loss: 0.570  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 14:20:05] d2.utils.events INFO: eta: 3:38:12  iter: 70059  total_loss: 0.887  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0298  data_time: 0.0022  lr: 0.000100  max_mem: 9404M
[12/27 14:21:05] d2.utils.events INFO: eta: 3:37:07  iter: 70079  total_loss: 0.428  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.125  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0297  data_time: 0.0020  lr: 0.000100  max_mem: 9404M
[12/27 14:22:05] d2.utils.events INFO: eta: 3:36:01  iter: 70099  total_loss: 0.536  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0025  lr: 0.000100  max_mem: 9404M
[12/27 14:23:05] d2.utils.events INFO: eta: 3:35:00  iter: 70119  total_loss: 0.742  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.101  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.108  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0297  data_time: 0.0030  lr: 0.000100  max_mem: 9404M
[12/27 14:24:07] d2.utils.events INFO: eta: 3:33:59  iter: 70139  total_loss: 0.648  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0029  lr: 0.000100  max_mem: 9404M
[12/27 14:25:06] d2.utils.events INFO: eta: 3:32:55  iter: 70159  total_loss: 0.542  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 14:26:06] d2.utils.events INFO: eta: 3:31:53  iter: 70179  total_loss: 0.522  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 14:27:07] d2.utils.events INFO: eta: 3:30:54  iter: 70199  total_loss: 0.565  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0021  lr: 0.000100  max_mem: 9404M
[12/27 14:28:07] d2.utils.events INFO: eta: 3:29:52  iter: 70219  total_loss: 0.557  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0026  lr: 0.000100  max_mem: 9404M
[12/27 14:29:07] d2.utils.events INFO: eta: 3:28:54  iter: 70239  total_loss: 0.535  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0296  data_time: 0.0023  lr: 0.000100  max_mem: 9404M
[12/27 14:30:09] d2.utils.events INFO: eta: 3:27:55  iter: 70259  total_loss: 0.503  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0027  lr: 0.000100  max_mem: 9404M
[12/27 14:31:09] d2.utils.events INFO: eta: 3:26:53  iter: 70279  total_loss: 0.637  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0024  lr: 0.000100  max_mem: 9404M
[12/27 14:33:46] detectron2 INFO: Rank of current process: 0. World size: 2
[12/27 14:33:51] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/27 14:33:51] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/27 14:33:51] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_test",)  #my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 74368 
  BASE_LR: 0.01     ### 
  STEPS: (74100, 74300)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/27 14:33:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 74368
  MOMENTUM: 0.9
  STEPS: (74100, 74300)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/27 14:33:51] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/27 14:33:51] d2.utils.env INFO: Using a generated random seed 51124684
[12/27 14:33:54] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/27 14:33:54] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0069999.pth
[12/27 14:35:22] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/27 14:35:22] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/27 14:35:23] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/27 14:35:23] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/27 14:36:17] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4838 s / img. ETA=2:15:27
[12/27 14:36:41] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4835 s / img. ETA=2:14:57
[12/27 14:37:05] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4846 s / img. ETA=2:14:52
[12/27 14:37:30] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4859 s / img. ETA=2:14:50
[12/27 14:37:54] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4852 s / img. ETA=2:14:13
[12/27 14:38:18] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4847 s / img. ETA=2:13:42
[12/27 14:38:42] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4847 s / img. ETA=2:13:17
[12/27 14:39:07] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4849 s / img. ETA=2:12:55
[12/27 14:39:31] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4851 s / img. ETA=2:12:36
[12/27 14:39:55] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4850 s / img. ETA=2:12:10
[12/27 14:40:20] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4851 s / img. ETA=2:11:47
[12/27 14:40:44] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4850 s / img. ETA=2:11:21
[12/27 14:41:08] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4852 s / img. ETA=2:11:00
[12/27 14:41:32] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4852 s / img. ETA=2:10:36
[12/27 14:41:57] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4854 s / img. ETA=2:10:14
[12/27 14:42:21] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4853 s / img. ETA=2:09:49
[12/27 14:42:45] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4852 s / img. ETA=2:09:23
[12/27 14:43:09] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4851 s / img. ETA=2:08:56
[12/27 14:43:34] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4850 s / img. ETA=2:08:31
[12/27 14:43:58] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4849 s / img. ETA=2:08:05
[12/27 14:44:22] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4848 s / img. ETA=2:07:40
[12/27 14:44:46] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4847 s / img. ETA=2:07:14
[12/27 14:45:10] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4847 s / img. ETA=2:06:49
[12/27 14:45:35] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4848 s / img. ETA=2:06:26
[12/27 14:45:59] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4848 s / img. ETA=2:06:02
[12/27 14:46:23] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4849 s / img. ETA=2:05:40
[12/27 14:46:48] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4850 s / img. ETA=2:05:18
[12/27 14:47:12] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4852 s / img. ETA=2:04:56
[12/27 14:47:36] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4852 s / img. ETA=2:04:31
[12/27 14:48:01] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4851 s / img. ETA=2:04:06
[12/27 14:48:25] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4852 s / img. ETA=2:03:42
[12/27 14:48:49] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4851 s / img. ETA=2:03:18
[12/27 14:49:13] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4851 s / img. ETA=2:02:53
[12/27 14:49:37] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4851 s / img. ETA=2:02:28
[12/27 14:50:02] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4850 s / img. ETA=2:02:03
[12/27 14:50:26] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4849 s / img. ETA=2:01:38
[12/27 14:50:50] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4849 s / img. ETA=2:01:13
[12/27 14:51:14] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4849 s / img. ETA=2:00:49
[12/27 14:51:39] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4850 s / img. ETA=2:00:26
[12/27 14:52:03] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4851 s / img. ETA=2:00:03
[12/27 14:52:27] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4850 s / img. ETA=1:59:38
[12/27 14:52:51] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4850 s / img. ETA=1:59:14
[12/27 14:53:16] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4850 s / img. ETA=1:58:49
[12/27 14:53:40] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4850 s / img. ETA=1:58:25
[12/27 14:54:04] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4849 s / img. ETA=1:58:00
[12/27 14:54:28] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4850 s / img. ETA=1:57:36
[12/27 14:54:52] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4849 s / img. ETA=1:57:11
[12/27 14:55:17] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4849 s / img. ETA=1:56:46
[12/27 14:55:43] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4858 s / img. ETA=1:56:35
[12/27 14:56:07] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4858 s / img. ETA=1:56:11
[12/27 14:56:32] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4858 s / img. ETA=1:55:47
[12/27 14:56:56] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4857 s / img. ETA=1:55:21
[12/27 14:57:20] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4857 s / img. ETA=1:54:56
[12/27 14:57:44] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4857 s / img. ETA=1:54:32
[12/27 14:58:08] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4856 s / img. ETA=1:54:07
[12/27 14:58:32] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4856 s / img. ETA=1:53:42
[12/27 14:58:57] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4856 s / img. ETA=1:53:18
[12/27 14:59:21] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4856 s / img. ETA=1:52:53
[12/27 14:59:45] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4855 s / img. ETA=1:52:28
[12/27 15:00:09] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4854 s / img. ETA=1:52:02
[12/27 15:00:33] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4854 s / img. ETA=1:51:38
[12/27 15:00:58] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4854 s / img. ETA=1:51:14
[12/27 15:01:22] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4854 s / img. ETA=1:50:49
[12/27 15:01:46] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4853 s / img. ETA=1:50:24
[12/27 15:02:10] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4853 s / img. ETA=1:49:59
[12/27 15:02:34] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4853 s / img. ETA=1:49:35
[12/27 15:02:58] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4852 s / img. ETA=1:49:10
[12/27 15:03:23] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4852 s / img. ETA=1:48:46
[12/27 15:03:47] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4852 s / img. ETA=1:48:21
[12/27 15:04:11] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4851 s / img. ETA=1:47:56
[12/27 15:04:35] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4851 s / img. ETA=1:47:31
[12/27 15:04:59] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4850 s / img. ETA=1:47:06
[12/27 15:05:23] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4850 s / img. ETA=1:46:41
[12/27 15:05:47] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4850 s / img. ETA=1:46:17
[12/27 15:06:11] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4849 s / img. ETA=1:45:52
[12/27 15:06:35] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4849 s / img. ETA=1:45:27
[12/27 15:07:00] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4849 s / img. ETA=1:45:03
[12/27 15:07:24] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4849 s / img. ETA=1:44:39
[12/27 15:07:48] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4849 s / img. ETA=1:44:14
[12/27 15:08:12] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4848 s / img. ETA=1:43:49
[12/27 15:08:36] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4848 s / img. ETA=1:43:25
[12/27 15:09:00] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4848 s / img. ETA=1:43:00
[12/27 15:09:24] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4847 s / img. ETA=1:42:35
[12/27 15:09:49] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4847 s / img. ETA=1:42:11
[12/27 15:10:13] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4847 s / img. ETA=1:41:46
[12/27 15:10:37] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4846 s / img. ETA=1:41:22
[12/27 15:11:01] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4846 s / img. ETA=1:40:57
[12/27 15:11:25] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4846 s / img. ETA=1:40:33
[12/27 15:11:49] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4846 s / img. ETA=1:40:08
[12/27 15:12:13] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4845 s / img. ETA=1:39:43
[12/27 15:12:37] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4845 s / img. ETA=1:39:19
[12/27 15:13:01] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4844 s / img. ETA=1:38:54
[12/27 15:13:25] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4844 s / img. ETA=1:38:30
[12/27 15:13:50] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4844 s / img. ETA=1:38:05
[12/27 15:14:14] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4844 s / img. ETA=1:37:41
[12/27 15:14:38] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4844 s / img. ETA=1:37:16
[12/27 15:15:02] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4843 s / img. ETA=1:36:51
[12/27 15:15:26] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4843 s / img. ETA=1:36:27
[12/27 15:15:50] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4843 s / img. ETA=1:36:03
[12/27 15:16:14] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4843 s / img. ETA=1:35:38
[12/27 15:16:39] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4843 s / img. ETA=1:35:14
[12/27 15:17:03] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4843 s / img. ETA=1:34:50
[12/27 15:17:27] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4843 s / img. ETA=1:34:26
[12/27 15:17:51] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4843 s / img. ETA=1:34:01
[12/27 15:18:15] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4843 s / img. ETA=1:33:37
[12/27 15:18:39] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4842 s / img. ETA=1:33:12
[12/27 15:19:03] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4842 s / img. ETA=1:32:48
[12/27 15:19:27] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4842 s / img. ETA=1:32:24
[12/27 15:19:52] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4842 s / img. ETA=1:32:00
[12/27 15:20:16] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4843 s / img. ETA=1:31:36
[12/27 15:20:41] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4843 s / img. ETA=1:31:12
[12/27 15:21:05] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4843 s / img. ETA=1:30:48
[12/27 15:21:29] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4843 s / img. ETA=1:30:23
[12/27 15:21:53] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4843 s / img. ETA=1:29:59
[12/27 15:22:17] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4843 s / img. ETA=1:29:35
[12/27 15:22:42] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4843 s / img. ETA=1:29:11
[12/27 15:23:06] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4842 s / img. ETA=1:28:46
[12/27 15:23:30] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4842 s / img. ETA=1:28:22
[12/27 15:23:54] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4842 s / img. ETA=1:27:58
[12/27 15:24:18] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4842 s / img. ETA=1:27:34
[12/27 15:24:43] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4843 s / img. ETA=1:27:09
[12/27 15:25:07] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4842 s / img. ETA=1:26:45
[12/27 15:25:31] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4842 s / img. ETA=1:26:21
[12/27 15:25:55] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4842 s / img. ETA=1:25:56
[12/27 15:26:19] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4842 s / img. ETA=1:25:32
[12/27 15:26:43] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4842 s / img. ETA=1:25:08
[12/27 15:27:07] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4842 s / img. ETA=1:24:43
[12/27 15:27:31] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4842 s / img. ETA=1:24:19
[12/27 15:27:55] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4841 s / img. ETA=1:23:54
[12/27 15:28:20] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4841 s / img. ETA=1:23:30
[12/27 15:28:44] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4841 s / img. ETA=1:23:06
[12/27 15:29:08] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4841 s / img. ETA=1:22:41
[12/27 15:29:32] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4841 s / img. ETA=1:22:17
[12/27 15:29:56] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4841 s / img. ETA=1:21:53
[12/27 15:30:21] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4841 s / img. ETA=1:21:29
[12/27 15:30:45] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4841 s / img. ETA=1:21:05
[12/27 15:31:09] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4841 s / img. ETA=1:20:41
[12/27 15:31:33] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4841 s / img. ETA=1:20:17
[12/27 15:31:58] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4841 s / img. ETA=1:19:52
[12/27 15:32:22] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4841 s / img. ETA=1:19:28
[12/27 15:32:46] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4841 s / img. ETA=1:19:04
[12/27 15:33:10] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4841 s / img. ETA=1:18:39
[12/27 15:33:34] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4841 s / img. ETA=1:18:15
[12/27 15:33:58] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4841 s / img. ETA=1:17:51
[12/27 15:34:22] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4841 s / img. ETA=1:17:27
[12/27 15:34:47] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4841 s / img. ETA=1:17:02
[12/27 15:35:11] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4841 s / img. ETA=1:16:38
[12/27 15:35:35] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4841 s / img. ETA=1:16:14
[12/27 15:35:59] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4840 s / img. ETA=1:15:49
[12/27 15:36:23] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4840 s / img. ETA=1:15:25
[12/27 15:36:47] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4840 s / img. ETA=1:15:01
[12/27 15:37:11] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4840 s / img. ETA=1:14:37
[12/27 15:37:35] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4840 s / img. ETA=1:14:12
[12/27 15:38:00] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4840 s / img. ETA=1:13:48
[12/27 15:38:24] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4840 s / img. ETA=1:13:24
[12/27 15:38:48] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4840 s / img. ETA=1:13:00
[12/27 15:39:13] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4841 s / img. ETA=1:12:36
[12/27 15:39:37] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4841 s / img. ETA=1:12:12
[12/27 15:40:01] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4841 s / img. ETA=1:11:48
[12/27 15:40:25] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4841 s / img. ETA=1:11:24
[12/27 15:40:50] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4841 s / img. ETA=1:11:00
[12/27 15:41:14] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4841 s / img. ETA=1:10:35
[12/27 15:41:38] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4841 s / img. ETA=1:10:11
[12/27 15:42:02] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4841 s / img. ETA=1:09:47
[12/27 15:42:27] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4841 s / img. ETA=1:09:23
[12/27 15:42:51] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4841 s / img. ETA=1:08:58
[12/27 15:43:15] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4841 s / img. ETA=1:08:34
[12/27 15:43:39] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4841 s / img. ETA=1:08:10
[12/27 15:44:03] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4840 s / img. ETA=1:07:45
[12/27 15:44:27] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4840 s / img. ETA=1:07:21
[12/27 15:44:51] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4840 s / img. ETA=1:06:57
[12/27 15:45:16] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4840 s / img. ETA=1:06:33
[12/27 15:45:40] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4840 s / img. ETA=1:06:09
[12/27 15:46:04] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4840 s / img. ETA=1:05:44
[12/27 15:46:28] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4840 s / img. ETA=1:05:20
[12/27 15:46:53] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4841 s / img. ETA=1:04:56
[12/27 15:47:17] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4841 s / img. ETA=1:04:32
[12/27 15:47:41] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4841 s / img. ETA=1:04:08
[12/27 15:48:05] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4841 s / img. ETA=1:03:44
[12/27 15:48:30] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4841 s / img. ETA=1:03:20
[12/27 15:48:54] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4841 s / img. ETA=1:02:55
[12/27 15:49:18] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4841 s / img. ETA=1:02:31
[12/27 15:49:42] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4841 s / img. ETA=1:02:07
[12/27 15:50:06] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4841 s / img. ETA=1:01:43
[12/27 15:50:31] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4841 s / img. ETA=1:01:19
[12/27 15:50:55] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4841 s / img. ETA=1:00:54
[12/27 15:51:19] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4841 s / img. ETA=1:00:30
[12/27 15:51:43] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4841 s / img. ETA=1:00:06
[12/27 15:52:07] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4841 s / img. ETA=0:59:42
[12/27 15:52:32] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4841 s / img. ETA=0:59:18
[12/27 15:52:57] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4842 s / img. ETA=0:58:54
[12/27 15:53:21] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4842 s / img. ETA=0:58:30
[12/27 15:53:45] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4842 s / img. ETA=0:58:06
[12/27 15:54:09] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4842 s / img. ETA=0:57:41
[12/27 15:54:34] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4842 s / img. ETA=0:57:17
[12/27 15:54:58] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4842 s / img. ETA=0:56:53
[12/27 15:55:22] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4842 s / img. ETA=0:56:29
[12/27 15:55:48] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4844 s / img. ETA=0:56:06
[12/27 15:56:12] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4843 s / img. ETA=0:55:41
[12/27 15:56:36] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4844 s / img. ETA=0:55:17
[12/27 15:57:01] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4844 s / img. ETA=0:54:53
[12/27 15:57:25] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4843 s / img. ETA=0:54:29
[12/27 15:57:49] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4843 s / img. ETA=0:54:05
[12/27 15:58:13] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4843 s / img. ETA=0:53:40
[12/27 15:58:37] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4843 s / img. ETA=0:53:16
[12/27 15:59:01] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4843 s / img. ETA=0:52:52
[12/27 15:59:26] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4843 s / img. ETA=0:52:28
[12/27 15:59:50] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4843 s / img. ETA=0:52:03
[12/27 16:00:14] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4843 s / img. ETA=0:51:39
[12/27 16:00:38] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4843 s / img. ETA=0:51:15
[12/27 16:01:02] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4843 s / img. ETA=0:50:51
[12/27 16:01:26] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4843 s / img. ETA=0:50:26
[12/27 16:01:51] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4843 s / img. ETA=0:50:02
[12/27 16:02:15] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4843 s / img. ETA=0:49:38
[12/27 16:02:39] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4843 s / img. ETA=0:49:14
[12/27 16:03:04] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4843 s / img. ETA=0:48:50
[12/27 16:03:28] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4843 s / img. ETA=0:48:25
[12/27 16:03:52] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4843 s / img. ETA=0:48:01
[12/27 16:04:16] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4843 s / img. ETA=0:47:37
[12/27 16:04:40] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4843 s / img. ETA=0:47:13
[12/27 16:05:04] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4843 s / img. ETA=0:46:48
[12/27 16:05:28] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4843 s / img. ETA=0:46:24
[12/27 16:05:52] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4843 s / img. ETA=0:46:00
[12/27 16:06:17] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4843 s / img. ETA=0:45:36
[12/27 16:06:41] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4843 s / img. ETA=0:45:11
[12/27 16:07:05] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4843 s / img. ETA=0:44:47
[12/27 16:07:29] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4843 s / img. ETA=0:44:23
[12/27 16:07:53] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4843 s / img. ETA=0:43:59
[12/27 16:08:17] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4842 s / img. ETA=0:43:34
[12/27 16:08:41] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4842 s / img. ETA=0:43:10
[12/27 16:09:06] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4842 s / img. ETA=0:42:46
[12/27 16:09:30] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4842 s / img. ETA=0:42:22
[12/27 16:09:54] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4842 s / img. ETA=0:41:57
[12/27 16:10:18] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4842 s / img. ETA=0:41:33
[12/27 16:10:42] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4842 s / img. ETA=0:41:09
[12/27 16:11:06] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4842 s / img. ETA=0:40:45
[12/27 16:11:31] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4842 s / img. ETA=0:40:21
[12/27 16:11:55] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4842 s / img. ETA=0:39:56
[12/27 16:12:19] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4842 s / img. ETA=0:39:32
[12/27 16:12:43] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4842 s / img. ETA=0:39:08
[12/27 16:13:08] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4842 s / img. ETA=0:38:44
[12/27 16:13:32] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4842 s / img. ETA=0:38:19
[12/27 16:13:56] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4842 s / img. ETA=0:37:55
[12/27 16:14:20] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4842 s / img. ETA=0:37:31
[12/27 16:14:44] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4842 s / img. ETA=0:37:07
[12/27 16:15:08] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4842 s / img. ETA=0:36:43
[12/27 16:15:32] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4842 s / img. ETA=0:36:18
[12/27 16:15:56] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4842 s / img. ETA=0:35:54
[12/27 16:16:21] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4842 s / img. ETA=0:35:30
[12/27 16:16:45] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4842 s / img. ETA=0:35:06
[12/27 16:17:09] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4841 s / img. ETA=0:34:41
[12/27 16:17:33] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4841 s / img. ETA=0:34:17
[12/27 16:17:57] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4841 s / img. ETA=0:33:53
[12/27 16:18:21] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4841 s / img. ETA=0:33:29
[12/27 16:18:45] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4841 s / img. ETA=0:33:04
[12/27 16:19:09] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4841 s / img. ETA=0:32:40
[12/27 16:19:34] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4841 s / img. ETA=0:32:16
[12/27 16:19:58] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4841 s / img. ETA=0:31:52
[12/27 16:20:22] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4841 s / img. ETA=0:31:28
[12/27 16:20:46] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4841 s / img. ETA=0:31:03
[12/27 16:21:10] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4841 s / img. ETA=0:30:39
[12/27 16:21:35] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4841 s / img. ETA=0:30:15
[12/27 16:21:59] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4841 s / img. ETA=0:29:51
[12/27 16:22:23] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4841 s / img. ETA=0:29:26
[12/27 16:22:47] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4841 s / img. ETA=0:29:02
[12/27 16:23:11] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4841 s / img. ETA=0:28:38
[12/27 16:23:35] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4841 s / img. ETA=0:28:14
[12/27 16:24:00] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4841 s / img. ETA=0:27:50
[12/27 16:24:24] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4841 s / img. ETA=0:27:25
[12/27 16:24:48] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4841 s / img. ETA=0:27:01
[12/27 16:25:12] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4841 s / img. ETA=0:26:37
[12/27 16:25:36] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4840 s / img. ETA=0:26:13
[12/27 16:26:00] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4840 s / img. ETA=0:25:48
[12/27 16:26:24] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4840 s / img. ETA=0:25:24
[12/27 16:26:48] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4840 s / img. ETA=0:25:00
[12/27 16:27:12] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4840 s / img. ETA=0:24:36
[12/27 16:27:36] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4840 s / img. ETA=0:24:11
[12/27 16:28:00] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4840 s / img. ETA=0:23:47
[12/27 16:28:24] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4840 s / img. ETA=0:23:23
[12/27 16:28:49] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4840 s / img. ETA=0:22:59
[12/27 16:29:13] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4840 s / img. ETA=0:22:35
[12/27 16:29:37] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4840 s / img. ETA=0:22:11
[12/27 16:30:02] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4840 s / img. ETA=0:21:46
[12/27 16:30:26] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4840 s / img. ETA=0:21:22
[12/27 16:30:50] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4840 s / img. ETA=0:20:58
[12/27 16:31:14] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4840 s / img. ETA=0:20:34
[12/27 16:31:38] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4840 s / img. ETA=0:20:09
[12/27 16:32:02] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4840 s / img. ETA=0:19:45
[12/27 16:32:26] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4840 s / img. ETA=0:19:21
[12/27 16:32:50] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4840 s / img. ETA=0:18:57
[12/27 16:33:15] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4840 s / img. ETA=0:18:33
[12/27 16:33:39] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4840 s / img. ETA=0:18:08
[12/27 16:34:03] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4840 s / img. ETA=0:17:44
[12/27 16:34:27] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4839 s / img. ETA=0:17:20
[12/27 16:34:51] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4839 s / img. ETA=0:16:56
[12/27 16:35:15] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4839 s / img. ETA=0:16:32
[12/27 16:35:39] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4839 s / img. ETA=0:16:07
[12/27 16:36:03] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4839 s / img. ETA=0:15:43
[12/27 16:36:27] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4839 s / img. ETA=0:15:19
[12/27 16:36:52] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4839 s / img. ETA=0:14:55
[12/27 16:37:16] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4839 s / img. ETA=0:14:31
[12/27 16:37:40] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4839 s / img. ETA=0:14:06
[12/27 16:38:04] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4839 s / img. ETA=0:13:42
[12/27 16:38:28] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4839 s / img. ETA=0:13:18
[12/27 16:38:52] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4839 s / img. ETA=0:12:54
[12/27 16:39:16] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4839 s / img. ETA=0:12:30
[12/27 16:39:40] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4839 s / img. ETA=0:12:05
[12/27 16:40:05] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4839 s / img. ETA=0:11:41
[12/27 16:40:29] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4839 s / img. ETA=0:11:17
[12/27 16:40:53] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4839 s / img. ETA=0:10:53
[12/27 16:41:18] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4839 s / img. ETA=0:10:29
[12/27 16:41:42] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4839 s / img. ETA=0:10:04
[12/27 16:42:06] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4839 s / img. ETA=0:09:40
[12/27 16:42:30] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4839 s / img. ETA=0:09:16
[12/27 16:42:54] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4839 s / img. ETA=0:08:52
[12/27 16:43:18] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4839 s / img. ETA=0:08:28
[12/27 16:43:42] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4839 s / img. ETA=0:08:03
[12/27 16:44:06] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4839 s / img. ETA=0:07:39
[12/27 16:44:31] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4839 s / img. ETA=0:07:15
[12/27 16:44:55] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4839 s / img. ETA=0:06:51
[12/27 16:45:19] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4839 s / img. ETA=0:06:27
[12/27 16:45:43] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4839 s / img. ETA=0:06:02
[12/27 16:46:07] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4839 s / img. ETA=0:05:38
[12/27 16:46:31] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4839 s / img. ETA=0:05:14
[12/27 16:46:55] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4838 s / img. ETA=0:04:50
[12/27 16:47:19] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4838 s / img. ETA=0:04:26
[12/27 16:47:44] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4838 s / img. ETA=0:04:01
[12/27 16:48:08] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4838 s / img. ETA=0:03:37
[12/27 16:48:32] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4838 s / img. ETA=0:03:13
[12/27 16:48:56] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4838 s / img. ETA=0:02:49
[12/27 16:49:20] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4838 s / img. ETA=0:02:25
[12/27 16:49:45] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4838 s / img. ETA=0:02:00
[12/27 16:50:09] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4838 s / img. ETA=0:01:36
[12/27 16:50:33] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4838 s / img. ETA=0:01:12
[12/27 16:50:57] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4838 s / img. ETA=0:00:48
[12/27 16:51:21] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4838 s / img. ETA=0:00:24
[12/27 16:51:45] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4838 s / img. ETA=0:00:00
[12/27 16:51:46] d2.evaluation.evaluator INFO: Total inference time: 2:15:50 (0.483823 s / img per device, on 2 devices)
[12/27 16:51:46] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:58 (0.480773 s / img per device, on 2 devices)
[12/27 16:51:48] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/27 16:51:48] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/27 16:51:49] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/27 16:52:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/27 16:52:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/27 16:52:19] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/27 16:52:19] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/27 16:52:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/27 16:52:19] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/29 09:37:48] detectron2 INFO: Rank of current process: 0. World size: 2
[12/29 09:37:52] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/29 09:37:52] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/29 09:37:52] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_val_light",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 96368  ## 46368 74368(70000) 96368
  BASE_LR: 0.01     ### 
  STEPS: (76100, 76300)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/29 09:37:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_light',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 96368
  MOMENTUM: 0.9
  STEPS: (76100, 76300)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/29 09:37:52] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/29 09:37:52] d2.utils.env INFO: Using a generated random seed 52434850
[12/29 09:37:55] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/29 09:37:56] d2.data.datasets.coco INFO: Loaded 14085 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_light.json
[12/29 09:37:56] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 4485         |   ASC-US   | 4590         |    HSIL     | 1983         |
|    LSIL    | 2574         |  Candida   | 1198         | Trichomonas | 7388         |
|            |              |            |              |             |              |
|   total    | 22218        |            |              |             |              |[0m
[12/29 09:37:56] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[12/29 09:37:56] d2.data.build INFO: Using training sampler TrainingSampler
[12/29 09:39:03] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0069999.pth
[12/29 09:39:04] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0069999.pth
[12/29 09:39:04] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0069999.pth
[12/29 09:39:04] d2.engine.train_loop INFO: Starting training from iteration 70000
[12/29 09:40:05] d2.utils.events INFO: eta: 22:19:01  iter: 70019  total_loss: 0.556  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0028  lr: 0.000100  max_mem: 8585M
[12/29 09:41:06] d2.utils.events INFO: eta: 22:17:06  iter: 70039  total_loss: 0.620  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0229  data_time: 0.0024  lr: 0.000100  max_mem: 8585M
[12/29 09:42:06] d2.utils.events INFO: eta: 22:13:11  iter: 70059  total_loss: 0.628  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0195  data_time: 0.0030  lr: 0.000100  max_mem: 8585M
[12/29 09:43:07] d2.utils.events INFO: eta: 22:12:10  iter: 70079  total_loss: 0.636  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0338  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 09:44:08] d2.utils.events INFO: eta: 22:10:39  iter: 70099  total_loss: 0.804  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 09:45:09] d2.utils.events INFO: eta: 22:11:05  iter: 70119  total_loss: 0.596  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0365  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 09:46:08] d2.utils.events INFO: eta: 22:06:49  iter: 70139  total_loss: 0.411  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0208  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 09:47:08] d2.utils.events INFO: eta: 22:05:49  iter: 70159  total_loss: 0.426  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0174  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 09:48:10] d2.utils.events INFO: eta: 22:06:52  iter: 70179  total_loss: 0.668  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0295  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 09:49:09] d2.utils.events INFO: eta: 22:05:11  iter: 70199  total_loss: 0.430  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0228  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 09:50:10] d2.utils.events INFO: eta: 22:04:11  iter: 70219  total_loss: 0.648  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.112  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0221  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 09:51:09] d2.utils.events INFO: eta: 22:01:56  iter: 70239  total_loss: 0.597  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0176  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 09:52:09] d2.utils.events INFO: eta: 22:00:24  iter: 70259  total_loss: 0.461  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0171  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 09:53:10] d2.utils.events INFO: eta: 21:59:23  iter: 70279  total_loss: 0.407  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0176  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 09:54:11] d2.utils.events INFO: eta: 21:58:49  iter: 70299  total_loss: 0.664  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0200  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 09:55:11] d2.utils.events INFO: eta: 21:57:53  iter: 70319  total_loss: 0.694  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0196  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 09:56:13] d2.utils.events INFO: eta: 21:57:38  iter: 70339  total_loss: 0.592  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0235  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 09:57:14] d2.utils.events INFO: eta: 21:56:54  iter: 70359  total_loss: 0.494  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0247  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 09:58:15] d2.utils.events INFO: eta: 21:56:01  iter: 70379  total_loss: 0.741  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0248  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 09:59:16] d2.utils.events INFO: eta: 21:55:04  iter: 70399  total_loss: 0.695  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0262  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 10:00:16] d2.utils.events INFO: eta: 21:54:00  iter: 70419  total_loss: 0.763  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0254  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:01:16] d2.utils.events INFO: eta: 21:52:59  iter: 70439  total_loss: 0.501  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0246  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 10:02:17] d2.utils.events INFO: eta: 21:52:01  iter: 70459  total_loss: 0.677  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0256  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:03:17] d2.utils.events INFO: eta: 21:51:05  iter: 70479  total_loss: 0.607  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0250  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:04:18] d2.utils.events INFO: eta: 21:50:08  iter: 70499  total_loss: 0.386  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0256  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 10:05:20] d2.utils.events INFO: eta: 21:49:28  iter: 70519  total_loss: 0.734  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0278  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:06:22] d2.utils.events INFO: eta: 21:48:51  iter: 70539  total_loss: 0.630  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 10:07:22] d2.utils.events INFO: eta: 21:47:27  iter: 70559  total_loss: 0.611  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 10:08:21] d2.utils.events INFO: eta: 21:46:26  iter: 70579  total_loss: 0.725  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 10:09:23] d2.utils.events INFO: eta: 21:45:35  iter: 70599  total_loss: 0.569  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0286  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:10:25] d2.utils.events INFO: eta: 21:44:48  iter: 70619  total_loss: 0.548  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:11:24] d2.utils.events INFO: eta: 21:43:16  iter: 70639  total_loss: 0.538  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:12:25] d2.utils.events INFO: eta: 21:42:33  iter: 70659  total_loss: 0.559  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:13:27] d2.utils.events INFO: eta: 21:41:54  iter: 70679  total_loss: 0.742  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0308  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 10:14:28] d2.utils.events INFO: eta: 21:41:20  iter: 70699  total_loss: 0.552  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:15:27] d2.utils.events INFO: eta: 21:40:00  iter: 70719  total_loss: 0.728  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 10:16:29] d2.utils.events INFO: eta: 21:39:08  iter: 70739  total_loss: 0.798  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:17:28] d2.utils.events INFO: eta: 21:37:56  iter: 70759  total_loss: 0.556  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:18:29] d2.utils.events INFO: eta: 21:36:58  iter: 70779  total_loss: 0.540  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0295  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:19:30] d2.utils.events INFO: eta: 21:35:57  iter: 70799  total_loss: 0.584  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 10:20:31] d2.utils.events INFO: eta: 21:34:56  iter: 70819  total_loss: 0.705  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 10:21:32] d2.utils.events INFO: eta: 21:33:53  iter: 70839  total_loss: 0.554  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:22:31] d2.utils.events INFO: eta: 21:32:42  iter: 70859  total_loss: 0.562  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 10:23:31] d2.utils.events INFO: eta: 21:31:24  iter: 70879  total_loss: 0.545  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:24:33] d2.utils.events INFO: eta: 21:30:51  iter: 70899  total_loss: 0.647  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:25:34] d2.utils.events INFO: eta: 21:29:52  iter: 70919  total_loss: 0.560  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0035  lr: 0.000100  max_mem: 9269M
[12/29 10:26:35] d2.utils.events INFO: eta: 21:28:49  iter: 70939  total_loss: 0.638  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:27:35] d2.utils.events INFO: eta: 21:27:45  iter: 70959  total_loss: 0.689  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 10:28:36] d2.utils.events INFO: eta: 21:26:45  iter: 70979  total_loss: 0.625  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:29:36] d2.utils.events INFO: eta: 21:25:32  iter: 70999  total_loss: 0.725  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:30:36] d2.utils.events INFO: eta: 21:24:02  iter: 71019  total_loss: 0.766  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 10:31:36] d2.utils.events INFO: eta: 21:23:00  iter: 71039  total_loss: 0.447  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:32:36] d2.utils.events INFO: eta: 21:22:03  iter: 71059  total_loss: 0.598  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 10:33:37] d2.utils.events INFO: eta: 21:20:58  iter: 71079  total_loss: 0.646  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:34:36] d2.utils.events INFO: eta: 21:19:53  iter: 71099  total_loss: 0.534  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:35:36] d2.utils.events INFO: eta: 21:18:46  iter: 71119  total_loss: 0.428  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0267  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 10:36:38] d2.utils.events INFO: eta: 21:18:23  iter: 71139  total_loss: 0.802  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0279  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 10:37:39] d2.utils.events INFO: eta: 21:17:32  iter: 71159  total_loss: 0.839  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0279  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 10:38:39] d2.utils.events INFO: eta: 21:15:46  iter: 71179  total_loss: 0.639  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0019  lr: 0.000100  max_mem: 9269M
[12/29 10:39:39] d2.utils.events INFO: eta: 21:14:58  iter: 71199  total_loss: 0.551  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 10:40:41] d2.utils.events INFO: eta: 21:14:38  iter: 71219  total_loss: 0.487  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:41:41] d2.utils.events INFO: eta: 21:13:38  iter: 71239  total_loss: 0.600  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0279  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 10:42:41] d2.utils.events INFO: eta: 21:12:48  iter: 71259  total_loss: 0.756  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0272  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 10:43:43] d2.utils.events INFO: eta: 21:11:50  iter: 71279  total_loss: 0.594  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0282  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 10:44:44] d2.utils.events INFO: eta: 21:10:49  iter: 71299  total_loss: 0.429  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 10:45:44] d2.utils.events INFO: eta: 21:09:41  iter: 71319  total_loss: 0.661  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0285  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:46:45] d2.utils.events INFO: eta: 21:08:35  iter: 71339  total_loss: 0.407  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 10:47:46] d2.utils.events INFO: eta: 21:07:33  iter: 71359  total_loss: 0.579  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:48:45] d2.utils.events INFO: eta: 21:05:54  iter: 71379  total_loss: 0.308  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.091  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:49:44] d2.utils.events INFO: eta: 21:04:35  iter: 71399  total_loss: 0.682  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0268  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 10:50:44] d2.utils.events INFO: eta: 21:03:34  iter: 71419  total_loss: 0.377  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0266  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:51:45] d2.utils.events INFO: eta: 21:02:49  iter: 71439  total_loss: 0.548  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0268  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:52:47] d2.utils.events INFO: eta: 21:01:53  iter: 71459  total_loss: 0.719  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 10:53:48] d2.utils.events INFO: eta: 21:00:52  iter: 71479  total_loss: 0.485  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0281  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 10:54:49] d2.utils.events INFO: eta: 21:00:09  iter: 71499  total_loss: 0.447  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0278  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:55:50] d2.utils.events INFO: eta: 20:58:51  iter: 71519  total_loss: 0.628  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 10:56:51] d2.utils.events INFO: eta: 20:57:50  iter: 71539  total_loss: 0.721  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0284  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 10:57:52] d2.utils.events INFO: eta: 20:57:11  iter: 71559  total_loss: 0.650  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 10:58:53] d2.utils.events INFO: eta: 20:56:11  iter: 71579  total_loss: 0.839  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0290  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 10:59:54] d2.utils.events INFO: eta: 20:54:53  iter: 71599  total_loss: 0.714  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0290  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 11:00:52] d2.utils.events INFO: eta: 20:53:37  iter: 71619  total_loss: 0.364  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0279  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 11:01:54] d2.utils.events INFO: eta: 20:52:58  iter: 71639  total_loss: 0.477  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 11:02:56] d2.utils.events INFO: eta: 20:51:58  iter: 71659  total_loss: 0.741  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 11:03:57] d2.utils.events INFO: eta: 20:50:44  iter: 71679  total_loss: 0.639  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:04:57] d2.utils.events INFO: eta: 20:48:59  iter: 71699  total_loss: 0.686  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 11:05:58] d2.utils.events INFO: eta: 20:48:17  iter: 71719  total_loss: 0.649  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 11:06:59] d2.utils.events INFO: eta: 20:47:16  iter: 71739  total_loss: 0.535  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 11:07:59] d2.utils.events INFO: eta: 20:46:17  iter: 71759  total_loss: 0.592  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 11:09:00] d2.utils.events INFO: eta: 20:45:16  iter: 71779  total_loss: 0.615  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.100  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0295  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 11:10:00] d2.utils.events INFO: eta: 20:44:08  iter: 71799  total_loss: 0.571  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0294  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:11:02] d2.utils.events INFO: eta: 20:43:11  iter: 71819  total_loss: 0.646  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:12:01] d2.utils.events INFO: eta: 20:42:23  iter: 71839  total_loss: 0.470  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 11:13:02] d2.utils.events INFO: eta: 20:41:38  iter: 71859  total_loss: 0.760  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0291  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 11:14:02] d2.utils.events INFO: eta: 20:40:49  iter: 71879  total_loss: 0.478  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 11:15:02] d2.utils.events INFO: eta: 20:39:21  iter: 71899  total_loss: 0.652  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0284  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 11:16:04] d2.utils.events INFO: eta: 20:38:35  iter: 71919  total_loss: 0.551  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0292  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 11:17:04] d2.utils.events INFO: eta: 20:37:39  iter: 71939  total_loss: 0.671  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:18:05] d2.utils.events INFO: eta: 20:36:55  iter: 71959  total_loss: 0.663  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0293  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:19:06] d2.utils.events INFO: eta: 20:35:54  iter: 71979  total_loss: 0.621  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0296  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:20:05] d2.utils.events INFO: eta: 20:35:03  iter: 71999  total_loss: 0.580  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:21:06] d2.utils.events INFO: eta: 20:34:05  iter: 72019  total_loss: 0.458  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 11:22:05] d2.utils.events INFO: eta: 20:32:35  iter: 72039  total_loss: 0.554  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0283  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:23:06] d2.utils.events INFO: eta: 20:31:35  iter: 72059  total_loss: 0.413  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.137  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0283  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:24:06] d2.utils.events INFO: eta: 20:30:41  iter: 72079  total_loss: 0.550  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 11:25:08] d2.utils.events INFO: eta: 20:30:13  iter: 72099  total_loss: 0.571  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 11:26:08] d2.utils.events INFO: eta: 20:28:58  iter: 72119  total_loss: 0.461  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0282  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 11:27:09] d2.utils.events INFO: eta: 20:27:57  iter: 72139  total_loss: 0.628  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 11:28:08] d2.utils.events INFO: eta: 20:26:33  iter: 72159  total_loss: 0.479  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0280  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 11:29:09] d2.utils.events INFO: eta: 20:26:03  iter: 72179  total_loss: 0.672  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 11:30:09] d2.utils.events INFO: eta: 20:24:49  iter: 72199  total_loss: 0.450  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 11:31:09] d2.utils.events INFO: eta: 20:22:59  iter: 72219  total_loss: 0.692  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 11:32:10] d2.utils.events INFO: eta: 20:22:11  iter: 72239  total_loss: 0.705  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:33:11] d2.utils.events INFO: eta: 20:21:21  iter: 72259  total_loss: 0.631  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0280  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 11:34:10] d2.utils.events INFO: eta: 20:19:53  iter: 72279  total_loss: 0.503  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 11:35:11] d2.utils.events INFO: eta: 20:18:52  iter: 72299  total_loss: 0.509  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 11:36:12] d2.utils.events INFO: eta: 20:17:55  iter: 72319  total_loss: 0.461  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 11:37:14] d2.utils.events INFO: eta: 20:16:54  iter: 72339  total_loss: 0.843  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0281  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 11:38:15] d2.utils.events INFO: eta: 20:15:50  iter: 72359  total_loss: 0.438  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.124  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0283  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 11:39:15] d2.utils.events INFO: eta: 20:15:12  iter: 72379  total_loss: 0.653  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0281  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:40:16] d2.utils.events INFO: eta: 20:14:23  iter: 72399  total_loss: 0.545  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0284  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:41:18] d2.utils.events INFO: eta: 20:13:53  iter: 72419  total_loss: 0.723  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0287  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:42:19] d2.utils.events INFO: eta: 20:12:52  iter: 72439  total_loss: 0.693  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0035  lr: 0.000100  max_mem: 9269M
[12/29 11:43:20] d2.utils.events INFO: eta: 20:11:39  iter: 72459  total_loss: 0.653  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 11:44:22] d2.utils.events INFO: eta: 20:11:07  iter: 72479  total_loss: 0.637  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 11:45:23] d2.utils.events INFO: eta: 20:10:12  iter: 72499  total_loss: 0.535  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 11:46:23] d2.utils.events INFO: eta: 20:08:57  iter: 72519  total_loss: 0.577  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0295  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:47:22] d2.utils.events INFO: eta: 20:07:37  iter: 72539  total_loss: 0.667  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:48:22] d2.utils.events INFO: eta: 20:06:15  iter: 72559  total_loss: 0.672  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0289  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:49:22] d2.utils.events INFO: eta: 20:04:53  iter: 72579  total_loss: 0.417  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 11:50:21] d2.utils.events INFO: eta: 20:03:44  iter: 72599  total_loss: 0.492  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0279  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:51:22] d2.utils.events INFO: eta: 20:03:13  iter: 72619  total_loss: 0.796  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0282  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 11:52:23] d2.utils.events INFO: eta: 20:02:02  iter: 72639  total_loss: 0.686  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 11:53:25] d2.utils.events INFO: eta: 20:01:23  iter: 72659  total_loss: 0.800  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0286  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 11:54:25] d2.utils.events INFO: eta: 20:00:40  iter: 72679  total_loss: 0.563  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:55:26] d2.utils.events INFO: eta: 19:59:47  iter: 72699  total_loss: 0.855  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.343  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 11:56:28] d2.utils.events INFO: eta: 19:58:54  iter: 72719  total_loss: 0.649  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 11:57:28] d2.utils.events INFO: eta: 19:57:51  iter: 72739  total_loss: 0.465  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 11:58:28] d2.utils.events INFO: eta: 19:56:45  iter: 72759  total_loss: 0.576  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 11:59:29] d2.utils.events INFO: eta: 19:55:18  iter: 72779  total_loss: 0.567  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 12:00:30] d2.utils.events INFO: eta: 19:54:55  iter: 72799  total_loss: 0.554  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:01:31] d2.utils.events INFO: eta: 19:53:47  iter: 72819  total_loss: 0.566  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:02:31] d2.utils.events INFO: eta: 19:52:16  iter: 72839  total_loss: 0.652  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 12:03:31] d2.utils.events INFO: eta: 19:51:02  iter: 72859  total_loss: 0.723  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:04:33] d2.utils.events INFO: eta: 19:50:27  iter: 72879  total_loss: 0.597  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:05:33] d2.utils.events INFO: eta: 19:49:08  iter: 72899  total_loss: 0.562  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:06:33] d2.utils.events INFO: eta: 19:47:51  iter: 72919  total_loss: 0.574  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0288  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:07:34] d2.utils.events INFO: eta: 19:46:59  iter: 72939  total_loss: 0.717  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 12:08:35] d2.utils.events INFO: eta: 19:46:05  iter: 72959  total_loss: 0.536  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:09:35] d2.utils.events INFO: eta: 19:45:02  iter: 72979  total_loss: 0.792  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 12:10:36] d2.utils.events INFO: eta: 19:44:09  iter: 72999  total_loss: 0.628  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 12:11:37] d2.utils.events INFO: eta: 19:43:02  iter: 73019  total_loss: 0.687  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 12:12:38] d2.utils.events INFO: eta: 19:42:20  iter: 73039  total_loss: 0.461  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:13:38] d2.utils.events INFO: eta: 19:41:10  iter: 73059  total_loss: 0.343  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 12:14:39] d2.utils.events INFO: eta: 19:40:43  iter: 73079  total_loss: 0.685  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:15:40] d2.utils.events INFO: eta: 19:39:26  iter: 73099  total_loss: 0.544  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 12:16:40] d2.utils.events INFO: eta: 19:38:39  iter: 73119  total_loss: 0.406  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0289  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:17:40] d2.utils.events INFO: eta: 19:37:31  iter: 73139  total_loss: 0.647  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:18:41] d2.utils.events INFO: eta: 19:36:37  iter: 73159  total_loss: 0.703  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0037  lr: 0.000100  max_mem: 9269M
[12/29 12:19:41] d2.utils.events INFO: eta: 19:35:15  iter: 73179  total_loss: 0.679  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0289  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 12:20:41] d2.utils.events INFO: eta: 19:33:59  iter: 73199  total_loss: 0.662  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 12:21:42] d2.utils.events INFO: eta: 19:33:22  iter: 73219  total_loss: 0.430  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0286  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 12:22:42] d2.utils.events INFO: eta: 19:32:39  iter: 73239  total_loss: 0.539  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:23:42] d2.utils.events INFO: eta: 19:31:38  iter: 73259  total_loss: 0.646  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0283  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 12:24:43] d2.utils.events INFO: eta: 19:30:59  iter: 73279  total_loss: 0.579  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0286  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 12:25:46] d2.utils.events INFO: eta: 19:30:05  iter: 73299  total_loss: 0.726  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0293  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 12:26:47] d2.utils.events INFO: eta: 19:29:04  iter: 73319  total_loss: 0.758  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:27:47] d2.utils.events INFO: eta: 19:27:45  iter: 73339  total_loss: 0.618  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 12:28:48] d2.utils.events INFO: eta: 19:26:55  iter: 73359  total_loss: 0.660  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:29:48] d2.utils.events INFO: eta: 19:26:00  iter: 73379  total_loss: 0.629  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:30:50] d2.utils.events INFO: eta: 19:24:48  iter: 73399  total_loss: 0.619  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0295  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 12:31:50] d2.utils.events INFO: eta: 19:23:32  iter: 73419  total_loss: 0.750  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:32:50] d2.utils.events INFO: eta: 19:22:28  iter: 73439  total_loss: 0.464  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:33:50] d2.utils.events INFO: eta: 19:21:24  iter: 73459  total_loss: 0.532  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:34:50] d2.utils.events INFO: eta: 19:19:45  iter: 73479  total_loss: 0.763  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0288  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 12:35:51] d2.utils.events INFO: eta: 19:18:44  iter: 73499  total_loss: 0.784  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:36:53] d2.utils.events INFO: eta: 19:18:12  iter: 73519  total_loss: 0.512  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0293  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:37:54] d2.utils.events INFO: eta: 19:17:13  iter: 73539  total_loss: 0.581  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:38:54] d2.utils.events INFO: eta: 19:16:13  iter: 73559  total_loss: 0.726  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0293  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 12:39:57] d2.utils.events INFO: eta: 19:15:40  iter: 73579  total_loss: 0.633  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 12:40:58] d2.utils.events INFO: eta: 19:14:53  iter: 73599  total_loss: 0.714  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:42:00] d2.utils.events INFO: eta: 19:13:55  iter: 73619  total_loss: 0.590  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.005  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:43:00] d2.utils.events INFO: eta: 19:12:50  iter: 73639  total_loss: 0.674  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:43:59] d2.utils.events INFO: eta: 19:11:18  iter: 73659  total_loss: 0.522  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0296  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:45:00] d2.utils.events INFO: eta: 19:10:17  iter: 73679  total_loss: 0.804  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 12:45:59] d2.utils.events INFO: eta: 19:09:08  iter: 73699  total_loss: 0.531  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0294  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:46:59] d2.utils.events INFO: eta: 19:08:06  iter: 73719  total_loss: 0.531  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 12:47:59] d2.utils.events INFO: eta: 19:07:06  iter: 73739  total_loss: 0.651  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 12:49:00] d2.utils.events INFO: eta: 19:06:14  iter: 73759  total_loss: 0.585  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 12:50:01] d2.utils.events INFO: eta: 19:05:15  iter: 73779  total_loss: 0.506  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0292  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:51:01] d2.utils.events INFO: eta: 19:04:00  iter: 73799  total_loss: 0.738  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0291  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 12:52:00] d2.utils.events INFO: eta: 19:02:38  iter: 73819  total_loss: 0.586  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 12:53:03] d2.utils.events INFO: eta: 19:02:13  iter: 73839  total_loss: 0.682  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0292  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 12:54:04] d2.utils.events INFO: eta: 19:01:23  iter: 73859  total_loss: 0.743  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0294  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 12:55:06] d2.utils.events INFO: eta: 19:00:16  iter: 73879  total_loss: 0.760  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0298  data_time: 0.0034  lr: 0.000100  max_mem: 9269M
[12/29 12:56:07] d2.utils.events INFO: eta: 18:59:22  iter: 73899  total_loss: 0.729  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 12:57:07] d2.utils.events INFO: eta: 18:58:09  iter: 73919  total_loss: 0.572  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 12:58:07] d2.utils.events INFO: eta: 18:57:02  iter: 73939  total_loss: 0.698  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0295  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 12:59:06] d2.utils.events INFO: eta: 18:55:36  iter: 73959  total_loss: 0.605  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:00:08] d2.utils.events INFO: eta: 18:54:56  iter: 73979  total_loss: 0.755  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0294  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:01:08] d2.utils.events INFO: eta: 18:53:45  iter: 73999  total_loss: 0.879  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0293  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 13:02:08] d2.utils.events INFO: eta: 18:52:54  iter: 74019  total_loss: 0.555  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 13:03:09] d2.utils.events INFO: eta: 18:52:02  iter: 74039  total_loss: 0.557  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:04:10] d2.utils.events INFO: eta: 18:51:16  iter: 74059  total_loss: 0.555  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0295  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 13:05:10] d2.utils.events INFO: eta: 18:49:51  iter: 74079  total_loss: 0.558  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 13:06:10] d2.utils.events INFO: eta: 18:48:51  iter: 74099  total_loss: 0.655  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0291  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:07:12] d2.utils.events INFO: eta: 18:47:59  iter: 74119  total_loss: 0.782  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0294  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 13:08:11] d2.utils.events INFO: eta: 18:46:48  iter: 74139  total_loss: 0.687  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0291  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 13:09:11] d2.utils.events INFO: eta: 18:45:49  iter: 74159  total_loss: 0.658  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0289  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 13:10:11] d2.utils.events INFO: eta: 18:44:41  iter: 74179  total_loss: 0.703  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0287  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:11:12] d2.utils.events INFO: eta: 18:43:47  iter: 74199  total_loss: 0.621  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0288  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 13:12:12] d2.utils.events INFO: eta: 18:42:39  iter: 74219  total_loss: 0.645  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 13:13:13] d2.utils.events INFO: eta: 18:41:25  iter: 74239  total_loss: 0.793  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 13:14:14] d2.utils.events INFO: eta: 18:40:29  iter: 74259  total_loss: 0.762  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:15:15] d2.utils.events INFO: eta: 18:39:15  iter: 74279  total_loss: 0.737  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0289  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 13:16:15] d2.utils.events INFO: eta: 18:38:03  iter: 74299  total_loss: 0.540  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:17:15] d2.utils.events INFO: eta: 18:36:41  iter: 74319  total_loss: 0.423  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.128  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 13:18:15] d2.utils.events INFO: eta: 18:35:54  iter: 74339  total_loss: 0.484  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 13:19:16] d2.utils.events INFO: eta: 18:34:53  iter: 74359  total_loss: 0.665  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:20:17] d2.utils.events INFO: eta: 18:33:59  iter: 74379  total_loss: 0.675  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0286  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:21:18] d2.utils.events INFO: eta: 18:32:59  iter: 74399  total_loss: 0.469  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0287  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:22:18] d2.utils.events INFO: eta: 18:31:50  iter: 74419  total_loss: 0.545  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:23:18] d2.utils.events INFO: eta: 18:30:37  iter: 74439  total_loss: 0.536  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 13:24:19] d2.utils.events INFO: eta: 18:29:56  iter: 74459  total_loss: 0.641  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:25:20] d2.utils.events INFO: eta: 18:29:07  iter: 74479  total_loss: 0.789  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0288  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 13:26:20] d2.utils.events INFO: eta: 18:27:31  iter: 74499  total_loss: 0.561  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 13:27:22] d2.utils.events INFO: eta: 18:26:42  iter: 74519  total_loss: 0.539  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0033  lr: 0.000100  max_mem: 9269M
[12/29 13:28:21] d2.utils.events INFO: eta: 18:25:25  iter: 74539  total_loss: 0.591  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 13:29:21] d2.utils.events INFO: eta: 18:24:24  iter: 74559  total_loss: 0.646  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0283  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:30:20] d2.utils.events INFO: eta: 18:22:49  iter: 74579  total_loss: 0.617  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0281  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:31:20] d2.utils.events INFO: eta: 18:21:39  iter: 74599  total_loss: 0.798  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0278  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:32:21] d2.utils.events INFO: eta: 18:20:34  iter: 74619  total_loss: 0.638  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0280  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:33:22] d2.utils.events INFO: eta: 18:19:44  iter: 74639  total_loss: 0.456  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.082  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0281  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 13:34:21] d2.utils.events INFO: eta: 18:18:42  iter: 74659  total_loss: 0.612  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0278  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:35:22] d2.utils.events INFO: eta: 18:17:43  iter: 74679  total_loss: 0.662  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0279  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 13:36:23] d2.utils.events INFO: eta: 18:17:06  iter: 74699  total_loss: 0.635  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0279  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 13:37:24] d2.utils.events INFO: eta: 18:16:13  iter: 74719  total_loss: 0.622  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0281  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 13:38:26] d2.utils.events INFO: eta: 18:15:17  iter: 74739  total_loss: 0.527  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0282  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:39:26] d2.utils.events INFO: eta: 18:14:14  iter: 74759  total_loss: 0.612  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 13:40:27] d2.utils.events INFO: eta: 18:13:26  iter: 74779  total_loss: 0.678  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0283  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 13:41:26] d2.utils.events INFO: eta: 18:12:20  iter: 74799  total_loss: 0.539  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0280  data_time: 0.0031  lr: 0.000100  max_mem: 9269M
[12/29 13:42:28] d2.utils.events INFO: eta: 18:11:43  iter: 74819  total_loss: 0.521  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 13:43:29] d2.utils.events INFO: eta: 18:10:34  iter: 74839  total_loss: 0.590  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0282  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 13:44:28] d2.utils.events INFO: eta: 18:09:20  iter: 74859  total_loss: 0.573  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0281  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 13:45:28] d2.utils.events INFO: eta: 18:07:53  iter: 74879  total_loss: 0.539  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0279  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 13:46:30] d2.utils.events INFO: eta: 18:07:18  iter: 74899  total_loss: 0.808  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:47:30] d2.utils.events INFO: eta: 18:06:25  iter: 74919  total_loss: 0.723  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0280  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 13:48:30] d2.utils.events INFO: eta: 18:05:38  iter: 74939  total_loss: 0.748  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.099  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0280  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 13:49:32] d2.utils.events INFO: eta: 18:04:45  iter: 74959  total_loss: 0.834  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0281  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 13:50:32] d2.utils.events INFO: eta: 18:03:44  iter: 74979  total_loss: 0.649  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 13:51:33] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0074999.pth
[12/29 13:51:39] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/29 13:51:39] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 760          |   ASC-US   | 760          |    HSIL     | 365          |
|    LSIL    | 416          |  Candida   | 197          | Trichomonas | 1144         |
|            |              |            |              |             |              |
|   total    | 3642         |            |              |             |              |[0m
[12/29 13:51:39] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/29 13:52:45] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4808 s / img. ETA=0:09:00
[12/29 13:53:09] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4818 s / img. ETA=0:08:37
[12/29 13:53:33] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4818 s / img. ETA=0:08:13
[12/29 13:53:57] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4820 s / img. ETA=0:07:49
[12/29 13:54:21] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4819 s / img. ETA=0:07:25
[12/29 13:54:46] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4819 s / img. ETA=0:07:01
[12/29 13:55:10] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4818 s / img. ETA=0:06:36
[12/29 13:55:35] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4839 s / img. ETA=0:06:14
[12/29 13:56:00] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4858 s / img. ETA=0:05:51
[12/29 13:56:24] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4854 s / img. ETA=0:05:27
[12/29 13:56:48] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4851 s / img. ETA=0:05:02
[12/29 13:57:12] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4848 s / img. ETA=0:04:38
[12/29 13:57:36] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4847 s / img. ETA=0:04:13
[12/29 13:58:00] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4847 s / img. ETA=0:03:49
[12/29 13:58:25] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4850 s / img. ETA=0:03:25
[12/29 13:58:49] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4851 s / img. ETA=0:03:01
[12/29 13:59:13] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4852 s / img. ETA=0:02:37
[12/29 13:59:37] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4850 s / img. ETA=0:02:12
[12/29 14:00:02] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4848 s / img. ETA=0:01:48
[12/29 14:00:26] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4847 s / img. ETA=0:01:24
[12/29 14:00:50] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4846 s / img. ETA=0:01:00
[12/29 14:01:14] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4844 s / img. ETA=0:00:35
[12/29 14:01:38] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4843 s / img. ETA=0:00:11
[12/29 14:01:50] d2.evaluation.evaluator INFO: Total inference time: 0:09:26 (0.484175 s / img per device, on 2 devices)
[12/29 14:01:50] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:22 (0.481190 s / img per device, on 2 devices)
[12/29 14:01:50] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/29 14:01:50] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/29 14:01:50] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/29 14:01:54] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.257 | 70.410 | 55.321 | 22.618 | 42.191 | 50.744 |
[12/29 14:01:54] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 52.906 | ASC-US     | 48.048 | HSIL        | 65.884 |
| LSIL       | 62.134 | Candida    | 46.155 | Trichomonas | 20.418 |
[12/29 14:01:54] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/29 14:01:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/29 14:01:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/29 14:01:54] d2.evaluation.testing INFO: copypaste: 49.2575,70.4104,55.3208,22.6177,42.1915,50.7435
[12/29 14:01:54] d2.utils.events INFO: eta: 18:02:36  iter: 74999  total_loss: 0.580  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0281  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 14:02:56] d2.utils.events INFO: eta: 18:01:49  iter: 75019  total_loss: 0.685  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0283  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 14:03:56] d2.utils.events INFO: eta: 18:00:34  iter: 75039  total_loss: 0.581  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0282  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 14:04:58] d2.utils.events INFO: eta: 17:59:30  iter: 75059  total_loss: 0.475  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:05:58] d2.utils.events INFO: eta: 17:58:48  iter: 75079  total_loss: 0.731  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0284  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 14:06:59] d2.utils.events INFO: eta: 17:57:35  iter: 75099  total_loss: 0.495  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 14:08:02] d2.utils.events INFO: eta: 17:57:00  iter: 75119  total_loss: 0.766  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.100  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:09:02] d2.utils.events INFO: eta: 17:56:09  iter: 75139  total_loss: 0.586  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:10:03] d2.utils.events INFO: eta: 17:55:13  iter: 75159  total_loss: 0.526  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 14:11:03] d2.utils.events INFO: eta: 17:54:12  iter: 75179  total_loss: 0.581  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 14:12:03] d2.utils.events INFO: eta: 17:53:21  iter: 75199  total_loss: 0.629  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:13:04] d2.utils.events INFO: eta: 17:52:16  iter: 75219  total_loss: 0.692  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:14:03] d2.utils.events INFO: eta: 17:51:20  iter: 75239  total_loss: 0.551  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:15:04] d2.utils.events INFO: eta: 17:50:06  iter: 75259  total_loss: 0.551  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 14:16:03] d2.utils.events INFO: eta: 17:49:01  iter: 75279  total_loss: 0.630  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0281  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:17:03] d2.utils.events INFO: eta: 17:48:13  iter: 75299  total_loss: 0.465  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:18:03] d2.utils.events INFO: eta: 17:47:20  iter: 75319  total_loss: 0.719  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0280  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:19:04] d2.utils.events INFO: eta: 17:46:22  iter: 75339  total_loss: 0.764  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0280  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:20:04] d2.utils.events INFO: eta: 17:45:15  iter: 75359  total_loss: 0.757  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0279  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 14:21:06] d2.utils.events INFO: eta: 17:44:17  iter: 75379  total_loss: 0.576  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0281  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:22:06] d2.utils.events INFO: eta: 17:43:08  iter: 75399  total_loss: 0.409  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0280  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:23:05] d2.utils.events INFO: eta: 17:42:15  iter: 75419  total_loss: 0.741  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0279  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:24:04] d2.utils.events INFO: eta: 17:41:18  iter: 75439  total_loss: 0.585  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 14:25:05] d2.utils.events INFO: eta: 17:40:14  iter: 75459  total_loss: 0.498  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:26:06] d2.utils.events INFO: eta: 17:39:18  iter: 75479  total_loss: 0.681  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0277  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 14:27:07] d2.utils.events INFO: eta: 17:38:17  iter: 75499  total_loss: 0.592  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 14:28:07] d2.utils.events INFO: eta: 17:36:59  iter: 75519  total_loss: 0.412  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:29:07] d2.utils.events INFO: eta: 17:35:50  iter: 75539  total_loss: 0.612  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0274  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 14:30:07] d2.utils.events INFO: eta: 17:34:41  iter: 75559  total_loss: 0.533  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:31:09] d2.utils.events INFO: eta: 17:33:45  iter: 75579  total_loss: 0.644  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0276  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:32:09] d2.utils.events INFO: eta: 17:32:55  iter: 75599  total_loss: 0.632  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:33:09] d2.utils.events INFO: eta: 17:31:48  iter: 75619  total_loss: 0.558  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 14:34:10] d2.utils.events INFO: eta: 17:30:45  iter: 75639  total_loss: 0.536  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 14:35:11] d2.utils.events INFO: eta: 17:29:53  iter: 75659  total_loss: 0.642  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 14:36:11] d2.utils.events INFO: eta: 17:28:46  iter: 75679  total_loss: 0.696  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:37:10] d2.utils.events INFO: eta: 17:27:40  iter: 75699  total_loss: 0.621  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0273  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:38:11] d2.utils.events INFO: eta: 17:26:34  iter: 75719  total_loss: 0.627  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 14:39:11] d2.utils.events INFO: eta: 17:25:13  iter: 75739  total_loss: 0.512  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 14:40:12] d2.utils.events INFO: eta: 17:24:32  iter: 75759  total_loss: 0.759  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0273  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:41:13] d2.utils.events INFO: eta: 17:23:11  iter: 75779  total_loss: 0.656  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0273  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:42:14] d2.utils.events INFO: eta: 17:22:30  iter: 75799  total_loss: 0.469  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:43:15] d2.utils.events INFO: eta: 17:21:29  iter: 75819  total_loss: 0.608  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 14:44:17] d2.utils.events INFO: eta: 17:20:31  iter: 75839  total_loss: 0.613  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0278  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:45:17] d2.utils.events INFO: eta: 17:19:28  iter: 75859  total_loss: 0.637  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:46:17] d2.utils.events INFO: eta: 17:18:26  iter: 75879  total_loss: 0.801  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:47:17] d2.utils.events INFO: eta: 17:16:47  iter: 75899  total_loss: 0.611  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:48:18] d2.utils.events INFO: eta: 17:16:04  iter: 75919  total_loss: 0.682  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:49:19] d2.utils.events INFO: eta: 17:14:48  iter: 75939  total_loss: 0.541  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 14:50:18] d2.utils.events INFO: eta: 17:13:24  iter: 75959  total_loss: 0.864  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0274  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 14:51:18] d2.utils.events INFO: eta: 17:12:16  iter: 75979  total_loss: 0.696  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:52:20] d2.utils.events INFO: eta: 17:11:36  iter: 75999  total_loss: 0.632  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 14:53:21] d2.utils.events INFO: eta: 17:10:42  iter: 76019  total_loss: 0.644  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 14:54:21] d2.utils.events INFO: eta: 17:09:42  iter: 76039  total_loss: 0.551  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 14:55:22] d2.utils.events INFO: eta: 17:08:25  iter: 76059  total_loss: 0.616  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:56:25] d2.utils.events INFO: eta: 17:07:39  iter: 76079  total_loss: 0.387  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.082  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0278  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 14:57:24] d2.utils.events INFO: eta: 17:06:26  iter: 76099  total_loss: 0.612  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:58:26] d2.utils.events INFO: eta: 17:05:25  iter: 76119  total_loss: 0.728  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0279  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 14:59:28] d2.utils.events INFO: eta: 17:04:31  iter: 76139  total_loss: 0.741  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0280  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:00:29] d2.utils.events INFO: eta: 17:03:21  iter: 76159  total_loss: 0.694  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0281  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:01:28] d2.utils.events INFO: eta: 17:02:16  iter: 76179  total_loss: 0.573  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0278  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:02:27] d2.utils.events INFO: eta: 17:00:42  iter: 76199  total_loss: 0.619  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:03:27] d2.utils.events INFO: eta: 16:59:33  iter: 76219  total_loss: 0.516  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 15:04:28] d2.utils.events INFO: eta: 16:58:41  iter: 76239  total_loss: 0.591  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:05:29] d2.utils.events INFO: eta: 16:57:54  iter: 76259  total_loss: 0.776  loss_cls_stage0: 0.087  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.093  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 15:06:30] d2.utils.events INFO: eta: 16:57:15  iter: 76279  total_loss: 0.691  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0277  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:07:29] d2.utils.events INFO: eta: 16:55:52  iter: 76299  total_loss: 0.485  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:08:29] d2.utils.events INFO: eta: 16:54:52  iter: 76319  total_loss: 0.570  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:09:29] d2.utils.events INFO: eta: 16:53:51  iter: 76339  total_loss: 0.653  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 15:10:27] d2.utils.events INFO: eta: 16:52:28  iter: 76359  total_loss: 0.599  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:11:28] d2.utils.events INFO: eta: 16:51:28  iter: 76379  total_loss: 0.719  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:12:29] d2.utils.events INFO: eta: 16:50:40  iter: 76399  total_loss: 0.565  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:13:30] d2.utils.events INFO: eta: 16:49:34  iter: 76419  total_loss: 0.565  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:14:31] d2.utils.events INFO: eta: 16:48:39  iter: 76439  total_loss: 0.507  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:15:31] d2.utils.events INFO: eta: 16:47:25  iter: 76459  total_loss: 0.529  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 15:16:32] d2.utils.events INFO: eta: 16:46:05  iter: 76479  total_loss: 0.783  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.087  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.095  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0272  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 15:17:32] d2.utils.events INFO: eta: 16:44:49  iter: 76499  total_loss: 0.563  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:18:34] d2.utils.events INFO: eta: 16:43:58  iter: 76519  total_loss: 0.611  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 15:19:35] d2.utils.events INFO: eta: 16:43:28  iter: 76539  total_loss: 0.732  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0274  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 15:20:37] d2.utils.events INFO: eta: 16:42:39  iter: 76559  total_loss: 0.625  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 15:21:39] d2.utils.events INFO: eta: 16:42:05  iter: 76579  total_loss: 0.549  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:22:38] d2.utils.events INFO: eta: 16:40:59  iter: 76599  total_loss: 0.607  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 15:23:37] d2.utils.events INFO: eta: 16:39:27  iter: 76619  total_loss: 0.603  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:24:37] d2.utils.events INFO: eta: 16:38:18  iter: 76639  total_loss: 0.628  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:25:37] d2.utils.events INFO: eta: 16:37:04  iter: 76659  total_loss: 0.578  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:26:38] d2.utils.events INFO: eta: 16:36:23  iter: 76679  total_loss: 0.678  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:27:40] d2.utils.events INFO: eta: 16:35:50  iter: 76699  total_loss: 0.690  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:28:40] d2.utils.events INFO: eta: 16:34:49  iter: 76719  total_loss: 0.680  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:29:40] d2.utils.events INFO: eta: 16:33:43  iter: 76739  total_loss: 0.568  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 15:30:40] d2.utils.events INFO: eta: 16:32:20  iter: 76759  total_loss: 0.608  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:31:42] d2.utils.events INFO: eta: 16:31:33  iter: 76779  total_loss: 0.555  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 15:32:43] d2.utils.events INFO: eta: 16:30:33  iter: 76799  total_loss: 0.695  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:33:44] d2.utils.events INFO: eta: 16:29:20  iter: 76819  total_loss: 0.450  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:34:43] d2.utils.events INFO: eta: 16:27:47  iter: 76839  total_loss: 0.579  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 15:35:43] d2.utils.events INFO: eta: 16:27:14  iter: 76859  total_loss: 0.513  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:36:43] d2.utils.events INFO: eta: 16:26:22  iter: 76879  total_loss: 0.743  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:37:43] d2.utils.events INFO: eta: 16:25:37  iter: 76899  total_loss: 0.568  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 15:38:43] d2.utils.events INFO: eta: 16:24:21  iter: 76919  total_loss: 0.730  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:39:44] d2.utils.events INFO: eta: 16:23:20  iter: 76939  total_loss: 0.472  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 15:40:44] d2.utils.events INFO: eta: 16:22:50  iter: 76959  total_loss: 0.724  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 15:41:44] d2.utils.events INFO: eta: 16:21:49  iter: 76979  total_loss: 0.879  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0269  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 15:42:45] d2.utils.events INFO: eta: 16:21:01  iter: 76999  total_loss: 0.606  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:43:45] d2.utils.events INFO: eta: 16:19:37  iter: 77019  total_loss: 0.584  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0268  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 15:44:47] d2.utils.events INFO: eta: 16:18:43  iter: 77039  total_loss: 0.610  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0270  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:45:47] d2.utils.events INFO: eta: 16:17:50  iter: 77059  total_loss: 0.582  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:46:49] d2.utils.events INFO: eta: 16:16:45  iter: 77079  total_loss: 0.571  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 15:47:48] d2.utils.events INFO: eta: 16:16:10  iter: 77099  total_loss: 0.473  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 15:48:47] d2.utils.events INFO: eta: 16:14:21  iter: 77119  total_loss: 0.574  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0266  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:49:47] d2.utils.events INFO: eta: 16:13:10  iter: 77139  total_loss: 0.727  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0266  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:50:48] d2.utils.events INFO: eta: 16:12:12  iter: 77159  total_loss: 0.533  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0266  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:51:48] d2.utils.events INFO: eta: 16:11:55  iter: 77179  total_loss: 0.654  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0266  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:52:49] d2.utils.events INFO: eta: 16:11:29  iter: 77199  total_loss: 0.728  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0266  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 15:53:49] d2.utils.events INFO: eta: 16:10:31  iter: 77219  total_loss: 0.570  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0266  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 15:54:50] d2.utils.events INFO: eta: 16:09:19  iter: 77239  total_loss: 0.513  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0267  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 15:55:52] d2.utils.events INFO: eta: 16:08:10  iter: 77259  total_loss: 0.768  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0268  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 15:56:53] d2.utils.events INFO: eta: 16:07:10  iter: 77279  total_loss: 0.719  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0268  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 15:57:54] d2.utils.events INFO: eta: 16:06:35  iter: 77299  total_loss: 0.514  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 15:58:56] d2.utils.events INFO: eta: 16:05:47  iter: 77319  total_loss: 0.541  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 15:59:56] d2.utils.events INFO: eta: 16:04:55  iter: 77339  total_loss: 0.549  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:00:54] d2.utils.events INFO: eta: 16:03:56  iter: 77359  total_loss: 0.706  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0267  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:01:54] d2.utils.events INFO: eta: 16:02:37  iter: 77379  total_loss: 0.760  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0266  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 16:02:55] d2.utils.events INFO: eta: 16:01:35  iter: 77399  total_loss: 0.643  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0266  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:03:53] d2.utils.events INFO: eta: 16:00:31  iter: 77419  total_loss: 0.534  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0264  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:04:55] d2.utils.events INFO: eta: 15:59:30  iter: 77439  total_loss: 0.645  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0265  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:05:55] d2.utils.events INFO: eta: 15:58:25  iter: 77459  total_loss: 0.820  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.006  loss_rpn_loc: 0.012  time: 3.0264  data_time: 0.0038  lr: 0.000100  max_mem: 9269M
[12/29 16:06:56] d2.utils.events INFO: eta: 15:57:21  iter: 77479  total_loss: 0.523  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0265  data_time: 0.0041  lr: 0.000100  max_mem: 9269M
[12/29 16:07:57] d2.utils.events INFO: eta: 15:56:39  iter: 77499  total_loss: 0.432  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0266  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:08:58] d2.utils.events INFO: eta: 15:55:46  iter: 77519  total_loss: 0.580  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0267  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:09:59] d2.utils.events INFO: eta: 15:54:45  iter: 77539  total_loss: 0.573  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0266  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 16:10:59] d2.utils.events INFO: eta: 15:53:28  iter: 77559  total_loss: 0.571  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0266  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:12:02] d2.utils.events INFO: eta: 15:52:32  iter: 77579  total_loss: 0.480  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:13:03] d2.utils.events INFO: eta: 15:51:33  iter: 77599  total_loss: 0.591  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:14:03] d2.utils.events INFO: eta: 15:50:41  iter: 77619  total_loss: 0.786  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:15:05] d2.utils.events INFO: eta: 15:49:48  iter: 77639  total_loss: 0.643  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:16:07] d2.utils.events INFO: eta: 15:48:49  iter: 77659  total_loss: 0.476  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:17:06] d2.utils.events INFO: eta: 15:47:45  iter: 77679  total_loss: 0.545  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:18:07] d2.utils.events INFO: eta: 15:46:43  iter: 77699  total_loss: 0.568  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:19:07] d2.utils.events INFO: eta: 15:45:46  iter: 77719  total_loss: 0.522  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:20:07] d2.utils.events INFO: eta: 15:44:44  iter: 77739  total_loss: 0.463  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:21:09] d2.utils.events INFO: eta: 15:43:47  iter: 77759  total_loss: 0.432  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:22:09] d2.utils.events INFO: eta: 15:42:42  iter: 77779  total_loss: 0.676  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:23:08] d2.utils.events INFO: eta: 15:41:37  iter: 77799  total_loss: 0.531  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:24:07] d2.utils.events INFO: eta: 15:40:33  iter: 77819  total_loss: 0.860  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0267  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:25:08] d2.utils.events INFO: eta: 15:39:36  iter: 77839  total_loss: 0.402  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0268  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:26:08] d2.utils.events INFO: eta: 15:38:35  iter: 77859  total_loss: 0.504  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0267  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:27:11] d2.utils.events INFO: eta: 15:37:37  iter: 77879  total_loss: 0.653  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:28:11] d2.utils.events INFO: eta: 15:36:38  iter: 77899  total_loss: 0.798  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0269  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 16:29:10] d2.utils.events INFO: eta: 15:35:33  iter: 77919  total_loss: 0.600  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0268  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 16:30:09] d2.utils.events INFO: eta: 15:34:31  iter: 77939  total_loss: 0.434  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0265  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:31:08] d2.utils.events INFO: eta: 15:33:16  iter: 77959  total_loss: 0.557  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0264  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:32:08] d2.utils.events INFO: eta: 15:32:11  iter: 77979  total_loss: 0.651  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0263  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 16:33:09] d2.utils.events INFO: eta: 15:30:52  iter: 77999  total_loss: 0.509  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0263  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:34:09] d2.utils.events INFO: eta: 15:29:55  iter: 78019  total_loss: 0.544  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0263  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:35:10] d2.utils.events INFO: eta: 15:28:51  iter: 78039  total_loss: 0.714  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0263  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:36:11] d2.utils.events INFO: eta: 15:27:50  iter: 78059  total_loss: 0.775  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0263  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:37:09] d2.utils.events INFO: eta: 15:26:13  iter: 78079  total_loss: 0.511  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0261  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:38:11] d2.utils.events INFO: eta: 15:25:12  iter: 78099  total_loss: 0.657  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0262  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:39:13] d2.utils.events INFO: eta: 15:24:21  iter: 78119  total_loss: 0.595  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0263  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 16:40:13] d2.utils.events INFO: eta: 15:23:34  iter: 78139  total_loss: 0.506  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0263  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 16:41:15] d2.utils.events INFO: eta: 15:22:47  iter: 78159  total_loss: 0.609  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0265  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:42:15] d2.utils.events INFO: eta: 15:21:20  iter: 78179  total_loss: 0.436  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0264  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:43:17] d2.utils.events INFO: eta: 15:20:19  iter: 78199  total_loss: 0.563  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0266  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:44:16] d2.utils.events INFO: eta: 15:19:14  iter: 78219  total_loss: 0.632  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0265  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 16:45:17] d2.utils.events INFO: eta: 15:18:42  iter: 78239  total_loss: 0.464  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.125  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0265  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:46:15] d2.utils.events INFO: eta: 15:17:05  iter: 78259  total_loss: 0.575  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0262  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:47:14] d2.utils.events INFO: eta: 15:15:44  iter: 78279  total_loss: 0.423  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.090  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0260  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:48:14] d2.utils.events INFO: eta: 15:14:08  iter: 78299  total_loss: 0.529  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0258  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:49:14] d2.utils.events INFO: eta: 15:12:58  iter: 78319  total_loss: 0.488  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0258  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:50:15] d2.utils.events INFO: eta: 15:11:58  iter: 78339  total_loss: 0.620  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0259  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:51:14] d2.utils.events INFO: eta: 15:11:15  iter: 78359  total_loss: 0.581  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0257  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:52:14] d2.utils.events INFO: eta: 15:10:40  iter: 78379  total_loss: 0.511  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0256  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:53:15] d2.utils.events INFO: eta: 15:09:39  iter: 78399  total_loss: 0.656  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0257  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 16:54:17] d2.utils.events INFO: eta: 15:08:59  iter: 78419  total_loss: 0.520  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0258  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 16:55:18] d2.utils.events INFO: eta: 15:07:47  iter: 78439  total_loss: 0.586  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0260  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 16:56:21] d2.utils.events INFO: eta: 15:07:05  iter: 78459  total_loss: 0.761  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0262  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 16:57:22] d2.utils.events INFO: eta: 15:06:00  iter: 78479  total_loss: 0.769  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0262  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 16:58:24] d2.utils.events INFO: eta: 15:04:53  iter: 78499  total_loss: 0.609  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0264  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 16:59:22] d2.utils.events INFO: eta: 15:03:21  iter: 78519  total_loss: 0.607  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0261  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 17:00:23] d2.utils.events INFO: eta: 15:02:34  iter: 78539  total_loss: 0.927  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.268  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.380  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0262  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:01:24] d2.utils.events INFO: eta: 15:01:54  iter: 78559  total_loss: 0.666  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0262  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:02:23] d2.utils.events INFO: eta: 15:00:33  iter: 78579  total_loss: 0.525  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0261  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:03:23] d2.utils.events INFO: eta: 14:59:15  iter: 78599  total_loss: 0.543  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0260  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 17:04:23] d2.utils.events INFO: eta: 14:58:06  iter: 78619  total_loss: 0.428  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0259  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:05:24] d2.utils.events INFO: eta: 14:56:49  iter: 78639  total_loss: 0.635  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0260  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 17:06:24] d2.utils.events INFO: eta: 14:55:36  iter: 78659  total_loss: 0.664  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.125  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0259  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:07:25] d2.utils.events INFO: eta: 14:54:26  iter: 78679  total_loss: 0.621  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0260  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 17:08:27] d2.utils.events INFO: eta: 14:53:35  iter: 78699  total_loss: 0.395  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0261  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:09:28] d2.utils.events INFO: eta: 14:52:39  iter: 78719  total_loss: 0.479  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0262  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:10:28] d2.utils.events INFO: eta: 14:51:45  iter: 78739  total_loss: 0.584  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0262  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:11:29] d2.utils.events INFO: eta: 14:50:44  iter: 78759  total_loss: 0.670  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0262  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:12:28] d2.utils.events INFO: eta: 14:49:32  iter: 78779  total_loss: 0.612  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0260  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:13:31] d2.utils.events INFO: eta: 14:49:18  iter: 78799  total_loss: 0.482  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0263  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 17:14:33] d2.utils.events INFO: eta: 14:48:41  iter: 78819  total_loss: 0.796  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0264  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:15:33] d2.utils.events INFO: eta: 14:47:36  iter: 78839  total_loss: 0.707  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0263  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:16:34] d2.utils.events INFO: eta: 14:46:42  iter: 78859  total_loss: 0.806  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0264  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 17:17:34] d2.utils.events INFO: eta: 14:45:02  iter: 78879  total_loss: 0.430  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0264  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 17:18:36] d2.utils.events INFO: eta: 14:44:20  iter: 78899  total_loss: 0.532  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0265  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:19:37] d2.utils.events INFO: eta: 14:43:26  iter: 78919  total_loss: 0.539  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0265  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:20:39] d2.utils.events INFO: eta: 14:42:49  iter: 78939  total_loss: 0.598  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0267  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 17:21:41] d2.utils.events INFO: eta: 14:42:19  iter: 78959  total_loss: 0.773  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0269  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 17:22:42] d2.utils.events INFO: eta: 14:41:28  iter: 78979  total_loss: 0.460  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 17:23:43] d2.utils.events INFO: eta: 14:40:48  iter: 78999  total_loss: 0.514  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:24:43] d2.utils.events INFO: eta: 14:39:39  iter: 79019  total_loss: 0.435  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0019  lr: 0.000100  max_mem: 9269M
[12/29 17:25:44] d2.utils.events INFO: eta: 14:38:41  iter: 79039  total_loss: 0.830  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:26:44] d2.utils.events INFO: eta: 14:37:25  iter: 79059  total_loss: 0.387  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0269  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:27:45] d2.utils.events INFO: eta: 14:36:47  iter: 79079  total_loss: 0.726  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:28:46] d2.utils.events INFO: eta: 14:35:50  iter: 79099  total_loss: 0.472  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0034  lr: 0.000100  max_mem: 9269M
[12/29 17:29:47] d2.utils.events INFO: eta: 14:34:45  iter: 79119  total_loss: 0.494  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 17:30:47] d2.utils.events INFO: eta: 14:33:44  iter: 79139  total_loss: 0.510  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:31:48] d2.utils.events INFO: eta: 14:32:34  iter: 79159  total_loss: 0.877  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:32:49] d2.utils.events INFO: eta: 14:31:40  iter: 79179  total_loss: 0.742  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0271  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:33:50] d2.utils.events INFO: eta: 14:30:34  iter: 79199  total_loss: 0.582  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 17:34:50] d2.utils.events INFO: eta: 14:29:41  iter: 79219  total_loss: 0.447  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:35:52] d2.utils.events INFO: eta: 14:28:40  iter: 79239  total_loss: 0.453  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:36:52] d2.utils.events INFO: eta: 14:27:53  iter: 79259  total_loss: 0.360  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.024  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.068  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 3.0271  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 17:37:54] d2.utils.events INFO: eta: 14:27:01  iter: 79279  total_loss: 0.543  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:38:53] d2.utils.events INFO: eta: 14:26:00  iter: 79299  total_loss: 0.795  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.008  loss_rpn_loc: 0.005  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:39:53] d2.utils.events INFO: eta: 14:24:59  iter: 79319  total_loss: 0.572  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:40:54] d2.utils.events INFO: eta: 14:23:57  iter: 79339  total_loss: 0.682  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:41:54] d2.utils.events INFO: eta: 14:22:53  iter: 79359  total_loss: 0.617  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:42:56] d2.utils.events INFO: eta: 14:21:55  iter: 79379  total_loss: 0.496  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:43:57] d2.utils.events INFO: eta: 14:20:55  iter: 79399  total_loss: 0.684  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:44:57] d2.utils.events INFO: eta: 14:19:53  iter: 79419  total_loss: 0.362  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.077  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:45:58] d2.utils.events INFO: eta: 14:18:50  iter: 79439  total_loss: 0.645  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0272  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 17:46:58] d2.utils.events INFO: eta: 14:17:49  iter: 79459  total_loss: 0.597  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 17:47:57] d2.utils.events INFO: eta: 14:16:47  iter: 79479  total_loss: 0.527  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 17:48:57] d2.utils.events INFO: eta: 14:15:35  iter: 79499  total_loss: 0.515  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:49:58] d2.utils.events INFO: eta: 14:14:47  iter: 79519  total_loss: 0.587  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 17:50:58] d2.utils.events INFO: eta: 14:13:48  iter: 79539  total_loss: 0.611  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.006  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:51:57] d2.utils.events INFO: eta: 14:12:42  iter: 79559  total_loss: 0.485  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0268  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 17:52:59] d2.utils.events INFO: eta: 14:11:45  iter: 79579  total_loss: 0.604  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 17:54:00] d2.utils.events INFO: eta: 14:10:47  iter: 79599  total_loss: 0.462  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 17:55:02] d2.utils.events INFO: eta: 14:09:52  iter: 79619  total_loss: 0.457  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 17:56:03] d2.utils.events INFO: eta: 14:08:49  iter: 79639  total_loss: 0.419  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 17:57:04] d2.utils.events INFO: eta: 14:07:51  iter: 79659  total_loss: 0.766  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 17:58:05] d2.utils.events INFO: eta: 14:06:48  iter: 79679  total_loss: 0.489  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 17:59:04] d2.utils.events INFO: eta: 14:05:38  iter: 79699  total_loss: 0.687  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 18:00:06] d2.utils.events INFO: eta: 14:04:35  iter: 79719  total_loss: 0.716  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:01:07] d2.utils.events INFO: eta: 14:03:35  iter: 79739  total_loss: 0.658  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 18:02:08] d2.utils.events INFO: eta: 14:02:27  iter: 79759  total_loss: 0.727  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0273  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:03:09] d2.utils.events INFO: eta: 14:01:34  iter: 79779  total_loss: 0.776  loss_cls_stage0: 0.090  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.108  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.098  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0273  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 18:04:08] d2.utils.events INFO: eta: 14:00:14  iter: 79799  total_loss: 0.461  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:05:09] d2.utils.events INFO: eta: 13:59:09  iter: 79819  total_loss: 0.460  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:06:08] d2.utils.events INFO: eta: 13:58:04  iter: 79839  total_loss: 0.515  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:07:08] d2.utils.events INFO: eta: 13:57:03  iter: 79859  total_loss: 0.434  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 18:08:08] d2.utils.events INFO: eta: 13:56:04  iter: 79879  total_loss: 0.602  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 18:09:09] d2.utils.events INFO: eta: 13:54:58  iter: 79899  total_loss: 0.728  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 18:10:10] d2.utils.events INFO: eta: 13:54:00  iter: 79919  total_loss: 0.624  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 18:11:10] d2.utils.events INFO: eta: 13:52:44  iter: 79939  total_loss: 0.771  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:12:10] d2.utils.events INFO: eta: 13:51:31  iter: 79959  total_loss: 0.523  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:13:11] d2.utils.events INFO: eta: 13:50:30  iter: 79979  total_loss: 0.580  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:14:13] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0079999.pth
[12/29 18:14:18] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/29 18:14:19] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/29 18:15:23] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4792 s / img. ETA=0:08:58
[12/29 18:15:47] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4794 s / img. ETA=0:08:34
[12/29 18:16:11] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4798 s / img. ETA=0:08:11
[12/29 18:16:35] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4799 s / img. ETA=0:07:47
[12/29 18:16:59] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4800 s / img. ETA=0:07:23
[12/29 18:17:23] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4797 s / img. ETA=0:06:59
[12/29 18:17:47] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4798 s / img. ETA=0:06:35
[12/29 18:18:11] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4798 s / img. ETA=0:06:11
[12/29 18:18:35] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4797 s / img. ETA=0:05:47
[12/29 18:18:59] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4797 s / img. ETA=0:05:23
[12/29 18:19:23] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4797 s / img. ETA=0:04:59
[12/29 18:19:47] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4796 s / img. ETA=0:04:35
[12/29 18:20:11] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4796 s / img. ETA=0:04:11
[12/29 18:20:35] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4796 s / img. ETA=0:03:47
[12/29 18:20:59] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4796 s / img. ETA=0:03:23
[12/29 18:21:23] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4797 s / img. ETA=0:02:59
[12/29 18:21:47] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4797 s / img. ETA=0:02:35
[12/29 18:22:11] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4798 s / img. ETA=0:02:11
[12/29 18:22:35] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4798 s / img. ETA=0:01:47
[12/29 18:22:59] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4798 s / img. ETA=0:01:23
[12/29 18:23:23] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4798 s / img. ETA=0:00:59
[12/29 18:23:47] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4798 s / img. ETA=0:00:35
[12/29 18:24:11] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4797 s / img. ETA=0:00:11
[12/29 18:24:23] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/29 18:24:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:17 (0.476623 s / img per device, on 2 devices)
[12/29 18:24:23] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/29 18:24:23] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/29 18:24:23] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/29 18:24:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.498 | 70.955 | 55.208 | 23.851 | 42.177 | 50.842 |
[12/29 18:24:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 52.941 | ASC-US     | 48.447 | HSIL        | 65.436 |
| LSIL       | 62.112 | Candida    | 46.928 | Trichomonas | 21.121 |
[12/29 18:24:27] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/29 18:24:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/29 18:24:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/29 18:24:27] d2.evaluation.testing INFO: copypaste: 49.4976,70.9551,55.2080,23.8512,42.1772,50.8418
[12/29 18:24:27] d2.utils.events INFO: eta: 13:49:35  iter: 79999  total_loss: 0.504  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:25:29] d2.utils.events INFO: eta: 13:48:46  iter: 80019  total_loss: 0.629  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:26:31] d2.utils.events INFO: eta: 13:47:59  iter: 80039  total_loss: 0.745  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0274  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:27:32] d2.utils.events INFO: eta: 13:47:00  iter: 80059  total_loss: 0.761  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:28:33] d2.utils.events INFO: eta: 13:45:56  iter: 80079  total_loss: 0.755  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:29:32] d2.utils.events INFO: eta: 13:44:46  iter: 80099  total_loss: 0.716  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0273  data_time: 0.0019  lr: 0.000100  max_mem: 9269M
[12/29 18:30:31] d2.utils.events INFO: eta: 13:43:37  iter: 80119  total_loss: 0.622  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0272  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 18:31:32] d2.utils.events INFO: eta: 13:42:36  iter: 80139  total_loss: 0.828  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.332  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 18:32:32] d2.utils.events INFO: eta: 13:41:35  iter: 80159  total_loss: 0.729  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:33:31] d2.utils.events INFO: eta: 13:40:28  iter: 80179  total_loss: 0.567  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 18:34:30] d2.utils.events INFO: eta: 13:39:25  iter: 80199  total_loss: 0.746  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0269  data_time: 0.0019  lr: 0.000100  max_mem: 9269M
[12/29 18:35:31] d2.utils.events INFO: eta: 13:38:24  iter: 80219  total_loss: 0.701  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0269  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 18:36:30] d2.utils.events INFO: eta: 13:37:09  iter: 80239  total_loss: 0.523  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0267  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 18:37:32] d2.utils.events INFO: eta: 13:36:15  iter: 80259  total_loss: 0.741  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0268  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:38:34] d2.utils.events INFO: eta: 13:35:07  iter: 80279  total_loss: 0.738  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:39:33] d2.utils.events INFO: eta: 13:34:09  iter: 80299  total_loss: 0.627  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:40:34] d2.utils.events INFO: eta: 13:33:06  iter: 80319  total_loss: 0.569  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:41:36] d2.utils.events INFO: eta: 13:32:04  iter: 80339  total_loss: 0.508  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.128  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:42:36] d2.utils.events INFO: eta: 13:31:07  iter: 80359  total_loss: 0.518  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:43:36] d2.utils.events INFO: eta: 13:30:06  iter: 80379  total_loss: 0.511  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:44:37] d2.utils.events INFO: eta: 13:29:05  iter: 80399  total_loss: 0.531  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 18:45:38] d2.utils.events INFO: eta: 13:28:07  iter: 80419  total_loss: 0.667  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:46:39] d2.utils.events INFO: eta: 13:27:15  iter: 80439  total_loss: 0.614  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:47:40] d2.utils.events INFO: eta: 13:26:14  iter: 80459  total_loss: 0.574  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 18:48:40] d2.utils.events INFO: eta: 13:25:16  iter: 80479  total_loss: 0.654  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 18:49:42] d2.utils.events INFO: eta: 13:24:22  iter: 80499  total_loss: 0.652  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 18:50:42] d2.utils.events INFO: eta: 13:23:22  iter: 80519  total_loss: 0.620  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:51:43] d2.utils.events INFO: eta: 13:22:10  iter: 80539  total_loss: 0.542  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0272  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 18:52:44] d2.utils.events INFO: eta: 13:21:16  iter: 80559  total_loss: 0.714  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:53:45] d2.utils.events INFO: eta: 13:20:15  iter: 80579  total_loss: 0.682  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 18:54:46] d2.utils.events INFO: eta: 13:19:14  iter: 80599  total_loss: 0.610  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:55:50] d2.utils.events INFO: eta: 13:18:24  iter: 80619  total_loss: 0.630  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0276  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 18:56:49] d2.utils.events INFO: eta: 13:17:09  iter: 80639  total_loss: 0.602  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 18:57:50] d2.utils.events INFO: eta: 13:16:15  iter: 80659  total_loss: 0.596  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 18:58:51] d2.utils.events INFO: eta: 13:15:21  iter: 80679  total_loss: 0.792  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 18:59:51] d2.utils.events INFO: eta: 13:14:27  iter: 80699  total_loss: 0.676  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 19:00:52] d2.utils.events INFO: eta: 13:13:26  iter: 80719  total_loss: 0.742  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:01:52] d2.utils.events INFO: eta: 13:12:25  iter: 80739  total_loss: 0.476  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 19:02:54] d2.utils.events INFO: eta: 13:11:32  iter: 80759  total_loss: 0.675  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:03:53] d2.utils.events INFO: eta: 13:10:25  iter: 80779  total_loss: 0.513  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 19:04:52] d2.utils.events INFO: eta: 13:09:25  iter: 80799  total_loss: 0.606  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0273  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:05:53] d2.utils.events INFO: eta: 13:08:29  iter: 80819  total_loss: 0.596  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 19:06:54] d2.utils.events INFO: eta: 13:07:31  iter: 80839  total_loss: 0.573  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0273  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:07:54] d2.utils.events INFO: eta: 13:06:25  iter: 80859  total_loss: 0.555  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:08:54] d2.utils.events INFO: eta: 13:05:24  iter: 80879  total_loss: 0.468  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0273  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:09:55] d2.utils.events INFO: eta: 13:04:23  iter: 80899  total_loss: 0.665  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0273  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 19:10:56] d2.utils.events INFO: eta: 13:03:18  iter: 80919  total_loss: 0.850  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0273  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:11:57] d2.utils.events INFO: eta: 13:02:33  iter: 80939  total_loss: 0.790  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0274  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:12:59] d2.utils.events INFO: eta: 13:01:35  iter: 80959  total_loss: 0.698  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 19:14:00] d2.utils.events INFO: eta: 13:00:36  iter: 80979  total_loss: 0.595  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:15:01] d2.utils.events INFO: eta: 12:59:24  iter: 80999  total_loss: 0.519  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:16:01] d2.utils.events INFO: eta: 12:58:12  iter: 81019  total_loss: 0.666  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:17:01] d2.utils.events INFO: eta: 12:56:50  iter: 81039  total_loss: 0.759  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 19:18:01] d2.utils.events INFO: eta: 12:55:54  iter: 81059  total_loss: 0.571  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0019  lr: 0.000100  max_mem: 9269M
[12/29 19:19:02] d2.utils.events INFO: eta: 12:54:49  iter: 81079  total_loss: 0.486  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:20:05] d2.utils.events INFO: eta: 12:54:01  iter: 81099  total_loss: 0.676  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:21:05] d2.utils.events INFO: eta: 12:53:09  iter: 81119  total_loss: 0.494  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 19:22:05] d2.utils.events INFO: eta: 12:52:06  iter: 81139  total_loss: 0.640  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:23:06] d2.utils.events INFO: eta: 12:51:19  iter: 81159  total_loss: 0.475  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 19:24:06] d2.utils.events INFO: eta: 12:50:20  iter: 81179  total_loss: 0.438  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 19:25:07] d2.utils.events INFO: eta: 12:49:21  iter: 81199  total_loss: 0.711  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:26:07] d2.utils.events INFO: eta: 12:48:21  iter: 81219  total_loss: 0.663  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:27:08] d2.utils.events INFO: eta: 12:47:20  iter: 81239  total_loss: 0.732  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 19:28:08] d2.utils.events INFO: eta: 12:46:14  iter: 81259  total_loss: 0.581  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 19:29:07] d2.utils.events INFO: eta: 12:45:01  iter: 81279  total_loss: 0.440  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 19:30:08] d2.utils.events INFO: eta: 12:44:09  iter: 81299  total_loss: 0.494  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 19:31:08] d2.utils.events INFO: eta: 12:43:02  iter: 81319  total_loss: 0.453  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:32:09] d2.utils.events INFO: eta: 12:42:10  iter: 81339  total_loss: 0.575  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:33:10] d2.utils.events INFO: eta: 12:41:08  iter: 81359  total_loss: 0.649  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:34:11] d2.utils.events INFO: eta: 12:40:00  iter: 81379  total_loss: 0.807  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:35:12] d2.utils.events INFO: eta: 12:38:59  iter: 81399  total_loss: 0.504  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:36:12] d2.utils.events INFO: eta: 12:37:52  iter: 81419  total_loss: 0.503  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:37:13] d2.utils.events INFO: eta: 12:36:54  iter: 81439  total_loss: 0.504  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:38:14] d2.utils.events INFO: eta: 12:35:55  iter: 81459  total_loss: 0.969  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.247  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.347  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 19:39:14] d2.utils.events INFO: eta: 12:34:54  iter: 81479  total_loss: 0.381  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:40:14] d2.utils.events INFO: eta: 12:33:40  iter: 81499  total_loss: 0.863  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.099  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:41:15] d2.utils.events INFO: eta: 12:32:43  iter: 81519  total_loss: 0.367  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.082  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 19:42:15] d2.utils.events INFO: eta: 12:31:51  iter: 81539  total_loss: 0.598  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:43:17] d2.utils.events INFO: eta: 12:30:50  iter: 81559  total_loss: 0.690  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 19:44:18] d2.utils.events INFO: eta: 12:29:48  iter: 81579  total_loss: 0.568  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 19:45:17] d2.utils.events INFO: eta: 12:28:44  iter: 81599  total_loss: 0.540  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 19:46:18] d2.utils.events INFO: eta: 12:27:36  iter: 81619  total_loss: 0.487  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:47:20] d2.utils.events INFO: eta: 12:26:54  iter: 81639  total_loss: 0.589  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 19:48:19] d2.utils.events INFO: eta: 12:25:47  iter: 81659  total_loss: 0.462  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:49:19] d2.utils.events INFO: eta: 12:24:44  iter: 81679  total_loss: 0.519  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 19:50:21] d2.utils.events INFO: eta: 12:23:50  iter: 81699  total_loss: 0.488  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 19:51:23] d2.utils.events INFO: eta: 12:22:50  iter: 81719  total_loss: 0.505  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:52:24] d2.utils.events INFO: eta: 12:21:53  iter: 81739  total_loss: 0.835  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 19:53:23] d2.utils.events INFO: eta: 12:20:43  iter: 81759  total_loss: 0.444  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:54:24] d2.utils.events INFO: eta: 12:19:46  iter: 81779  total_loss: 0.583  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 19:55:23] d2.utils.events INFO: eta: 12:18:47  iter: 81799  total_loss: 0.632  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:56:24] d2.utils.events INFO: eta: 12:17:44  iter: 81819  total_loss: 0.633  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 19:57:25] d2.utils.events INFO: eta: 12:16:46  iter: 81839  total_loss: 0.785  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 19:58:25] d2.utils.events INFO: eta: 12:15:40  iter: 81859  total_loss: 0.693  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 19:59:25] d2.utils.events INFO: eta: 12:14:37  iter: 81879  total_loss: 0.343  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.075  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:00:26] d2.utils.events INFO: eta: 12:13:39  iter: 81899  total_loss: 0.579  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 20:01:25] d2.utils.events INFO: eta: 12:12:34  iter: 81919  total_loss: 0.642  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 20:02:24] d2.utils.events INFO: eta: 12:11:24  iter: 81939  total_loss: 0.496  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0272  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 20:03:24] d2.utils.events INFO: eta: 12:10:20  iter: 81959  total_loss: 0.572  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:04:24] d2.utils.events INFO: eta: 12:09:14  iter: 81979  total_loss: 0.655  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0271  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 20:05:24] d2.utils.events INFO: eta: 12:08:13  iter: 81999  total_loss: 0.725  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 20:06:24] d2.utils.events INFO: eta: 12:07:08  iter: 82019  total_loss: 0.775  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:07:25] d2.utils.events INFO: eta: 12:06:11  iter: 82039  total_loss: 0.572  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 20:08:26] d2.utils.events INFO: eta: 12:05:15  iter: 82059  total_loss: 0.828  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0271  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 20:09:27] d2.utils.events INFO: eta: 12:04:17  iter: 82079  total_loss: 0.497  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:10:27] d2.utils.events INFO: eta: 12:03:13  iter: 82099  total_loss: 0.528  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 20:11:26] d2.utils.events INFO: eta: 12:02:01  iter: 82119  total_loss: 0.674  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 20:12:27] d2.utils.events INFO: eta: 12:01:07  iter: 82139  total_loss: 0.519  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:13:27] d2.utils.events INFO: eta: 11:59:59  iter: 82159  total_loss: 0.571  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 20:14:28] d2.utils.events INFO: eta: 11:58:59  iter: 82179  total_loss: 0.506  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:15:28] d2.utils.events INFO: eta: 11:57:58  iter: 82199  total_loss: 0.767  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 20:16:28] d2.utils.events INFO: eta: 11:56:47  iter: 82219  total_loss: 0.622  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0269  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:17:28] d2.utils.events INFO: eta: 11:55:37  iter: 82239  total_loss: 0.574  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 20:18:30] d2.utils.events INFO: eta: 11:54:56  iter: 82259  total_loss: 0.846  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.089  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.103  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:19:31] d2.utils.events INFO: eta: 11:53:58  iter: 82279  total_loss: 0.746  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 20:20:31] d2.utils.events INFO: eta: 11:52:50  iter: 82299  total_loss: 0.736  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.096  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:21:31] d2.utils.events INFO: eta: 11:51:49  iter: 82319  total_loss: 0.537  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:22:33] d2.utils.events INFO: eta: 11:50:39  iter: 82339  total_loss: 0.587  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:23:33] d2.utils.events INFO: eta: 11:49:41  iter: 82359  total_loss: 0.546  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:24:35] d2.utils.events INFO: eta: 11:48:47  iter: 82379  total_loss: 0.528  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 20:25:35] d2.utils.events INFO: eta: 11:47:48  iter: 82399  total_loss: 0.704  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:26:36] d2.utils.events INFO: eta: 11:46:50  iter: 82419  total_loss: 0.672  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0270  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 20:27:36] d2.utils.events INFO: eta: 11:45:46  iter: 82439  total_loss: 0.569  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 20:28:38] d2.utils.events INFO: eta: 11:44:44  iter: 82459  total_loss: 0.734  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0271  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:29:39] d2.utils.events INFO: eta: 11:43:47  iter: 82479  total_loss: 0.547  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0272  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:30:38] d2.utils.events INFO: eta: 11:42:47  iter: 82499  total_loss: 0.486  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 20:31:38] d2.utils.events INFO: eta: 11:41:45  iter: 82519  total_loss: 0.471  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0270  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 20:32:39] d2.utils.events INFO: eta: 11:40:41  iter: 82539  total_loss: 0.425  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.006  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 20:33:39] d2.utils.events INFO: eta: 11:39:34  iter: 82559  total_loss: 0.589  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 20:34:40] d2.utils.events INFO: eta: 11:38:27  iter: 82579  total_loss: 0.476  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0270  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:35:41] d2.utils.events INFO: eta: 11:37:38  iter: 82599  total_loss: 0.525  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0271  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:36:41] d2.utils.events INFO: eta: 11:36:14  iter: 82619  total_loss: 0.823  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 20:37:40] d2.utils.events INFO: eta: 11:34:46  iter: 82639  total_loss: 0.372  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0269  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:38:42] d2.utils.events INFO: eta: 11:34:21  iter: 82659  total_loss: 0.478  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0036  lr: 0.000100  max_mem: 9269M
[12/29 20:39:43] d2.utils.events INFO: eta: 11:33:29  iter: 82679  total_loss: 0.392  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 20:40:44] d2.utils.events INFO: eta: 11:32:20  iter: 82699  total_loss: 0.530  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.119  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:41:45] d2.utils.events INFO: eta: 11:31:10  iter: 82719  total_loss: 0.683  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:42:47] d2.utils.events INFO: eta: 11:30:05  iter: 82739  total_loss: 0.617  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:43:48] d2.utils.events INFO: eta: 11:29:30  iter: 82759  total_loss: 0.705  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 20:44:49] d2.utils.events INFO: eta: 11:28:31  iter: 82779  total_loss: 0.781  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0273  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 20:45:49] d2.utils.events INFO: eta: 11:27:31  iter: 82799  total_loss: 0.565  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:46:50] d2.utils.events INFO: eta: 11:26:32  iter: 82819  total_loss: 0.665  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0273  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 20:47:51] d2.utils.events INFO: eta: 11:25:35  iter: 82839  total_loss: 0.560  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 20:48:52] d2.utils.events INFO: eta: 11:24:34  iter: 82859  total_loss: 0.511  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0273  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:49:51] d2.utils.events INFO: eta: 11:23:28  iter: 82879  total_loss: 0.572  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 20:50:52] d2.utils.events INFO: eta: 11:22:27  iter: 82899  total_loss: 0.671  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0273  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 20:51:54] d2.utils.events INFO: eta: 11:21:36  iter: 82919  total_loss: 0.732  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0274  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 20:52:54] d2.utils.events INFO: eta: 11:20:40  iter: 82939  total_loss: 0.499  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0273  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 20:53:54] d2.utils.events INFO: eta: 11:19:39  iter: 82959  total_loss: 0.509  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0273  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 20:54:55] d2.utils.events INFO: eta: 11:18:41  iter: 82979  total_loss: 0.582  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 20:55:57] d2.utils.events INFO: eta: 11:17:42  iter: 82999  total_loss: 0.708  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0274  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 20:56:59] d2.utils.events INFO: eta: 11:16:54  iter: 83019  total_loss: 0.643  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:58:00] d2.utils.events INFO: eta: 11:15:46  iter: 83039  total_loss: 0.719  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 20:59:01] d2.utils.events INFO: eta: 11:14:49  iter: 83059  total_loss: 0.773  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.007  loss_rpn_loc: 0.007  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:00:03] d2.utils.events INFO: eta: 11:13:50  iter: 83079  total_loss: 0.554  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:01:03] d2.utils.events INFO: eta: 11:12:51  iter: 83099  total_loss: 0.487  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:02:03] d2.utils.events INFO: eta: 11:11:57  iter: 83119  total_loss: 0.681  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:03:04] d2.utils.events INFO: eta: 11:10:57  iter: 83139  total_loss: 0.838  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.338  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:04:06] d2.utils.events INFO: eta: 11:10:01  iter: 83159  total_loss: 0.434  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:05:06] d2.utils.events INFO: eta: 11:09:00  iter: 83179  total_loss: 0.603  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:06:07] d2.utils.events INFO: eta: 11:07:59  iter: 83199  total_loss: 0.531  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:07:07] d2.utils.events INFO: eta: 11:07:00  iter: 83219  total_loss: 0.646  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:08:09] d2.utils.events INFO: eta: 11:06:03  iter: 83239  total_loss: 0.828  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:09:10] d2.utils.events INFO: eta: 11:05:01  iter: 83259  total_loss: 0.651  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:10:11] d2.utils.events INFO: eta: 11:04:04  iter: 83279  total_loss: 0.536  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0279  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:11:11] d2.utils.events INFO: eta: 11:03:05  iter: 83299  total_loss: 0.569  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0278  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:12:12] d2.utils.events INFO: eta: 11:02:04  iter: 83319  total_loss: 0.446  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0278  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:13:11] d2.utils.events INFO: eta: 11:00:58  iter: 83339  total_loss: 0.589  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 21:14:11] d2.utils.events INFO: eta: 10:59:55  iter: 83359  total_loss: 0.685  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 21:15:12] d2.utils.events INFO: eta: 10:58:53  iter: 83379  total_loss: 0.524  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:16:13] d2.utils.events INFO: eta: 10:57:54  iter: 83399  total_loss: 0.928  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0277  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:17:14] d2.utils.events INFO: eta: 10:56:52  iter: 83419  total_loss: 0.739  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 21:18:15] d2.utils.events INFO: eta: 10:55:50  iter: 83439  total_loss: 0.779  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0030  lr: 0.000100  max_mem: 9269M
[12/29 21:19:15] d2.utils.events INFO: eta: 10:54:49  iter: 83459  total_loss: 0.497  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 21:20:15] d2.utils.events INFO: eta: 10:53:48  iter: 83479  total_loss: 0.755  loss_cls_stage0: 0.090  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.089  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:21:16] d2.utils.events INFO: eta: 10:52:48  iter: 83499  total_loss: 0.733  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0278  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:22:17] d2.utils.events INFO: eta: 10:51:47  iter: 83519  total_loss: 0.560  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:23:18] d2.utils.events INFO: eta: 10:50:48  iter: 83539  total_loss: 0.643  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:24:19] d2.utils.events INFO: eta: 10:49:47  iter: 83559  total_loss: 0.807  loss_cls_stage0: 0.082  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.094  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0279  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 21:25:19] d2.utils.events INFO: eta: 10:48:45  iter: 83579  total_loss: 0.483  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0278  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 21:26:20] d2.utils.events INFO: eta: 10:47:43  iter: 83599  total_loss: 0.748  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 21:27:19] d2.utils.events INFO: eta: 10:46:42  iter: 83619  total_loss: 0.544  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:28:19] d2.utils.events INFO: eta: 10:45:41  iter: 83639  total_loss: 0.491  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:29:18] d2.utils.events INFO: eta: 10:44:35  iter: 83659  total_loss: 0.556  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:30:18] d2.utils.events INFO: eta: 10:43:35  iter: 83679  total_loss: 0.653  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 21:31:19] d2.utils.events INFO: eta: 10:42:34  iter: 83699  total_loss: 0.601  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:32:19] d2.utils.events INFO: eta: 10:41:29  iter: 83719  total_loss: 0.739  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 21:33:18] d2.utils.events INFO: eta: 10:40:21  iter: 83739  total_loss: 0.509  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:34:20] d2.utils.events INFO: eta: 10:39:19  iter: 83759  total_loss: 0.535  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0020  lr: 0.000100  max_mem: 9269M
[12/29 21:35:21] d2.utils.events INFO: eta: 10:38:14  iter: 83779  total_loss: 0.592  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 21:36:22] d2.utils.events INFO: eta: 10:37:18  iter: 83799  total_loss: 0.824  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 21:37:23] d2.utils.events INFO: eta: 10:36:17  iter: 83819  total_loss: 0.572  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 21:38:24] d2.utils.events INFO: eta: 10:35:13  iter: 83839  total_loss: 0.670  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:39:26] d2.utils.events INFO: eta: 10:34:16  iter: 83859  total_loss: 0.699  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:40:25] d2.utils.events INFO: eta: 10:33:18  iter: 83879  total_loss: 0.430  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:41:25] d2.utils.events INFO: eta: 10:32:14  iter: 83899  total_loss: 0.525  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:42:26] d2.utils.events INFO: eta: 10:31:11  iter: 83919  total_loss: 0.665  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:43:28] d2.utils.events INFO: eta: 10:30:12  iter: 83939  total_loss: 0.624  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:44:30] d2.utils.events INFO: eta: 10:29:15  iter: 83959  total_loss: 0.526  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 21:45:29] d2.utils.events INFO: eta: 10:28:09  iter: 83979  total_loss: 0.520  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:46:30] d2.utils.events INFO: eta: 10:27:06  iter: 83999  total_loss: 0.399  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:47:29] d2.utils.events INFO: eta: 10:26:01  iter: 84019  total_loss: 0.669  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:48:31] d2.utils.events INFO: eta: 10:25:03  iter: 84039  total_loss: 0.786  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 21:49:31] d2.utils.events INFO: eta: 10:23:57  iter: 84059  total_loss: 0.536  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:50:30] d2.utils.events INFO: eta: 10:22:39  iter: 84079  total_loss: 0.674  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:51:31] d2.utils.events INFO: eta: 10:21:41  iter: 84099  total_loss: 0.563  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 21:52:31] d2.utils.events INFO: eta: 10:20:26  iter: 84119  total_loss: 0.554  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0275  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 21:53:32] d2.utils.events INFO: eta: 10:19:19  iter: 84139  total_loss: 0.631  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0275  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 21:54:31] d2.utils.events INFO: eta: 10:18:01  iter: 84159  total_loss: 0.423  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 21:55:31] d2.utils.events INFO: eta: 10:16:45  iter: 84179  total_loss: 0.710  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0274  data_time: 0.0033  lr: 0.000100  max_mem: 9269M
[12/29 21:56:34] d2.utils.events INFO: eta: 10:15:53  iter: 84199  total_loss: 0.475  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0276  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:57:36] d2.utils.events INFO: eta: 10:15:16  iter: 84219  total_loss: 0.572  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 21:58:37] d2.utils.events INFO: eta: 10:14:00  iter: 84239  total_loss: 0.435  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 21:59:38] d2.utils.events INFO: eta: 10:13:11  iter: 84259  total_loss: 0.871  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 22:00:37] d2.utils.events INFO: eta: 10:11:33  iter: 84279  total_loss: 0.758  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0276  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 22:01:38] d2.utils.events INFO: eta: 10:10:40  iter: 84299  total_loss: 0.534  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0032  lr: 0.000100  max_mem: 9269M
[12/29 22:02:39] d2.utils.events INFO: eta: 10:09:33  iter: 84319  total_loss: 0.610  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:03:39] d2.utils.events INFO: eta: 10:09:11  iter: 84339  total_loss: 0.646  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 22:04:40] d2.utils.events INFO: eta: 10:08:34  iter: 84359  total_loss: 0.581  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:05:43] d2.utils.events INFO: eta: 10:07:40  iter: 84379  total_loss: 0.568  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 22:06:42] d2.utils.events INFO: eta: 10:06:29  iter: 84399  total_loss: 0.519  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0277  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 22:07:42] d2.utils.events INFO: eta: 10:05:25  iter: 84419  total_loss: 0.701  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0277  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 22:08:43] d2.utils.events INFO: eta: 10:04:24  iter: 84439  total_loss: 0.580  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0277  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:09:42] d2.utils.events INFO: eta: 10:03:06  iter: 84459  total_loss: 0.483  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0276  data_time: 0.0027  lr: 0.000100  max_mem: 9269M
[12/29 22:10:43] d2.utils.events INFO: eta: 10:02:05  iter: 84479  total_loss: 0.663  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 22:11:43] d2.utils.events INFO: eta: 10:00:42  iter: 84499  total_loss: 0.534  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 22:12:43] d2.utils.events INFO: eta: 9:59:48  iter: 84519  total_loss: 0.609  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0275  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 22:13:43] d2.utils.events INFO: eta: 9:58:26  iter: 84539  total_loss: 0.679  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0275  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 22:14:42] d2.utils.events INFO: eta: 9:57:07  iter: 84559  total_loss: 0.578  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:15:41] d2.utils.events INFO: eta: 9:56:06  iter: 84579  total_loss: 0.382  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0273  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 22:16:41] d2.utils.events INFO: eta: 9:55:04  iter: 84599  total_loss: 0.599  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 22:17:42] d2.utils.events INFO: eta: 9:54:03  iter: 84619  total_loss: 0.629  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 22:18:41] d2.utils.events INFO: eta: 9:53:04  iter: 84639  total_loss: 0.399  loss_cls_stage0: 0.021  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0271  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 22:19:42] d2.utils.events INFO: eta: 9:52:33  iter: 84659  total_loss: 0.590  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0037  lr: 0.000100  max_mem: 9269M
[12/29 22:20:43] d2.utils.events INFO: eta: 9:51:33  iter: 84679  total_loss: 0.553  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 22:21:44] d2.utils.events INFO: eta: 9:50:38  iter: 84699  total_loss: 0.523  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 22:22:45] d2.utils.events INFO: eta: 9:50:08  iter: 84719  total_loss: 0.717  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:23:45] d2.utils.events INFO: eta: 9:49:13  iter: 84739  total_loss: 0.519  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 22:24:46] d2.utils.events INFO: eta: 9:48:10  iter: 84759  total_loss: 0.593  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0273  data_time: 0.0028  lr: 0.000100  max_mem: 9269M
[12/29 22:25:45] d2.utils.events INFO: eta: 9:47:07  iter: 84779  total_loss: 0.400  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0272  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:26:44] d2.utils.events INFO: eta: 9:45:13  iter: 84799  total_loss: 0.350  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.028  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0270  data_time: 0.0026  lr: 0.000100  max_mem: 9269M
[12/29 22:27:44] d2.utils.events INFO: eta: 9:44:20  iter: 84819  total_loss: 0.412  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.115  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0270  data_time: 0.0024  lr: 0.000100  max_mem: 9269M
[12/29 22:28:44] d2.utils.events INFO: eta: 9:43:02  iter: 84839  total_loss: 0.424  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0029  lr: 0.000100  max_mem: 9269M
[12/29 22:29:45] d2.utils.events INFO: eta: 9:42:07  iter: 84859  total_loss: 0.630  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0021  lr: 0.000100  max_mem: 9269M
[12/29 22:30:45] d2.utils.events INFO: eta: 9:41:10  iter: 84879  total_loss: 0.539  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 22:31:46] d2.utils.events INFO: eta: 9:40:25  iter: 84899  total_loss: 0.754  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0270  data_time: 0.0022  lr: 0.000100  max_mem: 9269M
[12/29 22:32:47] d2.utils.events INFO: eta: 9:39:09  iter: 84919  total_loss: 0.510  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0270  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 22:33:48] d2.utils.events INFO: eta: 9:38:35  iter: 84939  total_loss: 0.527  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0271  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 22:34:51] d2.utils.events INFO: eta: 9:37:48  iter: 84959  total_loss: 0.485  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0272  data_time: 0.0023  lr: 0.000100  max_mem: 9269M
[12/29 22:35:50] d2.utils.events INFO: eta: 9:36:15  iter: 84979  total_loss: 0.608  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0271  data_time: 0.0025  lr: 0.000100  max_mem: 9269M
[12/29 22:36:50] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0084999.pth
[12/29 22:36:56] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/29 22:36:56] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/29 22:38:01] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4799 s / img. ETA=0:08:59
[12/29 22:38:25] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4802 s / img. ETA=0:08:35
[12/29 22:38:49] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4799 s / img. ETA=0:08:11
[12/29 22:39:13] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4798 s / img. ETA=0:07:47
[12/29 22:39:37] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4799 s / img. ETA=0:07:23
[12/29 22:40:01] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4800 s / img. ETA=0:06:59
[12/29 22:40:25] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4799 s / img. ETA=0:06:35
[12/29 22:40:49] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4799 s / img. ETA=0:06:11
[12/29 22:42:05] detectron2 INFO: Rank of current process: 0. World size: 2
[12/29 22:42:09] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/29 22:42:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/29 22:42:09] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 96368  ## 46368 74368(70000) 96368
  BASE_LR: 0.01     ### 
  STEPS: (76100, 76300)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/29 22:42:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 96368
  MOMENTUM: 0.9
  STEPS: (76100, 76300)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/29 22:42:09] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/29 22:42:09] d2.utils.env INFO: Using a generated random seed 10070192
[12/29 22:42:13] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/29 22:42:13] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0084999.pth
[12/29 22:43:59] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/29 22:43:59] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/29 22:44:00] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/29 22:44:00] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/29 22:44:53] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4795 s / img. ETA=2:14:16
[12/29 22:45:17] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4814 s / img. ETA=2:14:23
[12/29 22:45:41] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4823 s / img. ETA=2:14:14
[12/29 22:46:06] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4830 s / img. ETA=2:14:01
[12/29 22:46:30] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4824 s / img. ETA=2:13:27
[12/29 22:46:54] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4822 s / img. ETA=2:13:00
[12/29 22:47:18] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4824 s / img. ETA=2:12:39
[12/29 22:47:42] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4827 s / img. ETA=2:12:20
[12/29 22:48:06] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4828 s / img. ETA=2:11:57
[12/29 22:48:30] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4826 s / img. ETA=2:11:30
[12/29 22:48:54] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4826 s / img. ETA=2:11:07
[12/29 22:49:19] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4826 s / img. ETA=2:10:42
[12/29 22:49:43] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4825 s / img. ETA=2:10:17
[12/29 22:50:07] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4826 s / img. ETA=2:09:53
[12/29 22:50:31] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4825 s / img. ETA=2:09:28
[12/29 22:50:55] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4825 s / img. ETA=2:09:03
[12/29 22:51:19] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4825 s / img. ETA=2:08:39
[12/29 22:51:43] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4825 s / img. ETA=2:08:15
[12/29 22:52:07] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4824 s / img. ETA=2:07:50
[12/29 22:52:31] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4824 s / img. ETA=2:07:26
[12/29 22:52:55] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4823 s / img. ETA=2:07:00
[12/29 22:53:19] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4823 s / img. ETA=2:06:35
[12/29 22:53:43] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4822 s / img. ETA=2:06:10
[12/29 22:54:08] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4823 s / img. ETA=2:05:47
[12/29 22:54:32] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4822 s / img. ETA=2:05:23
[12/29 22:54:56] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4823 s / img. ETA=2:04:59
[12/29 22:55:20] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4824 s / img. ETA=2:04:36
[12/29 22:55:46] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4838 s / img. ETA=2:04:35
[12/29 22:56:10] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4837 s / img. ETA=2:04:09
[12/29 22:56:34] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4837 s / img. ETA=2:03:44
[12/29 22:56:59] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4837 s / img. ETA=2:03:21
[12/29 22:57:23] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4837 s / img. ETA=2:02:56
[12/29 22:57:47] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4836 s / img. ETA=2:02:31
[12/29 22:58:11] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4836 s / img. ETA=2:02:06
[12/29 22:58:35] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4835 s / img. ETA=2:01:41
[12/29 22:58:59] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4835 s / img. ETA=2:01:16
[12/29 22:59:23] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4834 s / img. ETA=2:00:51
[12/29 22:59:47] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4833 s / img. ETA=2:00:25
[12/29 23:00:11] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4833 s / img. ETA=2:00:01
[12/29 23:00:35] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4833 s / img. ETA=1:59:36
[12/29 23:00:59] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4832 s / img. ETA=1:59:11
[12/29 23:01:24] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4832 s / img. ETA=1:58:46
[12/29 23:01:48] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4831 s / img. ETA=1:58:22
[12/29 23:02:12] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4831 s / img. ETA=1:57:57
[12/29 23:02:36] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4831 s / img. ETA=1:57:33
[12/29 23:03:00] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4831 s / img. ETA=1:57:08
[12/29 23:03:24] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4831 s / img. ETA=1:56:44
[12/29 23:03:48] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4830 s / img. ETA=1:56:20
[12/29 23:04:12] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4830 s / img. ETA=1:55:55
[12/29 23:04:36] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4830 s / img. ETA=1:55:31
[12/29 23:05:01] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4830 s / img. ETA=1:55:07
[12/29 23:05:25] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4830 s / img. ETA=1:54:42
[12/29 23:05:49] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4830 s / img. ETA=1:54:18
[12/29 23:06:13] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4830 s / img. ETA=1:53:54
[12/29 23:06:37] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4830 s / img. ETA=1:53:29
[12/29 23:07:01] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4829 s / img. ETA=1:53:05
[12/29 23:07:25] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4829 s / img. ETA=1:52:40
[12/29 23:07:49] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4829 s / img. ETA=1:52:16
[12/29 23:08:13] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4828 s / img. ETA=1:51:51
[12/29 23:08:37] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4828 s / img. ETA=1:51:26
[12/29 23:09:01] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4828 s / img. ETA=1:51:02
[12/29 23:09:26] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4828 s / img. ETA=1:50:38
[12/29 23:09:50] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4828 s / img. ETA=1:50:13
[12/29 23:10:14] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4828 s / img. ETA=1:49:49
[12/29 23:10:38] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4828 s / img. ETA=1:49:25
[12/29 23:11:02] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4828 s / img. ETA=1:49:01
[12/29 23:11:26] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4828 s / img. ETA=1:48:37
[12/29 23:11:50] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4828 s / img. ETA=1:48:13
[12/29 23:12:15] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4828 s / img. ETA=1:47:49
[12/29 23:12:39] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4827 s / img. ETA=1:47:24
[12/29 23:13:03] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4827 s / img. ETA=1:47:00
[12/29 23:13:27] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4827 s / img. ETA=1:46:35
[12/29 23:13:51] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4827 s / img. ETA=1:46:11
[12/29 23:14:15] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4827 s / img. ETA=1:45:47
[12/29 23:14:39] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4827 s / img. ETA=1:45:23
[12/29 23:15:03] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4826 s / img. ETA=1:44:58
[12/29 23:15:27] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4826 s / img. ETA=1:44:34
[12/29 23:15:51] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4826 s / img. ETA=1:44:09
[12/29 23:16:15] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4826 s / img. ETA=1:43:45
[12/29 23:16:39] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4826 s / img. ETA=1:43:21
[12/29 23:17:03] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4826 s / img. ETA=1:42:57
[12/29 23:17:27] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4826 s / img. ETA=1:42:32
[12/29 23:17:52] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4826 s / img. ETA=1:42:08
[12/29 23:18:16] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4825 s / img. ETA=1:41:44
[12/29 23:18:40] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4825 s / img. ETA=1:41:19
[12/29 23:19:04] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4826 s / img. ETA=1:40:56
[12/29 23:19:28] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4826 s / img. ETA=1:40:32
[12/29 23:19:52] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4825 s / img. ETA=1:40:07
[12/29 23:20:16] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4825 s / img. ETA=1:39:43
[12/29 23:20:40] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4825 s / img. ETA=1:39:18
[12/29 23:21:04] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4825 s / img. ETA=1:38:54
[12/29 23:21:28] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4825 s / img. ETA=1:38:30
[12/29 23:21:52] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4824 s / img. ETA=1:38:05
[12/29 23:22:16] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4824 s / img. ETA=1:37:41
[12/29 23:22:40] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4824 s / img. ETA=1:37:17
[12/29 23:23:04] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4824 s / img. ETA=1:36:52
[12/29 23:23:28] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4824 s / img. ETA=1:36:28
[12/29 23:23:53] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4824 s / img. ETA=1:36:04
[12/29 23:24:17] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4824 s / img. ETA=1:35:40
[12/29 23:24:41] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4824 s / img. ETA=1:35:15
[12/29 23:25:05] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4824 s / img. ETA=1:34:51
[12/29 23:25:29] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4823 s / img. ETA=1:34:27
[12/29 23:25:53] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4823 s / img. ETA=1:34:03
[12/29 23:26:17] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4823 s / img. ETA=1:33:39
[12/29 23:26:41] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4823 s / img. ETA=1:33:14
[12/29 23:27:05] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4823 s / img. ETA=1:32:50
[12/29 23:27:29] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4823 s / img. ETA=1:32:26
[12/29 23:27:53] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4823 s / img. ETA=1:32:01
[12/29 23:28:17] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4823 s / img. ETA=1:31:37
[12/29 23:28:41] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4822 s / img. ETA=1:31:13
[12/29 23:29:05] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4822 s / img. ETA=1:30:49
[12/29 23:29:29] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4822 s / img. ETA=1:30:25
[12/29 23:29:54] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4822 s / img. ETA=1:30:00
[12/29 23:30:18] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4822 s / img. ETA=1:29:36
[12/29 23:30:42] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4823 s / img. ETA=1:29:13
[12/29 23:31:06] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4822 s / img. ETA=1:28:48
[12/29 23:31:30] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4822 s / img. ETA=1:28:24
[12/29 23:31:54] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4822 s / img. ETA=1:28:00
[12/29 23:32:18] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4822 s / img. ETA=1:27:36
[12/29 23:32:42] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4822 s / img. ETA=1:27:12
[12/29 23:33:06] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4822 s / img. ETA=1:26:47
[12/29 23:33:30] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4822 s / img. ETA=1:26:23
[12/29 23:33:54] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4822 s / img. ETA=1:25:59
[12/29 23:34:18] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4822 s / img. ETA=1:25:34
[12/29 23:34:42] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4822 s / img. ETA=1:25:10
[12/29 23:35:06] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4821 s / img. ETA=1:24:46
[12/29 23:35:30] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4821 s / img. ETA=1:24:22
[12/29 23:35:55] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4821 s / img. ETA=1:23:58
[12/29 23:36:19] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4821 s / img. ETA=1:23:34
[12/29 23:36:43] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4821 s / img. ETA=1:23:09
[12/29 23:37:07] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4821 s / img. ETA=1:22:45
[12/29 23:37:31] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4821 s / img. ETA=1:22:21
[12/29 23:37:55] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4821 s / img. ETA=1:21:57
[12/29 23:38:19] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4821 s / img. ETA=1:21:33
[12/29 23:38:43] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4821 s / img. ETA=1:21:09
[12/29 23:39:07] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4821 s / img. ETA=1:20:45
[12/29 23:39:31] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4821 s / img. ETA=1:20:21
[12/29 23:39:55] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4821 s / img. ETA=1:19:56
[12/29 23:40:20] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4821 s / img. ETA=1:19:33
[12/29 23:40:44] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4821 s / img. ETA=1:19:08
[12/29 23:41:08] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4821 s / img. ETA=1:18:44
[12/29 23:41:32] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4821 s / img. ETA=1:18:20
[12/29 23:41:56] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4821 s / img. ETA=1:17:56
[12/29 23:42:20] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4821 s / img. ETA=1:17:32
[12/29 23:42:44] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4821 s / img. ETA=1:17:08
[12/29 23:43:08] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4821 s / img. ETA=1:16:44
[12/29 23:43:32] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4821 s / img. ETA=1:16:20
[12/29 23:43:56] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4821 s / img. ETA=1:15:55
[12/29 23:44:20] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4821 s / img. ETA=1:15:31
[12/29 23:44:44] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4821 s / img. ETA=1:15:07
[12/29 23:45:08] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4821 s / img. ETA=1:14:43
[12/29 23:45:32] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4820 s / img. ETA=1:14:18
[12/29 23:45:57] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4820 s / img. ETA=1:13:54
[12/29 23:46:21] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4820 s / img. ETA=1:13:30
[12/29 23:46:45] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4820 s / img. ETA=1:13:06
[12/29 23:47:09] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4820 s / img. ETA=1:12:42
[12/29 23:47:33] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4820 s / img. ETA=1:12:18
[12/29 23:47:57] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4820 s / img. ETA=1:11:54
[12/29 23:48:21] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4820 s / img. ETA=1:11:29
[12/29 23:48:45] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4820 s / img. ETA=1:11:05
[12/29 23:49:09] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4820 s / img. ETA=1:10:41
[12/29 23:49:33] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4820 s / img. ETA=1:10:17
[12/29 23:49:57] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4820 s / img. ETA=1:09:53
[12/29 23:50:21] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4820 s / img. ETA=1:09:29
[12/29 23:50:45] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4820 s / img. ETA=1:09:05
[12/29 23:51:09] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4820 s / img. ETA=1:08:41
[12/29 23:51:34] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4820 s / img. ETA=1:08:16
[12/29 23:51:58] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4820 s / img. ETA=1:07:52
[12/29 23:52:22] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4820 s / img. ETA=1:07:28
[12/29 23:52:46] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4820 s / img. ETA=1:07:04
[12/29 23:53:10] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4820 s / img. ETA=1:06:40
[12/29 23:53:34] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4820 s / img. ETA=1:06:16
[12/29 23:53:58] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4820 s / img. ETA=1:05:52
[12/29 23:54:22] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4820 s / img. ETA=1:05:28
[12/29 23:54:46] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4820 s / img. ETA=1:05:03
[12/29 23:55:10] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4820 s / img. ETA=1:04:39
[12/29 23:55:35] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4821 s / img. ETA=1:04:16
[12/29 23:56:00] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4822 s / img. ETA=1:03:53
[12/29 23:56:24] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4822 s / img. ETA=1:03:28
[12/29 23:56:48] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4821 s / img. ETA=1:03:04
[12/29 23:57:12] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4821 s / img. ETA=1:02:40
[12/29 23:57:36] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4821 s / img. ETA=1:02:16
[12/29 23:58:00] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4821 s / img. ETA=1:01:52
[12/29 23:58:24] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4821 s / img. ETA=1:01:28
[12/29 23:58:49] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4821 s / img. ETA=1:01:04
[12/29 23:59:13] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4821 s / img. ETA=1:00:39
[12/29 23:59:37] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4821 s / img. ETA=1:00:15
[12/30 00:00:01] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4821 s / img. ETA=0:59:51
[12/30 00:00:25] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4821 s / img. ETA=0:59:27
[12/30 00:00:49] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4821 s / img. ETA=0:59:03
[12/30 00:01:13] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4821 s / img. ETA=0:58:39
[12/30 00:01:37] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4821 s / img. ETA=0:58:15
[12/30 00:02:01] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4821 s / img. ETA=0:57:51
[12/30 00:02:25] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4821 s / img. ETA=0:57:27
[12/30 00:02:49] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4821 s / img. ETA=0:57:02
[12/30 00:03:13] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4821 s / img. ETA=0:56:38
[12/30 00:03:37] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4821 s / img. ETA=0:56:14
[12/30 00:04:01] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4821 s / img. ETA=0:55:50
[12/30 00:04:25] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4820 s / img. ETA=0:55:26
[12/30 00:04:49] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4820 s / img. ETA=0:55:01
[12/30 00:05:13] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4820 s / img. ETA=0:54:37
[12/30 00:05:38] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4820 s / img. ETA=0:54:13
[12/30 00:06:02] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4820 s / img. ETA=0:53:49
[12/30 00:06:26] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4820 s / img. ETA=0:53:25
[12/30 00:06:50] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4820 s / img. ETA=0:53:01
[12/30 00:07:14] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4820 s / img. ETA=0:52:37
[12/30 00:07:38] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4820 s / img. ETA=0:52:13
[12/30 00:08:02] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4820 s / img. ETA=0:51:48
[12/30 00:08:26] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4820 s / img. ETA=0:51:24
[12/30 00:08:50] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4820 s / img. ETA=0:51:00
[12/30 00:09:14] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4820 s / img. ETA=0:50:36
[12/30 00:09:38] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4820 s / img. ETA=0:50:12
[12/30 00:10:02] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4820 s / img. ETA=0:49:48
[12/30 00:10:26] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4820 s / img. ETA=0:49:24
[12/30 00:10:50] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4820 s / img. ETA=0:49:00
[12/30 00:11:15] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4820 s / img. ETA=0:48:36
[12/30 00:11:38] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4820 s / img. ETA=0:48:11
[12/30 00:12:03] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4820 s / img. ETA=0:47:47
[12/30 00:12:27] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4820 s / img. ETA=0:47:23
[12/30 00:12:51] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4820 s / img. ETA=0:46:59
[12/30 00:13:15] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4820 s / img. ETA=0:46:35
[12/30 00:13:39] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4820 s / img. ETA=0:46:11
[12/30 00:14:03] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4820 s / img. ETA=0:45:47
[12/30 00:14:27] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4820 s / img. ETA=0:45:23
[12/30 00:14:51] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4820 s / img. ETA=0:44:59
[12/30 00:15:15] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4820 s / img. ETA=0:44:34
[12/30 00:15:39] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4820 s / img. ETA=0:44:10
[12/30 00:16:03] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4820 s / img. ETA=0:43:46
[12/30 00:16:28] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4820 s / img. ETA=0:43:22
[12/30 00:16:52] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4820 s / img. ETA=0:42:58
[12/30 00:17:16] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4820 s / img. ETA=0:42:34
[12/30 00:17:40] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4820 s / img. ETA=0:42:10
[12/30 00:18:04] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4820 s / img. ETA=0:41:46
[12/30 00:18:28] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4820 s / img. ETA=0:41:22
[12/30 00:18:52] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4820 s / img. ETA=0:40:58
[12/30 00:19:16] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4820 s / img. ETA=0:40:33
[12/30 00:19:40] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4820 s / img. ETA=0:40:09
[12/30 00:20:04] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4820 s / img. ETA=0:39:45
[12/30 00:20:28] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4820 s / img. ETA=0:39:21
[12/30 00:20:52] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4820 s / img. ETA=0:38:57
[12/30 00:21:16] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4820 s / img. ETA=0:38:33
[12/30 00:21:41] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4820 s / img. ETA=0:38:09
[12/30 00:22:05] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4820 s / img. ETA=0:37:45
[12/30 00:22:29] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4820 s / img. ETA=0:37:21
[12/30 00:22:53] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4820 s / img. ETA=0:36:56
[12/30 00:23:17] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4820 s / img. ETA=0:36:32
[12/30 00:23:41] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4819 s / img. ETA=0:36:08
[12/30 00:24:05] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4819 s / img. ETA=0:35:44
[12/30 00:24:29] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4819 s / img. ETA=0:35:20
[12/30 00:24:53] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4819 s / img. ETA=0:34:56
[12/30 00:25:17] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4819 s / img. ETA=0:34:32
[12/30 00:25:41] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4819 s / img. ETA=0:34:08
[12/30 00:26:05] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4819 s / img. ETA=0:33:44
[12/30 00:26:29] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4819 s / img. ETA=0:33:20
[12/30 00:26:54] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4819 s / img. ETA=0:32:55
[12/30 00:27:18] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4819 s / img. ETA=0:32:31
[12/30 00:27:42] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4819 s / img. ETA=0:32:07
[12/30 00:28:06] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4819 s / img. ETA=0:31:43
[12/30 00:28:30] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4819 s / img. ETA=0:31:19
[12/30 00:28:54] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4819 s / img. ETA=0:30:55
[12/30 00:29:18] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4819 s / img. ETA=0:30:31
[12/30 00:29:42] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4819 s / img. ETA=0:30:07
[12/30 00:30:06] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4819 s / img. ETA=0:29:43
[12/30 00:30:30] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4819 s / img. ETA=0:29:18
[12/30 00:30:54] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4819 s / img. ETA=0:28:54
[12/30 00:31:18] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4819 s / img. ETA=0:28:30
[12/30 00:31:42] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4819 s / img. ETA=0:28:06
[12/30 00:32:06] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4819 s / img. ETA=0:27:42
[12/30 00:32:30] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4819 s / img. ETA=0:27:18
[12/30 00:32:54] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4819 s / img. ETA=0:26:54
[12/30 00:33:18] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4819 s / img. ETA=0:26:30
[12/30 00:33:42] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4819 s / img. ETA=0:26:06
[12/30 00:34:07] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4819 s / img. ETA=0:25:42
[12/30 00:34:31] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4819 s / img. ETA=0:25:17
[12/30 00:34:55] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4819 s / img. ETA=0:24:53
[12/30 00:35:19] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4819 s / img. ETA=0:24:29
[12/30 00:35:43] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4819 s / img. ETA=0:24:05
[12/30 00:36:07] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4819 s / img. ETA=0:23:41
[12/30 00:36:31] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4819 s / img. ETA=0:23:17
[12/30 00:36:55] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4819 s / img. ETA=0:22:53
[12/30 00:37:19] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4819 s / img. ETA=0:22:29
[12/30 00:37:43] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4819 s / img. ETA=0:22:05
[12/30 00:38:07] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4819 s / img. ETA=0:21:41
[12/30 00:38:31] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4819 s / img. ETA=0:21:16
[12/30 00:38:55] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4819 s / img. ETA=0:20:52
[12/30 00:39:20] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4819 s / img. ETA=0:20:28
[12/30 00:39:44] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4819 s / img. ETA=0:20:04
[12/30 00:40:08] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4819 s / img. ETA=0:19:40
[12/30 00:40:32] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4819 s / img. ETA=0:19:16
[12/30 00:40:56] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4818 s / img. ETA=0:18:52
[12/30 00:41:20] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4818 s / img. ETA=0:18:28
[12/30 00:41:44] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4818 s / img. ETA=0:18:04
[12/30 00:42:08] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4818 s / img. ETA=0:17:40
[12/30 00:42:32] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4818 s / img. ETA=0:17:15
[12/30 00:42:56] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4818 s / img. ETA=0:16:51
[12/30 00:43:20] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4818 s / img. ETA=0:16:27
[12/30 00:43:44] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4818 s / img. ETA=0:16:03
[12/30 00:44:08] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4818 s / img. ETA=0:15:39
[12/30 00:44:32] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4818 s / img. ETA=0:15:15
[12/30 00:44:56] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4818 s / img. ETA=0:14:51
[12/30 00:45:20] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4818 s / img. ETA=0:14:27
[12/30 00:45:44] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4818 s / img. ETA=0:14:03
[12/30 00:46:08] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4818 s / img. ETA=0:13:39
[12/30 00:46:32] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4818 s / img. ETA=0:13:14
[12/30 00:46:56] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4818 s / img. ETA=0:12:50
[12/30 00:47:20] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4818 s / img. ETA=0:12:26
[12/30 00:47:44] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4818 s / img. ETA=0:12:02
[12/30 00:48:08] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4818 s / img. ETA=0:11:38
[12/30 00:48:32] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4818 s / img. ETA=0:11:14
[12/30 00:48:56] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4818 s / img. ETA=0:10:50
[12/30 00:49:20] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4818 s / img. ETA=0:10:26
[12/30 00:49:44] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4818 s / img. ETA=0:10:02
[12/30 00:50:08] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4818 s / img. ETA=0:09:38
[12/30 00:50:33] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4818 s / img. ETA=0:09:14
[12/30 00:50:57] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4818 s / img. ETA=0:08:49
[12/30 00:51:21] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4818 s / img. ETA=0:08:25
[12/30 00:51:45] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4818 s / img. ETA=0:08:01
[12/30 00:52:09] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4818 s / img. ETA=0:07:37
[12/30 00:52:33] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4818 s / img. ETA=0:07:13
[12/30 00:52:57] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4818 s / img. ETA=0:06:49
[12/30 00:53:21] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4818 s / img. ETA=0:06:25
[12/30 00:53:45] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4818 s / img. ETA=0:06:01
[12/30 00:54:10] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4818 s / img. ETA=0:05:37
[12/30 00:54:34] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4818 s / img. ETA=0:05:13
[12/30 00:54:58] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4818 s / img. ETA=0:04:49
[12/30 00:55:22] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4818 s / img. ETA=0:04:24
[12/30 00:55:47] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4819 s / img. ETA=0:04:00
[12/30 00:56:11] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4819 s / img. ETA=0:03:36
[12/30 00:56:35] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4819 s / img. ETA=0:03:12
[12/30 00:57:00] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4819 s / img. ETA=0:02:48
[12/30 00:57:24] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4819 s / img. ETA=0:02:24
[12/30 00:57:48] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4819 s / img. ETA=0:02:00
[12/30 00:58:12] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4819 s / img. ETA=0:01:36
[12/30 00:58:36] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4819 s / img. ETA=0:01:12
[12/30 00:59:00] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4819 s / img. ETA=0:00:48
[12/30 00:59:24] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4819 s / img. ETA=0:00:24
[12/30 00:59:48] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4819 s / img. ETA=0:00:00
[12/30 01:00:22] d2.evaluation.evaluator INFO: Total inference time: 2:15:50 (0.483823 s / img per device, on 2 devices)
[12/30 01:00:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:24 (0.478754 s / img per device, on 2 devices)
[12/30 01:00:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/30 01:00:24] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/30 01:00:25] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/30 01:00:53] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/30 01:00:53] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/30 01:00:54] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/30 01:00:54] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/30 01:00:54] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/30 01:00:54] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/30 01:18:13] detectron2 INFO: Rank of current process: 0. World size: 2
[12/30 01:18:17] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/30 01:18:17] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/30 01:18:17] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_val_light",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 96368  ## 46368 74368(70000) 96368(8500)
  BASE_LR: 0.01     ### 
  STEPS: (76100, 76300)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/30 01:18:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_light',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 96368
  MOMENTUM: 0.9
  STEPS: (76100, 76300)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/30 01:18:17] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/30 01:18:17] d2.utils.env INFO: Using a generated random seed 17865857
[12/30 01:18:21] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/30 01:18:21] d2.data.datasets.coco INFO: Loaded 14085 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_light.json
[12/30 01:18:22] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 4485         |   ASC-US   | 4590         |    HSIL     | 1983         |
|    LSIL    | 2574         |  Candida   | 1198         | Trichomonas | 7388         |
|            |              |            |              |             |              |
|   total    | 22218        |            |              |             |              |[0m
[12/30 01:18:22] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[12/30 01:18:22] d2.data.build INFO: Using training sampler TrainingSampler
[12/30 01:19:24] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0084999.pth
[12/30 01:19:25] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0084999.pth
[12/30 01:19:26] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0084999.pth
[12/30 01:19:26] d2.engine.train_loop INFO: Starting training from iteration 85000
[12/30 01:20:24] d2.utils.events INFO: eta: 9:08:12  iter: 85019  total_loss: 0.460  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 2.9276  data_time: 0.0033  lr: 0.000100  max_mem: 8339M
[12/30 01:21:25] d2.utils.events INFO: eta: 9:33:38  iter: 85039  total_loss: 0.602  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 2.9844  data_time: 0.0026  lr: 0.000100  max_mem: 8339M
[12/30 01:22:24] d2.utils.events INFO: eta: 9:30:13  iter: 85059  total_loss: 0.518  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 2.9747  data_time: 0.0030  lr: 0.000100  max_mem: 8572M
[12/30 01:23:24] d2.utils.events INFO: eta: 9:29:12  iter: 85079  total_loss: 0.631  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 2.9797  data_time: 0.0029  lr: 0.000100  max_mem: 8572M
[12/30 01:24:24] d2.utils.events INFO: eta: 9:28:12  iter: 85099  total_loss: 0.657  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 2.9792  data_time: 0.0026  lr: 0.000100  max_mem: 8572M
[12/30 01:25:25] d2.utils.events INFO: eta: 9:27:16  iter: 85119  total_loss: 0.580  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 2.9891  data_time: 0.0026  lr: 0.000100  max_mem: 8573M
[12/30 01:26:25] d2.utils.events INFO: eta: 9:27:00  iter: 85139  total_loss: 0.608  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 2.9916  data_time: 0.0028  lr: 0.000100  max_mem: 8573M
[12/30 01:27:26] d2.utils.events INFO: eta: 9:26:11  iter: 85159  total_loss: 0.859  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 2.9977  data_time: 0.0024  lr: 0.000100  max_mem: 8573M
[12/30 01:28:26] d2.utils.events INFO: eta: 9:25:11  iter: 85179  total_loss: 0.498  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0024  data_time: 0.0021  lr: 0.000100  max_mem: 8573M
[12/30 01:29:26] d2.utils.events INFO: eta: 9:24:08  iter: 85199  total_loss: 0.378  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.084  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0002  data_time: 0.0028  lr: 0.000100  max_mem: 8573M
[12/30 01:30:26] d2.utils.events INFO: eta: 9:23:01  iter: 85219  total_loss: 0.626  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 2.9988  data_time: 0.0026  lr: 0.000100  max_mem: 8573M
[12/30 01:31:27] d2.utils.events INFO: eta: 9:22:10  iter: 85239  total_loss: 0.680  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0040  data_time: 0.0024  lr: 0.000100  max_mem: 8573M
[12/30 01:32:29] d2.utils.events INFO: eta: 9:21:37  iter: 85259  total_loss: 0.806  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0108  data_time: 0.0026  lr: 0.000100  max_mem: 8573M
[12/30 01:33:30] d2.utils.events INFO: eta: 9:20:47  iter: 85279  total_loss: 0.719  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0128  data_time: 0.0026  lr: 0.000100  max_mem: 8573M
[12/30 01:34:31] d2.utils.events INFO: eta: 9:19:57  iter: 85299  total_loss: 0.588  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0165  data_time: 0.0026  lr: 0.000100  max_mem: 8573M
[12/30 01:35:32] d2.utils.events INFO: eta: 9:18:57  iter: 85319  total_loss: 0.647  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0178  data_time: 0.0027  lr: 0.000100  max_mem: 8573M
[12/30 01:36:32] d2.utils.events INFO: eta: 9:17:45  iter: 85339  total_loss: 0.687  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0169  data_time: 0.0027  lr: 0.000100  max_mem: 8573M
[12/30 01:37:32] d2.utils.events INFO: eta: 9:16:42  iter: 85359  total_loss: 0.393  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.112  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0164  data_time: 0.0024  lr: 0.000100  max_mem: 8573M
[12/30 01:38:34] d2.utils.events INFO: eta: 9:16:06  iter: 85379  total_loss: 0.593  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0211  data_time: 0.0033  lr: 0.000100  max_mem: 8573M
[12/30 01:39:36] d2.utils.events INFO: eta: 9:15:14  iter: 85399  total_loss: 0.497  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0230  data_time: 0.0029  lr: 0.000100  max_mem: 8573M
[12/30 01:40:35] d2.utils.events INFO: eta: 9:14:08  iter: 85419  total_loss: 0.521  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0204  data_time: 0.0030  lr: 0.000100  max_mem: 8573M
[12/30 01:41:36] d2.utils.events INFO: eta: 9:13:13  iter: 85439  total_loss: 0.664  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0218  data_time: 0.0026  lr: 0.000100  max_mem: 8573M
[12/30 01:42:35] d2.utils.events INFO: eta: 9:12:02  iter: 85459  total_loss: 0.852  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0196  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 01:43:35] d2.utils.events INFO: eta: 9:11:00  iter: 85479  total_loss: 0.547  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0186  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 01:44:36] d2.utils.events INFO: eta: 9:10:05  iter: 85499  total_loss: 0.738  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0195  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 01:45:36] d2.utils.events INFO: eta: 9:09:00  iter: 85519  total_loss: 0.466  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0191  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 01:46:38] d2.utils.events INFO: eta: 9:08:03  iter: 85539  total_loss: 0.492  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0210  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 01:47:40] d2.utils.events INFO: eta: 9:07:17  iter: 85559  total_loss: 0.545  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.137  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0240  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 01:48:41] d2.utils.events INFO: eta: 9:06:17  iter: 85579  total_loss: 0.644  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0243  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 01:49:43] d2.utils.events INFO: eta: 9:05:27  iter: 85599  total_loss: 0.581  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0265  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 01:50:45] d2.utils.events INFO: eta: 9:04:43  iter: 85619  total_loss: 0.669  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 01:51:44] d2.utils.events INFO: eta: 9:03:42  iter: 85639  total_loss: 0.390  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 01:52:44] d2.utils.events INFO: eta: 9:02:52  iter: 85659  total_loss: 0.569  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0269  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 01:53:44] d2.utils.events INFO: eta: 9:01:39  iter: 85679  total_loss: 0.608  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0254  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 01:54:46] d2.utils.events INFO: eta: 9:00:43  iter: 85699  total_loss: 0.828  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0271  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 01:55:47] d2.utils.events INFO: eta: 8:59:54  iter: 85719  total_loss: 0.546  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0274  data_time: 0.0042  lr: 0.000100  max_mem: 8788M
[12/30 01:56:47] d2.utils.events INFO: eta: 8:58:56  iter: 85739  total_loss: 0.543  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0277  data_time: 0.0031  lr: 0.000100  max_mem: 8788M
[12/30 01:57:47] d2.utils.events INFO: eta: 8:57:52  iter: 85759  total_loss: 0.478  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0267  data_time: 0.0035  lr: 0.000100  max_mem: 8788M
[12/30 01:58:48] d2.utils.events INFO: eta: 8:56:55  iter: 85779  total_loss: 0.567  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0268  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 01:59:49] d2.utils.events INFO: eta: 8:55:55  iter: 85799  total_loss: 0.652  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0276  data_time: 0.0031  lr: 0.000100  max_mem: 8788M
[12/30 02:00:51] d2.utils.events INFO: eta: 8:54:58  iter: 85819  total_loss: 0.613  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0288  data_time: 0.0034  lr: 0.000100  max_mem: 8788M
[12/30 02:01:52] d2.utils.events INFO: eta: 8:53:55  iter: 85839  total_loss: 0.545  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0021  lr: 0.000100  max_mem: 8788M
[12/30 02:02:54] d2.utils.events INFO: eta: 8:53:01  iter: 85859  total_loss: 0.723  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0314  data_time: 0.0034  lr: 0.000100  max_mem: 8788M
[12/30 02:03:55] d2.utils.events INFO: eta: 8:52:00  iter: 85879  total_loss: 0.614  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:04:56] d2.utils.events INFO: eta: 8:50:59  iter: 85899  total_loss: 0.584  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:05:58] d2.utils.events INFO: eta: 8:50:03  iter: 85919  total_loss: 0.668  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0336  data_time: 0.0022  lr: 0.000100  max_mem: 8788M
[12/30 02:06:58] d2.utils.events INFO: eta: 8:49:01  iter: 85939  total_loss: 0.667  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0331  data_time: 0.0021  lr: 0.000100  max_mem: 8788M
[12/30 02:07:59] d2.utils.events INFO: eta: 8:48:05  iter: 85959  total_loss: 0.527  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0033  lr: 0.000100  max_mem: 8788M
[12/30 02:09:01] d2.utils.events INFO: eta: 8:47:09  iter: 85979  total_loss: 0.557  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0343  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:10:01] d2.utils.events INFO: eta: 8:46:03  iter: 85999  total_loss: 0.727  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0032  lr: 0.000100  max_mem: 8788M
[12/30 02:11:03] d2.utils.events INFO: eta: 8:45:08  iter: 86019  total_loss: 0.771  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0350  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 02:12:03] d2.utils.events INFO: eta: 8:44:01  iter: 86039  total_loss: 0.486  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0026  lr: 0.000100  max_mem: 8788M
[12/30 02:13:04] d2.utils.events INFO: eta: 8:43:05  iter: 86059  total_loss: 0.556  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 02:14:05] d2.utils.events INFO: eta: 8:42:04  iter: 86079  total_loss: 0.636  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0352  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:15:07] d2.utils.events INFO: eta: 8:41:05  iter: 86099  total_loss: 0.551  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0359  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 02:16:07] d2.utils.events INFO: eta: 8:40:03  iter: 86119  total_loss: 0.590  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0355  data_time: 0.0032  lr: 0.000100  max_mem: 8788M
[12/30 02:17:08] d2.utils.events INFO: eta: 8:39:02  iter: 86139  total_loss: 0.529  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0026  lr: 0.000100  max_mem: 8788M
[12/30 02:18:09] d2.utils.events INFO: eta: 8:38:01  iter: 86159  total_loss: 0.615  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0361  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:19:09] d2.utils.events INFO: eta: 8:36:59  iter: 86179  total_loss: 0.632  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0352  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 02:20:09] d2.utils.events INFO: eta: 8:35:58  iter: 86199  total_loss: 0.655  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 02:21:10] d2.utils.events INFO: eta: 8:34:58  iter: 86219  total_loss: 0.523  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 02:22:10] d2.utils.events INFO: eta: 8:33:50  iter: 86239  total_loss: 0.544  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:23:10] d2.utils.events INFO: eta: 8:32:46  iter: 86259  total_loss: 0.398  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0334  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 02:24:10] d2.utils.events INFO: eta: 8:31:44  iter: 86279  total_loss: 0.520  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0022  lr: 0.000100  max_mem: 8788M
[12/30 02:25:11] d2.utils.events INFO: eta: 8:30:41  iter: 86299  total_loss: 0.588  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0330  data_time: 0.0021  lr: 0.000100  max_mem: 8788M
[12/30 02:26:12] d2.utils.events INFO: eta: 8:29:40  iter: 86319  total_loss: 0.696  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:27:11] d2.utils.events INFO: eta: 8:28:38  iter: 86339  total_loss: 0.497  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 8788M
[12/30 02:28:12] d2.utils.events INFO: eta: 8:27:37  iter: 86359  total_loss: 0.544  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 02:29:13] d2.utils.events INFO: eta: 8:26:34  iter: 86379  total_loss: 0.707  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0329  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:30:14] d2.utils.events INFO: eta: 8:25:33  iter: 86399  total_loss: 0.688  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0328  data_time: 0.0026  lr: 0.000100  max_mem: 8788M
[12/30 02:31:15] d2.utils.events INFO: eta: 8:24:35  iter: 86419  total_loss: 0.560  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0334  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 02:32:16] d2.utils.events INFO: eta: 8:23:33  iter: 86439  total_loss: 0.645  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0334  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:33:18] d2.utils.events INFO: eta: 8:22:36  iter: 86459  total_loss: 0.877  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.094  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.106  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:34:18] d2.utils.events INFO: eta: 8:21:38  iter: 86479  total_loss: 0.521  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0339  data_time: 0.0031  lr: 0.000100  max_mem: 8788M
[12/30 02:35:20] d2.utils.events INFO: eta: 8:20:36  iter: 86499  total_loss: 0.663  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 02:36:19] d2.utils.events INFO: eta: 8:19:36  iter: 86519  total_loss: 0.617  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0336  data_time: 0.0026  lr: 0.000100  max_mem: 8788M
[12/30 02:37:21] d2.utils.events INFO: eta: 8:18:34  iter: 86539  total_loss: 0.634  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 02:38:21] d2.utils.events INFO: eta: 8:17:30  iter: 86559  total_loss: 0.522  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0340  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 02:39:21] d2.utils.events INFO: eta: 8:16:29  iter: 86579  total_loss: 0.391  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0335  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 02:40:22] d2.utils.events INFO: eta: 8:15:27  iter: 86599  total_loss: 0.673  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0335  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:41:24] d2.utils.events INFO: eta: 8:14:26  iter: 86619  total_loss: 0.717  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0034  lr: 0.000100  max_mem: 8788M
[12/30 02:42:24] d2.utils.events INFO: eta: 8:13:25  iter: 86639  total_loss: 0.452  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0341  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 02:43:24] d2.utils.events INFO: eta: 8:12:22  iter: 86659  total_loss: 0.559  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 02:44:25] d2.utils.events INFO: eta: 8:11:24  iter: 86679  total_loss: 0.663  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:45:25] d2.utils.events INFO: eta: 8:10:23  iter: 86699  total_loss: 0.583  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0335  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:46:26] d2.utils.events INFO: eta: 8:09:22  iter: 86719  total_loss: 0.539  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0336  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 02:47:27] d2.utils.events INFO: eta: 8:08:20  iter: 86739  total_loss: 0.437  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.078  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0336  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 02:48:28] d2.utils.events INFO: eta: 8:07:21  iter: 86759  total_loss: 0.579  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0337  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 02:49:29] d2.utils.events INFO: eta: 8:06:19  iter: 86779  total_loss: 0.581  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0337  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 02:50:29] d2.utils.events INFO: eta: 8:05:17  iter: 86799  total_loss: 0.407  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 02:51:28] d2.utils.events INFO: eta: 8:04:13  iter: 86819  total_loss: 0.697  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0033  lr: 0.000100  max_mem: 8788M
[12/30 02:52:29] d2.utils.events INFO: eta: 8:03:14  iter: 86839  total_loss: 0.548  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.005  loss_rpn_loc: 0.003  time: 3.0327  data_time: 0.0031  lr: 0.000100  max_mem: 8788M
[12/30 02:53:31] d2.utils.events INFO: eta: 8:02:12  iter: 86859  total_loss: 0.570  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0032  lr: 0.000100  max_mem: 8788M
[12/30 02:54:31] d2.utils.events INFO: eta: 8:01:11  iter: 86879  total_loss: 0.673  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0332  data_time: 0.0022  lr: 0.000100  max_mem: 8788M
[12/30 02:55:30] d2.utils.events INFO: eta: 8:00:05  iter: 86899  total_loss: 0.616  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0020  lr: 0.000100  max_mem: 8788M
[12/30 02:56:32] d2.utils.events INFO: eta: 7:59:01  iter: 86919  total_loss: 0.464  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0328  data_time: 0.0037  lr: 0.000100  max_mem: 8788M
[12/30 02:57:32] d2.utils.events INFO: eta: 7:58:01  iter: 86939  total_loss: 0.543  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0325  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:58:33] d2.utils.events INFO: eta: 7:56:57  iter: 86959  total_loss: 0.740  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0326  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 02:59:34] d2.utils.events INFO: eta: 7:55:56  iter: 86979  total_loss: 0.538  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0330  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 03:00:34] d2.utils.events INFO: eta: 7:54:57  iter: 86999  total_loss: 0.722  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0023  lr: 0.000100  max_mem: 8788M
[12/30 03:01:33] d2.utils.events INFO: eta: 7:53:49  iter: 87019  total_loss: 0.473  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0021  lr: 0.000100  max_mem: 8788M
[12/30 03:02:35] d2.utils.events INFO: eta: 7:52:55  iter: 87039  total_loss: 0.851  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0325  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 03:03:36] d2.utils.events INFO: eta: 7:51:51  iter: 87059  total_loss: 0.877  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0325  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 03:04:36] d2.utils.events INFO: eta: 7:50:54  iter: 87079  total_loss: 0.624  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 03:05:37] d2.utils.events INFO: eta: 7:49:51  iter: 87099  total_loss: 0.479  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 8788M
[12/30 03:06:38] d2.utils.events INFO: eta: 7:48:54  iter: 87119  total_loss: 0.528  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0030  lr: 0.000100  max_mem: 8788M
[12/30 03:07:39] d2.utils.events INFO: eta: 7:47:52  iter: 87139  total_loss: 0.864  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0327  data_time: 0.0024  lr: 0.000100  max_mem: 8788M
[12/30 03:08:40] d2.utils.events INFO: eta: 7:46:51  iter: 87159  total_loss: 0.522  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 03:09:42] d2.utils.events INFO: eta: 7:45:54  iter: 87179  total_loss: 0.745  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.008  loss_rpn_loc: 0.010  time: 3.0334  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 03:10:42] d2.utils.events INFO: eta: 7:44:54  iter: 87199  total_loss: 0.737  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0333  data_time: 0.0028  lr: 0.000100  max_mem: 8788M
[12/30 03:11:43] d2.utils.events INFO: eta: 7:43:52  iter: 87219  total_loss: 0.558  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0330  data_time: 0.0032  lr: 0.000100  max_mem: 8788M
[12/30 03:12:42] d2.utils.events INFO: eta: 7:42:52  iter: 87239  total_loss: 0.531  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0023  lr: 0.000100  max_mem: 8788M
[12/30 03:13:44] d2.utils.events INFO: eta: 7:41:52  iter: 87259  total_loss: 0.634  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0329  data_time: 0.0032  lr: 0.000100  max_mem: 8788M
[12/30 03:14:45] d2.utils.events INFO: eta: 7:40:54  iter: 87279  total_loss: 0.585  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0027  lr: 0.000100  max_mem: 8788M
[12/30 03:15:45] d2.utils.events INFO: eta: 7:39:53  iter: 87299  total_loss: 0.505  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0025  lr: 0.000100  max_mem: 8788M
[12/30 03:16:44] d2.utils.events INFO: eta: 7:38:51  iter: 87319  total_loss: 0.499  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0029  lr: 0.000100  max_mem: 8788M
[12/30 03:17:45] d2.utils.events INFO: eta: 7:37:54  iter: 87339  total_loss: 0.434  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0023  lr: 0.000100  max_mem: 8788M
[12/30 03:18:46] d2.utils.events INFO: eta: 7:36:55  iter: 87359  total_loss: 0.613  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0023  lr: 0.000100  max_mem: 8788M
[12/30 03:19:49] d2.utils.events INFO: eta: 7:35:55  iter: 87379  total_loss: 0.632  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0332  data_time: 0.0034  lr: 0.000100  max_mem: 9045M
[12/30 03:20:48] d2.utils.events INFO: eta: 7:34:51  iter: 87399  total_loss: 0.591  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 03:21:48] d2.utils.events INFO: eta: 7:33:46  iter: 87419  total_loss: 0.437  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0326  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 03:22:49] d2.utils.events INFO: eta: 7:32:48  iter: 87439  total_loss: 0.470  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0323  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 03:23:48] d2.utils.events INFO: eta: 7:31:41  iter: 87459  total_loss: 0.465  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0320  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 03:24:49] d2.utils.events INFO: eta: 7:30:42  iter: 87479  total_loss: 0.541  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:25:49] d2.utils.events INFO: eta: 7:29:39  iter: 87499  total_loss: 0.438  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 03:26:49] d2.utils.events INFO: eta: 7:28:38  iter: 87519  total_loss: 0.513  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0313  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 03:27:50] d2.utils.events INFO: eta: 7:27:37  iter: 87539  total_loss: 0.654  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 03:28:51] d2.utils.events INFO: eta: 7:26:37  iter: 87559  total_loss: 0.491  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 03:29:53] d2.utils.events INFO: eta: 7:25:39  iter: 87579  total_loss: 0.626  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 03:30:53] d2.utils.events INFO: eta: 7:24:35  iter: 87599  total_loss: 0.562  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 03:31:53] d2.utils.events INFO: eta: 7:23:33  iter: 87619  total_loss: 0.441  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 03:32:53] d2.utils.events INFO: eta: 7:22:33  iter: 87639  total_loss: 0.651  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 03:33:54] d2.utils.events INFO: eta: 7:21:33  iter: 87659  total_loss: 0.415  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0043  lr: 0.000100  max_mem: 9045M
[12/30 03:34:54] d2.utils.events INFO: eta: 7:20:31  iter: 87679  total_loss: 0.721  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 03:35:54] d2.utils.events INFO: eta: 7:19:28  iter: 87699  total_loss: 0.358  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0312  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 03:36:54] d2.utils.events INFO: eta: 7:18:23  iter: 87719  total_loss: 0.492  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 03:37:55] d2.utils.events INFO: eta: 7:17:23  iter: 87739  total_loss: 0.482  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 03:38:56] d2.utils.events INFO: eta: 7:16:21  iter: 87759  total_loss: 0.661  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 03:39:58] d2.utils.events INFO: eta: 7:15:22  iter: 87779  total_loss: 0.601  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 03:40:59] d2.utils.events INFO: eta: 7:14:26  iter: 87799  total_loss: 0.712  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0319  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 03:41:59] d2.utils.events INFO: eta: 7:13:25  iter: 87819  total_loss: 0.508  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 03:42:58] d2.utils.events INFO: eta: 7:12:24  iter: 87839  total_loss: 0.683  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 03:44:00] d2.utils.events INFO: eta: 7:11:23  iter: 87859  total_loss: 0.480  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:45:01] d2.utils.events INFO: eta: 7:10:23  iter: 87879  total_loss: 0.689  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 03:46:03] d2.utils.events INFO: eta: 7:09:23  iter: 87899  total_loss: 0.629  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 03:47:03] d2.utils.events INFO: eta: 7:08:21  iter: 87919  total_loss: 0.701  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:48:04] d2.utils.events INFO: eta: 7:07:21  iter: 87939  total_loss: 0.688  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 03:49:05] d2.utils.events INFO: eta: 7:06:20  iter: 87959  total_loss: 0.475  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 03:50:07] d2.utils.events INFO: eta: 7:05:19  iter: 87979  total_loss: 0.627  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:51:09] d2.utils.events INFO: eta: 7:04:22  iter: 87999  total_loss: 0.614  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0328  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:52:09] d2.utils.events INFO: eta: 7:03:24  iter: 88019  total_loss: 0.532  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:53:11] d2.utils.events INFO: eta: 7:02:22  iter: 88039  total_loss: 0.482  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 03:54:12] d2.utils.events INFO: eta: 7:01:21  iter: 88059  total_loss: 0.522  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 03:55:13] d2.utils.events INFO: eta: 7:00:20  iter: 88079  total_loss: 0.467  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 03:56:15] d2.utils.events INFO: eta: 6:59:20  iter: 88099  total_loss: 0.679  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0336  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 03:57:15] d2.utils.events INFO: eta: 6:58:16  iter: 88119  total_loss: 0.500  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0333  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 03:58:15] d2.utils.events INFO: eta: 6:57:14  iter: 88139  total_loss: 0.605  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0033  lr: 0.000100  max_mem: 9045M
[12/30 03:59:15] d2.utils.events INFO: eta: 6:56:10  iter: 88159  total_loss: 0.425  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0032  lr: 0.000100  max_mem: 9045M
[12/30 04:00:17] d2.utils.events INFO: eta: 6:55:06  iter: 88179  total_loss: 0.648  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 04:01:17] d2.utils.events INFO: eta: 6:54:01  iter: 88199  total_loss: 0.481  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0331  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 04:02:19] d2.utils.events INFO: eta: 6:53:06  iter: 88219  total_loss: 0.598  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0335  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 04:03:18] d2.utils.events INFO: eta: 6:52:07  iter: 88239  total_loss: 0.454  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:04:19] d2.utils.events INFO: eta: 6:51:04  iter: 88259  total_loss: 0.593  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:05:19] d2.utils.events INFO: eta: 6:50:01  iter: 88279  total_loss: 0.654  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0330  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 04:06:19] d2.utils.events INFO: eta: 6:49:02  iter: 88299  total_loss: 0.689  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0327  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 04:07:19] d2.utils.events INFO: eta: 6:48:02  iter: 88319  total_loss: 0.345  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:08:19] d2.utils.events INFO: eta: 6:47:01  iter: 88339  total_loss: 0.704  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:09:21] d2.utils.events INFO: eta: 6:46:02  iter: 88359  total_loss: 0.668  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0326  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:10:22] d2.utils.events INFO: eta: 6:44:58  iter: 88379  total_loss: 0.475  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0328  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 04:11:23] d2.utils.events INFO: eta: 6:44:02  iter: 88399  total_loss: 0.504  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0329  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:12:22] d2.utils.events INFO: eta: 6:43:01  iter: 88419  total_loss: 0.612  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:13:23] d2.utils.events INFO: eta: 6:41:57  iter: 88439  total_loss: 0.488  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0324  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 04:14:23] d2.utils.events INFO: eta: 6:40:59  iter: 88459  total_loss: 0.548  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:15:24] d2.utils.events INFO: eta: 6:39:55  iter: 88479  total_loss: 0.418  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:16:24] d2.utils.events INFO: eta: 6:38:58  iter: 88499  total_loss: 0.567  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:17:26] d2.utils.events INFO: eta: 6:38:01  iter: 88519  total_loss: 0.531  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0327  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:18:26] d2.utils.events INFO: eta: 6:37:01  iter: 88539  total_loss: 0.529  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:19:28] d2.utils.events INFO: eta: 6:36:00  iter: 88559  total_loss: 0.368  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 04:20:27] d2.utils.events INFO: eta: 6:34:56  iter: 88579  total_loss: 0.614  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:21:27] d2.utils.events INFO: eta: 6:33:57  iter: 88599  total_loss: 0.593  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0322  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:22:27] d2.utils.events INFO: eta: 6:32:54  iter: 88619  total_loss: 0.705  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0318  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:23:27] d2.utils.events INFO: eta: 6:31:52  iter: 88639  total_loss: 0.550  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 04:24:29] d2.utils.events INFO: eta: 6:30:51  iter: 88659  total_loss: 0.503  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:25:29] d2.utils.events INFO: eta: 6:29:47  iter: 88679  total_loss: 0.490  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:26:29] d2.utils.events INFO: eta: 6:28:46  iter: 88699  total_loss: 0.512  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0318  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:27:30] d2.utils.events INFO: eta: 6:27:49  iter: 88719  total_loss: 0.544  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:28:31] d2.utils.events INFO: eta: 6:26:48  iter: 88739  total_loss: 0.462  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0319  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:29:32] d2.utils.events INFO: eta: 6:25:50  iter: 88759  total_loss: 0.581  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 04:30:31] d2.utils.events INFO: eta: 6:24:42  iter: 88779  total_loss: 0.552  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:31:32] d2.utils.events INFO: eta: 6:23:37  iter: 88799  total_loss: 0.524  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:32:32] d2.utils.events INFO: eta: 6:22:37  iter: 88819  total_loss: 0.452  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:33:33] d2.utils.events INFO: eta: 6:21:40  iter: 88839  total_loss: 0.534  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:34:35] d2.utils.events INFO: eta: 6:20:42  iter: 88859  total_loss: 0.450  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:35:36] d2.utils.events INFO: eta: 6:19:42  iter: 88879  total_loss: 0.669  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0020  lr: 0.000100  max_mem: 9045M
[12/30 04:36:36] d2.utils.events INFO: eta: 6:18:40  iter: 88899  total_loss: 0.591  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:37:38] d2.utils.events INFO: eta: 6:17:43  iter: 88919  total_loss: 0.519  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:38:40] d2.utils.events INFO: eta: 6:16:42  iter: 88939  total_loss: 0.434  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:39:42] d2.utils.events INFO: eta: 6:15:43  iter: 88959  total_loss: 0.785  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0328  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:40:42] d2.utils.events INFO: eta: 6:14:39  iter: 88979  total_loss: 0.572  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:41:42] d2.utils.events INFO: eta: 6:13:33  iter: 88999  total_loss: 0.522  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 04:42:42] d2.utils.events INFO: eta: 6:12:32  iter: 89019  total_loss: 0.452  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 04:43:41] d2.utils.events INFO: eta: 6:11:27  iter: 89039  total_loss: 0.506  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 04:44:42] d2.utils.events INFO: eta: 6:10:25  iter: 89059  total_loss: 0.553  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 04:45:42] d2.utils.events INFO: eta: 6:09:24  iter: 89079  total_loss: 0.510  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:46:43] d2.utils.events INFO: eta: 6:08:24  iter: 89099  total_loss: 0.568  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0319  data_time: 0.0032  lr: 0.000100  max_mem: 9045M
[12/30 04:47:42] d2.utils.events INFO: eta: 6:07:21  iter: 89119  total_loss: 0.472  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.064  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:48:44] d2.utils.events INFO: eta: 6:06:22  iter: 89139  total_loss: 0.588  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:49:43] d2.utils.events INFO: eta: 6:05:21  iter: 89159  total_loss: 0.453  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 04:50:44] d2.utils.events INFO: eta: 6:04:20  iter: 89179  total_loss: 0.727  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:51:44] d2.utils.events INFO: eta: 6:03:21  iter: 89199  total_loss: 0.650  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:52:44] d2.utils.events INFO: eta: 6:02:17  iter: 89219  total_loss: 0.619  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 04:53:45] d2.utils.events INFO: eta: 6:01:18  iter: 89239  total_loss: 0.457  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 04:54:46] d2.utils.events INFO: eta: 6:00:16  iter: 89259  total_loss: 0.563  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 04:55:50] d2.utils.events INFO: eta: 5:59:18  iter: 89279  total_loss: 0.796  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0320  data_time: 0.0032  lr: 0.000100  max_mem: 9045M
[12/30 04:56:48] d2.utils.events INFO: eta: 5:58:15  iter: 89299  total_loss: 0.613  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:57:48] d2.utils.events INFO: eta: 5:57:15  iter: 89319  total_loss: 0.712  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0313  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 04:58:48] d2.utils.events INFO: eta: 5:56:14  iter: 89339  total_loss: 0.508  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 04:59:50] d2.utils.events INFO: eta: 5:55:13  iter: 89359  total_loss: 0.624  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:00:51] d2.utils.events INFO: eta: 5:54:14  iter: 89379  total_loss: 0.605  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:01:52] d2.utils.events INFO: eta: 5:53:13  iter: 89399  total_loss: 0.625  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0318  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 05:02:53] d2.utils.events INFO: eta: 5:52:12  iter: 89419  total_loss: 0.694  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 05:03:52] d2.utils.events INFO: eta: 5:51:12  iter: 89439  total_loss: 0.746  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 05:04:54] d2.utils.events INFO: eta: 5:50:13  iter: 89459  total_loss: 0.475  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:05:53] d2.utils.events INFO: eta: 5:49:10  iter: 89479  total_loss: 0.509  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0314  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 05:06:55] d2.utils.events INFO: eta: 5:48:09  iter: 89499  total_loss: 0.690  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:07:55] d2.utils.events INFO: eta: 5:47:05  iter: 89519  total_loss: 0.674  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 05:08:55] d2.utils.events INFO: eta: 5:46:03  iter: 89539  total_loss: 0.640  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0312  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 05:09:54] d2.utils.events INFO: eta: 5:44:54  iter: 89559  total_loss: 0.382  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.068  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.113  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0309  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:10:53] d2.utils.events INFO: eta: 5:43:46  iter: 89579  total_loss: 0.717  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 05:11:52] d2.utils.events INFO: eta: 5:42:41  iter: 89599  total_loss: 0.683  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:12:53] d2.utils.events INFO: eta: 5:41:52  iter: 89619  total_loss: 0.431  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0303  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 05:13:54] d2.utils.events INFO: eta: 5:40:59  iter: 89639  total_loss: 0.865  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 05:14:56] d2.utils.events INFO: eta: 5:39:59  iter: 89659  total_loss: 0.597  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 05:15:56] d2.utils.events INFO: eta: 5:38:56  iter: 89679  total_loss: 0.661  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:16:57] d2.utils.events INFO: eta: 5:37:55  iter: 89699  total_loss: 0.724  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 05:17:58] d2.utils.events INFO: eta: 5:36:54  iter: 89719  total_loss: 0.722  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:18:58] d2.utils.events INFO: eta: 5:35:48  iter: 89739  total_loss: 0.496  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 05:19:59] d2.utils.events INFO: eta: 5:34:42  iter: 89759  total_loss: 0.649  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 05:20:59] d2.utils.events INFO: eta: 5:33:43  iter: 89779  total_loss: 0.557  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 05:21:59] d2.utils.events INFO: eta: 5:32:38  iter: 89799  total_loss: 0.675  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 05:23:00] d2.utils.events INFO: eta: 5:31:44  iter: 89819  total_loss: 0.506  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 05:24:00] d2.utils.events INFO: eta: 5:30:34  iter: 89839  total_loss: 0.430  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:25:00] d2.utils.events INFO: eta: 5:29:27  iter: 89859  total_loss: 0.555  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 05:26:01] d2.utils.events INFO: eta: 5:28:26  iter: 89879  total_loss: 0.547  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0035  lr: 0.000100  max_mem: 9045M
[12/30 05:27:03] d2.utils.events INFO: eta: 5:27:32  iter: 89899  total_loss: 0.653  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 05:28:03] d2.utils.events INFO: eta: 5:26:33  iter: 89919  total_loss: 0.774  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:29:04] d2.utils.events INFO: eta: 5:25:26  iter: 89939  total_loss: 0.617  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0304  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 05:30:07] d2.utils.events INFO: eta: 5:24:32  iter: 89959  total_loss: 0.840  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0310  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:31:08] d2.utils.events INFO: eta: 5:23:31  iter: 89979  total_loss: 0.610  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 05:32:09] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0089999.pth
[12/30 05:32:16] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/30 05:32:16] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 760          |   ASC-US   | 760          |    HSIL     | 365          |
|    LSIL    | 416          |  Candida   | 197          | Trichomonas | 1144         |
|            |              |            |              |             |              |
|   total    | 3642         |            |              |             |              |[0m
[12/30 05:32:16] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/30 05:33:21] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4803 s / img. ETA=0:08:59
[12/30 05:33:45] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4809 s / img. ETA=0:08:36
[12/30 05:34:09] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4810 s / img. ETA=0:08:12
[12/30 05:34:34] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4813 s / img. ETA=0:07:48
[12/30 05:34:58] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4813 s / img. ETA=0:07:24
[12/30 05:35:22] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4812 s / img. ETA=0:07:00
[12/30 05:35:46] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4811 s / img. ETA=0:06:36
[12/30 05:36:10] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4811 s / img. ETA=0:06:12
[12/30 05:36:34] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4811 s / img. ETA=0:05:48
[12/30 05:36:58] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4811 s / img. ETA=0:05:24
[12/30 05:37:22] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4812 s / img. ETA=0:05:00
[12/30 05:37:46] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4812 s / img. ETA=0:04:36
[12/30 05:38:10] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4812 s / img. ETA=0:04:12
[12/30 05:38:34] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4812 s / img. ETA=0:03:48
[12/30 05:38:58] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4812 s / img. ETA=0:03:24
[12/30 05:39:22] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4813 s / img. ETA=0:02:59
[12/30 05:39:46] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4813 s / img. ETA=0:02:35
[12/30 05:40:10] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4814 s / img. ETA=0:02:11
[12/30 05:40:35] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4814 s / img. ETA=0:01:47
[12/30 05:40:59] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4814 s / img. ETA=0:01:23
[12/30 05:41:23] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4814 s / img. ETA=0:00:59
[12/30 05:41:47] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4814 s / img. ETA=0:00:35
[12/30 05:42:11] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4814 s / img. ETA=0:00:11
[12/30 05:42:23] d2.evaluation.evaluator INFO: Total inference time: 0:09:23 (0.481608 s / img per device, on 2 devices)
[12/30 05:42:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:19 (0.478320 s / img per device, on 2 devices)
[12/30 05:42:23] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/30 05:42:23] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/30 05:42:23] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/30 05:42:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.503 | 69.679 | 53.817 | 23.513 | 41.258 | 49.758 |
[12/30 05:42:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 52.138 | ASC-US     | 47.363 | HSIL        | 63.561 |
| LSIL       | 61.437 | Candida    | 45.211 | Trichomonas | 21.305 |
[12/30 05:42:27] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/30 05:42:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/30 05:42:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/30 05:42:27] d2.evaluation.testing INFO: copypaste: 48.5026,69.6789,53.8165,23.5125,41.2582,49.7581
[12/30 05:42:27] d2.utils.events INFO: eta: 5:22:37  iter: 89999  total_loss: 0.575  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 05:43:28] d2.utils.events INFO: eta: 5:21:45  iter: 90019  total_loss: 0.683  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:44:29] d2.utils.events INFO: eta: 5:20:45  iter: 90039  total_loss: 0.573  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 05:45:28] d2.utils.events INFO: eta: 5:19:44  iter: 90059  total_loss: 0.610  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 05:46:30] d2.utils.events INFO: eta: 5:18:44  iter: 90079  total_loss: 0.572  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 05:47:31] d2.utils.events INFO: eta: 5:17:44  iter: 90099  total_loss: 0.929  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:48:31] d2.utils.events INFO: eta: 5:16:43  iter: 90119  total_loss: 0.394  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0311  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 05:49:31] d2.utils.events INFO: eta: 5:15:42  iter: 90139  total_loss: 0.659  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:50:30] d2.utils.events INFO: eta: 5:14:42  iter: 90159  total_loss: 0.555  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 05:51:31] d2.utils.events INFO: eta: 5:13:41  iter: 90179  total_loss: 0.568  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 05:52:33] d2.utils.events INFO: eta: 5:12:41  iter: 90199  total_loss: 0.622  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.122  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:53:34] d2.utils.events INFO: eta: 5:11:42  iter: 90219  total_loss: 0.745  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 05:54:36] d2.utils.events INFO: eta: 5:10:41  iter: 90239  total_loss: 0.749  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 05:55:38] d2.utils.events INFO: eta: 5:09:43  iter: 90259  total_loss: 0.449  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 05:56:39] d2.utils.events INFO: eta: 5:08:39  iter: 90279  total_loss: 0.885  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 05:57:40] d2.utils.events INFO: eta: 5:07:41  iter: 90299  total_loss: 0.478  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.086  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 05:58:41] d2.utils.events INFO: eta: 5:06:40  iter: 90319  total_loss: 0.683  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0318  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 05:59:42] d2.utils.events INFO: eta: 5:05:39  iter: 90339  total_loss: 0.533  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 06:00:41] d2.utils.events INFO: eta: 5:04:35  iter: 90359  total_loss: 0.571  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 06:01:42] d2.utils.events INFO: eta: 5:03:33  iter: 90379  total_loss: 0.657  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 06:02:42] d2.utils.events INFO: eta: 5:02:32  iter: 90399  total_loss: 0.533  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:03:43] d2.utils.events INFO: eta: 5:01:32  iter: 90419  total_loss: 0.530  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:04:43] d2.utils.events INFO: eta: 5:00:31  iter: 90439  total_loss: 0.578  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0314  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 06:05:43] d2.utils.events INFO: eta: 4:59:30  iter: 90459  total_loss: 0.543  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:06:43] d2.utils.events INFO: eta: 4:58:29  iter: 90479  total_loss: 0.749  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0036  lr: 0.000100  max_mem: 9045M
[12/30 06:07:44] d2.utils.events INFO: eta: 4:57:28  iter: 90499  total_loss: 0.712  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 06:08:43] d2.utils.events INFO: eta: 4:56:27  iter: 90519  total_loss: 0.600  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:09:42] d2.utils.events INFO: eta: 4:55:27  iter: 90539  total_loss: 0.422  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 06:10:41] d2.utils.events INFO: eta: 4:54:26  iter: 90559  total_loss: 0.446  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 06:11:42] d2.utils.events INFO: eta: 4:53:25  iter: 90579  total_loss: 0.457  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 06:12:43] d2.utils.events INFO: eta: 4:52:25  iter: 90599  total_loss: 0.542  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:13:43] d2.utils.events INFO: eta: 4:51:24  iter: 90619  total_loss: 0.476  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 06:14:43] d2.utils.events INFO: eta: 4:50:22  iter: 90639  total_loss: 0.601  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0037  lr: 0.000100  max_mem: 9045M
[12/30 06:15:43] d2.utils.events INFO: eta: 4:49:20  iter: 90659  total_loss: 0.497  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:16:44] d2.utils.events INFO: eta: 4:48:21  iter: 90679  total_loss: 0.647  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:17:45] d2.utils.events INFO: eta: 4:47:19  iter: 90699  total_loss: 0.598  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:18:46] d2.utils.events INFO: eta: 4:46:19  iter: 90719  total_loss: 0.728  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:19:47] d2.utils.events INFO: eta: 4:45:19  iter: 90739  total_loss: 0.580  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 06:20:47] d2.utils.events INFO: eta: 4:44:18  iter: 90759  total_loss: 0.570  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:21:47] d2.utils.events INFO: eta: 4:43:17  iter: 90779  total_loss: 0.678  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0301  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 06:22:48] d2.utils.events INFO: eta: 4:42:16  iter: 90799  total_loss: 0.613  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 06:23:47] d2.utils.events INFO: eta: 4:41:14  iter: 90819  total_loss: 0.548  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:24:48] d2.utils.events INFO: eta: 4:40:14  iter: 90839  total_loss: 0.620  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 06:25:49] d2.utils.events INFO: eta: 4:39:13  iter: 90859  total_loss: 0.855  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:26:50] d2.utils.events INFO: eta: 4:38:12  iter: 90879  total_loss: 0.759  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:27:51] d2.utils.events INFO: eta: 4:37:09  iter: 90899  total_loss: 0.693  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:28:51] d2.utils.events INFO: eta: 4:36:03  iter: 90919  total_loss: 0.638  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 06:29:51] d2.utils.events INFO: eta: 4:35:00  iter: 90939  total_loss: 0.777  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 06:30:50] d2.utils.events INFO: eta: 4:33:48  iter: 90959  total_loss: 0.568  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0297  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:31:51] d2.utils.events INFO: eta: 4:32:50  iter: 90979  total_loss: 0.650  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 06:32:51] d2.utils.events INFO: eta: 4:31:41  iter: 90999  total_loss: 0.664  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 06:33:52] d2.utils.events INFO: eta: 4:30:35  iter: 91019  total_loss: 0.658  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:34:53] d2.utils.events INFO: eta: 4:29:22  iter: 91039  total_loss: 0.517  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:35:54] d2.utils.events INFO: eta: 4:28:42  iter: 91059  total_loss: 0.521  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 06:36:55] d2.utils.events INFO: eta: 4:27:24  iter: 91079  total_loss: 0.540  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 06:37:55] d2.utils.events INFO: eta: 4:26:32  iter: 91099  total_loss: 0.662  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:38:57] d2.utils.events INFO: eta: 4:25:37  iter: 91119  total_loss: 0.626  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 06:39:57] d2.utils.events INFO: eta: 4:24:22  iter: 91139  total_loss: 0.568  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 06:40:57] d2.utils.events INFO: eta: 4:23:25  iter: 91159  total_loss: 0.555  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:41:59] d2.utils.events INFO: eta: 4:22:40  iter: 91179  total_loss: 0.584  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:43:01] d2.utils.events INFO: eta: 4:21:29  iter: 91199  total_loss: 0.744  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:44:00] d2.utils.events INFO: eta: 4:20:12  iter: 91219  total_loss: 0.668  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:45:01] d2.utils.events INFO: eta: 4:19:09  iter: 91239  total_loss: 0.796  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0300  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 06:46:01] d2.utils.events INFO: eta: 4:18:01  iter: 91259  total_loss: 0.511  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 06:47:02] d2.utils.events INFO: eta: 4:17:01  iter: 91279  total_loss: 0.526  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 06:48:02] d2.utils.events INFO: eta: 4:15:58  iter: 91299  total_loss: 0.644  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:49:03] d2.utils.events INFO: eta: 4:14:52  iter: 91319  total_loss: 0.466  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0298  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 06:50:03] d2.utils.events INFO: eta: 4:13:51  iter: 91339  total_loss: 0.270  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.027  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.069  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.089  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0297  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:51:04] d2.utils.events INFO: eta: 4:12:59  iter: 91359  total_loss: 0.609  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 06:52:07] d2.utils.events INFO: eta: 4:12:07  iter: 91379  total_loss: 0.651  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 06:53:07] d2.utils.events INFO: eta: 4:11:09  iter: 91399  total_loss: 0.385  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.081  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.130  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 06:54:09] d2.utils.events INFO: eta: 4:10:09  iter: 91419  total_loss: 0.553  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 06:55:08] d2.utils.events INFO: eta: 4:09:01  iter: 91439  total_loss: 0.602  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 06:56:09] d2.utils.events INFO: eta: 4:07:58  iter: 91459  total_loss: 0.628  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 06:57:10] d2.utils.events INFO: eta: 4:07:06  iter: 91479  total_loss: 0.671  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 06:58:11] d2.utils.events INFO: eta: 4:06:09  iter: 91499  total_loss: 0.592  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 06:59:11] d2.utils.events INFO: eta: 4:05:13  iter: 91519  total_loss: 0.561  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0302  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 07:00:12] d2.utils.events INFO: eta: 4:04:16  iter: 91539  total_loss: 0.477  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0303  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 07:01:13] d2.utils.events INFO: eta: 4:03:26  iter: 91559  total_loss: 0.588  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:02:14] d2.utils.events INFO: eta: 4:02:23  iter: 91579  total_loss: 0.522  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0303  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 07:03:14] d2.utils.events INFO: eta: 4:01:22  iter: 91599  total_loss: 0.777  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0303  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 07:04:14] d2.utils.events INFO: eta: 4:00:09  iter: 91619  total_loss: 0.592  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0301  data_time: 0.0020  lr: 0.000100  max_mem: 9045M
[12/30 07:05:14] d2.utils.events INFO: eta: 3:59:17  iter: 91639  total_loss: 0.734  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0301  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:06:15] d2.utils.events INFO: eta: 3:58:21  iter: 91659  total_loss: 0.676  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0302  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:07:15] d2.utils.events INFO: eta: 3:57:20  iter: 91679  total_loss: 0.472  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0300  data_time: 0.0020  lr: 0.000100  max_mem: 9045M
[12/30 07:08:15] d2.utils.events INFO: eta: 3:56:19  iter: 91699  total_loss: 0.532  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:09:16] d2.utils.events INFO: eta: 3:55:17  iter: 91719  total_loss: 0.558  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:10:18] d2.utils.events INFO: eta: 3:54:17  iter: 91739  total_loss: 0.737  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0301  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 07:11:19] d2.utils.events INFO: eta: 3:53:19  iter: 91759  total_loss: 0.605  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0302  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:12:20] d2.utils.events INFO: eta: 3:52:24  iter: 91779  total_loss: 0.676  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0303  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:13:19] d2.utils.events INFO: eta: 3:51:16  iter: 91799  total_loss: 0.533  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 07:14:20] d2.utils.events INFO: eta: 3:50:19  iter: 91819  total_loss: 0.603  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 07:15:19] d2.utils.events INFO: eta: 3:49:14  iter: 91839  total_loss: 0.528  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0299  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 07:16:20] d2.utils.events INFO: eta: 3:48:11  iter: 91859  total_loss: 0.682  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 07:17:21] d2.utils.events INFO: eta: 3:47:04  iter: 91879  total_loss: 0.589  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0300  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 07:18:22] d2.utils.events INFO: eta: 3:46:03  iter: 91899  total_loss: 0.796  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0300  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 07:19:23] d2.utils.events INFO: eta: 3:45:10  iter: 91919  total_loss: 0.521  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0300  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:20:22] d2.utils.events INFO: eta: 3:44:13  iter: 91939  total_loss: 0.580  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0299  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 07:21:23] d2.utils.events INFO: eta: 3:43:14  iter: 91959  total_loss: 0.684  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0299  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:22:23] d2.utils.events INFO: eta: 3:42:14  iter: 91979  total_loss: 0.695  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 07:23:24] d2.utils.events INFO: eta: 3:41:11  iter: 91999  total_loss: 0.511  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0298  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:24:24] d2.utils.events INFO: eta: 3:40:08  iter: 92019  total_loss: 0.498  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:25:24] d2.utils.events INFO: eta: 3:39:09  iter: 92039  total_loss: 0.690  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:26:24] d2.utils.events INFO: eta: 3:38:05  iter: 92059  total_loss: 0.595  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 07:27:24] d2.utils.events INFO: eta: 3:37:05  iter: 92079  total_loss: 0.660  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 07:28:24] d2.utils.events INFO: eta: 3:35:56  iter: 92099  total_loss: 0.521  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 07:29:24] d2.utils.events INFO: eta: 3:34:50  iter: 92119  total_loss: 0.738  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:30:24] d2.utils.events INFO: eta: 3:34:02  iter: 92139  total_loss: 0.732  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 07:31:24] d2.utils.events INFO: eta: 3:32:56  iter: 92159  total_loss: 0.611  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0292  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 07:32:24] d2.utils.events INFO: eta: 3:31:44  iter: 92179  total_loss: 0.706  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0291  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:33:26] d2.utils.events INFO: eta: 3:30:46  iter: 92199  total_loss: 0.537  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0292  data_time: 0.0031  lr: 0.000100  max_mem: 9045M
[12/30 07:34:26] d2.utils.events INFO: eta: 3:29:43  iter: 92219  total_loss: 0.615  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0291  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:35:27] d2.utils.events INFO: eta: 3:28:42  iter: 92239  total_loss: 0.514  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:36:27] d2.utils.events INFO: eta: 3:27:45  iter: 92259  total_loss: 0.606  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:37:28] d2.utils.events INFO: eta: 3:26:48  iter: 92279  total_loss: 0.488  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 07:38:29] d2.utils.events INFO: eta: 3:25:56  iter: 92299  total_loss: 0.560  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 07:39:30] d2.utils.events INFO: eta: 3:24:58  iter: 92319  total_loss: 0.737  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 07:40:32] d2.utils.events INFO: eta: 3:23:59  iter: 92339  total_loss: 0.517  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0294  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:41:31] d2.utils.events INFO: eta: 3:22:55  iter: 92359  total_loss: 0.587  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 07:42:33] d2.utils.events INFO: eta: 3:21:44  iter: 92379  total_loss: 0.661  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0294  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:43:35] d2.utils.events INFO: eta: 3:20:53  iter: 92399  total_loss: 0.714  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0296  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 07:44:36] d2.utils.events INFO: eta: 3:19:53  iter: 92419  total_loss: 0.541  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0297  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:45:38] d2.utils.events INFO: eta: 3:18:55  iter: 92439  total_loss: 0.581  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 07:46:39] d2.utils.events INFO: eta: 3:17:55  iter: 92459  total_loss: 0.567  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 07:47:38] d2.utils.events INFO: eta: 3:16:53  iter: 92479  total_loss: 0.515  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:48:38] d2.utils.events INFO: eta: 3:15:52  iter: 92499  total_loss: 0.629  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0296  data_time: 0.0020  lr: 0.000100  max_mem: 9045M
[12/30 07:49:39] d2.utils.events INFO: eta: 3:14:53  iter: 92519  total_loss: 0.567  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0297  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:50:41] d2.utils.events INFO: eta: 3:13:52  iter: 92539  total_loss: 0.529  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0298  data_time: 0.0030  lr: 0.000100  max_mem: 9045M
[12/30 07:51:40] d2.utils.events INFO: eta: 3:12:51  iter: 92559  total_loss: 0.473  loss_cls_stage0: 0.021  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0297  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:52:41] d2.utils.events INFO: eta: 3:11:50  iter: 92579  total_loss: 0.554  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0296  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 07:53:40] d2.utils.events INFO: eta: 3:10:49  iter: 92599  total_loss: 0.453  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0295  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 07:54:40] d2.utils.events INFO: eta: 3:09:49  iter: 92619  total_loss: 0.601  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0293  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:55:41] d2.utils.events INFO: eta: 3:08:49  iter: 92639  total_loss: 0.526  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0294  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 07:56:42] d2.utils.events INFO: eta: 3:07:47  iter: 92659  total_loss: 0.559  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0295  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 07:57:41] d2.utils.events INFO: eta: 3:06:46  iter: 92679  total_loss: 0.362  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0293  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 07:58:43] d2.utils.events INFO: eta: 3:05:45  iter: 92699  total_loss: 0.498  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0294  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 07:59:42] d2.utils.events INFO: eta: 3:04:44  iter: 92719  total_loss: 0.568  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0292  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 08:00:42] d2.utils.events INFO: eta: 3:03:42  iter: 92739  total_loss: 0.494  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0291  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 08:01:42] d2.utils.events INFO: eta: 3:02:34  iter: 92759  total_loss: 0.605  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0020  lr: 0.000100  max_mem: 9045M
[12/30 08:02:43] d2.utils.events INFO: eta: 3:01:37  iter: 92779  total_loss: 0.422  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0291  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 08:03:42] d2.utils.events INFO: eta: 3:00:41  iter: 92799  total_loss: 0.474  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 08:04:43] d2.utils.events INFO: eta: 2:59:40  iter: 92819  total_loss: 0.614  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 08:05:43] d2.utils.events INFO: eta: 2:58:39  iter: 92839  total_loss: 0.520  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 08:06:43] d2.utils.events INFO: eta: 2:57:38  iter: 92859  total_loss: 0.522  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 08:07:44] d2.utils.events INFO: eta: 2:56:36  iter: 92879  total_loss: 0.618  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 08:08:44] d2.utils.events INFO: eta: 2:55:33  iter: 92899  total_loss: 0.533  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0287  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 08:09:45] d2.utils.events INFO: eta: 2:54:34  iter: 92919  total_loss: 0.530  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0029  lr: 0.000100  max_mem: 9045M
[12/30 08:10:45] d2.utils.events INFO: eta: 2:53:35  iter: 92939  total_loss: 0.507  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 08:11:46] d2.utils.events INFO: eta: 2:52:35  iter: 92959  total_loss: 0.449  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 08:12:46] d2.utils.events INFO: eta: 2:51:34  iter: 92979  total_loss: 0.575  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 08:13:47] d2.utils.events INFO: eta: 2:50:34  iter: 92999  total_loss: 0.599  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0287  data_time: 0.0027  lr: 0.000100  max_mem: 9045M
[12/30 08:14:47] d2.utils.events INFO: eta: 2:49:33  iter: 93019  total_loss: 0.488  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 08:15:49] d2.utils.events INFO: eta: 2:48:33  iter: 93039  total_loss: 0.540  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0289  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 08:16:51] d2.utils.events INFO: eta: 2:47:34  iter: 93059  total_loss: 0.755  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0290  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 08:17:50] d2.utils.events INFO: eta: 2:46:33  iter: 93079  total_loss: 0.547  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9045M
[12/30 08:18:50] d2.utils.events INFO: eta: 2:45:33  iter: 93099  total_loss: 0.560  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0288  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 08:19:52] d2.utils.events INFO: eta: 2:44:34  iter: 93119  total_loss: 0.474  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 08:20:52] d2.utils.events INFO: eta: 2:43:33  iter: 93139  total_loss: 0.553  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0288  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 08:21:52] d2.utils.events INFO: eta: 2:42:33  iter: 93159  total_loss: 0.546  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0021  lr: 0.000100  max_mem: 9045M
[12/30 08:22:54] d2.utils.events INFO: eta: 2:41:33  iter: 93179  total_loss: 0.686  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0028  lr: 0.000100  max_mem: 9045M
[12/30 08:23:55] d2.utils.events INFO: eta: 2:40:32  iter: 93199  total_loss: 0.700  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 08:24:54] d2.utils.events INFO: eta: 2:39:32  iter: 93219  total_loss: 0.446  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0289  data_time: 0.0026  lr: 0.000100  max_mem: 9045M
[12/30 08:25:55] d2.utils.events INFO: eta: 2:38:30  iter: 93239  total_loss: 0.406  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0024  lr: 0.000100  max_mem: 9045M
[12/30 08:26:54] d2.utils.events INFO: eta: 2:37:30  iter: 93259  total_loss: 0.847  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0287  data_time: 0.0022  lr: 0.000100  max_mem: 9045M
[12/30 08:27:54] d2.utils.events INFO: eta: 2:36:29  iter: 93279  total_loss: 0.439  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0025  lr: 0.000100  max_mem: 9045M
[12/30 08:28:56] d2.utils.events INFO: eta: 2:35:28  iter: 93299  total_loss: 0.477  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 08:29:57] d2.utils.events INFO: eta: 2:34:26  iter: 93319  total_loss: 0.475  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0030  lr: 0.000100  max_mem: 9125M
[12/30 08:30:59] d2.utils.events INFO: eta: 2:33:26  iter: 93339  total_loss: 0.581  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0030  lr: 0.000100  max_mem: 9125M
[12/30 08:31:59] d2.utils.events INFO: eta: 2:32:26  iter: 93359  total_loss: 0.469  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 08:33:00] d2.utils.events INFO: eta: 2:31:25  iter: 93379  total_loss: 0.497  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 08:34:01] d2.utils.events INFO: eta: 2:30:22  iter: 93399  total_loss: 0.663  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 08:35:01] d2.utils.events INFO: eta: 2:29:22  iter: 93419  total_loss: 0.510  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 08:36:00] d2.utils.events INFO: eta: 2:28:17  iter: 93439  total_loss: 0.505  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0020  lr: 0.000100  max_mem: 9125M
[12/30 08:36:59] d2.utils.events INFO: eta: 2:27:15  iter: 93459  total_loss: 0.536  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0285  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 08:37:59] d2.utils.events INFO: eta: 2:26:16  iter: 93479  total_loss: 0.515  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 08:39:01] d2.utils.events INFO: eta: 2:25:16  iter: 93499  total_loss: 0.507  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0286  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 08:40:01] d2.utils.events INFO: eta: 2:24:14  iter: 93519  total_loss: 0.461  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 08:41:03] d2.utils.events INFO: eta: 2:23:15  iter: 93539  total_loss: 0.620  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0027  lr: 0.000100  max_mem: 9125M
[12/30 08:42:03] d2.utils.events INFO: eta: 2:22:14  iter: 93559  total_loss: 0.674  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 08:43:03] d2.utils.events INFO: eta: 2:21:14  iter: 93579  total_loss: 0.703  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 08:44:04] d2.utils.events INFO: eta: 2:20:16  iter: 93599  total_loss: 0.502  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0028  lr: 0.000100  max_mem: 9125M
[12/30 08:45:04] d2.utils.events INFO: eta: 2:19:14  iter: 93619  total_loss: 0.463  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0285  data_time: 0.0030  lr: 0.000100  max_mem: 9125M
[12/30 08:46:04] d2.utils.events INFO: eta: 2:18:12  iter: 93639  total_loss: 0.668  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0284  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 08:47:04] d2.utils.events INFO: eta: 2:17:12  iter: 93659  total_loss: 0.544  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 08:48:05] d2.utils.events INFO: eta: 2:16:12  iter: 93679  total_loss: 0.653  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 08:49:06] d2.utils.events INFO: eta: 2:15:10  iter: 93699  total_loss: 0.575  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0285  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 08:50:07] d2.utils.events INFO: eta: 2:14:11  iter: 93719  total_loss: 0.407  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0033  lr: 0.000100  max_mem: 9125M
[12/30 08:51:08] d2.utils.events INFO: eta: 2:13:11  iter: 93739  total_loss: 0.579  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0286  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 08:52:08] d2.utils.events INFO: eta: 2:12:10  iter: 93759  total_loss: 0.658  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 08:53:08] d2.utils.events INFO: eta: 2:11:08  iter: 93779  total_loss: 0.647  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0285  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 08:54:08] d2.utils.events INFO: eta: 2:10:06  iter: 93799  total_loss: 0.633  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0284  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 08:55:10] d2.utils.events INFO: eta: 2:09:07  iter: 93819  total_loss: 0.467  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0286  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 08:56:12] d2.utils.events INFO: eta: 2:08:07  iter: 93839  total_loss: 0.507  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 08:57:13] d2.utils.events INFO: eta: 2:07:07  iter: 93859  total_loss: 0.413  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 08:58:14] d2.utils.events INFO: eta: 2:06:07  iter: 93879  total_loss: 0.694  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 08:59:15] d2.utils.events INFO: eta: 2:05:06  iter: 93899  total_loss: 0.648  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0289  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 09:00:15] d2.utils.events INFO: eta: 2:04:06  iter: 93919  total_loss: 0.462  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9125M
[12/30 09:01:15] d2.utils.events INFO: eta: 2:03:04  iter: 93939  total_loss: 0.625  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0019  lr: 0.000100  max_mem: 9125M
[12/30 09:02:15] d2.utils.events INFO: eta: 2:02:03  iter: 93959  total_loss: 0.714  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:03:16] d2.utils.events INFO: eta: 2:01:03  iter: 93979  total_loss: 0.646  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0287  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:04:16] d2.utils.events INFO: eta: 2:00:02  iter: 93999  total_loss: 0.499  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:05:15] d2.utils.events INFO: eta: 1:59:01  iter: 94019  total_loss: 0.459  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0284  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:06:17] d2.utils.events INFO: eta: 1:58:00  iter: 94039  total_loss: 0.733  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0286  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 09:07:17] d2.utils.events INFO: eta: 1:56:59  iter: 94059  total_loss: 0.621  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0286  data_time: 0.0031  lr: 0.000100  max_mem: 9125M
[12/30 09:08:18] d2.utils.events INFO: eta: 1:55:59  iter: 94079  total_loss: 0.435  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 09:09:20] d2.utils.events INFO: eta: 1:54:59  iter: 94099  total_loss: 0.512  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:10:21] d2.utils.events INFO: eta: 1:53:58  iter: 94119  total_loss: 0.735  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0288  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:11:23] d2.utils.events INFO: eta: 1:52:57  iter: 94139  total_loss: 0.554  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:12:23] d2.utils.events INFO: eta: 1:51:56  iter: 94159  total_loss: 0.596  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:13:23] d2.utils.events INFO: eta: 1:50:55  iter: 94179  total_loss: 0.491  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:14:24] d2.utils.events INFO: eta: 1:49:54  iter: 94199  total_loss: 0.564  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0288  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:15:23] d2.utils.events INFO: eta: 1:48:53  iter: 94219  total_loss: 0.774  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0287  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:16:24] d2.utils.events INFO: eta: 1:47:52  iter: 94239  total_loss: 0.493  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:17:23] d2.utils.events INFO: eta: 1:46:52  iter: 94259  total_loss: 0.676  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0285  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:18:24] d2.utils.events INFO: eta: 1:45:52  iter: 94279  total_loss: 0.572  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 09:19:25] d2.utils.events INFO: eta: 1:44:51  iter: 94299  total_loss: 0.698  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:20:26] d2.utils.events INFO: eta: 1:43:50  iter: 94319  total_loss: 0.556  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 09:21:27] d2.utils.events INFO: eta: 1:42:49  iter: 94339  total_loss: 0.718  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0287  data_time: 0.0028  lr: 0.000100  max_mem: 9125M
[12/30 09:22:28] d2.utils.events INFO: eta: 1:41:48  iter: 94359  total_loss: 0.468  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0031  lr: 0.000100  max_mem: 9125M
[12/30 09:23:30] d2.utils.events INFO: eta: 1:40:47  iter: 94379  total_loss: 0.549  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0288  data_time: 0.0027  lr: 0.000100  max_mem: 9125M
[12/30 09:24:31] d2.utils.events INFO: eta: 1:39:46  iter: 94399  total_loss: 0.703  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:25:31] d2.utils.events INFO: eta: 1:38:45  iter: 94419  total_loss: 0.641  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0289  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:26:32] d2.utils.events INFO: eta: 1:37:45  iter: 94439  total_loss: 0.613  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0289  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:27:34] d2.utils.events INFO: eta: 1:36:46  iter: 94459  total_loss: 0.431  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0290  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 09:28:35] d2.utils.events INFO: eta: 1:35:45  iter: 94479  total_loss: 0.610  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0291  data_time: 0.0028  lr: 0.000100  max_mem: 9125M
[12/30 09:29:36] d2.utils.events INFO: eta: 1:34:43  iter: 94499  total_loss: 0.797  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0291  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 09:30:37] d2.utils.events INFO: eta: 1:33:43  iter: 94519  total_loss: 0.532  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0291  data_time: 0.0028  lr: 0.000100  max_mem: 9125M
[12/30 09:31:39] d2.utils.events INFO: eta: 1:32:42  iter: 94539  total_loss: 0.548  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0293  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:32:39] d2.utils.events INFO: eta: 1:31:41  iter: 94559  total_loss: 0.573  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0292  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 09:33:41] d2.utils.events INFO: eta: 1:30:40  iter: 94579  total_loss: 0.768  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0294  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 09:34:42] d2.utils.events INFO: eta: 1:29:39  iter: 94599  total_loss: 0.546  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0294  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:35:40] d2.utils.events INFO: eta: 1:28:38  iter: 94619  total_loss: 0.361  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.096  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0292  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 09:36:39] d2.utils.events INFO: eta: 1:27:37  iter: 94639  total_loss: 0.538  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0290  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 09:37:39] d2.utils.events INFO: eta: 1:26:36  iter: 94659  total_loss: 0.555  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0290  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:38:38] d2.utils.events INFO: eta: 1:25:35  iter: 94679  total_loss: 0.474  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0287  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 09:39:38] d2.utils.events INFO: eta: 1:24:34  iter: 94699  total_loss: 0.684  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0287  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 09:40:38] d2.utils.events INFO: eta: 1:23:33  iter: 94719  total_loss: 0.547  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0287  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:41:39] d2.utils.events INFO: eta: 1:22:32  iter: 94739  total_loss: 0.725  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0287  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 09:42:39] d2.utils.events INFO: eta: 1:21:31  iter: 94759  total_loss: 0.325  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.078  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.119  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0286  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:43:38] d2.utils.events INFO: eta: 1:20:31  iter: 94779  total_loss: 0.762  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0285  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 09:44:39] d2.utils.events INFO: eta: 1:19:30  iter: 94799  total_loss: 0.527  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0285  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 09:45:39] d2.utils.events INFO: eta: 1:18:29  iter: 94819  total_loss: 0.563  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0284  data_time: 0.0027  lr: 0.000100  max_mem: 9125M
[12/30 09:46:39] d2.utils.events INFO: eta: 1:17:28  iter: 94839  total_loss: 0.656  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0284  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:47:39] d2.utils.events INFO: eta: 1:16:27  iter: 94859  total_loss: 0.743  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0283  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 09:48:40] d2.utils.events INFO: eta: 1:15:26  iter: 94879  total_loss: 0.488  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0283  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 09:49:41] d2.utils.events INFO: eta: 1:14:25  iter: 94899  total_loss: 0.494  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0284  data_time: 0.0021  lr: 0.000100  max_mem: 9125M
[12/30 09:50:39] d2.utils.events INFO: eta: 1:13:23  iter: 94919  total_loss: 0.440  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.079  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0282  data_time: 0.0029  lr: 0.000100  max_mem: 9125M
[12/30 09:51:40] d2.utils.events INFO: eta: 1:12:22  iter: 94939  total_loss: 0.446  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 09:52:40] d2.utils.events INFO: eta: 1:11:21  iter: 94959  total_loss: 0.508  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 09:53:41] d2.utils.events INFO: eta: 1:10:21  iter: 94979  total_loss: 0.665  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 09:54:41] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0094999.pth
[12/30 09:54:47] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/30 09:54:47] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/30 09:55:55] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.5021 s / img. ETA=0:09:24
[12/30 09:56:19] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4903 s / img. ETA=0:08:46
[12/30 09:56:43] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4870 s / img. ETA=0:08:18
[12/30 09:57:07] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4850 s / img. ETA=0:07:52
[12/30 09:57:31] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4840 s / img. ETA=0:07:27
[12/30 09:57:55] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4831 s / img. ETA=0:07:02
[12/30 09:58:19] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4830 s / img. ETA=0:06:38
[12/30 09:58:43] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4829 s / img. ETA=0:06:13
[12/30 09:59:08] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4828 s / img. ETA=0:05:49
[12/30 09:59:32] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4825 s / img. ETA=0:05:25
[12/30 09:59:55] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4821 s / img. ETA=0:05:00
[12/30 10:00:19] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4819 s / img. ETA=0:04:36
[12/30 10:00:44] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4818 s / img. ETA=0:04:12
[12/30 10:01:07] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4817 s / img. ETA=0:03:48
[12/30 10:01:31] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4815 s / img. ETA=0:03:24
[12/30 10:01:55] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4814 s / img. ETA=0:03:00
[12/30 10:02:19] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4813 s / img. ETA=0:02:35
[12/30 10:02:44] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4813 s / img. ETA=0:02:11
[12/30 10:03:08] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4813 s / img. ETA=0:01:47
[12/30 10:03:32] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4812 s / img. ETA=0:01:23
[12/30 10:03:56] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4812 s / img. ETA=0:00:59
[12/30 10:04:20] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4811 s / img. ETA=0:00:35
[12/30 10:04:44] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4810 s / img. ETA=0:00:11
[12/30 10:04:55] d2.evaluation.evaluator INFO: Total inference time: 0:09:22 (0.480753 s / img per device, on 2 devices)
[12/30 10:04:55] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:18 (0.477955 s / img per device, on 2 devices)
[12/30 10:04:55] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/30 10:04:55] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/30 10:04:56] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/30 10:05:00] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.354 | 69.970 | 53.800 | 23.643 | 41.128 | 49.507 |
[12/30 10:05:00] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 51.751 | ASC-US     | 47.004 | HSIL        | 64.761 |
| LSIL       | 60.712 | Candida    | 44.649 | Trichomonas | 21.248 |
[12/30 10:05:00] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/30 10:05:00] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/30 10:05:00] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/30 10:05:00] d2.evaluation.testing INFO: copypaste: 48.3542,69.9699,53.7996,23.6433,41.1280,49.5074
[12/30 10:05:00] d2.utils.events INFO: eta: 1:09:20  iter: 94999  total_loss: 0.490  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0281  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 10:06:00] d2.utils.events INFO: eta: 1:08:20  iter: 95019  total_loss: 0.582  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0280  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 10:07:00] d2.utils.events INFO: eta: 1:07:18  iter: 95039  total_loss: 0.466  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0280  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 10:08:01] d2.utils.events INFO: eta: 1:06:18  iter: 95059  total_loss: 0.600  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0281  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 10:09:03] d2.utils.events INFO: eta: 1:05:17  iter: 95079  total_loss: 0.656  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 10:10:03] d2.utils.events INFO: eta: 1:04:17  iter: 95099  total_loss: 0.485  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0281  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 10:11:04] d2.utils.events INFO: eta: 1:03:15  iter: 95119  total_loss: 0.799  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.007  loss_rpn_loc: 0.009  time: 3.0282  data_time: 0.0023  lr: 0.000100  max_mem: 9125M
[12/30 10:12:06] d2.utils.events INFO: eta: 1:02:15  iter: 95139  total_loss: 0.643  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0282  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 10:13:07] d2.utils.events INFO: eta: 1:01:14  iter: 95159  total_loss: 0.555  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0283  data_time: 0.0026  lr: 0.000100  max_mem: 9125M
[12/30 10:14:08] d2.utils.events INFO: eta: 1:00:13  iter: 95179  total_loss: 0.569  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0283  data_time: 0.0027  lr: 0.000100  max_mem: 9125M
[12/30 10:15:08] d2.utils.events INFO: eta: 0:59:12  iter: 95199  total_loss: 0.543  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0283  data_time: 0.0022  lr: 0.000100  max_mem: 9125M
[12/30 10:16:07] d2.utils.events INFO: eta: 0:58:11  iter: 95219  total_loss: 0.402  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0282  data_time: 0.0024  lr: 0.000100  max_mem: 9125M
[12/30 10:17:08] d2.utils.events INFO: eta: 0:57:10  iter: 95239  total_loss: 0.548  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0282  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 10:18:08] d2.utils.events INFO: eta: 0:56:09  iter: 95259  total_loss: 0.673  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0281  data_time: 0.0027  lr: 0.000100  max_mem: 9125M
[12/30 10:19:09] d2.utils.events INFO: eta: 0:55:08  iter: 95279  total_loss: 0.504  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0281  data_time: 0.0025  lr: 0.000100  max_mem: 9125M
[12/30 10:21:20] detectron2 INFO: Rank of current process: 0. World size: 2
[12/30 10:21:23] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/30 10:21:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/30 10:21:23] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_val_light",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 116368  ## 46368 74368(70000) 96368(8500) 
  BASE_LR: 0.01     ### 
  STEPS: (116068, 116268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/30 10:21:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_light',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 116368
  MOMENTUM: 0.9
  STEPS: (116068, 116268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/30 10:21:24] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/30 10:21:24] d2.utils.env INFO: Using a generated random seed 24091364
[12/30 10:21:27] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/30 10:21:27] d2.data.datasets.coco INFO: Loaded 14085 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_light.json
[12/30 10:21:28] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 4485         |   ASC-US   | 4590         |    HSIL     | 1983         |
|    LSIL    | 2574         |  Candida   | 1198         | Trichomonas | 7388         |
|            |              |            |              |             |              |
|   total    | 22218        |            |              |             |              |[0m
[12/30 10:21:28] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[12/30 10:21:28] d2.data.build INFO: Using training sampler TrainingSampler
[12/30 10:22:27] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0094999.pth
[12/30 10:22:28] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0094999.pth
[12/30 10:22:28] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0094999.pth
[12/30 10:22:28] d2.engine.train_loop INFO: Starting training from iteration 95000
[12/30 10:23:28] d2.utils.events INFO: eta: 18:05:32  iter: 95019  total_loss: 0.586  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0179  data_time: 0.0029  lr: 0.000100  max_mem: 8338M
[12/30 10:24:29] d2.utils.events INFO: eta: 18:04:56  iter: 95039  total_loss: 0.560  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0371  data_time: 0.0027  lr: 0.000100  max_mem: 8338M
[12/30 10:25:30] d2.utils.events INFO: eta: 18:03:26  iter: 95059  total_loss: 0.458  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0371  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:26:30] d2.utils.events INFO: eta: 18:02:16  iter: 95079  total_loss: 0.589  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0237  data_time: 0.0020  lr: 0.000100  max_mem: 8571M
[12/30 10:27:31] d2.utils.events INFO: eta: 18:01:25  iter: 95099  total_loss: 0.515  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0278  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:28:32] d2.utils.events INFO: eta: 18:00:24  iter: 95119  total_loss: 0.497  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0299  data_time: 0.0025  lr: 0.000100  max_mem: 8571M
[12/30 10:29:34] d2.utils.events INFO: eta: 17:59:55  iter: 95139  total_loss: 0.559  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0412  data_time: 0.0028  lr: 0.000100  max_mem: 8571M
[12/30 10:30:34] d2.utils.events INFO: eta: 17:58:38  iter: 95159  total_loss: 0.579  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0377  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:31:36] d2.utils.events INFO: eta: 17:57:45  iter: 95179  total_loss: 0.595  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0440  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:32:35] d2.utils.events INFO: eta: 17:55:58  iter: 95199  total_loss: 0.440  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0361  data_time: 0.0025  lr: 0.000100  max_mem: 8571M
[12/30 10:33:37] d2.utils.events INFO: eta: 17:55:21  iter: 95219  total_loss: 0.631  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0420  data_time: 0.0031  lr: 0.000100  max_mem: 8571M
[12/30 10:34:38] d2.utils.events INFO: eta: 17:54:15  iter: 95239  total_loss: 0.644  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0425  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:35:40] d2.utils.events INFO: eta: 17:53:21  iter: 95259  total_loss: 0.413  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0464  data_time: 0.0028  lr: 0.000100  max_mem: 8571M
[12/30 10:36:41] d2.utils.events INFO: eta: 17:52:18  iter: 95279  total_loss: 0.641  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0439  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 10:37:42] d2.utils.events INFO: eta: 17:51:19  iter: 95299  total_loss: 0.794  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0455  data_time: 0.0027  lr: 0.000100  max_mem: 8571M
[12/30 10:38:43] d2.utils.events INFO: eta: 17:50:18  iter: 95319  total_loss: 0.506  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0445  data_time: 0.0028  lr: 0.000100  max_mem: 8571M
[12/30 10:39:44] d2.utils.events INFO: eta: 17:49:17  iter: 95339  total_loss: 0.657  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0447  data_time: 0.0022  lr: 0.000100  max_mem: 8571M
[12/30 10:40:43] d2.utils.events INFO: eta: 17:48:05  iter: 95359  total_loss: 0.499  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0410  data_time: 0.0032  lr: 0.000100  max_mem: 8571M
[12/30 10:41:43] d2.utils.events INFO: eta: 17:47:01  iter: 95379  total_loss: 0.782  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0390  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:42:43] d2.utils.events INFO: eta: 17:45:52  iter: 95399  total_loss: 0.430  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0367  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 10:43:44] d2.utils.events INFO: eta: 17:44:56  iter: 95419  total_loss: 0.517  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0363  data_time: 0.0032  lr: 0.000100  max_mem: 8571M
[12/30 10:44:45] d2.utils.events INFO: eta: 17:43:49  iter: 95439  total_loss: 0.538  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0370  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 10:45:44] d2.utils.events INFO: eta: 17:42:35  iter: 95459  total_loss: 0.532  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0339  data_time: 0.0031  lr: 0.000100  max_mem: 8571M
[12/30 10:46:45] d2.utils.events INFO: eta: 17:41:40  iter: 95479  total_loss: 0.779  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0339  data_time: 0.0021  lr: 0.000100  max_mem: 8571M
[12/30 10:47:46] d2.utils.events INFO: eta: 17:40:41  iter: 95499  total_loss: 0.517  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0357  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 10:48:49] d2.utils.events INFO: eta: 17:39:53  iter: 95519  total_loss: 0.611  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0396  data_time: 0.0030  lr: 0.000100  max_mem: 8571M
[12/30 10:49:50] d2.utils.events INFO: eta: 17:38:52  iter: 95539  total_loss: 0.587  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0390  data_time: 0.0025  lr: 0.000100  max_mem: 8571M
[12/30 10:50:50] d2.utils.events INFO: eta: 17:37:51  iter: 95559  total_loss: 0.436  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0377  data_time: 0.0027  lr: 0.000100  max_mem: 8571M
[12/30 10:51:50] d2.utils.events INFO: eta: 17:36:40  iter: 95579  total_loss: 0.664  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0029  lr: 0.000100  max_mem: 8571M
[12/30 10:52:51] d2.utils.events INFO: eta: 17:35:36  iter: 95599  total_loss: 0.523  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0368  data_time: 0.0030  lr: 0.000100  max_mem: 8571M
[12/30 10:53:51] d2.utils.events INFO: eta: 17:34:31  iter: 95619  total_loss: 0.500  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0357  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 10:54:50] d2.utils.events INFO: eta: 17:33:24  iter: 95639  total_loss: 0.550  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0336  data_time: 0.0027  lr: 0.000100  max_mem: 8571M
[12/30 10:55:52] d2.utils.events INFO: eta: 17:32:25  iter: 95659  total_loss: 0.571  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0357  data_time: 0.0023  lr: 0.000100  max_mem: 8571M
[12/30 10:56:54] d2.utils.events INFO: eta: 17:31:22  iter: 95679  total_loss: 0.532  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0362  data_time: 0.0025  lr: 0.000100  max_mem: 8571M
[12/30 10:57:53] d2.utils.events INFO: eta: 17:30:16  iter: 95699  total_loss: 0.656  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0342  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:58:52] d2.utils.events INFO: eta: 17:29:06  iter: 95719  total_loss: 0.632  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0325  data_time: 0.0024  lr: 0.000100  max_mem: 8571M
[12/30 10:59:52] d2.utils.events INFO: eta: 17:27:58  iter: 95739  total_loss: 0.418  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0029  lr: 0.000100  max_mem: 8571M
[12/30 11:00:54] d2.utils.events INFO: eta: 17:27:02  iter: 95759  total_loss: 0.588  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0329  data_time: 0.0027  lr: 0.000100  max_mem: 8571M
[12/30 11:01:55] d2.utils.events INFO: eta: 17:26:01  iter: 95779  total_loss: 0.606  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0337  data_time: 0.0027  lr: 0.000100  max_mem: 8571M
[12/30 11:02:57] d2.utils.events INFO: eta: 17:25:12  iter: 95799  total_loss: 0.689  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0355  data_time: 0.0023  lr: 0.000100  max_mem: 8571M
[12/30 11:03:58] d2.utils.events INFO: eta: 17:24:07  iter: 95819  total_loss: 0.592  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0349  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 11:04:59] d2.utils.events INFO: eta: 17:23:09  iter: 95839  total_loss: 0.384  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.083  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.114  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0354  data_time: 0.0023  lr: 0.000100  max_mem: 8571M
[12/30 11:06:00] d2.utils.events INFO: eta: 17:22:10  iter: 95859  total_loss: 0.854  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0026  lr: 0.000100  max_mem: 8571M
[12/30 11:07:00] d2.utils.events INFO: eta: 17:20:57  iter: 95879  total_loss: 0.400  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 11:08:00] d2.utils.events INFO: eta: 17:19:55  iter: 95899  total_loss: 0.676  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0347  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:09:02] d2.utils.events INFO: eta: 17:18:55  iter: 95919  total_loss: 0.623  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:10:03] d2.utils.events INFO: eta: 17:17:56  iter: 95939  total_loss: 0.454  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0360  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:11:03] d2.utils.events INFO: eta: 17:16:53  iter: 95959  total_loss: 0.537  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0348  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:12:03] d2.utils.events INFO: eta: 17:15:51  iter: 95979  total_loss: 0.548  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0345  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:13:03] d2.utils.events INFO: eta: 17:14:42  iter: 95999  total_loss: 0.594  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0337  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 11:14:06] d2.utils.events INFO: eta: 17:13:49  iter: 96019  total_loss: 0.524  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0359  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:15:07] d2.utils.events INFO: eta: 17:12:40  iter: 96039  total_loss: 0.798  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0359  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:16:08] d2.utils.events INFO: eta: 17:11:43  iter: 96059  total_loss: 0.552  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0361  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:17:08] d2.utils.events INFO: eta: 17:10:29  iter: 96079  total_loss: 0.414  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0355  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 11:18:09] d2.utils.events INFO: eta: 17:09:07  iter: 96099  total_loss: 0.437  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0357  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:19:09] d2.utils.events INFO: eta: 17:08:06  iter: 96119  total_loss: 0.516  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0350  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:20:10] d2.utils.events INFO: eta: 17:06:54  iter: 96139  total_loss: 0.415  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.028  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.074  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.122  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0351  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:21:11] d2.utils.events INFO: eta: 17:06:02  iter: 96159  total_loss: 0.484  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.078  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0353  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 11:22:11] d2.utils.events INFO: eta: 17:05:03  iter: 96179  total_loss: 0.436  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0350  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:23:12] d2.utils.events INFO: eta: 17:04:29  iter: 96199  total_loss: 0.535  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:24:13] d2.utils.events INFO: eta: 17:03:24  iter: 96219  total_loss: 0.642  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:25:13] d2.utils.events INFO: eta: 17:02:03  iter: 96239  total_loss: 0.531  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0349  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:26:13] d2.utils.events INFO: eta: 17:00:48  iter: 96259  total_loss: 0.714  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0342  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 11:27:14] d2.utils.events INFO: eta: 17:00:01  iter: 96279  total_loss: 0.520  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 11:28:13] d2.utils.events INFO: eta: 16:58:41  iter: 96299  total_loss: 0.642  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0335  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:29:15] d2.utils.events INFO: eta: 16:57:41  iter: 96319  total_loss: 0.522  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 11:30:16] d2.utils.events INFO: eta: 16:56:23  iter: 96339  total_loss: 0.678  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:31:15] d2.utils.events INFO: eta: 16:55:13  iter: 96359  total_loss: 0.442  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.130  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:32:16] d2.utils.events INFO: eta: 16:54:21  iter: 96379  total_loss: 0.533  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:33:17] d2.utils.events INFO: eta: 16:53:40  iter: 96399  total_loss: 0.553  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0334  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:34:19] d2.utils.events INFO: eta: 16:52:36  iter: 96419  total_loss: 0.734  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 11:35:18] d2.utils.events INFO: eta: 16:51:12  iter: 96439  total_loss: 0.690  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0334  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/30 11:36:18] d2.utils.events INFO: eta: 16:50:38  iter: 96459  total_loss: 0.533  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:37:19] d2.utils.events INFO: eta: 16:49:17  iter: 96479  total_loss: 0.510  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0331  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:38:20] d2.utils.events INFO: eta: 16:48:16  iter: 96499  total_loss: 0.537  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0334  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:39:20] d2.utils.events INFO: eta: 16:46:50  iter: 96519  total_loss: 0.507  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:40:21] d2.utils.events INFO: eta: 16:45:34  iter: 96539  total_loss: 0.409  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0330  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:41:23] d2.utils.events INFO: eta: 16:44:55  iter: 96559  total_loss: 0.704  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0336  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:42:22] d2.utils.events INFO: eta: 16:44:01  iter: 96579  total_loss: 0.603  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0329  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:43:23] d2.utils.events INFO: eta: 16:43:11  iter: 96599  total_loss: 0.693  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 11:44:25] d2.utils.events INFO: eta: 16:42:17  iter: 96619  total_loss: 0.736  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0335  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:45:26] d2.utils.events INFO: eta: 16:41:42  iter: 96639  total_loss: 0.590  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0341  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:46:26] d2.utils.events INFO: eta: 16:40:32  iter: 96659  total_loss: 0.648  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0337  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 11:47:28] d2.utils.events INFO: eta: 16:39:33  iter: 96679  total_loss: 0.689  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 11:48:28] d2.utils.events INFO: eta: 16:38:47  iter: 96699  total_loss: 0.472  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 11:49:28] d2.utils.events INFO: eta: 16:37:52  iter: 96719  total_loss: 0.580  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0334  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 11:50:26] d2.utils.events INFO: eta: 16:36:37  iter: 96739  total_loss: 0.571  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:51:26] d2.utils.events INFO: eta: 16:35:31  iter: 96759  total_loss: 0.516  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.133  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 11:52:27] d2.utils.events INFO: eta: 16:34:26  iter: 96779  total_loss: 0.736  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0318  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/30 11:53:29] d2.utils.events INFO: eta: 16:33:05  iter: 96799  total_loss: 0.533  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 11:54:30] d2.utils.events INFO: eta: 16:32:24  iter: 96819  total_loss: 0.380  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.086  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 11:55:33] d2.utils.events INFO: eta: 16:31:28  iter: 96839  total_loss: 0.672  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0337  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:56:34] d2.utils.events INFO: eta: 16:30:23  iter: 96859  total_loss: 0.471  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.127  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 11:57:34] d2.utils.events INFO: eta: 16:29:22  iter: 96879  total_loss: 0.394  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.068  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0335  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:58:36] d2.utils.events INFO: eta: 16:28:28  iter: 96899  total_loss: 0.708  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 11:59:37] d2.utils.events INFO: eta: 16:27:14  iter: 96919  total_loss: 0.616  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 12:00:38] d2.utils.events INFO: eta: 16:26:06  iter: 96939  total_loss: 0.519  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0347  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:01:39] d2.utils.events INFO: eta: 16:25:12  iter: 96959  total_loss: 0.543  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 12:02:41] d2.utils.events INFO: eta: 16:24:26  iter: 96979  total_loss: 0.601  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0353  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:03:40] d2.utils.events INFO: eta: 16:23:27  iter: 96999  total_loss: 0.618  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0344  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 12:04:42] d2.utils.events INFO: eta: 16:22:23  iter: 97019  total_loss: 0.767  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0350  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 12:05:42] d2.utils.events INFO: eta: 16:21:22  iter: 97039  total_loss: 0.502  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 12:06:41] d2.utils.events INFO: eta: 16:20:01  iter: 97059  total_loss: 0.582  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:07:42] d2.utils.events INFO: eta: 16:19:20  iter: 97079  total_loss: 0.657  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0343  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 12:08:42] d2.utils.events INFO: eta: 16:18:06  iter: 97099  total_loss: 0.448  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0336  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 12:09:41] d2.utils.events INFO: eta: 16:16:58  iter: 97119  total_loss: 0.754  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0330  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 12:10:42] d2.utils.events INFO: eta: 16:15:57  iter: 97139  total_loss: 0.760  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0330  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 12:11:42] d2.utils.events INFO: eta: 16:14:36  iter: 97159  total_loss: 0.700  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 12:12:43] d2.utils.events INFO: eta: 16:13:39  iter: 97179  total_loss: 0.710  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0331  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 12:13:43] d2.utils.events INFO: eta: 16:12:31  iter: 97199  total_loss: 0.646  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:14:44] d2.utils.events INFO: eta: 16:11:17  iter: 97219  total_loss: 0.562  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0328  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 12:15:45] d2.utils.events INFO: eta: 16:10:25  iter: 97239  total_loss: 0.393  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0329  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:16:46] d2.utils.events INFO: eta: 16:09:36  iter: 97259  total_loss: 0.781  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0330  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 12:17:47] d2.utils.events INFO: eta: 16:08:30  iter: 97279  total_loss: 0.457  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0332  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:18:49] d2.utils.events INFO: eta: 16:07:45  iter: 97299  total_loss: 0.807  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0336  data_time: 0.0035  lr: 0.000100  max_mem: 9260M
[12/30 12:19:49] d2.utils.events INFO: eta: 16:06:33  iter: 97319  total_loss: 0.562  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0337  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 12:20:50] d2.utils.events INFO: eta: 16:05:32  iter: 97339  total_loss: 0.578  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0334  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:21:51] d2.utils.events INFO: eta: 16:04:58  iter: 97359  total_loss: 0.596  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0337  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 12:22:52] d2.utils.events INFO: eta: 16:03:46  iter: 97379  total_loss: 0.516  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0336  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:23:52] d2.utils.events INFO: eta: 16:02:36  iter: 97399  total_loss: 0.529  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0335  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:24:53] d2.utils.events INFO: eta: 16:01:33  iter: 97419  total_loss: 0.608  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.005  loss_rpn_loc: 0.003  time: 3.0336  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 12:25:55] d2.utils.events INFO: eta: 16:01:02  iter: 97439  total_loss: 0.638  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:26:55] d2.utils.events INFO: eta: 15:59:57  iter: 97459  total_loss: 0.454  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 12:27:55] d2.utils.events INFO: eta: 15:58:51  iter: 97479  total_loss: 0.633  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0337  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 12:28:56] d2.utils.events INFO: eta: 15:57:47  iter: 97499  total_loss: 0.595  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0336  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 12:29:57] d2.utils.events INFO: eta: 15:56:50  iter: 97519  total_loss: 0.586  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0337  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:30:57] d2.utils.events INFO: eta: 15:55:49  iter: 97539  total_loss: 0.442  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.019  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0337  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:32:00] d2.utils.events INFO: eta: 15:54:53  iter: 97559  total_loss: 0.663  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:33:01] d2.utils.events INFO: eta: 15:53:53  iter: 97579  total_loss: 0.472  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 12:34:01] d2.utils.events INFO: eta: 15:52:42  iter: 97599  total_loss: 0.500  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:35:02] d2.utils.events INFO: eta: 15:51:41  iter: 97619  total_loss: 0.659  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0345  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 12:36:02] d2.utils.events INFO: eta: 15:50:25  iter: 97639  total_loss: 0.527  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:37:04] d2.utils.events INFO: eta: 15:49:39  iter: 97659  total_loss: 0.342  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.084  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0346  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:38:04] d2.utils.events INFO: eta: 15:48:42  iter: 97679  total_loss: 0.644  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0344  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 12:39:05] d2.utils.events INFO: eta: 15:47:28  iter: 97699  total_loss: 0.582  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:40:05] d2.utils.events INFO: eta: 15:46:13  iter: 97719  total_loss: 0.473  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0341  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:41:06] d2.utils.events INFO: eta: 15:45:39  iter: 97739  total_loss: 0.456  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:42:06] d2.utils.events INFO: eta: 15:44:39  iter: 97759  total_loss: 0.603  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0341  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 12:43:06] d2.utils.events INFO: eta: 15:43:21  iter: 97779  total_loss: 0.441  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0337  data_time: 0.0038  lr: 0.000100  max_mem: 9260M
[12/30 12:44:08] d2.utils.events INFO: eta: 15:42:37  iter: 97799  total_loss: 0.517  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0341  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 12:45:08] d2.utils.events INFO: eta: 15:41:25  iter: 97819  total_loss: 0.484  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0339  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:46:10] d2.utils.events INFO: eta: 15:40:21  iter: 97839  total_loss: 0.689  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0343  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:47:11] d2.utils.events INFO: eta: 15:39:22  iter: 97859  total_loss: 0.644  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:48:12] d2.utils.events INFO: eta: 15:38:35  iter: 97879  total_loss: 0.514  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 12:49:14] d2.utils.events INFO: eta: 15:37:36  iter: 97899  total_loss: 0.637  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0352  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 12:50:15] d2.utils.events INFO: eta: 15:36:33  iter: 97919  total_loss: 0.543  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0352  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 12:51:16] d2.utils.events INFO: eta: 15:35:35  iter: 97939  total_loss: 0.430  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0353  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 12:52:18] d2.utils.events INFO: eta: 15:34:31  iter: 97959  total_loss: 0.622  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0356  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 12:53:18] d2.utils.events INFO: eta: 15:33:16  iter: 97979  total_loss: 0.460  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0353  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:54:17] d2.utils.events INFO: eta: 15:32:15  iter: 97999  total_loss: 0.572  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0350  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 12:55:18] d2.utils.events INFO: eta: 15:31:03  iter: 98019  total_loss: 0.694  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0350  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 12:56:20] d2.utils.events INFO: eta: 15:30:04  iter: 98039  total_loss: 0.638  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 12:57:20] d2.utils.events INFO: eta: 15:29:01  iter: 98059  total_loss: 0.415  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0350  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 12:58:20] d2.utils.events INFO: eta: 15:28:00  iter: 98079  total_loss: 0.616  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 12:59:20] d2.utils.events INFO: eta: 15:27:05  iter: 98099  total_loss: 0.552  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0346  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:00:20] d2.utils.events INFO: eta: 15:25:59  iter: 98119  total_loss: 0.355  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.083  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:01:21] d2.utils.events INFO: eta: 15:24:59  iter: 98139  total_loss: 0.674  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0345  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:02:24] d2.utils.events INFO: eta: 15:24:12  iter: 98159  total_loss: 0.609  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0351  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 13:03:24] d2.utils.events INFO: eta: 15:23:09  iter: 98179  total_loss: 0.744  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0351  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:04:25] d2.utils.events INFO: eta: 15:22:10  iter: 98199  total_loss: 0.735  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0349  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:05:26] d2.utils.events INFO: eta: 15:21:19  iter: 98219  total_loss: 0.599  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0352  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 13:06:27] d2.utils.events INFO: eta: 15:20:19  iter: 98239  total_loss: 0.509  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:07:29] d2.utils.events INFO: eta: 15:19:18  iter: 98259  total_loss: 0.604  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0356  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 13:08:29] d2.utils.events INFO: eta: 15:18:17  iter: 98279  total_loss: 0.671  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0355  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:09:29] d2.utils.events INFO: eta: 15:17:02  iter: 98299  total_loss: 0.622  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 13:10:30] d2.utils.events INFO: eta: 15:16:05  iter: 98319  total_loss: 0.518  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0353  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 13:11:29] d2.utils.events INFO: eta: 15:15:02  iter: 98339  total_loss: 0.458  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0348  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:12:29] d2.utils.events INFO: eta: 15:13:59  iter: 98359  total_loss: 0.610  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0344  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 13:13:29] d2.utils.events INFO: eta: 15:12:57  iter: 98379  total_loss: 0.442  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:14:32] d2.utils.events INFO: eta: 15:12:04  iter: 98399  total_loss: 0.786  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:15:34] d2.utils.events INFO: eta: 15:11:03  iter: 98419  total_loss: 0.717  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0352  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:16:33] d2.utils.events INFO: eta: 15:09:53  iter: 98439  total_loss: 0.532  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0348  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 13:17:33] d2.utils.events INFO: eta: 15:08:50  iter: 98459  total_loss: 0.650  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0345  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 13:18:34] d2.utils.events INFO: eta: 15:07:51  iter: 98479  total_loss: 0.640  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 13:19:35] d2.utils.events INFO: eta: 15:06:47  iter: 98499  total_loss: 0.579  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 13:20:35] d2.utils.events INFO: eta: 15:05:41  iter: 98519  total_loss: 0.653  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 13:21:36] d2.utils.events INFO: eta: 15:04:47  iter: 98539  total_loss: 0.673  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:22:37] d2.utils.events INFO: eta: 15:03:39  iter: 98559  total_loss: 0.652  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 13:23:39] d2.utils.events INFO: eta: 15:02:46  iter: 98579  total_loss: 0.686  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0351  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 13:24:40] d2.utils.events INFO: eta: 15:01:47  iter: 98599  total_loss: 0.461  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.082  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0353  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:25:42] d2.utils.events INFO: eta: 15:00:54  iter: 98619  total_loss: 0.650  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 13:26:43] d2.utils.events INFO: eta: 14:59:59  iter: 98639  total_loss: 0.862  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0355  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:27:45] d2.utils.events INFO: eta: 14:58:59  iter: 98659  total_loss: 0.586  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0358  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:28:46] d2.utils.events INFO: eta: 14:58:00  iter: 98679  total_loss: 0.559  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0360  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:29:47] d2.utils.events INFO: eta: 14:57:00  iter: 98699  total_loss: 0.879  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0362  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 13:30:47] d2.utils.events INFO: eta: 14:56:04  iter: 98719  total_loss: 0.484  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0359  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:31:49] d2.utils.events INFO: eta: 14:55:03  iter: 98739  total_loss: 0.612  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.098  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0361  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:32:49] d2.utils.events INFO: eta: 14:54:02  iter: 98759  total_loss: 0.539  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0361  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:33:50] d2.utils.events INFO: eta: 14:52:59  iter: 98779  total_loss: 0.666  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0359  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 13:34:50] d2.utils.events INFO: eta: 14:51:55  iter: 98799  total_loss: 0.574  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0358  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 13:35:50] d2.utils.events INFO: eta: 14:50:52  iter: 98819  total_loss: 0.431  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 13:36:51] d2.utils.events INFO: eta: 14:49:52  iter: 98839  total_loss: 0.579  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0356  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:37:52] d2.utils.events INFO: eta: 14:48:51  iter: 98859  total_loss: 0.613  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0357  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:38:50] d2.utils.events INFO: eta: 14:47:39  iter: 98879  total_loss: 0.377  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0351  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:39:51] d2.utils.events INFO: eta: 14:46:37  iter: 98899  total_loss: 0.695  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0352  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 13:40:52] d2.utils.events INFO: eta: 14:45:40  iter: 98919  total_loss: 0.557  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0352  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 13:41:53] d2.utils.events INFO: eta: 14:44:39  iter: 98939  total_loss: 0.647  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 13:42:54] d2.utils.events INFO: eta: 14:43:42  iter: 98959  total_loss: 0.581  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 13:43:56] d2.utils.events INFO: eta: 14:42:48  iter: 98979  total_loss: 0.739  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0357  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 13:44:57] d2.utils.events INFO: eta: 14:41:53  iter: 98999  total_loss: 0.453  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0358  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 13:45:59] d2.utils.events INFO: eta: 14:41:01  iter: 99019  total_loss: 0.679  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0361  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 13:47:01] d2.utils.events INFO: eta: 14:40:01  iter: 99039  total_loss: 0.653  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0364  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:48:03] d2.utils.events INFO: eta: 14:39:10  iter: 99059  total_loss: 0.949  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0367  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 13:49:04] d2.utils.events INFO: eta: 14:38:09  iter: 99079  total_loss: 0.540  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0368  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 13:50:04] d2.utils.events INFO: eta: 14:37:06  iter: 99099  total_loss: 0.574  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0365  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:51:06] d2.utils.events INFO: eta: 14:36:11  iter: 99119  total_loss: 0.610  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0369  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:52:07] d2.utils.events INFO: eta: 14:35:11  iter: 99139  total_loss: 0.622  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0370  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 13:53:07] d2.utils.events INFO: eta: 14:34:02  iter: 99159  total_loss: 0.585  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0366  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 13:54:07] d2.utils.events INFO: eta: 14:32:58  iter: 99179  total_loss: 0.342  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0366  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 13:55:08] d2.utils.events INFO: eta: 14:32:03  iter: 99199  total_loss: 0.524  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0366  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 13:56:11] d2.utils.events INFO: eta: 14:31:04  iter: 99219  total_loss: 0.593  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0370  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 13:57:11] d2.utils.events INFO: eta: 14:30:01  iter: 99239  total_loss: 0.506  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0369  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 13:58:11] d2.utils.events INFO: eta: 14:29:00  iter: 99259  total_loss: 0.428  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0367  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 13:59:12] d2.utils.events INFO: eta: 14:27:54  iter: 99279  total_loss: 0.650  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0368  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:00:12] d2.utils.events INFO: eta: 14:26:59  iter: 99299  total_loss: 0.606  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0365  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:01:13] d2.utils.events INFO: eta: 14:25:54  iter: 99319  total_loss: 0.499  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0366  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:02:14] d2.utils.events INFO: eta: 14:24:57  iter: 99339  total_loss: 0.692  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0366  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 14:03:16] d2.utils.events INFO: eta: 14:24:00  iter: 99359  total_loss: 0.546  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0370  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 14:04:17] d2.utils.events INFO: eta: 14:23:00  iter: 99379  total_loss: 0.603  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0370  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 14:05:17] d2.utils.events INFO: eta: 14:21:57  iter: 99399  total_loss: 0.578  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0369  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 14:06:19] d2.utils.events INFO: eta: 14:20:56  iter: 99419  total_loss: 0.523  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0370  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 14:07:20] d2.utils.events INFO: eta: 14:19:57  iter: 99439  total_loss: 0.558  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0371  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:08:21] d2.utils.events INFO: eta: 14:19:05  iter: 99459  total_loss: 0.761  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0373  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 14:09:23] d2.utils.events INFO: eta: 14:18:04  iter: 99479  total_loss: 0.487  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0376  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 14:10:23] d2.utils.events INFO: eta: 14:17:04  iter: 99499  total_loss: 0.607  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0373  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 14:11:24] d2.utils.events INFO: eta: 14:16:06  iter: 99519  total_loss: 0.556  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0374  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 14:12:24] d2.utils.events INFO: eta: 14:15:02  iter: 99539  total_loss: 0.456  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0373  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 14:13:24] d2.utils.events INFO: eta: 14:13:59  iter: 99559  total_loss: 0.670  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0371  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 14:14:24] d2.utils.events INFO: eta: 14:12:50  iter: 99579  total_loss: 0.579  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0368  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:15:24] d2.utils.events INFO: eta: 14:11:49  iter: 99599  total_loss: 0.600  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0368  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:16:25] d2.utils.events INFO: eta: 14:10:44  iter: 99619  total_loss: 0.554  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0367  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 14:17:27] d2.utils.events INFO: eta: 14:09:45  iter: 99639  total_loss: 0.730  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0370  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:18:28] d2.utils.events INFO: eta: 14:08:43  iter: 99659  total_loss: 0.529  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0370  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 14:19:29] d2.utils.events INFO: eta: 14:07:42  iter: 99679  total_loss: 0.637  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0371  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 14:20:31] d2.utils.events INFO: eta: 14:06:45  iter: 99699  total_loss: 0.539  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0373  data_time: 0.0033  lr: 0.000100  max_mem: 9260M
[12/30 14:21:31] d2.utils.events INFO: eta: 14:05:44  iter: 99719  total_loss: 0.606  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0371  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 14:22:30] d2.utils.events INFO: eta: 14:04:40  iter: 99739  total_loss: 0.578  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0369  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 14:23:31] d2.utils.events INFO: eta: 14:03:40  iter: 99759  total_loss: 0.590  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0370  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 14:24:32] d2.utils.events INFO: eta: 14:02:44  iter: 99779  total_loss: 0.532  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0369  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:25:32] d2.utils.events INFO: eta: 14:01:40  iter: 99799  total_loss: 0.639  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0368  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/30 14:26:31] d2.utils.events INFO: eta: 14:00:35  iter: 99819  total_loss: 0.411  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0364  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 14:27:30] d2.utils.events INFO: eta: 13:59:32  iter: 99839  total_loss: 0.620  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 14:28:30] d2.utils.events INFO: eta: 13:58:31  iter: 99859  total_loss: 0.737  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0360  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 14:29:31] d2.utils.events INFO: eta: 13:57:33  iter: 99879  total_loss: 0.517  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 14:30:32] d2.utils.events INFO: eta: 13:56:31  iter: 99899  total_loss: 0.654  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0361  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/30 14:31:32] d2.utils.events INFO: eta: 13:55:27  iter: 99919  total_loss: 0.733  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0358  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:32:32] d2.utils.events INFO: eta: 13:54:19  iter: 99939  total_loss: 0.589  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:33:33] d2.utils.events INFO: eta: 13:53:23  iter: 99959  total_loss: 0.641  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:34:32] d2.utils.events INFO: eta: 13:52:11  iter: 99979  total_loss: 0.635  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0354  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:35:33] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0099999.pth
[12/30 14:35:38] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/30 14:35:38] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 760          |   ASC-US   | 760          |    HSIL     | 365          |
|    LSIL    | 416          |  Candida   | 197          | Trichomonas | 1144         |
|            |              |            |              |             |              |
|   total    | 3642         |            |              |             |              |[0m
[12/30 14:35:38] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/30 14:36:44] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4827 s / img. ETA=0:09:02
[12/30 14:37:08] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4824 s / img. ETA=0:08:38
[12/30 14:37:32] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4823 s / img. ETA=0:08:13
[12/30 14:37:56] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4830 s / img. ETA=0:07:50
[12/30 14:38:21] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4839 s / img. ETA=0:07:27
[12/30 14:38:45] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4838 s / img. ETA=0:07:02
[12/30 14:39:09] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4837 s / img. ETA=0:06:38
[12/30 14:39:33] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4839 s / img. ETA=0:06:14
[12/30 14:39:57] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4843 s / img. ETA=0:05:50
[12/30 14:40:22] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4846 s / img. ETA=0:05:26
[12/30 14:40:46] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4850 s / img. ETA=0:05:02
[12/30 14:41:10] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4849 s / img. ETA=0:04:38
[12/30 14:41:35] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4848 s / img. ETA=0:04:14
[12/30 14:41:59] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4845 s / img. ETA=0:03:49
[12/30 14:42:23] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4848 s / img. ETA=0:03:25
[12/30 14:42:47] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4849 s / img. ETA=0:03:01
[12/30 14:43:12] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4847 s / img. ETA=0:02:37
[12/30 14:43:36] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4845 s / img. ETA=0:02:12
[12/30 14:44:00] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4844 s / img. ETA=0:01:48
[12/30 14:44:24] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4844 s / img. ETA=0:01:24
[12/30 14:44:48] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4843 s / img. ETA=0:01:00
[12/30 14:45:12] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4842 s / img. ETA=0:00:35
[12/30 14:45:36] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4841 s / img. ETA=0:00:11
[12/30 14:45:48] d2.evaluation.evaluator INFO: Total inference time: 0:09:26 (0.484175 s / img per device, on 2 devices)
[12/30 14:45:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:22 (0.480970 s / img per device, on 2 devices)
[12/30 14:45:48] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/30 14:45:48] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/30 14:45:48] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/30 14:45:52] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.316 | 69.535 | 53.448 | 23.427 | 40.754 | 49.711 |
[12/30 14:45:52] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 51.521 | ASC-US     | 46.061 | HSIL        | 64.985 |
| LSIL       | 60.960 | Candida    | 45.425 | Trichomonas | 20.945 |
[12/30 14:45:52] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/30 14:45:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/30 14:45:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/30 14:45:52] d2.evaluation.testing INFO: copypaste: 48.3162,69.5350,53.4484,23.4268,40.7544,49.7109
[12/30 14:45:52] d2.utils.events INFO: eta: 13:51:12  iter: 99999  total_loss: 0.608  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0354  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:46:55] d2.utils.events INFO: eta: 13:50:20  iter: 100019  total_loss: 0.713  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0358  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:47:57] d2.utils.events INFO: eta: 13:49:21  iter: 100039  total_loss: 0.554  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:48:58] d2.utils.events INFO: eta: 13:48:17  iter: 100059  total_loss: 0.591  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0360  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:49:57] d2.utils.events INFO: eta: 13:47:06  iter: 100079  total_loss: 0.462  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.144  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:50:58] d2.utils.events INFO: eta: 13:46:08  iter: 100099  total_loss: 0.540  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0358  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 14:51:59] d2.utils.events INFO: eta: 13:45:05  iter: 100119  total_loss: 0.583  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0358  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:52:59] d2.utils.events INFO: eta: 13:43:58  iter: 100139  total_loss: 0.716  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0357  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:54:01] d2.utils.events INFO: eta: 13:43:06  iter: 100159  total_loss: 0.888  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0359  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 14:55:03] d2.utils.events INFO: eta: 13:42:09  iter: 100179  total_loss: 0.532  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0361  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 14:56:06] d2.utils.events INFO: eta: 13:41:11  iter: 100199  total_loss: 0.561  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0366  data_time: 0.0416  lr: 0.000100  max_mem: 9260M
[12/30 14:57:07] d2.utils.events INFO: eta: 13:40:08  iter: 100219  total_loss: 0.676  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0366  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 14:58:07] d2.utils.events INFO: eta: 13:39:05  iter: 100239  total_loss: 0.439  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0366  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 14:59:07] d2.utils.events INFO: eta: 13:38:01  iter: 100259  total_loss: 0.343  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.072  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.085  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0363  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 15:00:07] d2.utils.events INFO: eta: 13:37:03  iter: 100279  total_loss: 0.511  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0363  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 15:01:08] d2.utils.events INFO: eta: 13:36:00  iter: 100299  total_loss: 0.542  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0362  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 15:02:08] d2.utils.events INFO: eta: 13:34:57  iter: 100319  total_loss: 0.624  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0361  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:03:09] d2.utils.events INFO: eta: 13:33:56  iter: 100339  total_loss: 0.685  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0361  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 15:04:10] d2.utils.events INFO: eta: 13:32:52  iter: 100359  total_loss: 0.600  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0361  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:05:11] d2.utils.events INFO: eta: 13:31:51  iter: 100379  total_loss: 0.435  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0362  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:06:10] d2.utils.events INFO: eta: 13:30:42  iter: 100399  total_loss: 0.542  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0359  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 15:07:12] d2.utils.events INFO: eta: 13:29:46  iter: 100419  total_loss: 0.530  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0361  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 15:08:12] d2.utils.events INFO: eta: 13:28:33  iter: 100439  total_loss: 0.334  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.114  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0361  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 15:09:13] d2.utils.events INFO: eta: 13:27:28  iter: 100459  total_loss: 0.699  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:10:12] d2.utils.events INFO: eta: 13:26:19  iter: 100479  total_loss: 0.501  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0358  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:11:13] d2.utils.events INFO: eta: 13:25:11  iter: 100499  total_loss: 0.304  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.128  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0358  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 15:12:13] d2.utils.events INFO: eta: 13:24:09  iter: 100519  total_loss: 0.719  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0357  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 15:13:14] d2.utils.events INFO: eta: 13:23:07  iter: 100539  total_loss: 0.423  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0356  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:14:15] d2.utils.events INFO: eta: 13:22:02  iter: 100559  total_loss: 0.641  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 15:15:15] d2.utils.events INFO: eta: 13:21:01  iter: 100579  total_loss: 0.544  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:16:16] d2.utils.events INFO: eta: 13:20:04  iter: 100599  total_loss: 0.690  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0357  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 15:17:16] d2.utils.events INFO: eta: 13:19:00  iter: 100619  total_loss: 0.619  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0355  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 15:18:17] d2.utils.events INFO: eta: 13:17:55  iter: 100639  total_loss: 0.477  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0355  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 15:19:17] d2.utils.events INFO: eta: 13:16:45  iter: 100659  total_loss: 0.814  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0354  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 15:20:18] d2.utils.events INFO: eta: 13:15:44  iter: 100679  total_loss: 0.603  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0356  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:21:19] d2.utils.events INFO: eta: 13:14:40  iter: 100699  total_loss: 0.564  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0356  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 15:22:19] d2.utils.events INFO: eta: 13:13:37  iter: 100719  total_loss: 0.445  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0354  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:23:20] d2.utils.events INFO: eta: 13:12:37  iter: 100739  total_loss: 0.418  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0354  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:24:22] d2.utils.events INFO: eta: 13:11:37  iter: 100759  total_loss: 0.550  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0356  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:25:21] d2.utils.events INFO: eta: 13:10:35  iter: 100779  total_loss: 0.354  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.019  loss_box_reg_stage1: 0.080  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0354  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 15:26:23] d2.utils.events INFO: eta: 13:09:38  iter: 100799  total_loss: 0.579  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0356  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:27:24] d2.utils.events INFO: eta: 13:08:51  iter: 100819  total_loss: 0.548  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0357  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:28:26] d2.utils.events INFO: eta: 13:07:55  iter: 100839  total_loss: 0.617  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0359  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:29:28] d2.utils.events INFO: eta: 13:06:55  iter: 100859  total_loss: 0.621  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0360  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:30:28] d2.utils.events INFO: eta: 13:05:52  iter: 100879  total_loss: 0.403  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0360  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 15:31:29] d2.utils.events INFO: eta: 13:04:51  iter: 100899  total_loss: 0.635  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0360  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 15:32:30] d2.utils.events INFO: eta: 13:03:59  iter: 100919  total_loss: 0.577  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:33:31] d2.utils.events INFO: eta: 13:02:59  iter: 100939  total_loss: 0.455  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:34:31] d2.utils.events INFO: eta: 13:01:57  iter: 100959  total_loss: 0.620  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0359  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:35:30] d2.utils.events INFO: eta: 13:00:53  iter: 100979  total_loss: 0.492  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 15:36:32] d2.utils.events INFO: eta: 12:59:57  iter: 100999  total_loss: 0.686  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0359  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:37:34] d2.utils.events INFO: eta: 12:58:50  iter: 101019  total_loss: 0.631  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0360  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:38:34] d2.utils.events INFO: eta: 12:57:45  iter: 101039  total_loss: 0.447  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0359  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 15:39:34] d2.utils.events INFO: eta: 12:56:44  iter: 101059  total_loss: 0.535  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0359  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:40:36] d2.utils.events INFO: eta: 12:55:46  iter: 101079  total_loss: 0.541  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0360  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:41:36] d2.utils.events INFO: eta: 12:54:44  iter: 101099  total_loss: 0.599  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0359  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:42:36] d2.utils.events INFO: eta: 12:53:38  iter: 101119  total_loss: 0.308  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.078  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.106  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0357  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 15:43:36] d2.utils.events INFO: eta: 12:52:41  iter: 101139  total_loss: 0.579  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 15:44:36] d2.utils.events INFO: eta: 12:51:33  iter: 101159  total_loss: 0.404  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.016  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0355  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 15:45:36] d2.utils.events INFO: eta: 12:50:28  iter: 101179  total_loss: 0.640  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0019  lr: 0.000100  max_mem: 9260M
[12/30 15:46:36] d2.utils.events INFO: eta: 12:49:16  iter: 101199  total_loss: 0.506  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0353  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:47:37] d2.utils.events INFO: eta: 12:48:15  iter: 101219  total_loss: 0.630  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 15:48:38] d2.utils.events INFO: eta: 12:47:15  iter: 101239  total_loss: 0.771  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0353  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:49:39] d2.utils.events INFO: eta: 12:46:14  iter: 101259  total_loss: 0.474  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.141  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0354  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 15:50:39] d2.utils.events INFO: eta: 12:45:08  iter: 101279  total_loss: 0.609  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0353  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 15:51:41] d2.utils.events INFO: eta: 12:44:12  iter: 101299  total_loss: 0.457  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0355  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:52:41] d2.utils.events INFO: eta: 12:43:13  iter: 101319  total_loss: 0.563  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0354  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:53:42] d2.utils.events INFO: eta: 12:42:11  iter: 101339  total_loss: 0.528  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0354  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:54:42] d2.utils.events INFO: eta: 12:41:09  iter: 101359  total_loss: 0.614  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0354  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:55:45] d2.utils.events INFO: eta: 12:40:08  iter: 101379  total_loss: 0.572  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 15:56:46] d2.utils.events INFO: eta: 12:39:09  iter: 101399  total_loss: 0.521  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0357  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:57:46] d2.utils.events INFO: eta: 12:37:51  iter: 101419  total_loss: 0.679  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0355  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 15:58:47] d2.utils.events INFO: eta: 12:36:49  iter: 101439  total_loss: 0.671  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0356  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 15:59:48] d2.utils.events INFO: eta: 12:35:55  iter: 101459  total_loss: 0.913  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0357  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 16:00:48] d2.utils.events INFO: eta: 12:34:53  iter: 101479  total_loss: 0.750  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0355  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 16:01:49] d2.utils.events INFO: eta: 12:34:00  iter: 101499  total_loss: 0.502  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0356  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:02:50] d2.utils.events INFO: eta: 12:32:59  iter: 101519  total_loss: 0.598  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0356  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:03:50] d2.utils.events INFO: eta: 12:32:04  iter: 101539  total_loss: 0.634  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0355  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:04:51] d2.utils.events INFO: eta: 12:31:04  iter: 101559  total_loss: 0.653  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0355  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:05:50] d2.utils.events INFO: eta: 12:30:02  iter: 101579  total_loss: 0.473  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0353  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:06:50] d2.utils.events INFO: eta: 12:28:59  iter: 101599  total_loss: 0.511  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0352  data_time: 0.0037  lr: 0.000100  max_mem: 9260M
[12/30 16:07:50] d2.utils.events INFO: eta: 12:27:52  iter: 101619  total_loss: 0.531  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.105  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0351  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:08:50] d2.utils.events INFO: eta: 12:26:42  iter: 101639  total_loss: 0.486  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0349  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:09:49] d2.utils.events INFO: eta: 12:25:41  iter: 101659  total_loss: 0.457  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0347  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 16:10:51] d2.utils.events INFO: eta: 12:24:37  iter: 101679  total_loss: 0.590  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:11:52] d2.utils.events INFO: eta: 12:23:36  iter: 101699  total_loss: 0.488  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0349  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:12:53] d2.utils.events INFO: eta: 12:22:37  iter: 101719  total_loss: 0.584  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:13:54] d2.utils.events INFO: eta: 12:21:38  iter: 101739  total_loss: 0.543  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0351  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:14:54] d2.utils.events INFO: eta: 12:20:26  iter: 101759  total_loss: 0.892  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0349  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:15:54] d2.utils.events INFO: eta: 12:19:25  iter: 101779  total_loss: 0.337  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.083  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.117  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0348  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 16:16:55] d2.utils.events INFO: eta: 12:18:20  iter: 101799  total_loss: 0.531  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0348  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:17:56] d2.utils.events INFO: eta: 12:17:24  iter: 101819  total_loss: 0.493  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/30 16:18:57] d2.utils.events INFO: eta: 12:16:19  iter: 101839  total_loss: 0.635  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 16:19:56] d2.utils.events INFO: eta: 12:14:59  iter: 101859  total_loss: 0.473  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0346  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:20:56] d2.utils.events INFO: eta: 12:13:39  iter: 101879  total_loss: 0.581  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0345  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:21:57] d2.utils.events INFO: eta: 12:12:47  iter: 101899  total_loss: 0.417  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0346  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:22:58] d2.utils.events INFO: eta: 12:11:51  iter: 101919  total_loss: 0.623  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0347  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:24:00] d2.utils.events INFO: eta: 12:10:56  iter: 101939  total_loss: 0.607  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0348  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 16:25:00] d2.utils.events INFO: eta: 12:09:51  iter: 101959  total_loss: 0.753  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0347  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 16:26:00] d2.utils.events INFO: eta: 12:08:54  iter: 101979  total_loss: 0.555  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0346  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/30 16:27:02] d2.utils.events INFO: eta: 12:07:47  iter: 101999  total_loss: 0.535  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:28:04] d2.utils.events INFO: eta: 12:06:50  iter: 102019  total_loss: 0.600  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:29:05] d2.utils.events INFO: eta: 12:05:59  iter: 102039  total_loss: 0.537  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:30:07] d2.utils.events INFO: eta: 12:05:10  iter: 102059  total_loss: 0.745  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0352  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 16:31:06] d2.utils.events INFO: eta: 12:03:55  iter: 102079  total_loss: 0.378  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.078  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.108  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0349  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:32:06] d2.utils.events INFO: eta: 12:02:54  iter: 102099  total_loss: 0.588  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0348  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:33:06] d2.utils.events INFO: eta: 12:02:00  iter: 102119  total_loss: 0.378  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.086  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0348  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:34:07] d2.utils.events INFO: eta: 12:00:52  iter: 102139  total_loss: 0.701  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0348  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:35:07] d2.utils.events INFO: eta: 11:59:47  iter: 102159  total_loss: 0.441  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0346  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:36:06] d2.utils.events INFO: eta: 11:58:46  iter: 102179  total_loss: 0.493  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 16:37:08] d2.utils.events INFO: eta: 11:57:57  iter: 102199  total_loss: 0.703  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:38:09] d2.utils.events INFO: eta: 11:56:49  iter: 102219  total_loss: 0.798  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0347  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:39:09] d2.utils.events INFO: eta: 11:55:48  iter: 102239  total_loss: 0.564  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0345  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:40:09] d2.utils.events INFO: eta: 11:54:42  iter: 102259  total_loss: 0.747  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0344  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 16:41:10] d2.utils.events INFO: eta: 11:53:49  iter: 102279  total_loss: 0.471  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0344  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 16:42:11] d2.utils.events INFO: eta: 11:52:46  iter: 102299  total_loss: 0.562  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:43:12] d2.utils.events INFO: eta: 11:51:43  iter: 102319  total_loss: 0.539  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:44:12] d2.utils.events INFO: eta: 11:50:47  iter: 102339  total_loss: 0.520  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:45:14] d2.utils.events INFO: eta: 11:49:56  iter: 102359  total_loss: 0.447  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 16:46:15] d2.utils.events INFO: eta: 11:49:01  iter: 102379  total_loss: 0.577  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:47:17] d2.utils.events INFO: eta: 11:48:09  iter: 102399  total_loss: 0.812  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:48:19] d2.utils.events INFO: eta: 11:47:17  iter: 102419  total_loss: 0.330  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.086  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0350  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 16:49:21] d2.utils.events INFO: eta: 11:46:20  iter: 102439  total_loss: 0.576  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0351  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:50:21] d2.utils.events INFO: eta: 11:45:11  iter: 102459  total_loss: 0.669  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0350  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 16:51:22] d2.utils.events INFO: eta: 11:44:19  iter: 102479  total_loss: 0.584  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0350  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:52:21] d2.utils.events INFO: eta: 11:43:04  iter: 102499  total_loss: 0.572  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0349  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 16:53:20] d2.utils.events INFO: eta: 11:42:02  iter: 102519  total_loss: 0.594  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 16:54:20] d2.utils.events INFO: eta: 11:41:01  iter: 102539  total_loss: 0.769  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 16:55:21] d2.utils.events INFO: eta: 11:40:00  iter: 102559  total_loss: 0.704  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0346  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 16:56:24] d2.utils.events INFO: eta: 11:39:11  iter: 102579  total_loss: 0.797  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0349  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 16:57:26] d2.utils.events INFO: eta: 11:38:18  iter: 102599  total_loss: 0.725  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0351  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 16:58:27] d2.utils.events INFO: eta: 11:37:21  iter: 102619  total_loss: 0.481  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0351  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 16:59:29] d2.utils.events INFO: eta: 11:36:22  iter: 102639  total_loss: 0.475  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0352  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:00:30] d2.utils.events INFO: eta: 11:35:25  iter: 102659  total_loss: 0.494  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:01:30] d2.utils.events INFO: eta: 11:34:30  iter: 102679  total_loss: 0.750  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0352  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:02:31] d2.utils.events INFO: eta: 11:33:26  iter: 102699  total_loss: 0.658  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0352  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:03:32] d2.utils.events INFO: eta: 11:32:30  iter: 102719  total_loss: 0.514  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0352  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:04:33] d2.utils.events INFO: eta: 11:31:21  iter: 102739  total_loss: 0.637  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:05:33] d2.utils.events INFO: eta: 11:30:20  iter: 102759  total_loss: 0.589  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0352  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:06:34] d2.utils.events INFO: eta: 11:29:23  iter: 102779  total_loss: 0.631  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0353  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 17:07:35] d2.utils.events INFO: eta: 11:28:25  iter: 102799  total_loss: 0.518  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0353  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:08:34] d2.utils.events INFO: eta: 11:27:14  iter: 102819  total_loss: 0.453  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0351  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 17:09:34] d2.utils.events INFO: eta: 11:26:12  iter: 102839  total_loss: 0.558  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0349  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:10:34] d2.utils.events INFO: eta: 11:25:16  iter: 102859  total_loss: 0.607  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0349  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:11:35] d2.utils.events INFO: eta: 11:24:25  iter: 102879  total_loss: 0.537  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0349  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:12:36] d2.utils.events INFO: eta: 11:23:24  iter: 102899  total_loss: 0.575  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0350  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:13:37] d2.utils.events INFO: eta: 11:22:19  iter: 102919  total_loss: 0.576  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0350  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:14:36] d2.utils.events INFO: eta: 11:21:09  iter: 102939  total_loss: 0.446  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0348  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 17:15:37] d2.utils.events INFO: eta: 11:20:13  iter: 102959  total_loss: 0.582  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:16:37] d2.utils.events INFO: eta: 11:19:04  iter: 102979  total_loss: 0.554  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0347  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:17:37] d2.utils.events INFO: eta: 11:17:55  iter: 102999  total_loss: 0.437  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0346  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 17:18:37] d2.utils.events INFO: eta: 11:16:41  iter: 103019  total_loss: 0.494  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0345  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 17:19:37] d2.utils.events INFO: eta: 11:15:38  iter: 103039  total_loss: 0.558  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0047  lr: 0.000100  max_mem: 9260M
[12/30 17:20:39] d2.utils.events INFO: eta: 11:14:25  iter: 103059  total_loss: 0.544  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:21:38] d2.utils.events INFO: eta: 11:13:32  iter: 103079  total_loss: 0.495  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:22:39] d2.utils.events INFO: eta: 11:12:34  iter: 103099  total_loss: 0.574  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 17:23:39] d2.utils.events INFO: eta: 11:11:43  iter: 103119  total_loss: 0.731  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:24:42] d2.utils.events INFO: eta: 11:11:00  iter: 103139  total_loss: 0.830  loss_cls_stage0: 0.098  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.090  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0346  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:25:43] d2.utils.events INFO: eta: 11:10:08  iter: 103159  total_loss: 0.673  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0346  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 17:26:43] d2.utils.events INFO: eta: 11:09:07  iter: 103179  total_loss: 0.620  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:27:43] d2.utils.events INFO: eta: 11:07:52  iter: 103199  total_loss: 0.525  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0344  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:28:44] d2.utils.events INFO: eta: 11:06:51  iter: 103219  total_loss: 0.543  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 17:29:45] d2.utils.events INFO: eta: 11:05:51  iter: 103239  total_loss: 0.534  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0345  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 17:30:45] d2.utils.events INFO: eta: 11:05:02  iter: 103259  total_loss: 0.390  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0345  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 17:31:46] d2.utils.events INFO: eta: 11:04:01  iter: 103279  total_loss: 0.349  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.036  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.090  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0344  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:32:46] d2.utils.events INFO: eta: 11:03:00  iter: 103299  total_loss: 0.626  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 17:33:48] d2.utils.events INFO: eta: 11:02:06  iter: 103319  total_loss: 0.564  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:34:50] d2.utils.events INFO: eta: 11:01:08  iter: 103339  total_loss: 0.713  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0347  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:35:50] d2.utils.events INFO: eta: 11:00:07  iter: 103359  total_loss: 0.601  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 17:36:50] d2.utils.events INFO: eta: 10:59:02  iter: 103379  total_loss: 0.541  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 17:37:52] d2.utils.events INFO: eta: 10:57:58  iter: 103399  total_loss: 0.666  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0346  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:38:52] d2.utils.events INFO: eta: 10:56:55  iter: 103419  total_loss: 0.544  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0346  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:39:52] d2.utils.events INFO: eta: 10:55:47  iter: 103439  total_loss: 0.464  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.033  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0345  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:40:54] d2.utils.events INFO: eta: 10:54:55  iter: 103459  total_loss: 0.542  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0346  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:41:54] d2.utils.events INFO: eta: 10:53:53  iter: 103479  total_loss: 0.602  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0346  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:42:56] d2.utils.events INFO: eta: 10:52:55  iter: 103499  total_loss: 0.566  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0347  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 17:43:55] d2.utils.events INFO: eta: 10:51:52  iter: 103519  total_loss: 0.465  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0345  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:44:55] d2.utils.events INFO: eta: 10:50:44  iter: 103539  total_loss: 0.505  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0344  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 17:45:54] d2.utils.events INFO: eta: 10:49:32  iter: 103559  total_loss: 0.573  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:46:55] d2.utils.events INFO: eta: 10:48:32  iter: 103579  total_loss: 0.360  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.131  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 17:47:54] d2.utils.events INFO: eta: 10:47:17  iter: 103599  total_loss: 0.375  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0341  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 17:48:56] d2.utils.events INFO: eta: 10:46:23  iter: 103619  total_loss: 0.769  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0341  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 17:49:55] d2.utils.events INFO: eta: 10:45:15  iter: 103639  total_loss: 0.744  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:50:58] d2.utils.events INFO: eta: 10:44:19  iter: 103659  total_loss: 0.463  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 17:51:57] d2.utils.events INFO: eta: 10:43:13  iter: 103679  total_loss: 0.344  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.086  loss_cls_stage2: 0.017  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0341  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 17:52:58] d2.utils.events INFO: eta: 10:42:15  iter: 103699  total_loss: 0.584  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 17:53:59] d2.utils.events INFO: eta: 10:41:14  iter: 103719  total_loss: 0.583  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0342  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 17:55:00] d2.utils.events INFO: eta: 10:40:10  iter: 103739  total_loss: 0.490  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:56:02] d2.utils.events INFO: eta: 10:39:19  iter: 103759  total_loss: 0.463  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 17:57:02] d2.utils.events INFO: eta: 10:38:16  iter: 103779  total_loss: 0.578  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0342  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 17:58:03] d2.utils.events INFO: eta: 10:37:11  iter: 103799  total_loss: 0.605  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0343  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 17:59:04] d2.utils.events INFO: eta: 10:36:18  iter: 103819  total_loss: 0.639  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:00:04] d2.utils.events INFO: eta: 10:35:18  iter: 103839  total_loss: 0.550  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:01:06] d2.utils.events INFO: eta: 10:34:27  iter: 103859  total_loss: 0.497  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:02:06] d2.utils.events INFO: eta: 10:33:19  iter: 103879  total_loss: 0.533  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:03:07] d2.utils.events INFO: eta: 10:32:18  iter: 103899  total_loss: 0.569  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:04:08] d2.utils.events INFO: eta: 10:31:18  iter: 103919  total_loss: 0.570  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0344  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:05:08] d2.utils.events INFO: eta: 10:30:18  iter: 103939  total_loss: 0.609  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 18:06:09] d2.utils.events INFO: eta: 10:29:16  iter: 103959  total_loss: 0.539  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:07:11] d2.utils.events INFO: eta: 10:28:24  iter: 103979  total_loss: 0.812  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0344  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:08:10] d2.utils.events INFO: eta: 10:27:24  iter: 103999  total_loss: 0.614  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:09:11] d2.utils.events INFO: eta: 10:26:17  iter: 104019  total_loss: 0.507  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:10:11] d2.utils.events INFO: eta: 10:25:13  iter: 104039  total_loss: 0.452  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.111  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0342  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:11:12] d2.utils.events INFO: eta: 10:24:12  iter: 104059  total_loss: 0.660  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0343  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:12:11] d2.utils.events INFO: eta: 10:23:11  iter: 104079  total_loss: 0.405  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:13:10] d2.utils.events INFO: eta: 10:22:07  iter: 104099  total_loss: 0.515  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:14:11] d2.utils.events INFO: eta: 10:21:06  iter: 104119  total_loss: 0.612  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0339  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:15:12] d2.utils.events INFO: eta: 10:20:04  iter: 104139  total_loss: 0.573  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:16:13] d2.utils.events INFO: eta: 10:19:01  iter: 104159  total_loss: 0.523  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:17:16] d2.utils.events INFO: eta: 10:18:04  iter: 104179  total_loss: 0.623  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0342  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:18:16] d2.utils.events INFO: eta: 10:17:06  iter: 104199  total_loss: 0.478  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 18:19:17] d2.utils.events INFO: eta: 10:16:03  iter: 104219  total_loss: 0.598  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0342  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:20:19] d2.utils.events INFO: eta: 10:15:04  iter: 104239  total_loss: 0.629  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0343  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:21:20] d2.utils.events INFO: eta: 10:14:04  iter: 104259  total_loss: 0.498  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:22:21] d2.utils.events INFO: eta: 10:13:04  iter: 104279  total_loss: 0.664  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0344  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 18:23:21] d2.utils.events INFO: eta: 10:12:02  iter: 104299  total_loss: 0.801  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0343  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:24:22] d2.utils.events INFO: eta: 10:11:01  iter: 104319  total_loss: 0.590  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0343  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:25:21] d2.utils.events INFO: eta: 10:09:53  iter: 104339  total_loss: 0.423  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0342  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:26:20] d2.utils.events INFO: eta: 10:08:51  iter: 104359  total_loss: 0.441  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.123  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:27:19] d2.utils.events INFO: eta: 10:07:24  iter: 104379  total_loss: 0.461  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.085  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.127  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0337  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:28:20] d2.utils.events INFO: eta: 10:06:33  iter: 104399  total_loss: 0.523  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:29:22] d2.utils.events INFO: eta: 10:05:36  iter: 104419  total_loss: 0.678  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0339  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 18:30:24] d2.utils.events INFO: eta: 10:04:49  iter: 104439  total_loss: 0.703  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0340  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:31:25] d2.utils.events INFO: eta: 10:03:48  iter: 104459  total_loss: 0.655  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0341  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:32:25] d2.utils.events INFO: eta: 10:02:47  iter: 104479  total_loss: 0.563  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0340  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:33:25] d2.utils.events INFO: eta: 10:01:41  iter: 104499  total_loss: 0.572  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0339  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 18:34:25] d2.utils.events INFO: eta: 10:00:45  iter: 104519  total_loss: 0.620  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0338  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 18:35:26] d2.utils.events INFO: eta: 9:59:47  iter: 104539  total_loss: 0.780  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0339  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 18:36:26] d2.utils.events INFO: eta: 9:58:52  iter: 104559  total_loss: 0.627  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0338  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:37:26] d2.utils.events INFO: eta: 9:57:46  iter: 104579  total_loss: 0.515  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0337  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:38:25] d2.utils.events INFO: eta: 9:56:49  iter: 104599  total_loss: 0.456  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0335  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:39:25] d2.utils.events INFO: eta: 9:55:42  iter: 104619  total_loss: 0.584  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0335  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:40:24] d2.utils.events INFO: eta: 9:54:41  iter: 104639  total_loss: 0.497  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:41:24] d2.utils.events INFO: eta: 9:53:39  iter: 104659  total_loss: 0.504  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:42:26] d2.utils.events INFO: eta: 9:52:42  iter: 104679  total_loss: 0.445  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0334  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:43:27] d2.utils.events INFO: eta: 9:51:41  iter: 104699  total_loss: 0.632  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0334  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:44:26] d2.utils.events INFO: eta: 9:50:37  iter: 104719  total_loss: 0.572  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:45:25] d2.utils.events INFO: eta: 9:49:34  iter: 104739  total_loss: 0.552  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0331  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:46:26] d2.utils.events INFO: eta: 9:48:31  iter: 104759  total_loss: 0.659  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:47:28] d2.utils.events INFO: eta: 9:47:34  iter: 104779  total_loss: 0.732  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 18:48:28] d2.utils.events INFO: eta: 9:46:33  iter: 104799  total_loss: 0.673  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0332  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 18:49:30] d2.utils.events INFO: eta: 9:45:32  iter: 104819  total_loss: 0.441  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0333  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:50:30] d2.utils.events INFO: eta: 9:44:28  iter: 104839  total_loss: 0.599  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:51:31] d2.utils.events INFO: eta: 9:43:15  iter: 104859  total_loss: 0.614  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:52:32] d2.utils.events INFO: eta: 9:42:25  iter: 104879  total_loss: 0.578  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 18:53:33] d2.utils.events INFO: eta: 9:41:18  iter: 104899  total_loss: 0.601  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 18:54:33] d2.utils.events INFO: eta: 9:40:13  iter: 104919  total_loss: 0.789  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0332  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 18:55:31] d2.utils.events INFO: eta: 9:39:06  iter: 104939  total_loss: 0.474  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0330  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 18:56:34] d2.utils.events INFO: eta: 9:38:11  iter: 104959  total_loss: 0.511  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0332  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 18:57:36] d2.utils.events INFO: eta: 9:37:15  iter: 104979  total_loss: 0.740  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0333  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 18:58:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0104999.pth
[12/30 18:58:41] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/30 18:58:41] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/30 18:59:47] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4797 s / img. ETA=0:08:59
[12/30 19:00:11] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4798 s / img. ETA=0:08:35
[12/30 19:00:35] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4798 s / img. ETA=0:08:11
[12/30 19:00:59] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4796 s / img. ETA=0:07:47
[12/30 19:01:23] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4797 s / img. ETA=0:07:23
[12/30 19:01:47] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4798 s / img. ETA=0:06:59
[12/30 19:02:11] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4800 s / img. ETA=0:06:35
[12/30 19:02:35] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4801 s / img. ETA=0:06:11
[12/30 19:02:59] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4801 s / img. ETA=0:05:47
[12/30 19:03:23] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4800 s / img. ETA=0:05:23
[12/30 19:03:47] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4800 s / img. ETA=0:04:59
[12/30 19:04:11] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4801 s / img. ETA=0:04:35
[12/30 19:04:35] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4801 s / img. ETA=0:04:11
[12/30 19:04:59] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4801 s / img. ETA=0:03:47
[12/30 19:05:23] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4801 s / img. ETA=0:03:23
[12/30 19:05:47] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4801 s / img. ETA=0:02:59
[12/30 19:06:11] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4801 s / img. ETA=0:02:35
[12/30 19:06:35] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4801 s / img. ETA=0:02:11
[12/30 19:06:59] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4802 s / img. ETA=0:01:47
[12/30 19:07:23] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4803 s / img. ETA=0:01:23
[12/30 19:07:47] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4803 s / img. ETA=0:00:59
[12/30 19:08:11] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4803 s / img. ETA=0:00:35
[12/30 19:08:35] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4804 s / img. ETA=0:00:11
[12/30 19:08:47] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/30 19:08:47] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:18 (0.477342 s / img per device, on 2 devices)
[12/30 19:08:47] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/30 19:08:47] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/30 19:08:47] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/30 19:08:51] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.539 | 68.471 | 53.566 | 22.641 | 40.291 | 49.106 |
[12/30 19:08:51] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 50.658 | ASC-US     | 45.855 | HSIL        | 62.509 |
| LSIL       | 60.019 | Candida    | 45.672 | Trichomonas | 20.522 |
[12/30 19:08:51] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/30 19:08:51] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/30 19:08:51] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/30 19:08:51] d2.evaluation.testing INFO: copypaste: 47.5390,68.4709,53.5656,22.6413,40.2908,49.1065
[12/30 19:08:51] d2.utils.events INFO: eta: 9:36:18  iter: 104999  total_loss: 0.583  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 19:09:53] d2.utils.events INFO: eta: 9:35:23  iter: 105019  total_loss: 0.480  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0333  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 19:10:52] d2.utils.events INFO: eta: 9:34:22  iter: 105039  total_loss: 0.501  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0331  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 19:11:53] d2.utils.events INFO: eta: 9:33:21  iter: 105059  total_loss: 0.525  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0331  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:12:53] d2.utils.events INFO: eta: 9:32:19  iter: 105079  total_loss: 0.403  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0331  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 19:13:53] d2.utils.events INFO: eta: 9:31:30  iter: 105099  total_loss: 0.537  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0330  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:14:53] d2.utils.events INFO: eta: 9:30:20  iter: 105119  total_loss: 0.509  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0329  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 19:15:54] d2.utils.events INFO: eta: 9:29:17  iter: 105139  total_loss: 0.591  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0329  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 19:16:54] d2.utils.events INFO: eta: 9:28:17  iter: 105159  total_loss: 0.523  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0329  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 19:17:55] d2.utils.events INFO: eta: 9:27:14  iter: 105179  total_loss: 0.473  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0329  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:18:56] d2.utils.events INFO: eta: 9:26:14  iter: 105199  total_loss: 0.597  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0330  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 19:19:55] d2.utils.events INFO: eta: 9:25:12  iter: 105219  total_loss: 0.297  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.019  loss_box_reg_stage1: 0.075  loss_cls_stage2: 0.018  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0328  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:20:57] d2.utils.events INFO: eta: 9:24:08  iter: 105239  total_loss: 0.510  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0329  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 19:21:57] d2.utils.events INFO: eta: 9:23:07  iter: 105259  total_loss: 0.640  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0329  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 19:22:59] d2.utils.events INFO: eta: 9:22:09  iter: 105279  total_loss: 0.579  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0330  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:24:01] d2.utils.events INFO: eta: 9:21:10  iter: 105299  total_loss: 0.452  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0331  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 19:25:00] d2.utils.events INFO: eta: 9:20:05  iter: 105319  total_loss: 0.538  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0330  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:26:01] d2.utils.events INFO: eta: 9:19:02  iter: 105339  total_loss: 0.602  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0330  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 19:27:03] d2.utils.events INFO: eta: 9:18:10  iter: 105359  total_loss: 0.641  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0331  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 19:28:04] d2.utils.events INFO: eta: 9:17:22  iter: 105379  total_loss: 0.645  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 19:29:05] d2.utils.events INFO: eta: 9:16:19  iter: 105399  total_loss: 0.577  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:30:06] d2.utils.events INFO: eta: 9:15:15  iter: 105419  total_loss: 0.633  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0332  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 19:31:06] d2.utils.events INFO: eta: 9:14:07  iter: 105439  total_loss: 0.395  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.083  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0331  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:32:07] d2.utils.events INFO: eta: 9:13:05  iter: 105459  total_loss: 0.691  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0332  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 19:33:08] d2.utils.events INFO: eta: 9:12:12  iter: 105479  total_loss: 0.532  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0332  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 19:34:08] d2.utils.events INFO: eta: 9:11:14  iter: 105499  total_loss: 0.649  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0332  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 19:35:08] d2.utils.events INFO: eta: 9:10:13  iter: 105519  total_loss: 0.422  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0330  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 19:36:07] d2.utils.events INFO: eta: 9:09:06  iter: 105539  total_loss: 0.523  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0329  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 19:37:07] d2.utils.events INFO: eta: 9:08:05  iter: 105559  total_loss: 0.653  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:38:07] d2.utils.events INFO: eta: 9:07:05  iter: 105579  total_loss: 0.531  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0327  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 19:39:08] d2.utils.events INFO: eta: 9:06:10  iter: 105599  total_loss: 0.576  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0328  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 19:40:08] d2.utils.events INFO: eta: 9:05:03  iter: 105619  total_loss: 0.619  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 19:41:08] d2.utils.events INFO: eta: 9:04:05  iter: 105639  total_loss: 0.487  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0327  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:42:07] d2.utils.events INFO: eta: 9:03:01  iter: 105659  total_loss: 0.529  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:43:10] d2.utils.events INFO: eta: 9:02:00  iter: 105679  total_loss: 0.549  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 19:44:11] d2.utils.events INFO: eta: 9:00:58  iter: 105699  total_loss: 0.505  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0327  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:45:11] d2.utils.events INFO: eta: 8:59:57  iter: 105719  total_loss: 0.703  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 19:46:13] d2.utils.events INFO: eta: 8:59:04  iter: 105739  total_loss: 0.666  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 19:47:13] d2.utils.events INFO: eta: 8:58:03  iter: 105759  total_loss: 0.475  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0327  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:48:14] d2.utils.events INFO: eta: 8:57:01  iter: 105779  total_loss: 0.604  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0328  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 19:49:13] d2.utils.events INFO: eta: 8:56:01  iter: 105799  total_loss: 0.343  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.001  time: 3.0327  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 19:50:13] d2.utils.events INFO: eta: 8:54:54  iter: 105819  total_loss: 0.469  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 19:51:14] d2.utils.events INFO: eta: 8:53:56  iter: 105839  total_loss: 0.759  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0326  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 19:52:14] d2.utils.events INFO: eta: 8:52:53  iter: 105859  total_loss: 0.612  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 19:53:15] d2.utils.events INFO: eta: 8:51:58  iter: 105879  total_loss: 0.688  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 19:54:17] d2.utils.events INFO: eta: 8:50:57  iter: 105899  total_loss: 0.610  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0327  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 19:55:17] d2.utils.events INFO: eta: 8:49:57  iter: 105919  total_loss: 0.637  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 19:56:19] d2.utils.events INFO: eta: 8:49:07  iter: 105939  total_loss: 0.592  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 19:57:20] d2.utils.events INFO: eta: 8:48:06  iter: 105959  total_loss: 0.440  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0328  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 19:58:19] d2.utils.events INFO: eta: 8:46:56  iter: 105979  total_loss: 0.654  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 19:59:19] d2.utils.events INFO: eta: 8:45:58  iter: 105999  total_loss: 0.618  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 20:00:19] d2.utils.events INFO: eta: 8:44:49  iter: 106019  total_loss: 0.461  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:01:21] d2.utils.events INFO: eta: 8:43:53  iter: 106039  total_loss: 0.492  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:02:21] d2.utils.events INFO: eta: 8:42:55  iter: 106059  total_loss: 0.542  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 20:03:23] d2.utils.events INFO: eta: 8:42:01  iter: 106079  total_loss: 0.675  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:04:24] d2.utils.events INFO: eta: 8:40:59  iter: 106099  total_loss: 0.731  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0327  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:05:23] d2.utils.events INFO: eta: 8:39:59  iter: 106119  total_loss: 0.562  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:06:23] d2.utils.events INFO: eta: 8:38:57  iter: 106139  total_loss: 0.423  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:07:24] d2.utils.events INFO: eta: 8:37:56  iter: 106159  total_loss: 0.560  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:08:23] d2.utils.events INFO: eta: 8:36:51  iter: 106179  total_loss: 0.416  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0323  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:09:23] d2.utils.events INFO: eta: 8:35:44  iter: 106199  total_loss: 0.441  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.084  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.125  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0323  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 20:10:24] d2.utils.events INFO: eta: 8:34:44  iter: 106219  total_loss: 0.596  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 20:11:24] d2.utils.events INFO: eta: 8:33:42  iter: 106239  total_loss: 0.560  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0322  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 20:12:24] d2.utils.events INFO: eta: 8:32:35  iter: 106259  total_loss: 0.343  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.026  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.062  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.101  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0322  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:13:25] d2.utils.events INFO: eta: 8:31:20  iter: 106279  total_loss: 0.487  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:14:25] d2.utils.events INFO: eta: 8:30:07  iter: 106299  total_loss: 0.488  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:15:26] d2.utils.events INFO: eta: 8:29:08  iter: 106319  total_loss: 0.725  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:16:28] d2.utils.events INFO: eta: 8:28:17  iter: 106339  total_loss: 0.787  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:17:29] d2.utils.events INFO: eta: 8:27:06  iter: 106359  total_loss: 0.597  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:18:30] d2.utils.events INFO: eta: 8:25:59  iter: 106379  total_loss: 0.557  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0035  lr: 0.000100  max_mem: 9260M
[12/30 20:19:31] d2.utils.events INFO: eta: 8:25:03  iter: 106399  total_loss: 0.407  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:20:30] d2.utils.events INFO: eta: 8:23:57  iter: 106419  total_loss: 0.579  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:21:31] d2.utils.events INFO: eta: 8:23:01  iter: 106439  total_loss: 0.633  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 20:22:33] d2.utils.events INFO: eta: 8:22:05  iter: 106459  total_loss: 0.558  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0324  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:23:34] d2.utils.events INFO: eta: 8:20:56  iter: 106479  total_loss: 0.755  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0324  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 20:24:33] d2.utils.events INFO: eta: 8:19:55  iter: 106499  total_loss: 0.424  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0019  lr: 0.000100  max_mem: 9260M
[12/30 20:25:34] d2.utils.events INFO: eta: 8:18:58  iter: 106519  total_loss: 0.586  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 20:26:35] d2.utils.events INFO: eta: 8:18:02  iter: 106539  total_loss: 0.750  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:27:35] d2.utils.events INFO: eta: 8:16:58  iter: 106559  total_loss: 0.521  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 20:28:34] d2.utils.events INFO: eta: 8:15:53  iter: 106579  total_loss: 0.489  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 20:29:35] d2.utils.events INFO: eta: 8:14:50  iter: 106599  total_loss: 0.719  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:30:35] d2.utils.events INFO: eta: 8:13:50  iter: 106619  total_loss: 0.642  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:31:36] d2.utils.events INFO: eta: 8:12:49  iter: 106639  total_loss: 0.555  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:32:35] d2.utils.events INFO: eta: 8:11:47  iter: 106659  total_loss: 0.540  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 20:33:33] d2.utils.events INFO: eta: 8:10:35  iter: 106679  total_loss: 0.538  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0318  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 20:34:34] d2.utils.events INFO: eta: 8:09:36  iter: 106699  total_loss: 0.471  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:35:37] d2.utils.events INFO: eta: 8:08:45  iter: 106719  total_loss: 0.491  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 20:36:38] d2.utils.events INFO: eta: 8:07:48  iter: 106739  total_loss: 0.648  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:37:39] d2.utils.events INFO: eta: 8:06:48  iter: 106759  total_loss: 0.416  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.091  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 20:38:40] d2.utils.events INFO: eta: 8:05:58  iter: 106779  total_loss: 0.482  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0321  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:39:40] d2.utils.events INFO: eta: 8:04:57  iter: 106799  total_loss: 0.487  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:40:41] d2.utils.events INFO: eta: 8:04:01  iter: 106819  total_loss: 0.697  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 20:41:41] d2.utils.events INFO: eta: 8:02:57  iter: 106839  total_loss: 0.506  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.108  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:42:41] d2.utils.events INFO: eta: 8:01:49  iter: 106859  total_loss: 0.485  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 20:43:41] d2.utils.events INFO: eta: 8:00:36  iter: 106879  total_loss: 0.583  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:44:42] d2.utils.events INFO: eta: 7:59:35  iter: 106899  total_loss: 0.616  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 20:45:41] d2.utils.events INFO: eta: 7:58:18  iter: 106919  total_loss: 0.460  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:46:39] d2.utils.events INFO: eta: 7:57:09  iter: 106939  total_loss: 0.491  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:47:39] d2.utils.events INFO: eta: 7:56:08  iter: 106959  total_loss: 0.453  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:48:40] d2.utils.events INFO: eta: 7:55:10  iter: 106979  total_loss: 0.510  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 20:49:42] d2.utils.events INFO: eta: 7:54:16  iter: 106999  total_loss: 0.637  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 20:50:44] d2.utils.events INFO: eta: 7:53:22  iter: 107019  total_loss: 0.515  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:51:43] d2.utils.events INFO: eta: 7:52:11  iter: 107039  total_loss: 0.419  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 20:52:44] d2.utils.events INFO: eta: 7:51:08  iter: 107059  total_loss: 0.607  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 20:53:43] d2.utils.events INFO: eta: 7:49:56  iter: 107079  total_loss: 0.505  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.001  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 20:54:44] d2.utils.events INFO: eta: 7:48:57  iter: 107099  total_loss: 0.544  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:55:47] d2.utils.events INFO: eta: 7:48:07  iter: 107119  total_loss: 0.814  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:56:47] d2.utils.events INFO: eta: 7:47:10  iter: 107139  total_loss: 0.634  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:57:49] d2.utils.events INFO: eta: 7:46:16  iter: 107159  total_loss: 0.493  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 20:58:49] d2.utils.events INFO: eta: 7:45:18  iter: 107179  total_loss: 0.361  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.147  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 20:59:48] d2.utils.events INFO: eta: 7:44:15  iter: 107199  total_loss: 0.538  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:00:49] d2.utils.events INFO: eta: 7:43:16  iter: 107219  total_loss: 0.596  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:01:51] d2.utils.events INFO: eta: 7:42:24  iter: 107239  total_loss: 0.641  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 21:02:50] d2.utils.events INFO: eta: 7:41:23  iter: 107259  total_loss: 0.577  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.136  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:03:51] d2.utils.events INFO: eta: 7:40:24  iter: 107279  total_loss: 0.446  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 21:04:54] d2.utils.events INFO: eta: 7:39:36  iter: 107299  total_loss: 0.590  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:05:52] d2.utils.events INFO: eta: 7:38:31  iter: 107319  total_loss: 0.569  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:06:52] d2.utils.events INFO: eta: 7:37:25  iter: 107339  total_loss: 0.574  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:07:52] d2.utils.events INFO: eta: 7:36:19  iter: 107359  total_loss: 0.447  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/30 21:08:54] d2.utils.events INFO: eta: 7:35:20  iter: 107379  total_loss: 0.651  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:09:54] d2.utils.events INFO: eta: 7:34:16  iter: 107399  total_loss: 0.469  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:10:55] d2.utils.events INFO: eta: 7:33:28  iter: 107419  total_loss: 0.548  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:11:56] d2.utils.events INFO: eta: 7:32:24  iter: 107439  total_loss: 0.586  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:12:56] d2.utils.events INFO: eta: 7:31:16  iter: 107459  total_loss: 0.591  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 21:13:57] d2.utils.events INFO: eta: 7:30:15  iter: 107479  total_loss: 0.582  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 21:14:57] d2.utils.events INFO: eta: 7:29:14  iter: 107499  total_loss: 0.548  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:15:59] d2.utils.events INFO: eta: 7:28:24  iter: 107519  total_loss: 0.643  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:17:00] d2.utils.events INFO: eta: 7:27:23  iter: 107539  total_loss: 0.646  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 21:18:01] d2.utils.events INFO: eta: 7:26:25  iter: 107559  total_loss: 0.609  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:19:01] d2.utils.events INFO: eta: 7:25:25  iter: 107579  total_loss: 0.687  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:20:02] d2.utils.events INFO: eta: 7:24:25  iter: 107599  total_loss: 0.596  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:21:02] d2.utils.events INFO: eta: 7:23:26  iter: 107619  total_loss: 0.619  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:22:04] d2.utils.events INFO: eta: 7:22:31  iter: 107639  total_loss: 0.595  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:23:04] d2.utils.events INFO: eta: 7:21:40  iter: 107659  total_loss: 0.535  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:24:05] d2.utils.events INFO: eta: 7:20:41  iter: 107679  total_loss: 0.559  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:25:05] d2.utils.events INFO: eta: 7:19:31  iter: 107699  total_loss: 0.548  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:26:05] d2.utils.events INFO: eta: 7:18:23  iter: 107719  total_loss: 0.550  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:27:07] d2.utils.events INFO: eta: 7:17:21  iter: 107739  total_loss: 0.613  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:28:08] d2.utils.events INFO: eta: 7:16:23  iter: 107759  total_loss: 0.607  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:29:09] d2.utils.events INFO: eta: 7:15:14  iter: 107779  total_loss: 0.688  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 21:30:11] d2.utils.events INFO: eta: 7:14:18  iter: 107799  total_loss: 0.599  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 21:31:11] d2.utils.events INFO: eta: 7:13:16  iter: 107819  total_loss: 0.469  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0318  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 21:32:10] d2.utils.events INFO: eta: 7:12:16  iter: 107839  total_loss: 0.524  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:33:11] d2.utils.events INFO: eta: 7:11:21  iter: 107859  total_loss: 0.677  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:34:13] d2.utils.events INFO: eta: 7:10:26  iter: 107879  total_loss: 0.488  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:35:13] d2.utils.events INFO: eta: 7:09:26  iter: 107899  total_loss: 0.725  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:36:16] d2.utils.events INFO: eta: 7:08:33  iter: 107919  total_loss: 0.764  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0318  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 21:37:17] d2.utils.events INFO: eta: 7:07:41  iter: 107939  total_loss: 0.673  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:38:16] d2.utils.events INFO: eta: 7:06:40  iter: 107959  total_loss: 0.604  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:39:15] d2.utils.events INFO: eta: 7:05:39  iter: 107979  total_loss: 0.407  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 21:40:15] d2.utils.events INFO: eta: 7:04:32  iter: 107999  total_loss: 0.595  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 21:41:17] d2.utils.events INFO: eta: 7:03:31  iter: 108019  total_loss: 0.684  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 21:42:16] d2.utils.events INFO: eta: 7:02:35  iter: 108039  total_loss: 0.479  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:43:17] d2.utils.events INFO: eta: 7:01:34  iter: 108059  total_loss: 0.532  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 21:44:18] d2.utils.events INFO: eta: 7:00:36  iter: 108079  total_loss: 0.573  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0316  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:45:18] d2.utils.events INFO: eta: 6:59:33  iter: 108099  total_loss: 0.705  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:46:20] d2.utils.events INFO: eta: 6:58:32  iter: 108119  total_loss: 0.492  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:47:21] d2.utils.events INFO: eta: 6:57:32  iter: 108139  total_loss: 0.591  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:48:23] d2.utils.events INFO: eta: 6:56:31  iter: 108159  total_loss: 0.551  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:49:24] d2.utils.events INFO: eta: 6:55:32  iter: 108179  total_loss: 0.555  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 21:50:26] d2.utils.events INFO: eta: 6:54:35  iter: 108199  total_loss: 0.486  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 21:51:27] d2.utils.events INFO: eta: 6:53:34  iter: 108219  total_loss: 0.600  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 21:52:27] d2.utils.events INFO: eta: 6:52:31  iter: 108239  total_loss: 0.709  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:53:27] d2.utils.events INFO: eta: 6:51:30  iter: 108259  total_loss: 0.289  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.026  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.065  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.117  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0318  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 21:54:27] d2.utils.events INFO: eta: 6:50:29  iter: 108279  total_loss: 0.538  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 21:55:28] d2.utils.events INFO: eta: 6:49:28  iter: 108299  total_loss: 0.587  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0319  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 21:56:31] d2.utils.events INFO: eta: 6:48:28  iter: 108319  total_loss: 0.374  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.126  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:57:30] d2.utils.events INFO: eta: 6:47:27  iter: 108339  total_loss: 0.474  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0319  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 21:58:32] d2.utils.events INFO: eta: 6:46:28  iter: 108359  total_loss: 0.597  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 21:59:34] d2.utils.events INFO: eta: 6:45:27  iter: 108379  total_loss: 0.741  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:00:34] d2.utils.events INFO: eta: 6:44:27  iter: 108399  total_loss: 0.715  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0320  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:01:34] d2.utils.events INFO: eta: 6:43:25  iter: 108419  total_loss: 0.680  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 22:02:35] d2.utils.events INFO: eta: 6:42:24  iter: 108439  total_loss: 0.491  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 22:03:36] d2.utils.events INFO: eta: 6:41:24  iter: 108459  total_loss: 0.622  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:04:39] d2.utils.events INFO: eta: 6:40:23  iter: 108479  total_loss: 0.624  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0322  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:05:40] d2.utils.events INFO: eta: 6:39:25  iter: 108499  total_loss: 0.683  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0322  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:06:40] d2.utils.events INFO: eta: 6:38:21  iter: 108519  total_loss: 0.376  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0322  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 22:07:40] d2.utils.events INFO: eta: 6:37:19  iter: 108539  total_loss: 0.552  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:08:40] d2.utils.events INFO: eta: 6:36:18  iter: 108559  total_loss: 0.518  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:09:39] d2.utils.events INFO: eta: 6:35:17  iter: 108579  total_loss: 0.477  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 22:10:40] d2.utils.events INFO: eta: 6:34:16  iter: 108599  total_loss: 0.802  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:11:41] d2.utils.events INFO: eta: 6:33:15  iter: 108619  total_loss: 0.580  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 22:12:42] d2.utils.events INFO: eta: 6:32:13  iter: 108639  total_loss: 0.550  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:13:43] d2.utils.events INFO: eta: 6:31:13  iter: 108659  total_loss: 0.610  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:14:42] d2.utils.events INFO: eta: 6:30:11  iter: 108679  total_loss: 0.537  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 22:15:42] d2.utils.events INFO: eta: 6:29:10  iter: 108699  total_loss: 0.526  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.096  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0319  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:16:43] d2.utils.events INFO: eta: 6:28:10  iter: 108719  total_loss: 0.502  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:17:45] d2.utils.events INFO: eta: 6:27:06  iter: 108739  total_loss: 0.660  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 22:18:47] d2.utils.events INFO: eta: 6:26:08  iter: 108759  total_loss: 0.638  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 22:19:49] d2.utils.events INFO: eta: 6:25:08  iter: 108779  total_loss: 0.593  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0321  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 22:20:49] d2.utils.events INFO: eta: 6:24:04  iter: 108799  total_loss: 0.692  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:21:51] d2.utils.events INFO: eta: 6:23:05  iter: 108819  total_loss: 0.541  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 22:22:54] d2.utils.events INFO: eta: 6:22:05  iter: 108839  total_loss: 0.589  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:23:54] d2.utils.events INFO: eta: 6:21:04  iter: 108859  total_loss: 0.658  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:24:54] d2.utils.events INFO: eta: 6:20:03  iter: 108879  total_loss: 0.606  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:25:56] d2.utils.events INFO: eta: 6:19:02  iter: 108899  total_loss: 0.494  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:26:56] d2.utils.events INFO: eta: 6:17:59  iter: 108919  total_loss: 0.498  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:27:56] d2.utils.events INFO: eta: 6:16:56  iter: 108939  total_loss: 0.522  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:28:57] d2.utils.events INFO: eta: 6:15:55  iter: 108959  total_loss: 0.631  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 22:29:57] d2.utils.events INFO: eta: 6:14:55  iter: 108979  total_loss: 0.510  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:30:58] d2.utils.events INFO: eta: 6:13:54  iter: 108999  total_loss: 0.558  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0323  data_time: 0.0036  lr: 0.000100  max_mem: 9260M
[12/30 22:31:58] d2.utils.events INFO: eta: 6:12:52  iter: 109019  total_loss: 0.542  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 22:32:59] d2.utils.events INFO: eta: 6:11:52  iter: 109039  total_loss: 0.471  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0322  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:33:59] d2.utils.events INFO: eta: 6:10:51  iter: 109059  total_loss: 0.847  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0322  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 22:35:01] d2.utils.events INFO: eta: 6:09:50  iter: 109079  total_loss: 0.747  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0323  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:36:01] d2.utils.events INFO: eta: 6:08:53  iter: 109099  total_loss: 0.512  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:37:02] d2.utils.events INFO: eta: 6:07:46  iter: 109119  total_loss: 0.594  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:38:04] d2.utils.events INFO: eta: 6:06:43  iter: 109139  total_loss: 0.696  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0323  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 22:39:03] d2.utils.events INFO: eta: 6:05:38  iter: 109159  total_loss: 0.662  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:40:04] d2.utils.events INFO: eta: 6:04:34  iter: 109179  total_loss: 0.530  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0323  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:41:06] d2.utils.events INFO: eta: 6:03:31  iter: 109199  total_loss: 0.553  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0324  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:42:07] d2.utils.events INFO: eta: 6:02:30  iter: 109219  total_loss: 0.570  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:43:08] d2.utils.events INFO: eta: 6:01:29  iter: 109239  total_loss: 0.501  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:44:08] d2.utils.events INFO: eta: 6:00:28  iter: 109259  total_loss: 0.518  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.171  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:45:10] d2.utils.events INFO: eta: 5:59:29  iter: 109279  total_loss: 0.590  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:46:12] d2.utils.events INFO: eta: 5:58:31  iter: 109299  total_loss: 0.540  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 22:47:12] d2.utils.events INFO: eta: 5:57:28  iter: 109319  total_loss: 0.860  loss_cls_stage0: 0.087  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.103  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  time: 3.0325  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:48:14] d2.utils.events INFO: eta: 5:56:30  iter: 109339  total_loss: 0.652  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0326  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:49:14] d2.utils.events INFO: eta: 5:55:26  iter: 109359  total_loss: 0.357  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0326  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 22:50:14] d2.utils.events INFO: eta: 5:54:24  iter: 109379  total_loss: 0.639  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:51:15] d2.utils.events INFO: eta: 5:53:24  iter: 109399  total_loss: 0.610  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0326  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 22:52:15] d2.utils.events INFO: eta: 5:52:22  iter: 109419  total_loss: 0.530  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:53:16] d2.utils.events INFO: eta: 5:51:21  iter: 109439  total_loss: 0.543  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:54:18] d2.utils.events INFO: eta: 5:50:20  iter: 109459  total_loss: 0.580  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:55:17] d2.utils.events INFO: eta: 5:49:15  iter: 109479  total_loss: 0.528  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0325  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:56:20] d2.utils.events INFO: eta: 5:48:17  iter: 109499  total_loss: 0.607  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0327  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 22:57:21] d2.utils.events INFO: eta: 5:47:17  iter: 109519  total_loss: 0.593  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0327  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 22:58:21] d2.utils.events INFO: eta: 5:46:14  iter: 109539  total_loss: 0.536  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 22:59:22] d2.utils.events INFO: eta: 5:45:16  iter: 109559  total_loss: 0.495  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 23:00:24] d2.utils.events INFO: eta: 5:44:18  iter: 109579  total_loss: 0.547  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0327  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 23:01:23] d2.utils.events INFO: eta: 5:43:14  iter: 109599  total_loss: 0.527  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:02:24] d2.utils.events INFO: eta: 5:42:16  iter: 109619  total_loss: 0.492  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0326  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 23:03:24] d2.utils.events INFO: eta: 5:41:14  iter: 109639  total_loss: 0.493  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0326  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:04:24] d2.utils.events INFO: eta: 5:40:12  iter: 109659  total_loss: 0.626  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0325  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:05:23] d2.utils.events INFO: eta: 5:39:14  iter: 109679  total_loss: 0.499  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0324  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:06:23] d2.utils.events INFO: eta: 5:38:13  iter: 109699  total_loss: 0.369  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.072  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.116  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0324  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 23:07:24] d2.utils.events INFO: eta: 5:37:10  iter: 109719  total_loss: 0.683  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0324  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 23:08:24] d2.utils.events INFO: eta: 5:36:07  iter: 109739  total_loss: 0.445  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 23:09:24] d2.utils.events INFO: eta: 5:35:01  iter: 109759  total_loss: 0.769  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0323  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:10:23] d2.utils.events INFO: eta: 5:33:54  iter: 109779  total_loss: 0.537  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 23:11:24] d2.utils.events INFO: eta: 5:32:53  iter: 109799  total_loss: 0.585  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0322  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 23:12:25] d2.utils.events INFO: eta: 5:31:47  iter: 109819  total_loss: 0.634  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0323  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 23:13:27] d2.utils.events INFO: eta: 5:30:35  iter: 109839  total_loss: 0.573  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:14:28] d2.utils.events INFO: eta: 5:29:50  iter: 109859  total_loss: 0.605  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0323  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:15:28] d2.utils.events INFO: eta: 5:28:54  iter: 109879  total_loss: 0.552  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:16:29] d2.utils.events INFO: eta: 5:27:49  iter: 109899  total_loss: 0.404  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.101  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0323  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:17:28] d2.utils.events INFO: eta: 5:26:47  iter: 109919  total_loss: 0.363  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0322  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 23:18:27] d2.utils.events INFO: eta: 5:25:31  iter: 109939  total_loss: 0.556  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:19:29] d2.utils.events INFO: eta: 5:24:34  iter: 109959  total_loss: 0.685  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0322  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/30 23:20:30] d2.utils.events INFO: eta: 5:23:45  iter: 109979  total_loss: 0.552  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0322  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:21:30] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0109999.pth
[12/30 23:21:36] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/30 23:21:36] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/30 23:22:41] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4787 s / img. ETA=0:08:58
[12/30 23:23:05] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4793 s / img. ETA=0:08:34
[12/30 23:23:29] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4794 s / img. ETA=0:08:10
[12/30 23:23:53] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4793 s / img. ETA=0:07:46
[12/30 23:24:17] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4793 s / img. ETA=0:07:22
[12/30 23:24:41] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4794 s / img. ETA=0:06:58
[12/30 23:25:05] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4796 s / img. ETA=0:06:35
[12/30 23:25:29] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4796 s / img. ETA=0:06:11
[12/30 23:25:53] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4797 s / img. ETA=0:05:47
[12/30 23:26:17] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4797 s / img. ETA=0:05:23
[12/30 23:26:41] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4798 s / img. ETA=0:04:59
[12/30 23:27:05] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4798 s / img. ETA=0:04:35
[12/30 23:27:29] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4799 s / img. ETA=0:04:11
[12/30 23:27:53] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4800 s / img. ETA=0:03:47
[12/30 23:28:17] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4800 s / img. ETA=0:03:23
[12/30 23:28:42] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4801 s / img. ETA=0:02:59
[12/30 23:29:06] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4802 s / img. ETA=0:02:35
[12/30 23:29:30] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4802 s / img. ETA=0:02:11
[12/30 23:29:54] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4802 s / img. ETA=0:01:47
[12/30 23:30:18] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4802 s / img. ETA=0:01:23
[12/30 23:30:42] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4802 s / img. ETA=0:00:59
[12/30 23:31:06] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4801 s / img. ETA=0:00:35
[12/30 23:31:30] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4802 s / img. ETA=0:00:11
[12/30 23:31:41] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/30 23:31:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:17 (0.477097 s / img per device, on 2 devices)
[12/30 23:31:42] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/30 23:31:42] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/30 23:31:42] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/30 23:31:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.522 | 68.625 | 53.213 | 23.405 | 40.028 | 49.329 |
[12/30 23:31:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 50.646 | ASC-US     | 45.237 | HSIL        | 63.713 |
| LSIL       | 60.070 | Candida    | 44.697 | Trichomonas | 20.770 |
[12/30 23:31:46] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/30 23:31:46] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/30 23:31:46] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/30 23:31:46] d2.evaluation.testing INFO: copypaste: 47.5220,68.6246,53.2133,23.4048,40.0278,49.3293
[12/30 23:31:46] d2.utils.events INFO: eta: 5:22:48  iter: 109999  total_loss: 0.498  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0322  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:32:46] d2.utils.events INFO: eta: 5:21:47  iter: 110019  total_loss: 0.501  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:33:46] d2.utils.events INFO: eta: 5:20:46  iter: 110039  total_loss: 0.444  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 23:34:46] d2.utils.events INFO: eta: 5:19:38  iter: 110059  total_loss: 0.383  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:35:45] d2.utils.events INFO: eta: 5:18:25  iter: 110079  total_loss: 0.601  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 23:36:46] d2.utils.events INFO: eta: 5:17:26  iter: 110099  total_loss: 0.649  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 23:37:47] d2.utils.events INFO: eta: 5:16:40  iter: 110119  total_loss: 0.548  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/30 23:38:48] d2.utils.events INFO: eta: 5:15:41  iter: 110139  total_loss: 0.668  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0320  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 23:39:49] d2.utils.events INFO: eta: 5:14:44  iter: 110159  total_loss: 0.723  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:40:49] d2.utils.events INFO: eta: 5:13:43  iter: 110179  total_loss: 0.538  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/30 23:41:51] d2.utils.events INFO: eta: 5:12:43  iter: 110199  total_loss: 0.649  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:42:52] d2.utils.events INFO: eta: 5:11:47  iter: 110219  total_loss: 0.679  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0321  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/30 23:43:52] d2.utils.events INFO: eta: 5:10:46  iter: 110239  total_loss: 0.403  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0321  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:44:52] d2.utils.events INFO: eta: 5:09:46  iter: 110259  total_loss: 0.478  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 23:45:53] d2.utils.events INFO: eta: 5:08:48  iter: 110279  total_loss: 0.633  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0321  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:46:53] d2.utils.events INFO: eta: 5:07:44  iter: 110299  total_loss: 0.734  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:47:53] d2.utils.events INFO: eta: 5:06:43  iter: 110319  total_loss: 0.605  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0319  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:48:52] d2.utils.events INFO: eta: 5:05:37  iter: 110339  total_loss: 0.562  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/30 23:49:52] d2.utils.events INFO: eta: 5:04:36  iter: 110359  total_loss: 0.384  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.098  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0037  lr: 0.000100  max_mem: 9260M
[12/30 23:50:52] d2.utils.events INFO: eta: 5:03:35  iter: 110379  total_loss: 0.507  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:51:52] d2.utils.events INFO: eta: 5:02:34  iter: 110399  total_loss: 0.503  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0317  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/30 23:52:53] d2.utils.events INFO: eta: 5:01:33  iter: 110419  total_loss: 0.625  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:53:53] d2.utils.events INFO: eta: 5:00:32  iter: 110439  total_loss: 0.615  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/30 23:54:53] d2.utils.events INFO: eta: 4:59:31  iter: 110459  total_loss: 0.451  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/30 23:55:55] d2.utils.events INFO: eta: 4:58:31  iter: 110479  total_loss: 0.453  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/30 23:56:57] d2.utils.events INFO: eta: 4:57:29  iter: 110499  total_loss: 0.568  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/30 23:57:57] d2.utils.events INFO: eta: 4:56:29  iter: 110519  total_loss: 0.489  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/30 23:58:58] d2.utils.events INFO: eta: 4:55:29  iter: 110539  total_loss: 0.680  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:00:00] d2.utils.events INFO: eta: 4:54:32  iter: 110559  total_loss: 0.687  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0319  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:01:01] d2.utils.events INFO: eta: 4:53:32  iter: 110579  total_loss: 0.603  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0319  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:02:03] d2.utils.events INFO: eta: 4:52:32  iter: 110599  total_loss: 0.621  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 00:03:03] d2.utils.events INFO: eta: 4:51:31  iter: 110619  total_loss: 0.511  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:04:04] d2.utils.events INFO: eta: 4:50:37  iter: 110639  total_loss: 0.643  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:05:05] d2.utils.events INFO: eta: 4:49:37  iter: 110659  total_loss: 0.483  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.158  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 00:06:06] d2.utils.events INFO: eta: 4:48:36  iter: 110679  total_loss: 0.705  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:07:07] d2.utils.events INFO: eta: 4:47:38  iter: 110699  total_loss: 0.525  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0320  data_time: 0.0058  lr: 0.000100  max_mem: 9260M
[12/31 00:08:08] d2.utils.events INFO: eta: 4:46:37  iter: 110719  total_loss: 0.580  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0320  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:09:08] d2.utils.events INFO: eta: 4:45:36  iter: 110739  total_loss: 0.561  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0320  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:10:06] d2.utils.events INFO: eta: 4:44:34  iter: 110759  total_loss: 0.732  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:11:07] d2.utils.events INFO: eta: 4:43:35  iter: 110779  total_loss: 0.460  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:12:08] d2.utils.events INFO: eta: 4:42:34  iter: 110799  total_loss: 0.565  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:13:08] d2.utils.events INFO: eta: 4:41:32  iter: 110819  total_loss: 0.571  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:14:07] d2.utils.events INFO: eta: 4:40:30  iter: 110839  total_loss: 0.492  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 00:15:07] d2.utils.events INFO: eta: 4:39:26  iter: 110859  total_loss: 0.556  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 00:16:07] d2.utils.events INFO: eta: 4:38:25  iter: 110879  total_loss: 0.481  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:17:09] d2.utils.events INFO: eta: 4:37:25  iter: 110899  total_loss: 0.577  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0317  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 00:18:08] d2.utils.events INFO: eta: 4:36:23  iter: 110919  total_loss: 0.670  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:19:10] d2.utils.events INFO: eta: 4:35:26  iter: 110939  total_loss: 0.384  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.151  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0317  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:20:11] d2.utils.events INFO: eta: 4:34:25  iter: 110959  total_loss: 0.534  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 00:21:12] d2.utils.events INFO: eta: 4:33:23  iter: 110979  total_loss: 0.453  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.134  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:22:14] d2.utils.events INFO: eta: 4:32:24  iter: 110999  total_loss: 0.580  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0318  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:23:14] d2.utils.events INFO: eta: 4:31:23  iter: 111019  total_loss: 0.621  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0318  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:24:14] d2.utils.events INFO: eta: 4:30:22  iter: 111039  total_loss: 0.462  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0318  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:25:14] d2.utils.events INFO: eta: 4:29:22  iter: 111059  total_loss: 0.396  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.079  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.129  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:26:14] d2.utils.events INFO: eta: 4:28:21  iter: 111079  total_loss: 0.523  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0317  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:27:13] d2.utils.events INFO: eta: 4:27:18  iter: 111099  total_loss: 0.524  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 00:28:14] d2.utils.events INFO: eta: 4:26:15  iter: 111119  total_loss: 0.598  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 00:29:15] d2.utils.events INFO: eta: 4:25:14  iter: 111139  total_loss: 0.623  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 00:30:14] d2.utils.events INFO: eta: 4:24:08  iter: 111159  total_loss: 0.474  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:31:14] d2.utils.events INFO: eta: 4:23:09  iter: 111179  total_loss: 0.595  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:32:15] d2.utils.events INFO: eta: 4:22:07  iter: 111199  total_loss: 0.582  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:33:16] d2.utils.events INFO: eta: 4:21:05  iter: 111219  total_loss: 0.638  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:34:18] d2.utils.events INFO: eta: 4:20:04  iter: 111239  total_loss: 0.447  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.099  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0316  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:35:18] d2.utils.events INFO: eta: 4:19:04  iter: 111259  total_loss: 0.711  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:36:21] d2.utils.events INFO: eta: 4:18:02  iter: 111279  total_loss: 0.664  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0317  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:37:21] d2.utils.events INFO: eta: 4:17:03  iter: 111299  total_loss: 0.652  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:38:21] d2.utils.events INFO: eta: 4:16:03  iter: 111319  total_loss: 0.382  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:39:22] d2.utils.events INFO: eta: 4:15:03  iter: 111339  total_loss: 0.729  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0316  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 00:40:23] d2.utils.events INFO: eta: 4:14:03  iter: 111359  total_loss: 0.653  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0316  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:41:21] d2.utils.events INFO: eta: 4:12:59  iter: 111379  total_loss: 0.299  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.018  loss_box_reg_stage1: 0.073  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.124  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:42:21] d2.utils.events INFO: eta: 4:11:59  iter: 111399  total_loss: 0.496  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 00:43:21] d2.utils.events INFO: eta: 4:10:57  iter: 111419  total_loss: 0.669  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:44:22] d2.utils.events INFO: eta: 4:09:56  iter: 111439  total_loss: 0.539  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:45:23] d2.utils.events INFO: eta: 4:08:56  iter: 111459  total_loss: 0.596  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 00:46:24] d2.utils.events INFO: eta: 4:07:57  iter: 111479  total_loss: 0.461  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:47:25] d2.utils.events INFO: eta: 4:06:55  iter: 111499  total_loss: 0.568  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:48:25] d2.utils.events INFO: eta: 4:05:54  iter: 111519  total_loss: 0.697  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 00:49:27] d2.utils.events INFO: eta: 4:04:53  iter: 111539  total_loss: 0.757  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:50:27] d2.utils.events INFO: eta: 4:03:51  iter: 111559  total_loss: 0.462  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.019  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.018  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:51:26] d2.utils.events INFO: eta: 4:02:45  iter: 111579  total_loss: 0.464  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 00:52:26] d2.utils.events INFO: eta: 4:01:39  iter: 111599  total_loss: 0.628  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 00:53:27] d2.utils.events INFO: eta: 4:00:39  iter: 111619  total_loss: 0.560  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 00:54:28] d2.utils.events INFO: eta: 3:59:34  iter: 111639  total_loss: 0.644  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 00:55:28] d2.utils.events INFO: eta: 3:58:36  iter: 111659  total_loss: 0.621  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 00:56:30] d2.utils.events INFO: eta: 3:57:36  iter: 111679  total_loss: 0.596  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 00:57:31] d2.utils.events INFO: eta: 3:56:35  iter: 111699  total_loss: 0.513  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 00:58:33] d2.utils.events INFO: eta: 3:55:34  iter: 111719  total_loss: 0.678  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0315  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 00:59:33] d2.utils.events INFO: eta: 3:54:33  iter: 111739  total_loss: 0.404  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.016  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.015  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:00:33] d2.utils.events INFO: eta: 3:53:35  iter: 111759  total_loss: 0.490  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:01:33] d2.utils.events INFO: eta: 3:52:32  iter: 111779  total_loss: 0.608  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:02:35] d2.utils.events INFO: eta: 3:51:34  iter: 111799  total_loss: 0.664  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:03:35] d2.utils.events INFO: eta: 3:50:33  iter: 111819  total_loss: 0.654  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:04:37] d2.utils.events INFO: eta: 3:49:34  iter: 111839  total_loss: 0.589  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:05:37] d2.utils.events INFO: eta: 3:48:33  iter: 111859  total_loss: 0.509  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.156  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 01:06:37] d2.utils.events INFO: eta: 3:47:28  iter: 111879  total_loss: 0.691  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:07:37] d2.utils.events INFO: eta: 3:46:21  iter: 111899  total_loss: 0.567  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:08:37] d2.utils.events INFO: eta: 3:45:26  iter: 111919  total_loss: 0.523  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:09:37] d2.utils.events INFO: eta: 3:44:19  iter: 111939  total_loss: 0.530  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:10:38] d2.utils.events INFO: eta: 3:43:20  iter: 111959  total_loss: 0.560  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 01:11:38] d2.utils.events INFO: eta: 3:42:19  iter: 111979  total_loss: 0.499  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:12:40] d2.utils.events INFO: eta: 3:41:15  iter: 111999  total_loss: 0.562  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 01:13:40] d2.utils.events INFO: eta: 3:40:14  iter: 112019  total_loss: 0.539  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:14:41] d2.utils.events INFO: eta: 3:39:13  iter: 112039  total_loss: 0.549  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:15:42] d2.utils.events INFO: eta: 3:38:12  iter: 112059  total_loss: 0.562  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:16:43] d2.utils.events INFO: eta: 3:37:12  iter: 112079  total_loss: 0.628  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:17:43] d2.utils.events INFO: eta: 3:36:18  iter: 112099  total_loss: 0.493  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:18:42] d2.utils.events INFO: eta: 3:35:14  iter: 112119  total_loss: 0.442  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.029  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.080  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.138  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 01:19:42] d2.utils.events INFO: eta: 3:34:11  iter: 112139  total_loss: 0.570  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0312  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:20:44] d2.utils.events INFO: eta: 3:33:18  iter: 112159  total_loss: 0.655  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:21:43] d2.utils.events INFO: eta: 3:32:19  iter: 112179  total_loss: 0.604  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0312  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:22:45] d2.utils.events INFO: eta: 3:31:17  iter: 112199  total_loss: 0.644  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0313  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:23:45] d2.utils.events INFO: eta: 3:30:15  iter: 112219  total_loss: 0.457  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.018  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0312  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:24:46] d2.utils.events INFO: eta: 3:29:16  iter: 112239  total_loss: 0.699  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:25:48] d2.utils.events INFO: eta: 3:28:16  iter: 112259  total_loss: 0.444  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.152  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 01:26:50] d2.utils.events INFO: eta: 3:27:15  iter: 112279  total_loss: 0.610  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 01:27:52] d2.utils.events INFO: eta: 3:26:13  iter: 112299  total_loss: 0.379  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.142  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:28:52] d2.utils.events INFO: eta: 3:25:12  iter: 112319  total_loss: 0.564  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:29:52] d2.utils.events INFO: eta: 3:24:12  iter: 112339  total_loss: 0.436  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 01:30:53] d2.utils.events INFO: eta: 3:23:10  iter: 112359  total_loss: 0.711  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:31:53] d2.utils.events INFO: eta: 3:22:13  iter: 112379  total_loss: 0.490  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:32:54] d2.utils.events INFO: eta: 3:21:13  iter: 112399  total_loss: 0.697  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0315  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:33:55] d2.utils.events INFO: eta: 3:20:14  iter: 112419  total_loss: 0.477  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 01:34:56] d2.utils.events INFO: eta: 3:19:15  iter: 112439  total_loss: 0.670  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0315  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 01:35:56] d2.utils.events INFO: eta: 3:18:12  iter: 112459  total_loss: 0.396  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0315  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:36:55] d2.utils.events INFO: eta: 3:17:06  iter: 112479  total_loss: 0.527  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.130  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0314  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 01:37:57] d2.utils.events INFO: eta: 3:16:08  iter: 112499  total_loss: 0.451  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:38:58] d2.utils.events INFO: eta: 3:15:08  iter: 112519  total_loss: 0.528  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:39:58] d2.utils.events INFO: eta: 3:14:07  iter: 112539  total_loss: 0.703  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0314  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:40:58] d2.utils.events INFO: eta: 3:13:05  iter: 112559  total_loss: 0.520  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0314  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:41:58] d2.utils.events INFO: eta: 3:12:04  iter: 112579  total_loss: 0.534  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 01:42:58] d2.utils.events INFO: eta: 3:11:05  iter: 112599  total_loss: 0.580  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:43:58] d2.utils.events INFO: eta: 3:10:05  iter: 112619  total_loss: 0.553  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:44:58] d2.utils.events INFO: eta: 3:09:04  iter: 112639  total_loss: 0.744  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0312  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 01:46:00] d2.utils.events INFO: eta: 3:08:03  iter: 112659  total_loss: 0.636  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0313  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:47:00] d2.utils.events INFO: eta: 3:07:01  iter: 112679  total_loss: 0.583  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0313  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:48:01] d2.utils.events INFO: eta: 3:05:58  iter: 112699  total_loss: 0.453  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0313  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 01:49:00] d2.utils.events INFO: eta: 3:04:56  iter: 112719  total_loss: 0.483  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0312  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 01:50:00] d2.utils.events INFO: eta: 3:03:55  iter: 112739  total_loss: 0.655  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 01:50:59] d2.utils.events INFO: eta: 3:02:53  iter: 112759  total_loss: 0.576  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:51:59] d2.utils.events INFO: eta: 3:01:52  iter: 112779  total_loss: 0.576  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 01:53:00] d2.utils.events INFO: eta: 3:00:48  iter: 112799  total_loss: 0.577  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:54:00] d2.utils.events INFO: eta: 2:59:49  iter: 112819  total_loss: 0.466  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 01:55:01] d2.utils.events INFO: eta: 2:58:48  iter: 112839  total_loss: 0.522  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 01:56:03] d2.utils.events INFO: eta: 2:57:47  iter: 112859  total_loss: 0.665  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 01:57:02] d2.utils.events INFO: eta: 2:56:47  iter: 112879  total_loss: 0.602  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0310  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 01:58:03] d2.utils.events INFO: eta: 2:55:49  iter: 112899  total_loss: 0.529  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 01:59:04] d2.utils.events INFO: eta: 2:54:48  iter: 112919  total_loss: 0.418  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:00:05] d2.utils.events INFO: eta: 2:53:48  iter: 112939  total_loss: 0.490  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0310  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 02:01:06] d2.utils.events INFO: eta: 2:52:49  iter: 112959  total_loss: 0.521  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:02:07] d2.utils.events INFO: eta: 2:51:49  iter: 112979  total_loss: 0.556  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:03:08] d2.utils.events INFO: eta: 2:50:47  iter: 112999  total_loss: 0.743  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:04:08] d2.utils.events INFO: eta: 2:49:45  iter: 113019  total_loss: 0.487  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:05:08] d2.utils.events INFO: eta: 2:48:44  iter: 113039  total_loss: 0.460  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.143  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 02:06:10] d2.utils.events INFO: eta: 2:47:43  iter: 113059  total_loss: 0.427  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.034  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.088  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.124  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:07:10] d2.utils.events INFO: eta: 2:46:42  iter: 113079  total_loss: 0.613  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:08:10] d2.utils.events INFO: eta: 2:45:39  iter: 113099  total_loss: 0.594  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0310  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:09:09] d2.utils.events INFO: eta: 2:44:40  iter: 113119  total_loss: 0.657  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 02:10:09] d2.utils.events INFO: eta: 2:43:40  iter: 113139  total_loss: 0.382  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.019  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.014  loss_box_reg_stage2: 0.159  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:11:10] d2.utils.events INFO: eta: 2:42:37  iter: 113159  total_loss: 0.451  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 02:12:10] d2.utils.events INFO: eta: 2:41:35  iter: 113179  total_loss: 0.492  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:13:10] d2.utils.events INFO: eta: 2:40:34  iter: 113199  total_loss: 0.515  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:14:08] d2.utils.events INFO: eta: 2:39:32  iter: 113219  total_loss: 0.627  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.161  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0307  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:15:10] d2.utils.events INFO: eta: 2:38:31  iter: 113239  total_loss: 0.628  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 02:16:10] d2.utils.events INFO: eta: 2:37:29  iter: 113259  total_loss: 0.618  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:17:09] d2.utils.events INFO: eta: 2:36:24  iter: 113279  total_loss: 0.635  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:18:10] d2.utils.events INFO: eta: 2:35:20  iter: 113299  total_loss: 0.530  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:19:09] d2.utils.events INFO: eta: 2:34:18  iter: 113319  total_loss: 0.608  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:20:10] d2.utils.events INFO: eta: 2:33:17  iter: 113339  total_loss: 0.608  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:21:10] d2.utils.events INFO: eta: 2:32:15  iter: 113359  total_loss: 0.426  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:22:11] d2.utils.events INFO: eta: 2:31:18  iter: 113379  total_loss: 0.616  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:23:10] d2.utils.events INFO: eta: 2:30:12  iter: 113399  total_loss: 0.543  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 02:24:10] d2.utils.events INFO: eta: 2:29:10  iter: 113419  total_loss: 0.516  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:25:09] d2.utils.events INFO: eta: 2:28:09  iter: 113439  total_loss: 0.479  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0304  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 02:26:11] d2.utils.events INFO: eta: 2:27:09  iter: 113459  total_loss: 0.705  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0304  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:27:13] d2.utils.events INFO: eta: 2:26:10  iter: 113479  total_loss: 0.501  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0048  lr: 0.000100  max_mem: 9260M
[12/31 02:28:14] d2.utils.events INFO: eta: 2:25:08  iter: 113499  total_loss: 0.487  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.092  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:29:15] d2.utils.events INFO: eta: 2:24:07  iter: 113519  total_loss: 0.522  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:30:17] d2.utils.events INFO: eta: 2:23:07  iter: 113539  total_loss: 0.588  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:31:19] d2.utils.events INFO: eta: 2:22:09  iter: 113559  total_loss: 0.888  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0034  lr: 0.000100  max_mem: 9260M
[12/31 02:32:18] d2.utils.events INFO: eta: 2:21:09  iter: 113579  total_loss: 0.484  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:33:20] d2.utils.events INFO: eta: 2:20:11  iter: 113599  total_loss: 0.600  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:34:21] d2.utils.events INFO: eta: 2:19:15  iter: 113619  total_loss: 0.587  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:35:21] d2.utils.events INFO: eta: 2:18:15  iter: 113639  total_loss: 0.507  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 02:36:23] d2.utils.events INFO: eta: 2:17:14  iter: 113659  total_loss: 0.621  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:37:21] d2.utils.events INFO: eta: 2:16:12  iter: 113679  total_loss: 0.726  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0306  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:38:21] d2.utils.events INFO: eta: 2:15:07  iter: 113699  total_loss: 0.571  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:39:22] d2.utils.events INFO: eta: 2:14:11  iter: 113719  total_loss: 0.682  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:40:23] d2.utils.events INFO: eta: 2:13:11  iter: 113739  total_loss: 0.794  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:41:22] d2.utils.events INFO: eta: 2:12:10  iter: 113759  total_loss: 0.363  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.083  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:42:23] d2.utils.events INFO: eta: 2:11:10  iter: 113779  total_loss: 0.642  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 02:43:25] d2.utils.events INFO: eta: 2:10:11  iter: 113799  total_loss: 0.593  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:44:26] d2.utils.events INFO: eta: 2:09:10  iter: 113819  total_loss: 0.602  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 02:45:28] d2.utils.events INFO: eta: 2:08:12  iter: 113839  total_loss: 0.829  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:46:29] d2.utils.events INFO: eta: 2:07:11  iter: 113859  total_loss: 0.654  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:47:30] d2.utils.events INFO: eta: 2:06:10  iter: 113879  total_loss: 0.679  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 02:48:30] d2.utils.events INFO: eta: 2:05:08  iter: 113899  total_loss: 0.412  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.102  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:49:30] d2.utils.events INFO: eta: 2:04:08  iter: 113919  total_loss: 0.803  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:50:31] d2.utils.events INFO: eta: 2:03:06  iter: 113939  total_loss: 0.591  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 02:51:31] d2.utils.events INFO: eta: 2:02:03  iter: 113959  total_loss: 0.685  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 02:52:30] d2.utils.events INFO: eta: 2:01:00  iter: 113979  total_loss: 0.399  loss_cls_stage0: 0.019  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.018  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:53:30] d2.utils.events INFO: eta: 1:59:59  iter: 113999  total_loss: 0.678  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:54:31] d2.utils.events INFO: eta: 1:59:01  iter: 114019  total_loss: 0.482  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.094  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.160  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 02:55:33] d2.utils.events INFO: eta: 1:58:03  iter: 114039  total_loss: 0.685  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 02:56:34] d2.utils.events INFO: eta: 1:57:02  iter: 114059  total_loss: 0.644  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 02:57:33] d2.utils.events INFO: eta: 1:56:00  iter: 114079  total_loss: 0.408  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.097  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.132  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 02:58:33] d2.utils.events INFO: eta: 1:55:00  iter: 114099  total_loss: 0.420  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.118  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 02:59:33] d2.utils.events INFO: eta: 1:53:59  iter: 114119  total_loss: 0.587  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 03:00:34] d2.utils.events INFO: eta: 1:52:59  iter: 114139  total_loss: 0.525  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:01:35] d2.utils.events INFO: eta: 1:51:58  iter: 114159  total_loss: 0.452  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.140  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:02:35] d2.utils.events INFO: eta: 1:50:58  iter: 114179  total_loss: 0.479  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 03:03:36] d2.utils.events INFO: eta: 1:49:58  iter: 114199  total_loss: 0.393  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:04:38] d2.utils.events INFO: eta: 1:49:00  iter: 114219  total_loss: 0.623  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:05:38] d2.utils.events INFO: eta: 1:47:59  iter: 114239  total_loss: 0.660  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:06:39] d2.utils.events INFO: eta: 1:46:58  iter: 114259  total_loss: 0.622  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:07:39] d2.utils.events INFO: eta: 1:45:57  iter: 114279  total_loss: 0.467  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.146  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:08:40] d2.utils.events INFO: eta: 1:44:57  iter: 114299  total_loss: 0.538  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 03:09:40] d2.utils.events INFO: eta: 1:43:56  iter: 114319  total_loss: 0.592  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:10:41] d2.utils.events INFO: eta: 1:42:55  iter: 114339  total_loss: 0.460  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:11:41] d2.utils.events INFO: eta: 1:41:54  iter: 114359  total_loss: 0.513  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 03:12:42] d2.utils.events INFO: eta: 1:40:54  iter: 114379  total_loss: 0.452  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.038  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.105  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.166  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 03:13:43] d2.utils.events INFO: eta: 1:39:54  iter: 114399  total_loss: 0.592  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:14:42] d2.utils.events INFO: eta: 1:38:53  iter: 114419  total_loss: 0.690  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:15:45] d2.utils.events INFO: eta: 1:37:53  iter: 114439  total_loss: 0.583  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:16:44] d2.utils.events INFO: eta: 1:36:52  iter: 114459  total_loss: 0.430  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0305  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:17:44] d2.utils.events INFO: eta: 1:35:51  iter: 114479  total_loss: 0.656  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0305  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 03:18:45] d2.utils.events INFO: eta: 1:34:49  iter: 114499  total_loss: 0.756  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0305  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 03:19:46] d2.utils.events INFO: eta: 1:33:49  iter: 114519  total_loss: 0.630  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0305  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:20:47] d2.utils.events INFO: eta: 1:32:48  iter: 114539  total_loss: 0.473  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.031  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.089  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.150  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0305  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 03:21:48] d2.utils.events INFO: eta: 1:31:47  iter: 114559  total_loss: 0.480  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 03:22:51] d2.utils.events INFO: eta: 1:30:47  iter: 114579  total_loss: 0.699  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:23:53] d2.utils.events INFO: eta: 1:29:46  iter: 114599  total_loss: 0.547  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.148  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 03:24:52] d2.utils.events INFO: eta: 1:28:44  iter: 114619  total_loss: 0.663  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:25:52] d2.utils.events INFO: eta: 1:27:43  iter: 114639  total_loss: 0.482  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 03:26:53] d2.utils.events INFO: eta: 1:26:42  iter: 114659  total_loss: 0.436  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.154  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 03:27:54] d2.utils.events INFO: eta: 1:25:42  iter: 114679  total_loss: 0.655  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/31 03:28:56] d2.utils.events INFO: eta: 1:24:41  iter: 114699  total_loss: 0.512  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:29:56] d2.utils.events INFO: eta: 1:23:40  iter: 114719  total_loss: 0.701  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:30:58] d2.utils.events INFO: eta: 1:22:39  iter: 114739  total_loss: 0.713  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0307  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 03:31:58] d2.utils.events INFO: eta: 1:21:39  iter: 114759  total_loss: 0.599  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:32:58] d2.utils.events INFO: eta: 1:20:37  iter: 114779  total_loss: 0.551  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:33:58] d2.utils.events INFO: eta: 1:19:36  iter: 114799  total_loss: 0.529  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 03:34:59] d2.utils.events INFO: eta: 1:18:35  iter: 114819  total_loss: 0.498  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:35:58] d2.utils.events INFO: eta: 1:17:33  iter: 114839  total_loss: 0.634  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0306  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 03:36:59] d2.utils.events INFO: eta: 1:16:32  iter: 114859  total_loss: 0.632  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 03:37:59] d2.utils.events INFO: eta: 1:15:31  iter: 114879  total_loss: 0.583  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0306  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 03:39:01] d2.utils.events INFO: eta: 1:14:31  iter: 114899  total_loss: 0.528  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0019  lr: 0.000100  max_mem: 9260M
[12/31 03:40:03] d2.utils.events INFO: eta: 1:13:31  iter: 114919  total_loss: 0.615  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 03:41:03] d2.utils.events INFO: eta: 1:12:30  iter: 114939  total_loss: 0.548  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 03:42:03] d2.utils.events INFO: eta: 1:11:29  iter: 114959  total_loss: 0.672  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0306  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:43:05] d2.utils.events INFO: eta: 1:10:28  iter: 114979  total_loss: 0.660  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 03:44:06] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0114999.pth
[12/31 03:44:11] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/31 03:44:11] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/31 03:45:17] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4794 s / img. ETA=0:08:58
[12/31 03:45:41] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4798 s / img. ETA=0:08:35
[12/31 03:46:05] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4800 s / img. ETA=0:08:11
[12/31 03:46:29] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4798 s / img. ETA=0:07:47
[12/31 03:46:53] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4800 s / img. ETA=0:07:23
[12/31 03:47:17] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4799 s / img. ETA=0:06:59
[12/31 03:47:41] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4800 s / img. ETA=0:06:35
[12/31 03:48:05] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4800 s / img. ETA=0:06:11
[12/31 03:48:29] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4800 s / img. ETA=0:05:47
[12/31 03:48:53] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4801 s / img. ETA=0:05:23
[12/31 03:49:17] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4802 s / img. ETA=0:04:59
[12/31 03:49:41] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4802 s / img. ETA=0:04:35
[12/31 03:50:05] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4803 s / img. ETA=0:04:11
[12/31 03:50:29] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4803 s / img. ETA=0:03:47
[12/31 03:50:53] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4803 s / img. ETA=0:03:23
[12/31 03:51:17] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4803 s / img. ETA=0:02:59
[12/31 03:51:41] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4803 s / img. ETA=0:02:35
[12/31 03:52:05] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4802 s / img. ETA=0:02:11
[12/31 03:52:29] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4802 s / img. ETA=0:01:47
[12/31 03:52:53] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4802 s / img. ETA=0:01:23
[12/31 03:53:17] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4803 s / img. ETA=0:00:59
[12/31 03:53:41] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4803 s / img. ETA=0:00:35
[12/31 03:54:05] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4803 s / img. ETA=0:00:11
[12/31 03:54:17] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/31 03:54:17] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:17 (0.477251 s / img per device, on 2 devices)
[12/31 03:54:17] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/31 03:54:17] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/31 03:54:17] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/31 03:54:21] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.842 | 67.894 | 52.527 | 23.149 | 39.666 | 48.197 |
[12/31 03:54:21] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 49.366 | ASC-US     | 43.659 | HSIL        | 64.374 |
| LSIL       | 59.294 | Candida    | 44.154 | Trichomonas | 20.203 |
[12/31 03:54:21] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/31 03:54:21] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/31 03:54:21] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/31 03:54:21] d2.evaluation.testing INFO: copypaste: 46.8415,67.8938,52.5273,23.1486,39.6657,48.1968
[12/31 03:54:21] d2.utils.events INFO: eta: 1:09:28  iter: 114999  total_loss: 0.542  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0307  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 03:55:22] d2.utils.events INFO: eta: 1:08:27  iter: 115019  total_loss: 0.441  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.100  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 03:56:25] d2.utils.events INFO: eta: 1:07:26  iter: 115039  total_loss: 0.555  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 03:57:25] d2.utils.events INFO: eta: 1:06:25  iter: 115059  total_loss: 0.624  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 03:58:27] d2.utils.events INFO: eta: 1:05:25  iter: 115079  total_loss: 0.643  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 03:59:27] d2.utils.events INFO: eta: 1:04:23  iter: 115099  total_loss: 0.620  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:00:27] d2.utils.events INFO: eta: 1:03:22  iter: 115119  total_loss: 0.518  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0308  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:01:27] d2.utils.events INFO: eta: 1:02:21  iter: 115139  total_loss: 0.695  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 04:02:29] d2.utils.events INFO: eta: 1:01:20  iter: 115159  total_loss: 0.513  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0308  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/31 04:03:29] d2.utils.events INFO: eta: 1:00:19  iter: 115179  total_loss: 0.530  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0308  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:04:30] d2.utils.events INFO: eta: 0:59:18  iter: 115199  total_loss: 0.760  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0308  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:05:29] d2.utils.events INFO: eta: 0:58:17  iter: 115219  total_loss: 0.490  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.039  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.107  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.167  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 04:06:31] d2.utils.events INFO: eta: 0:57:16  iter: 115239  total_loss: 0.611  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 04:07:33] d2.utils.events INFO: eta: 0:56:16  iter: 115259  total_loss: 0.560  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:08:33] d2.utils.events INFO: eta: 0:55:15  iter: 115279  total_loss: 0.442  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.002  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:09:33] d2.utils.events INFO: eta: 0:54:14  iter: 115299  total_loss: 0.567  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/31 04:10:35] d2.utils.events INFO: eta: 0:53:12  iter: 115319  total_loss: 0.636  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 04:11:34] d2.utils.events INFO: eta: 0:52:11  iter: 115339  total_loss: 0.370  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.030  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.121  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 3.0308  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 04:12:35] d2.utils.events INFO: eta: 0:51:11  iter: 115359  total_loss: 0.538  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 04:13:34] d2.utils.events INFO: eta: 0:50:10  iter: 115379  total_loss: 0.543  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0308  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 04:14:34] d2.utils.events INFO: eta: 0:49:09  iter: 115399  total_loss: 0.530  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:15:35] d2.utils.events INFO: eta: 0:48:08  iter: 115419  total_loss: 0.591  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:16:36] d2.utils.events INFO: eta: 0:47:07  iter: 115439  total_loss: 0.727  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:17:36] d2.utils.events INFO: eta: 0:46:07  iter: 115459  total_loss: 0.527  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 04:18:36] d2.utils.events INFO: eta: 0:45:06  iter: 115479  total_loss: 0.621  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 04:19:37] d2.utils.events INFO: eta: 0:44:05  iter: 115499  total_loss: 0.557  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 04:20:38] d2.utils.events INFO: eta: 0:43:04  iter: 115519  total_loss: 0.534  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:21:39] d2.utils.events INFO: eta: 0:42:03  iter: 115539  total_loss: 0.583  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0307  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:22:40] d2.utils.events INFO: eta: 0:41:02  iter: 115559  total_loss: 0.582  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0307  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:23:42] d2.utils.events INFO: eta: 0:40:01  iter: 115579  total_loss: 0.509  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0308  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 04:24:44] d2.utils.events INFO: eta: 0:39:00  iter: 115599  total_loss: 0.607  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0032  lr: 0.000100  max_mem: 9260M
[12/31 04:25:43] d2.utils.events INFO: eta: 0:37:59  iter: 115619  total_loss: 0.555  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0308  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:26:46] d2.utils.events INFO: eta: 0:36:59  iter: 115639  total_loss: 0.646  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:27:48] d2.utils.events INFO: eta: 0:35:58  iter: 115659  total_loss: 0.560  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0034  lr: 0.000100  max_mem: 9260M
[12/31 04:28:49] d2.utils.events INFO: eta: 0:34:57  iter: 115679  total_loss: 0.690  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:29:48] d2.utils.events INFO: eta: 0:33:56  iter: 115699  total_loss: 0.478  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:30:48] d2.utils.events INFO: eta: 0:32:55  iter: 115719  total_loss: 0.334  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.035  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.076  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.149  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:31:49] d2.utils.events INFO: eta: 0:31:55  iter: 115739  total_loss: 0.614  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:32:49] d2.utils.events INFO: eta: 0:30:54  iter: 115759  total_loss: 0.746  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:33:50] d2.utils.events INFO: eta: 0:29:53  iter: 115779  total_loss: 0.745  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:34:51] d2.utils.events INFO: eta: 0:28:52  iter: 115799  total_loss: 0.719  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 04:35:52] d2.utils.events INFO: eta: 0:27:51  iter: 115819  total_loss: 0.493  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0309  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:36:53] d2.utils.events INFO: eta: 0:26:50  iter: 115839  total_loss: 0.482  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0023  lr: 0.000100  max_mem: 9260M
[12/31 04:37:56] d2.utils.events INFO: eta: 0:25:50  iter: 115859  total_loss: 0.531  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 04:38:56] d2.utils.events INFO: eta: 0:24:49  iter: 115879  total_loss: 0.561  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0026  lr: 0.000100  max_mem: 9260M
[12/31 04:39:57] d2.utils.events INFO: eta: 0:23:48  iter: 115899  total_loss: 0.677  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0310  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 04:40:57] d2.utils.events INFO: eta: 0:22:47  iter: 115919  total_loss: 0.606  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0310  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:41:59] d2.utils.events INFO: eta: 0:21:46  iter: 115939  total_loss: 0.325  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.032  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.087  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.120  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 3.0311  data_time: 0.0030  lr: 0.000100  max_mem: 9260M
[12/31 04:43:01] d2.utils.events INFO: eta: 0:20:45  iter: 115959  total_loss: 0.645  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:44:00] d2.utils.events INFO: eta: 0:19:44  iter: 115979  total_loss: 0.510  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:45:01] d2.utils.events INFO: eta: 0:18:43  iter: 115999  total_loss: 0.516  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 04:46:01] d2.utils.events INFO: eta: 0:17:42  iter: 116019  total_loss: 0.487  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.095  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.145  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0031  lr: 0.000100  max_mem: 9260M
[12/31 04:47:02] d2.utils.events INFO: eta: 0:16:41  iter: 116039  total_loss: 0.524  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0027  lr: 0.000100  max_mem: 9260M
[12/31 04:48:03] d2.utils.events INFO: eta: 0:15:40  iter: 116059  total_loss: 0.549  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.168  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:49:03] d2.utils.events INFO: eta: 0:14:39  iter: 116079  total_loss: 0.680  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:50:03] d2.utils.events INFO: eta: 0:13:38  iter: 116099  total_loss: 0.675  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 04:51:04] d2.utils.events INFO: eta: 0:12:38  iter: 116119  total_loss: 0.654  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:52:03] d2.utils.events INFO: eta: 0:11:37  iter: 116139  total_loss: 0.477  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 04:53:04] d2.utils.events INFO: eta: 0:10:36  iter: 116159  total_loss: 0.510  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:54:04] d2.utils.events INFO: eta: 0:09:35  iter: 116179  total_loss: 0.523  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:55:05] d2.utils.events INFO: eta: 0:08:34  iter: 116199  total_loss: 0.449  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.037  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0309  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:56:08] d2.utils.events INFO: eta: 0:07:33  iter: 116219  total_loss: 0.887  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 04:57:09] d2.utils.events INFO: eta: 0:06:32  iter: 116239  total_loss: 0.433  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.164  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 04:58:10] d2.utils.events INFO: eta: 0:05:31  iter: 116259  total_loss: 0.531  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0311  data_time: 0.0021  lr: 0.000100  max_mem: 9260M
[12/31 04:59:10] d2.utils.events INFO: eta: 0:04:30  iter: 116279  total_loss: 0.727  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0310  data_time: 0.0022  lr: 0.000100  max_mem: 9260M
[12/31 05:00:10] d2.utils.events INFO: eta: 0:03:30  iter: 116299  total_loss: 0.582  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0028  lr: 0.000100  max_mem: 9260M
[12/31 05:01:11] d2.utils.events INFO: eta: 0:02:29  iter: 116319  total_loss: 0.611  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0025  lr: 0.000100  max_mem: 9260M
[12/31 05:02:12] d2.utils.events INFO: eta: 0:01:28  iter: 116339  total_loss: 0.711  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0310  data_time: 0.0029  lr: 0.000100  max_mem: 9260M
[12/31 05:03:12] d2.utils.events INFO: eta: 0:00:27  iter: 116359  total_loss: 0.479  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0311  data_time: 0.0024  lr: 0.000100  max_mem: 9260M
[12/31 05:03:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_final.pth
[12/31 05:03:43] d2.data.datasets.coco INFO: Loaded 2348 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_light.json
[12/31 05:03:43] d2.evaluation.evaluator INFO: Start inference on 1174 images
[12/31 05:04:49] d2.evaluation.evaluator INFO: Inference done 50/1174. 0.4794 s / img. ETA=0:08:58
[12/31 05:05:13] d2.evaluation.evaluator INFO: Inference done 100/1174. 0.4797 s / img. ETA=0:08:35
[12/31 05:05:37] d2.evaluation.evaluator INFO: Inference done 150/1174. 0.4800 s / img. ETA=0:08:11
[12/31 05:06:01] d2.evaluation.evaluator INFO: Inference done 200/1174. 0.4798 s / img. ETA=0:07:47
[12/31 05:06:25] d2.evaluation.evaluator INFO: Inference done 250/1174. 0.4799 s / img. ETA=0:07:23
[12/31 05:06:49] d2.evaluation.evaluator INFO: Inference done 300/1174. 0.4798 s / img. ETA=0:06:59
[12/31 05:07:13] d2.evaluation.evaluator INFO: Inference done 350/1174. 0.4798 s / img. ETA=0:06:35
[12/31 05:07:37] d2.evaluation.evaluator INFO: Inference done 400/1174. 0.4798 s / img. ETA=0:06:11
[12/31 05:08:01] d2.evaluation.evaluator INFO: Inference done 450/1174. 0.4799 s / img. ETA=0:05:47
[12/31 05:08:25] d2.evaluation.evaluator INFO: Inference done 500/1174. 0.4800 s / img. ETA=0:05:23
[12/31 05:08:49] d2.evaluation.evaluator INFO: Inference done 550/1174. 0.4800 s / img. ETA=0:04:59
[12/31 05:09:13] d2.evaluation.evaluator INFO: Inference done 600/1174. 0.4801 s / img. ETA=0:04:35
[12/31 05:09:37] d2.evaluation.evaluator INFO: Inference done 650/1174. 0.4801 s / img. ETA=0:04:11
[12/31 05:10:01] d2.evaluation.evaluator INFO: Inference done 700/1174. 0.4801 s / img. ETA=0:03:47
[12/31 05:10:25] d2.evaluation.evaluator INFO: Inference done 750/1174. 0.4800 s / img. ETA=0:03:23
[12/31 05:10:49] d2.evaluation.evaluator INFO: Inference done 800/1174. 0.4800 s / img. ETA=0:02:59
[12/31 05:11:13] d2.evaluation.evaluator INFO: Inference done 850/1174. 0.4800 s / img. ETA=0:02:35
[12/31 05:11:37] d2.evaluation.evaluator INFO: Inference done 900/1174. 0.4801 s / img. ETA=0:02:11
[12/31 05:12:01] d2.evaluation.evaluator INFO: Inference done 950/1174. 0.4800 s / img. ETA=0:01:47
[12/31 05:12:25] d2.evaluation.evaluator INFO: Inference done 1000/1174. 0.4800 s / img. ETA=0:01:23
[12/31 05:12:49] d2.evaluation.evaluator INFO: Inference done 1050/1174. 0.4800 s / img. ETA=0:00:59
[12/31 05:13:13] d2.evaluation.evaluator INFO: Inference done 1100/1174. 0.4802 s / img. ETA=0:00:35
[12/31 05:13:37] d2.evaluation.evaluator INFO: Inference done 1150/1174. 0.4801 s / img. ETA=0:00:11
[12/31 05:13:49] d2.evaluation.evaluator INFO: Total inference time: 0:09:21 (0.479897 s / img per device, on 2 devices)
[12/31 05:13:49] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:17 (0.477158 s / img per device, on 2 devices)
[12/31 05:13:49] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/31 05:13:49] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_light.json
[12/31 05:13:49] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/31 05:13:53] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 46.718 | 67.966 | 51.890 | 22.876 | 39.310 | 48.305 |
[12/31 05:13:53] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 50.603 | ASC-US     | 44.659 | HSIL        | 61.753 |
| LSIL       | 58.641 | Candida    | 43.807 | Trichomonas | 20.844 |
[12/31 05:13:53] d2.engine.defaults INFO: Evaluation results for my_dataset_val_light in csv format:
[12/31 05:13:53] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/31 05:13:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/31 05:13:53] d2.evaluation.testing INFO: copypaste: 46.7180,67.9660,51.8899,22.8759,39.3099,48.3046
[12/31 05:13:53] d2.utils.events INFO: eta: 0:00:03  iter: 116367  total_loss: 0.559  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0311  data_time: 0.0020  lr: 0.000100  max_mem: 9260M
[12/31 05:13:53] d2.engine.hooks INFO: Overall training speed: 21365 iterations in 17:59:24 (3.0313 s / it)
[12/31 05:13:53] d2.engine.hooks INFO: Total training time: 18:51:19 (0:51:54 on hooks)
[12/31 05:36:03] detectron2 INFO: Rank of current process: 0. World size: 2
[12/31 05:36:07] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/31 05:36:07] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/31 05:36:07] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 116368  ## 46368 74368(70000) 96368(8500) 
  BASE_LR: 0.01     ### 
  STEPS: (116068, 116268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/31 05:36:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 116368
  MOMENTUM: 0.9
  STEPS: (116068, 116268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/31 05:36:08] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/31 05:36:08] d2.utils.env INFO: Using a generated random seed 8070748
[12/31 05:36:11] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/31 05:36:11] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_final.pth
[12/31 05:36:41] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/31 05:36:41] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/31 05:36:42] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/31 05:36:42] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/31 05:37:35] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4828 s / img. ETA=2:15:11
[12/31 05:38:00] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4825 s / img. ETA=2:14:42
[12/31 05:38:24] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4821 s / img. ETA=2:14:10
[12/31 05:38:48] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4820 s / img. ETA=2:13:45
[12/31 05:39:12] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4817 s / img. ETA=2:13:15
[12/31 05:39:36] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4814 s / img. ETA=2:12:47
[12/31 05:40:00] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4815 s / img. ETA=2:12:25
[12/31 05:40:24] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4817 s / img. ETA=2:12:04
[12/31 05:40:48] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4819 s / img. ETA=2:11:42
[12/31 05:41:12] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4820 s / img. ETA=2:11:19
[12/31 05:41:36] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4820 s / img. ETA=2:10:57
[12/31 05:42:01] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4821 s / img. ETA=2:10:33
[12/31 05:42:25] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4820 s / img. ETA=2:10:09
[12/31 05:42:49] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4820 s / img. ETA=2:09:45
[12/31 05:43:13] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4821 s / img. ETA=2:09:21
[12/31 05:43:37] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4820 s / img. ETA=2:08:56
[12/31 05:44:01] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4820 s / img. ETA=2:08:31
[12/31 05:44:25] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4819 s / img. ETA=2:08:06
[12/31 05:44:49] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4819 s / img. ETA=2:07:41
[12/31 05:45:13] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4818 s / img. ETA=2:07:16
[12/31 05:45:37] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4818 s / img. ETA=2:06:51
[12/31 05:46:01] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4819 s / img. ETA=2:06:29
[12/31 05:46:25] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4818 s / img. ETA=2:06:05
[12/31 05:46:50] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4818 s / img. ETA=2:05:40
[12/31 05:47:14] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4818 s / img. ETA=2:05:16
[12/31 05:47:38] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4819 s / img. ETA=2:04:52
[12/31 05:48:02] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4819 s / img. ETA=2:04:29
[12/31 05:48:26] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4819 s / img. ETA=2:04:05
[12/31 05:48:50] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4819 s / img. ETA=2:03:41
[12/31 05:49:14] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4819 s / img. ETA=2:03:17
[12/31 05:49:38] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4819 s / img. ETA=2:02:52
[12/31 05:50:02] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4819 s / img. ETA=2:02:28
[12/31 05:50:26] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4819 s / img. ETA=2:02:04
[12/31 05:50:50] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4819 s / img. ETA=2:01:40
[12/31 05:51:15] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4819 s / img. ETA=2:01:16
[12/31 05:51:39] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4818 s / img. ETA=2:00:51
[12/31 05:52:03] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4818 s / img. ETA=2:00:27
[12/31 05:52:27] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4818 s / img. ETA=2:00:03
[12/31 05:52:51] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4819 s / img. ETA=1:59:39
[12/31 05:53:15] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4819 s / img. ETA=1:59:15
[12/31 05:53:39] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4818 s / img. ETA=1:58:50
[12/31 05:54:03] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4818 s / img. ETA=1:58:26
[12/31 05:54:27] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4818 s / img. ETA=1:58:02
[12/31 05:54:51] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4818 s / img. ETA=1:57:38
[12/31 05:55:15] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4818 s / img. ETA=1:57:14
[12/31 05:55:41] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4826 s / img. ETA=1:57:01
[12/31 05:56:05] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4826 s / img. ETA=1:56:37
[12/31 05:56:29] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4826 s / img. ETA=1:56:12
[12/31 05:56:54] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4826 s / img. ETA=1:55:49
[12/31 05:57:18] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4826 s / img. ETA=1:55:24
[12/31 05:57:42] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4826 s / img. ETA=1:55:00
[12/31 05:58:06] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4826 s / img. ETA=1:54:36
[12/31 05:58:30] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4825 s / img. ETA=1:54:12
[12/31 05:58:54] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4825 s / img. ETA=1:53:47
[12/31 05:59:18] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4825 s / img. ETA=1:53:23
[12/31 05:59:42] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4825 s / img. ETA=1:52:59
[12/31 06:00:06] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4825 s / img. ETA=1:52:34
[12/31 06:00:30] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4825 s / img. ETA=1:52:10
[12/31 06:00:55] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4825 s / img. ETA=1:51:46
[12/31 06:01:19] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4824 s / img. ETA=1:51:21
[12/31 06:01:43] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4824 s / img. ETA=1:50:57
[12/31 06:02:07] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4824 s / img. ETA=1:50:33
[12/31 06:02:31] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4824 s / img. ETA=1:50:08
[12/31 06:02:55] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4824 s / img. ETA=1:49:45
[12/31 06:03:19] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4825 s / img. ETA=1:49:21
[12/31 06:03:43] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4825 s / img. ETA=1:48:57
[12/31 06:04:08] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4825 s / img. ETA=1:48:33
[12/31 06:04:32] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4824 s / img. ETA=1:48:08
[12/31 06:04:56] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4825 s / img. ETA=1:47:45
[12/31 06:05:20] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4825 s / img. ETA=1:47:21
[12/31 06:05:44] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4825 s / img. ETA=1:46:57
[12/31 06:06:08] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4825 s / img. ETA=1:46:32
[12/31 06:06:32] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4825 s / img. ETA=1:46:08
[12/31 06:06:56] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4824 s / img. ETA=1:45:43
[12/31 06:07:20] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4824 s / img. ETA=1:45:19
[12/31 06:07:44] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4824 s / img. ETA=1:44:54
[12/31 06:08:08] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4824 s / img. ETA=1:44:30
[12/31 06:08:33] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4824 s / img. ETA=1:44:06
[12/31 06:08:57] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4824 s / img. ETA=1:43:42
[12/31 06:09:21] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4824 s / img. ETA=1:43:18
[12/31 06:09:45] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4824 s / img. ETA=1:42:54
[12/31 06:10:09] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4824 s / img. ETA=1:42:30
[12/31 06:10:33] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4824 s / img. ETA=1:42:06
[12/31 06:10:57] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4823 s / img. ETA=1:41:41
[12/31 06:11:21] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4823 s / img. ETA=1:41:17
[12/31 06:11:45] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4823 s / img. ETA=1:40:52
[12/31 06:12:09] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4822 s / img. ETA=1:40:28
[12/31 06:12:33] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4822 s / img. ETA=1:40:03
[12/31 06:12:57] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4822 s / img. ETA=1:39:39
[12/31 06:13:21] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4822 s / img. ETA=1:39:15
[12/31 06:13:45] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4822 s / img. ETA=1:38:50
[12/31 06:14:09] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4822 s / img. ETA=1:38:26
[12/31 06:14:34] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4822 s / img. ETA=1:38:02
[12/31 06:14:58] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4822 s / img. ETA=1:37:38
[12/31 06:15:22] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4822 s / img. ETA=1:37:14
[12/31 06:15:46] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4821 s / img. ETA=1:36:49
[12/31 06:16:10] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4821 s / img. ETA=1:36:25
[12/31 06:16:34] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4821 s / img. ETA=1:36:01
[12/31 06:16:58] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4821 s / img. ETA=1:35:37
[12/31 06:17:22] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4821 s / img. ETA=1:35:13
[12/31 06:17:46] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4821 s / img. ETA=1:34:48
[12/31 06:18:10] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4821 s / img. ETA=1:34:24
[12/31 06:18:34] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4821 s / img. ETA=1:34:00
[12/31 06:18:58] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4821 s / img. ETA=1:33:36
[12/31 06:19:22] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4821 s / img. ETA=1:33:11
[12/31 06:19:46] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4820 s / img. ETA=1:32:47
[12/31 06:20:10] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4820 s / img. ETA=1:32:23
[12/31 06:20:34] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4820 s / img. ETA=1:31:58
[12/31 06:20:58] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4820 s / img. ETA=1:31:34
[12/31 06:21:22] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4820 s / img. ETA=1:31:10
[12/31 06:21:46] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4820 s / img. ETA=1:30:46
[12/31 06:22:10] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4820 s / img. ETA=1:30:21
[12/31 06:22:34] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4820 s / img. ETA=1:29:57
[12/31 06:22:58] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4820 s / img. ETA=1:29:33
[12/31 06:23:22] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4819 s / img. ETA=1:29:09
[12/31 06:23:46] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4819 s / img. ETA=1:28:45
[12/31 06:24:11] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4819 s / img. ETA=1:28:21
[12/31 06:24:35] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4819 s / img. ETA=1:27:57
[12/31 06:24:59] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4819 s / img. ETA=1:27:32
[12/31 06:25:23] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4819 s / img. ETA=1:27:08
[12/31 06:25:47] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4819 s / img. ETA=1:26:44
[12/31 06:26:11] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4819 s / img. ETA=1:26:20
[12/31 06:26:35] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4819 s / img. ETA=1:25:55
[12/31 06:26:59] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4818 s / img. ETA=1:25:31
[12/31 06:27:23] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4818 s / img. ETA=1:25:07
[12/31 06:27:47] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4818 s / img. ETA=1:24:43
[12/31 06:28:11] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4818 s / img. ETA=1:24:19
[12/31 06:28:35] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4818 s / img. ETA=1:23:54
[12/31 06:28:59] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4818 s / img. ETA=1:23:30
[12/31 06:29:23] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4818 s / img. ETA=1:23:06
[12/31 06:29:47] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4818 s / img. ETA=1:22:42
[12/31 06:30:11] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4818 s / img. ETA=1:22:18
[12/31 06:30:35] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4818 s / img. ETA=1:21:54
[12/31 06:30:59] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4818 s / img. ETA=1:21:30
[12/31 06:31:23] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4818 s / img. ETA=1:21:06
[12/31 06:31:48] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4818 s / img. ETA=1:20:42
[12/31 06:32:12] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4818 s / img. ETA=1:20:18
[12/31 06:32:36] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4818 s / img. ETA=1:19:53
[12/31 06:33:00] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4818 s / img. ETA=1:19:29
[12/31 06:33:24] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4818 s / img. ETA=1:19:05
[12/31 06:33:48] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4818 s / img. ETA=1:18:41
[12/31 06:34:12] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4818 s / img. ETA=1:18:17
[12/31 06:34:36] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4818 s / img. ETA=1:17:53
[12/31 06:35:00] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4818 s / img. ETA=1:17:29
[12/31 06:35:24] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4818 s / img. ETA=1:17:04
[12/31 06:35:48] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4818 s / img. ETA=1:16:40
[12/31 06:36:12] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4818 s / img. ETA=1:16:16
[12/31 06:36:36] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4818 s / img. ETA=1:15:52
[12/31 06:37:00] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4818 s / img. ETA=1:15:28
[12/31 06:37:25] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4818 s / img. ETA=1:15:04
[12/31 06:37:49] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4818 s / img. ETA=1:14:40
[12/31 06:38:13] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4818 s / img. ETA=1:14:16
[12/31 06:38:37] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4818 s / img. ETA=1:13:52
[12/31 06:39:01] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4818 s / img. ETA=1:13:28
[12/31 06:39:25] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4818 s / img. ETA=1:13:03
[12/31 06:39:49] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4817 s / img. ETA=1:12:39
[12/31 06:40:13] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4817 s / img. ETA=1:12:15
[12/31 06:40:37] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4817 s / img. ETA=1:11:51
[12/31 06:41:01] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4817 s / img. ETA=1:11:27
[12/31 06:41:25] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4817 s / img. ETA=1:11:03
[12/31 06:41:49] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4817 s / img. ETA=1:10:39
[12/31 06:42:13] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4817 s / img. ETA=1:10:15
[12/31 06:42:37] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4817 s / img. ETA=1:09:50
[12/31 06:43:01] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4817 s / img. ETA=1:09:26
[12/31 06:43:25] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4817 s / img. ETA=1:09:02
[12/31 06:43:49] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4817 s / img. ETA=1:08:38
[12/31 06:44:13] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4817 s / img. ETA=1:08:14
[12/31 06:44:37] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4817 s / img. ETA=1:07:50
[12/31 06:45:01] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4817 s / img. ETA=1:07:25
[12/31 06:45:25] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4817 s / img. ETA=1:07:01
[12/31 06:45:49] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4816 s / img. ETA=1:06:37
[12/31 06:46:14] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4817 s / img. ETA=1:06:13
[12/31 06:46:38] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4817 s / img. ETA=1:05:49
[12/31 06:47:02] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4817 s / img. ETA=1:05:25
[12/31 06:47:26] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4817 s / img. ETA=1:05:01
[12/31 06:47:50] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4817 s / img. ETA=1:04:37
[12/31 06:48:14] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4817 s / img. ETA=1:04:13
[12/31 06:48:38] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4816 s / img. ETA=1:03:49
[12/31 06:49:02] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4816 s / img. ETA=1:03:24
[12/31 06:49:26] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4816 s / img. ETA=1:03:00
[12/31 06:49:50] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4816 s / img. ETA=1:02:36
[12/31 06:50:14] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4816 s / img. ETA=1:02:12
[12/31 06:50:38] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4816 s / img. ETA=1:01:48
[12/31 06:51:02] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4816 s / img. ETA=1:01:24
[12/31 06:51:26] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4816 s / img. ETA=1:01:00
[12/31 06:51:50] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4816 s / img. ETA=1:00:36
[12/31 06:52:14] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4816 s / img. ETA=1:00:12
[12/31 06:52:38] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4816 s / img. ETA=0:59:47
[12/31 06:53:02] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4816 s / img. ETA=0:59:23
[12/31 06:53:26] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4816 s / img. ETA=0:58:59
[12/31 06:53:51] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4816 s / img. ETA=0:58:35
[12/31 06:54:15] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4816 s / img. ETA=0:58:11
[12/31 06:54:39] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4816 s / img. ETA=0:57:47
[12/31 06:55:03] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4816 s / img. ETA=0:57:23
[12/31 06:55:27] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4816 s / img. ETA=0:56:59
[12/31 06:55:53] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4818 s / img. ETA=0:56:36
[12/31 06:56:17] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4818 s / img. ETA=0:56:12
[12/31 06:56:41] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4818 s / img. ETA=0:55:48
[12/31 06:57:05] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4818 s / img. ETA=0:55:24
[12/31 06:57:29] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4818 s / img. ETA=0:55:00
[12/31 06:57:53] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4818 s / img. ETA=0:54:36
[12/31 06:58:17] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4818 s / img. ETA=0:54:12
[12/31 06:58:41] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4818 s / img. ETA=0:53:47
[12/31 06:59:05] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4818 s / img. ETA=0:53:23
[12/31 06:59:30] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4818 s / img. ETA=0:52:59
[12/31 06:59:54] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4818 s / img. ETA=0:52:35
[12/31 07:00:18] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4818 s / img. ETA=0:52:11
[12/31 07:00:42] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4818 s / img. ETA=0:51:47
[12/31 07:01:06] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4818 s / img. ETA=0:51:23
[12/31 07:01:30] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4818 s / img. ETA=0:50:59
[12/31 07:01:54] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4818 s / img. ETA=0:50:35
[12/31 07:02:18] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4818 s / img. ETA=0:50:11
[12/31 07:02:42] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4818 s / img. ETA=0:49:47
[12/31 07:03:06] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4818 s / img. ETA=0:49:23
[12/31 07:03:31] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4818 s / img. ETA=0:48:58
[12/31 07:03:55] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4818 s / img. ETA=0:48:34
[12/31 07:04:19] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4818 s / img. ETA=0:48:10
[12/31 07:04:43] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4818 s / img. ETA=0:47:46
[12/31 07:05:07] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4818 s / img. ETA=0:47:22
[12/31 07:05:31] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4818 s / img. ETA=0:46:58
[12/31 07:05:55] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4818 s / img. ETA=0:46:34
[12/31 07:06:19] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4818 s / img. ETA=0:46:10
[12/31 07:06:43] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4818 s / img. ETA=0:45:46
[12/31 07:07:07] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4818 s / img. ETA=0:45:22
[12/31 07:07:31] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4818 s / img. ETA=0:44:57
[12/31 07:07:55] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4818 s / img. ETA=0:44:33
[12/31 07:08:19] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4818 s / img. ETA=0:44:09
[12/31 07:08:44] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4818 s / img. ETA=0:43:45
[12/31 07:09:08] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4818 s / img. ETA=0:43:21
[12/31 07:09:32] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4818 s / img. ETA=0:42:57
[12/31 07:09:56] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4818 s / img. ETA=0:42:33
[12/31 07:10:20] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4818 s / img. ETA=0:42:09
[12/31 07:10:44] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4818 s / img. ETA=0:41:45
[12/31 07:11:08] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4818 s / img. ETA=0:41:21
[12/31 07:11:32] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4818 s / img. ETA=0:40:57
[12/31 07:11:56] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4818 s / img. ETA=0:40:32
[12/31 07:12:20] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4818 s / img. ETA=0:40:08
[12/31 07:12:44] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4818 s / img. ETA=0:39:44
[12/31 07:13:08] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4818 s / img. ETA=0:39:20
[12/31 07:13:32] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4818 s / img. ETA=0:38:56
[12/31 07:13:56] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4818 s / img. ETA=0:38:32
[12/31 07:14:20] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4817 s / img. ETA=0:38:08
[12/31 07:14:45] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4818 s / img. ETA=0:37:44
[12/31 07:15:09] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4817 s / img. ETA=0:37:20
[12/31 07:15:33] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4817 s / img. ETA=0:36:56
[12/31 07:15:57] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4817 s / img. ETA=0:36:31
[12/31 07:16:21] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4817 s / img. ETA=0:36:07
[12/31 07:16:45] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4817 s / img. ETA=0:35:43
[12/31 07:17:09] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4817 s / img. ETA=0:35:19
[12/31 07:17:33] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4818 s / img. ETA=0:34:55
[12/31 07:17:57] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4817 s / img. ETA=0:34:31
[12/31 07:18:21] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4817 s / img. ETA=0:34:07
[12/31 07:18:45] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4817 s / img. ETA=0:33:43
[12/31 07:19:09] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4817 s / img. ETA=0:33:19
[12/31 07:19:33] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4817 s / img. ETA=0:32:55
[12/31 07:19:57] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4817 s / img. ETA=0:32:30
[12/31 07:20:21] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4817 s / img. ETA=0:32:06
[12/31 07:20:46] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4817 s / img. ETA=0:31:42
[12/31 07:21:10] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4817 s / img. ETA=0:31:18
[12/31 07:21:34] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4817 s / img. ETA=0:30:54
[12/31 07:21:58] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4817 s / img. ETA=0:30:30
[12/31 07:22:22] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4817 s / img. ETA=0:30:06
[12/31 07:22:46] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4817 s / img. ETA=0:29:42
[12/31 07:23:10] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4817 s / img. ETA=0:29:18
[12/31 07:23:34] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4817 s / img. ETA=0:28:54
[12/31 07:23:58] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4817 s / img. ETA=0:28:30
[12/31 07:24:22] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4817 s / img. ETA=0:28:05
[12/31 07:24:46] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4817 s / img. ETA=0:27:41
[12/31 07:25:10] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4817 s / img. ETA=0:27:17
[12/31 07:25:34] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4817 s / img. ETA=0:26:53
[12/31 07:25:58] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4817 s / img. ETA=0:26:29
[12/31 07:26:22] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4817 s / img. ETA=0:26:05
[12/31 07:26:46] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4817 s / img. ETA=0:25:41
[12/31 07:27:10] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4817 s / img. ETA=0:25:17
[12/31 07:27:34] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4817 s / img. ETA=0:24:53
[12/31 07:27:58] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4817 s / img. ETA=0:24:29
[12/31 07:28:22] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4817 s / img. ETA=0:24:05
[12/31 07:28:47] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4817 s / img. ETA=0:23:40
[12/31 07:29:11] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4817 s / img. ETA=0:23:16
[12/31 07:29:35] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4817 s / img. ETA=0:22:52
[12/31 07:29:59] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4817 s / img. ETA=0:22:28
[12/31 07:30:23] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4817 s / img. ETA=0:22:04
[12/31 07:30:47] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4817 s / img. ETA=0:21:40
[12/31 07:31:11] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4817 s / img. ETA=0:21:16
[12/31 07:31:35] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4817 s / img. ETA=0:20:52
[12/31 07:31:59] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4817 s / img. ETA=0:20:28
[12/31 07:32:23] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4817 s / img. ETA=0:20:04
[12/31 07:32:47] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4817 s / img. ETA=0:19:40
[12/31 07:33:11] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4817 s / img. ETA=0:19:15
[12/31 07:33:35] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4816 s / img. ETA=0:18:51
[12/31 07:33:59] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4816 s / img. ETA=0:18:27
[12/31 07:34:23] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4816 s / img. ETA=0:18:03
[12/31 07:34:47] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4816 s / img. ETA=0:17:39
[12/31 07:35:11] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4816 s / img. ETA=0:17:15
[12/31 07:35:35] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4816 s / img. ETA=0:16:51
[12/31 07:35:59] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4816 s / img. ETA=0:16:27
[12/31 07:36:23] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4816 s / img. ETA=0:16:03
[12/31 07:36:47] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4816 s / img. ETA=0:15:39
[12/31 07:37:12] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4816 s / img. ETA=0:15:15
[12/31 07:37:36] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4816 s / img. ETA=0:14:51
[12/31 07:38:00] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4816 s / img. ETA=0:14:26
[12/31 07:38:24] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4816 s / img. ETA=0:14:02
[12/31 07:38:48] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4816 s / img. ETA=0:13:38
[12/31 07:39:12] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4816 s / img. ETA=0:13:14
[12/31 07:39:36] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4816 s / img. ETA=0:12:50
[12/31 07:40:00] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4816 s / img. ETA=0:12:26
[12/31 07:40:24] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4816 s / img. ETA=0:12:02
[12/31 07:40:48] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4816 s / img. ETA=0:11:38
[12/31 07:41:12] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4816 s / img. ETA=0:11:14
[12/31 07:41:36] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4816 s / img. ETA=0:10:50
[12/31 07:42:00] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4816 s / img. ETA=0:10:26
[12/31 07:42:24] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4816 s / img. ETA=0:10:01
[12/31 07:42:48] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4816 s / img. ETA=0:09:37
[12/31 07:43:12] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4816 s / img. ETA=0:09:13
[12/31 07:43:36] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4816 s / img. ETA=0:08:49
[12/31 07:44:00] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4816 s / img. ETA=0:08:25
[12/31 07:44:24] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4816 s / img. ETA=0:08:01
[12/31 07:44:48] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4816 s / img. ETA=0:07:37
[12/31 07:45:12] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4816 s / img. ETA=0:07:13
[12/31 07:45:37] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4816 s / img. ETA=0:06:49
[12/31 07:46:01] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4816 s / img. ETA=0:06:25
[12/31 07:46:25] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4816 s / img. ETA=0:06:01
[12/31 07:46:49] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4816 s / img. ETA=0:05:37
[12/31 07:47:13] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4816 s / img. ETA=0:05:13
[12/31 07:47:37] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4816 s / img. ETA=0:04:48
[12/31 07:48:01] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4816 s / img. ETA=0:04:24
[12/31 07:48:25] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4816 s / img. ETA=0:04:00
[12/31 07:48:49] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4816 s / img. ETA=0:03:36
[12/31 07:49:13] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4816 s / img. ETA=0:03:12
[12/31 07:49:37] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4816 s / img. ETA=0:02:48
[12/31 07:50:01] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4816 s / img. ETA=0:02:24
[12/31 07:50:25] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4816 s / img. ETA=0:02:00
[12/31 07:50:49] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4816 s / img. ETA=0:01:36
[12/31 07:51:13] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4816 s / img. ETA=0:01:12
[12/31 07:51:38] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4816 s / img. ETA=0:00:48
[12/31 07:52:02] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4816 s / img. ETA=0:00:24
[12/31 07:52:26] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4816 s / img. ETA=0:00:00
[12/31 07:52:26] d2.evaluation.evaluator INFO: Total inference time: 2:15:12 (0.481567 s / img per device, on 2 devices)
[12/31 07:52:26] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:20 (0.478524 s / img per device, on 2 devices)
[12/31 07:52:29] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/31 07:52:30] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/31 07:52:30] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/31 07:52:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/31 07:52:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/31 07:52:56] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/31 07:52:56] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/31 07:52:56] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/31 07:52:56] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/31 10:40:53] detectron2 INFO: Rank of current process: 0. World size: 2
[12/31 10:40:57] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/31 10:40:57] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/31 10:40:57] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: True   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 116368  ## 46368 74368(70000 最好) 96368(8500)  116368
  BASE_LR: 0.01     ### 
  STEPS: (116068, 116268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/31 10:40:57] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 116368
  MOMENTUM: 0.9
  STEPS: (116068, 116268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: True
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/31 10:40:57] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/31 10:40:57] d2.utils.env INFO: Using a generated random seed 57841952
[12/31 10:41:00] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/31 10:41:00] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0069999.pth
[12/31 10:43:20] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/31 10:43:20] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/31 10:43:21] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/31 10:43:21] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/31 10:44:14] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4803 s / img. ETA=2:14:29
[12/31 10:44:39] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4811 s / img. ETA=2:14:19
[12/31 10:45:03] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4814 s / img. ETA=2:14:00
[12/31 10:45:27] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4816 s / img. ETA=2:13:38
[12/31 10:45:51] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4816 s / img. ETA=2:13:14
[12/31 10:46:15] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4819 s / img. ETA=2:12:55
[12/31 10:46:39] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4820 s / img. ETA=2:12:33
[12/31 10:47:03] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4823 s / img. ETA=2:12:13
[12/31 10:47:28] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4826 s / img. ETA=2:11:54
[12/31 10:47:52] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4829 s / img. ETA=2:11:35
[12/31 10:48:16] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4830 s / img. ETA=2:11:13
[12/31 10:48:40] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4834 s / img. ETA=2:10:54
[12/31 10:49:05] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4835 s / img. ETA=2:10:32
[12/31 10:49:29] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4835 s / img. ETA=2:10:08
[12/31 10:49:53] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4835 s / img. ETA=2:09:44
[12/31 10:50:17] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4834 s / img. ETA=2:09:18
[12/31 10:50:41] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4833 s / img. ETA=2:08:53
[12/31 10:51:05] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4832 s / img. ETA=2:08:26
[12/31 10:51:29] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4831 s / img. ETA=2:08:00
[12/31 10:51:53] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4830 s / img. ETA=2:07:36
[12/31 10:52:18] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4830 s / img. ETA=2:07:11
[12/31 10:52:42] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4829 s / img. ETA=2:06:45
[12/31 10:53:06] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4828 s / img. ETA=2:06:20
[12/31 10:53:30] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4828 s / img. ETA=2:05:55
[12/31 10:53:54] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4828 s / img. ETA=2:05:31
[12/31 10:54:18] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4827 s / img. ETA=2:05:06
[12/31 10:54:42] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4827 s / img. ETA=2:04:41
[12/31 10:55:06] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4827 s / img. ETA=2:04:17
[12/31 10:55:30] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4826 s / img. ETA=2:03:52
[12/31 10:55:56] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4838 s / img. ETA=2:03:46
[12/31 10:56:20] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4838 s / img. ETA=2:03:22
[12/31 10:56:45] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4838 s / img. ETA=2:02:57
[12/31 10:57:09] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4837 s / img. ETA=2:02:32
[12/31 10:57:33] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4837 s / img. ETA=2:02:08
[12/31 10:57:57] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4837 s / img. ETA=2:01:43
[12/31 10:58:21] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4836 s / img. ETA=2:01:18
[12/31 10:58:45] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4836 s / img. ETA=2:00:53
[12/31 10:59:09] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4836 s / img. ETA=2:00:30
[12/31 10:59:34] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4836 s / img. ETA=2:00:05
[12/31 10:59:58] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4836 s / img. ETA=1:59:42
[12/31 11:00:22] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4835 s / img. ETA=1:59:16
[12/31 11:00:46] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4835 s / img. ETA=1:58:51
[12/31 11:01:10] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4835 s / img. ETA=1:58:26
[12/31 11:01:34] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4834 s / img. ETA=1:58:02
[12/31 11:01:58] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4834 s / img. ETA=1:57:38
[12/31 11:02:22] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4834 s / img. ETA=1:57:13
[12/31 11:02:46] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4834 s / img. ETA=1:56:49
[12/31 11:03:11] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4834 s / img. ETA=1:56:24
[12/31 11:03:35] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4833 s / img. ETA=1:56:00
[12/31 11:03:59] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4833 s / img. ETA=1:55:35
[12/31 11:04:23] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4833 s / img. ETA=1:55:10
[12/31 11:04:47] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4833 s / img. ETA=1:54:46
[12/31 11:05:11] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4833 s / img. ETA=1:54:22
[12/31 11:05:35] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4833 s / img. ETA=1:53:58
[12/31 11:05:59] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4833 s / img. ETA=1:53:34
[12/31 11:06:24] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4833 s / img. ETA=1:53:09
[12/31 11:06:48] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4833 s / img. ETA=1:52:45
[12/31 11:07:12] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4833 s / img. ETA=1:52:21
[12/31 11:07:36] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4832 s / img. ETA=1:51:56
[12/31 11:08:00] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4832 s / img. ETA=1:51:31
[12/31 11:08:24] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4831 s / img. ETA=1:51:07
[12/31 11:08:48] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4831 s / img. ETA=1:50:42
[12/31 11:09:12] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4831 s / img. ETA=1:50:18
[12/31 11:09:37] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4832 s / img. ETA=1:49:55
[12/31 11:10:01] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4831 s / img. ETA=1:49:30
[12/31 11:10:25] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4831 s / img. ETA=1:49:06
[12/31 11:10:49] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4831 s / img. ETA=1:48:41
[12/31 11:11:13] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4831 s / img. ETA=1:48:17
[12/31 11:11:37] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4831 s / img. ETA=1:47:53
[12/31 11:12:01] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4831 s / img. ETA=1:47:29
[12/31 11:12:25] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4830 s / img. ETA=1:47:04
[12/31 11:12:49] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4830 s / img. ETA=1:46:39
[12/31 11:13:13] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4830 s / img. ETA=1:46:15
[12/31 11:13:38] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4830 s / img. ETA=1:45:51
[12/31 11:14:02] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4830 s / img. ETA=1:45:27
[12/31 11:14:26] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4830 s / img. ETA=1:45:02
[12/31 11:14:50] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4830 s / img. ETA=1:44:39
[12/31 11:15:14] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4830 s / img. ETA=1:44:14
[12/31 11:15:38] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4830 s / img. ETA=1:43:50
[12/31 11:16:02] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4830 s / img. ETA=1:43:26
[12/31 11:16:26] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4830 s / img. ETA=1:43:01
[12/31 11:16:51] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4830 s / img. ETA=1:42:37
[12/31 11:17:15] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4830 s / img. ETA=1:42:13
[12/31 11:17:39] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4830 s / img. ETA=1:41:49
[12/31 11:18:03] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4829 s / img. ETA=1:41:24
[12/31 11:18:27] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4830 s / img. ETA=1:41:01
[12/31 11:18:51] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4829 s / img. ETA=1:40:36
[12/31 11:19:15] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4830 s / img. ETA=1:40:12
[12/31 11:19:39] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4829 s / img. ETA=1:39:48
[12/31 11:20:04] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4829 s / img. ETA=1:39:24
[12/31 11:20:28] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4829 s / img. ETA=1:39:00
[12/31 11:20:52] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4830 s / img. ETA=1:38:36
[12/31 11:21:16] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4830 s / img. ETA=1:38:12
[12/31 11:21:40] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4829 s / img. ETA=1:37:47
[12/31 11:22:04] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4829 s / img. ETA=1:37:23
[12/31 11:22:28] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4829 s / img. ETA=1:36:59
[12/31 11:22:53] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4829 s / img. ETA=1:36:35
[12/31 11:23:17] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4829 s / img. ETA=1:36:11
[12/31 11:23:41] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4829 s / img. ETA=1:35:46
[12/31 11:24:05] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4829 s / img. ETA=1:35:22
[12/31 11:24:29] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4829 s / img. ETA=1:34:58
[12/31 11:24:53] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4829 s / img. ETA=1:34:34
[12/31 11:25:18] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4829 s / img. ETA=1:34:10
[12/31 11:25:42] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4829 s / img. ETA=1:33:46
[12/31 11:26:06] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4829 s / img. ETA=1:33:22
[12/31 11:26:30] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4829 s / img. ETA=1:32:57
[12/31 11:26:54] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4829 s / img. ETA=1:32:33
[12/31 11:27:18] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4829 s / img. ETA=1:32:09
[12/31 11:27:42] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4829 s / img. ETA=1:31:44
[12/31 11:28:06] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4829 s / img. ETA=1:31:20
[12/31 11:28:30] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4829 s / img. ETA=1:30:56
[12/31 11:28:54] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4828 s / img. ETA=1:30:32
[12/31 11:29:19] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4829 s / img. ETA=1:30:08
[12/31 11:29:43] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4829 s / img. ETA=1:29:43
[12/31 11:30:07] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4829 s / img. ETA=1:29:19
[12/31 11:30:31] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4828 s / img. ETA=1:28:55
[12/31 11:30:55] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4828 s / img. ETA=1:28:31
[12/31 11:31:19] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4828 s / img. ETA=1:28:06
[12/31 11:31:43] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4828 s / img. ETA=1:27:42
[12/31 11:32:07] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4828 s / img. ETA=1:27:18
[12/31 11:32:31] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4828 s / img. ETA=1:26:54
[12/31 11:32:56] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4828 s / img. ETA=1:26:30
[12/31 11:33:20] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4828 s / img. ETA=1:26:05
[12/31 11:33:44] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4828 s / img. ETA=1:25:41
[12/31 11:34:08] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4828 s / img. ETA=1:25:17
[12/31 11:34:32] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4828 s / img. ETA=1:24:53
[12/31 11:34:56] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4828 s / img. ETA=1:24:28
[12/31 11:35:20] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4828 s / img. ETA=1:24:04
[12/31 11:35:44] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4827 s / img. ETA=1:23:40
[12/31 11:36:08] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4827 s / img. ETA=1:23:16
[12/31 11:36:32] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4827 s / img. ETA=1:22:52
[12/31 11:36:56] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4827 s / img. ETA=1:22:27
[12/31 11:37:21] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4827 s / img. ETA=1:22:03
[12/31 11:37:45] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4827 s / img. ETA=1:21:39
[12/31 11:38:09] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4827 s / img. ETA=1:21:15
[12/31 11:38:33] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4827 s / img. ETA=1:20:51
[12/31 11:38:57] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4827 s / img. ETA=1:20:27
[12/31 11:39:21] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4827 s / img. ETA=1:20:03
[12/31 11:39:45] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4827 s / img. ETA=1:19:38
[12/31 11:40:10] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4827 s / img. ETA=1:19:14
[12/31 11:40:34] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4827 s / img. ETA=1:18:50
[12/31 11:40:58] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4827 s / img. ETA=1:18:26
[12/31 11:41:22] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4827 s / img. ETA=1:18:02
[12/31 11:41:46] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4827 s / img. ETA=1:17:38
[12/31 11:42:10] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4827 s / img. ETA=1:17:14
[12/31 11:42:34] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4827 s / img. ETA=1:16:50
[12/31 11:42:58] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4827 s / img. ETA=1:16:25
[12/31 11:43:23] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4827 s / img. ETA=1:16:01
[12/31 11:43:47] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4827 s / img. ETA=1:15:37
[12/31 11:44:11] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4827 s / img. ETA=1:15:13
[12/31 11:44:35] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4827 s / img. ETA=1:14:49
[12/31 11:44:59] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4827 s / img. ETA=1:14:25
[12/31 11:45:23] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4827 s / img. ETA=1:14:01
[12/31 11:45:47] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4827 s / img. ETA=1:13:36
[12/31 11:46:12] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4827 s / img. ETA=1:13:12
[12/31 11:46:36] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4827 s / img. ETA=1:12:48
[12/31 11:47:00] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4827 s / img. ETA=1:12:24
[12/31 11:47:24] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4827 s / img. ETA=1:12:00
[12/31 11:47:48] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4827 s / img. ETA=1:11:35
[12/31 11:48:12] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4827 s / img. ETA=1:11:11
[12/31 11:48:36] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4827 s / img. ETA=1:10:47
[12/31 11:49:00] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4827 s / img. ETA=1:10:23
[12/31 11:49:24] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4827 s / img. ETA=1:09:59
[12/31 11:49:49] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4827 s / img. ETA=1:09:35
[12/31 11:50:13] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4827 s / img. ETA=1:09:11
[12/31 11:50:37] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4827 s / img. ETA=1:08:47
[12/31 11:51:01] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4827 s / img. ETA=1:08:22
[12/31 11:51:25] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4827 s / img. ETA=1:07:58
[12/31 11:51:49] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4827 s / img. ETA=1:07:34
[12/31 11:52:13] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4827 s / img. ETA=1:07:10
[12/31 11:52:37] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4827 s / img. ETA=1:06:46
[12/31 11:53:02] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4827 s / img. ETA=1:06:22
[12/31 11:53:26] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4827 s / img. ETA=1:05:58
[12/31 11:53:50] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4827 s / img. ETA=1:05:34
[12/31 11:54:14] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4827 s / img. ETA=1:05:09
[12/31 11:54:38] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4827 s / img. ETA=1:04:45
[12/31 11:55:02] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4827 s / img. ETA=1:04:21
[12/31 11:55:26] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4827 s / img. ETA=1:03:57
[12/31 11:55:52] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4829 s / img. ETA=1:03:34
[12/31 11:56:17] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4829 s / img. ETA=1:03:10
[12/31 11:56:41] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4829 s / img. ETA=1:02:46
[12/31 11:57:05] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4829 s / img. ETA=1:02:22
[12/31 11:57:29] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4829 s / img. ETA=1:01:58
[12/31 11:57:53] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4829 s / img. ETA=1:01:33
[12/31 11:58:17] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4829 s / img. ETA=1:01:09
[12/31 11:58:42] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4829 s / img. ETA=1:00:45
[12/31 11:59:06] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4829 s / img. ETA=1:00:21
[12/31 11:59:30] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4829 s / img. ETA=0:59:57
[12/31 11:59:54] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4829 s / img. ETA=0:59:33
[12/31 12:00:18] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4829 s / img. ETA=0:59:09
[12/31 12:00:43] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4829 s / img. ETA=0:58:45
[12/31 12:01:07] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4829 s / img. ETA=0:58:21
[12/31 12:01:31] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4829 s / img. ETA=0:57:57
[12/31 12:01:55] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4829 s / img. ETA=0:57:32
[12/31 12:02:19] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4829 s / img. ETA=0:57:08
[12/31 12:02:43] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4829 s / img. ETA=0:56:44
[12/31 12:03:07] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4829 s / img. ETA=0:56:20
[12/31 12:03:31] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4829 s / img. ETA=0:55:56
[12/31 12:03:55] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4829 s / img. ETA=0:55:31
[12/31 12:04:19] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4829 s / img. ETA=0:55:07
[12/31 12:04:43] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4829 s / img. ETA=0:54:43
[12/31 12:05:08] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4829 s / img. ETA=0:54:19
[12/31 12:05:32] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4829 s / img. ETA=0:53:55
[12/31 12:05:56] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4829 s / img. ETA=0:53:31
[12/31 12:06:20] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4829 s / img. ETA=0:53:07
[12/31 12:06:44] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4829 s / img. ETA=0:52:42
[12/31 12:07:08] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4829 s / img. ETA=0:52:18
[12/31 12:07:32] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4829 s / img. ETA=0:51:54
[12/31 12:07:57] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4829 s / img. ETA=0:51:30
[12/31 12:08:21] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4829 s / img. ETA=0:51:06
[12/31 12:08:45] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4829 s / img. ETA=0:50:42
[12/31 12:09:09] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4829 s / img. ETA=0:50:18
[12/31 12:09:33] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4829 s / img. ETA=0:49:53
[12/31 12:09:57] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4829 s / img. ETA=0:49:29
[12/31 12:10:21] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4829 s / img. ETA=0:49:05
[12/31 12:10:45] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4829 s / img. ETA=0:48:41
[12/31 12:11:09] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4828 s / img. ETA=0:48:17
[12/31 12:11:33] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4828 s / img. ETA=0:47:52
[12/31 12:11:57] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4828 s / img. ETA=0:47:28
[12/31 12:12:22] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4828 s / img. ETA=0:47:04
[12/31 12:12:46] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4828 s / img. ETA=0:46:40
[12/31 12:13:10] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4828 s / img. ETA=0:46:16
[12/31 12:13:34] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4828 s / img. ETA=0:45:52
[12/31 12:13:58] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4828 s / img. ETA=0:45:28
[12/31 12:14:22] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4828 s / img. ETA=0:45:03
[12/31 12:14:47] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4828 s / img. ETA=0:44:39
[12/31 12:15:11] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4828 s / img. ETA=0:44:15
[12/31 12:15:35] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4828 s / img. ETA=0:43:51
[12/31 12:15:59] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4828 s / img. ETA=0:43:27
[12/31 12:16:23] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4828 s / img. ETA=0:43:03
[12/31 12:16:47] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4828 s / img. ETA=0:42:38
[12/31 12:17:11] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4828 s / img. ETA=0:42:14
[12/31 12:17:36] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4828 s / img. ETA=0:41:50
[12/31 12:18:00] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4828 s / img. ETA=0:41:26
[12/31 12:18:24] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4828 s / img. ETA=0:41:02
[12/31 12:18:48] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4828 s / img. ETA=0:40:38
[12/31 12:19:12] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4828 s / img. ETA=0:40:14
[12/31 12:19:36] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4828 s / img. ETA=0:39:50
[12/31 12:20:01] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4829 s / img. ETA=0:39:25
[12/31 12:20:25] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4828 s / img. ETA=0:39:01
[12/31 12:20:49] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4828 s / img. ETA=0:38:37
[12/31 12:21:13] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4828 s / img. ETA=0:38:13
[12/31 12:21:37] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4829 s / img. ETA=0:37:49
[12/31 12:22:01] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4829 s / img. ETA=0:37:25
[12/31 12:22:26] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4829 s / img. ETA=0:37:01
[12/31 12:22:50] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4829 s / img. ETA=0:36:36
[12/31 12:23:14] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4828 s / img. ETA=0:36:12
[12/31 12:23:38] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4828 s / img. ETA=0:35:48
[12/31 12:24:02] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4829 s / img. ETA=0:35:24
[12/31 12:24:26] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4828 s / img. ETA=0:35:00
[12/31 12:24:50] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4828 s / img. ETA=0:34:36
[12/31 12:25:14] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4828 s / img. ETA=0:34:12
[12/31 12:25:38] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4828 s / img. ETA=0:33:47
[12/31 12:26:02] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4828 s / img. ETA=0:33:23
[12/31 12:26:27] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4828 s / img. ETA=0:32:59
[12/31 12:26:51] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4828 s / img. ETA=0:32:35
[12/31 12:27:15] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4828 s / img. ETA=0:32:11
[12/31 12:27:39] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4828 s / img. ETA=0:31:47
[12/31 12:28:03] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4828 s / img. ETA=0:31:22
[12/31 12:28:27] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4828 s / img. ETA=0:30:58
[12/31 12:28:51] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4828 s / img. ETA=0:30:34
[12/31 12:29:15] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4828 s / img. ETA=0:30:10
[12/31 12:29:39] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4828 s / img. ETA=0:29:46
[12/31 12:30:04] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4828 s / img. ETA=0:29:22
[12/31 12:30:28] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4828 s / img. ETA=0:28:58
[12/31 12:30:52] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4828 s / img. ETA=0:28:33
[12/31 12:31:16] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4828 s / img. ETA=0:28:09
[12/31 12:31:40] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4828 s / img. ETA=0:27:45
[12/31 12:32:04] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4828 s / img. ETA=0:27:21
[12/31 12:32:28] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4828 s / img. ETA=0:26:57
[12/31 12:32:52] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4828 s / img. ETA=0:26:33
[12/31 12:33:16] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4828 s / img. ETA=0:26:08
[12/31 12:33:40] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4827 s / img. ETA=0:25:44
[12/31 12:34:04] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4827 s / img. ETA=0:25:20
[12/31 12:34:28] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4827 s / img. ETA=0:24:56
[12/31 12:34:53] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4828 s / img. ETA=0:24:32
[12/31 12:35:17] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4828 s / img. ETA=0:24:08
[12/31 12:35:41] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4828 s / img. ETA=0:23:44
[12/31 12:36:05] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4828 s / img. ETA=0:23:19
[12/31 12:36:29] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4828 s / img. ETA=0:22:55
[12/31 12:36:53] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4828 s / img. ETA=0:22:31
[12/31 12:37:17] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4828 s / img. ETA=0:22:07
[12/31 12:37:41] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4827 s / img. ETA=0:21:43
[12/31 12:38:05] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4827 s / img. ETA=0:21:19
[12/31 12:38:30] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4827 s / img. ETA=0:20:55
[12/31 12:38:54] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4827 s / img. ETA=0:20:30
[12/31 12:39:18] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4827 s / img. ETA=0:20:06
[12/31 12:39:42] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4827 s / img. ETA=0:19:42
[12/31 12:40:06] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4827 s / img. ETA=0:19:18
[12/31 12:40:30] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4827 s / img. ETA=0:18:54
[12/31 12:40:54] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4827 s / img. ETA=0:18:30
[12/31 12:41:18] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4827 s / img. ETA=0:18:06
[12/31 12:41:42] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4827 s / img. ETA=0:17:41
[12/31 12:42:06] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4827 s / img. ETA=0:17:17
[12/31 12:42:31] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4827 s / img. ETA=0:16:53
[12/31 12:42:55] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4827 s / img. ETA=0:16:29
[12/31 12:43:19] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4827 s / img. ETA=0:16:05
[12/31 12:43:43] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4827 s / img. ETA=0:15:41
[12/31 12:44:07] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4827 s / img. ETA=0:15:17
[12/31 12:44:31] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4827 s / img. ETA=0:14:53
[12/31 12:44:55] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4827 s / img. ETA=0:14:28
[12/31 12:45:19] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4827 s / img. ETA=0:14:04
[12/31 12:45:43] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4827 s / img. ETA=0:13:40
[12/31 12:46:07] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4827 s / img. ETA=0:13:16
[12/31 12:46:31] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4827 s / img. ETA=0:12:52
[12/31 12:46:55] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4827 s / img. ETA=0:12:28
[12/31 12:47:20] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4827 s / img. ETA=0:12:04
[12/31 12:47:44] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4827 s / img. ETA=0:11:39
[12/31 12:48:08] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4827 s / img. ETA=0:11:15
[12/31 12:48:32] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4827 s / img. ETA=0:10:51
[12/31 12:48:56] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4827 s / img. ETA=0:10:27
[12/31 12:49:20] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4826 s / img. ETA=0:10:03
[12/31 12:49:44] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4826 s / img. ETA=0:09:39
[12/31 12:50:08] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4826 s / img. ETA=0:09:15
[12/31 12:50:32] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4826 s / img. ETA=0:08:50
[12/31 12:50:56] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4826 s / img. ETA=0:08:26
[12/31 12:51:20] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4826 s / img. ETA=0:08:02
[12/31 12:51:44] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4826 s / img. ETA=0:07:38
[12/31 12:52:08] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4826 s / img. ETA=0:07:14
[12/31 12:52:33] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4826 s / img. ETA=0:06:50
[12/31 12:52:57] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4826 s / img. ETA=0:06:26
[12/31 12:53:21] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4826 s / img. ETA=0:06:01
[12/31 12:53:45] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4826 s / img. ETA=0:05:37
[12/31 12:54:09] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4826 s / img. ETA=0:05:13
[12/31 12:54:33] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4826 s / img. ETA=0:04:49
[12/31 12:54:57] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4826 s / img. ETA=0:04:25
[12/31 12:55:21] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4826 s / img. ETA=0:04:01
[12/31 12:55:47] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4827 s / img. ETA=0:03:37
[12/31 12:56:11] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4827 s / img. ETA=0:03:13
[12/31 12:56:36] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4827 s / img. ETA=0:02:48
[12/31 12:57:00] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4827 s / img. ETA=0:02:24
[12/31 12:57:24] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4827 s / img. ETA=0:02:00
[12/31 12:57:48] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4827 s / img. ETA=0:01:36
[12/31 12:58:12] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4827 s / img. ETA=0:01:12
[12/31 12:58:36] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4827 s / img. ETA=0:00:48
[12/31 12:59:00] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4827 s / img. ETA=0:00:24
[12/31 12:59:24] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4827 s / img. ETA=0:00:00
[12/31 12:59:24] d2.evaluation.evaluator INFO: Total inference time: 2:15:31 (0.482695 s / img per device, on 2 devices)
[12/31 12:59:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:39 (0.479613 s / img per device, on 2 devices)
[12/31 12:59:27] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/31 12:59:27] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/31 12:59:28] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/31 12:59:57] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/31 12:59:57] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/31 12:59:58] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/31 12:59:58] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/31 12:59:58] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/31 12:59:58] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/31 12:59:58] d2.trainer INFO: Running inference with test-time augmentation ...
[12/31 12:59:58] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/31 12:59:59] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/31 13:00:00] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/31 13:03:21] d2.evaluation.evaluator INFO: Inference done 50/16850. 3.3032 s / img. ETA=15:24:53
[12/31 13:06:08] d2.evaluation.evaluator INFO: Inference done 100/16850. 3.3177 s / img. ETA=15:26:11
[12/31 13:08:54] d2.evaluation.evaluator INFO: Inference done 150/16850. 3.3180 s / img. ETA=15:23:30
[12/31 13:11:39] d2.evaluation.evaluator INFO: Inference done 200/16850. 3.3172 s / img. ETA=15:20:31
[12/31 13:14:24] d2.evaluation.evaluator INFO: Inference done 250/16850. 3.3128 s / img. ETA=15:16:32
[12/31 13:17:09] d2.evaluation.evaluator INFO: Inference done 300/16850. 3.3092 s / img. ETA=15:12:47
[12/31 13:19:54] d2.evaluation.evaluator INFO: Inference done 350/16850. 3.3091 s / img. ETA=15:09:59
[12/31 13:22:40] d2.evaluation.evaluator INFO: Inference done 400/16850. 3.3087 s / img. ETA=15:07:07
[12/31 13:25:25] d2.evaluation.evaluator INFO: Inference done 450/16850. 3.3080 s / img. ETA=15:04:11
[12/31 13:28:10] d2.evaluation.evaluator INFO: Inference done 500/16850. 3.3080 s / img. ETA=15:01:26
[12/31 13:30:56] d2.evaluation.evaluator INFO: Inference done 550/16850. 3.3081 s / img. ETA=14:58:42
[12/31 13:33:41] d2.evaluation.evaluator INFO: Inference done 600/16850. 3.3080 s / img. ETA=14:55:54
[12/31 13:36:26] d2.evaluation.evaluator INFO: Inference done 650/16850. 3.3075 s / img. ETA=14:53:01
[12/31 13:39:11] d2.evaluation.evaluator INFO: Inference done 700/16850. 3.3070 s / img. ETA=14:50:08
[12/31 13:41:56] d2.evaluation.evaluator INFO: Inference done 750/16850. 3.3069 s / img. ETA=14:47:21
[12/31 13:44:41] d2.evaluation.evaluator INFO: Inference done 800/16850. 3.3065 s / img. ETA=14:44:29
[12/31 13:47:26] d2.evaluation.evaluator INFO: Inference done 850/16850. 3.3060 s / img. ETA=14:41:36
[12/31 13:50:11] d2.evaluation.evaluator INFO: Inference done 900/16850. 3.3056 s / img. ETA=14:38:44
[12/31 13:52:56] d2.evaluation.evaluator INFO: Inference done 950/16850. 3.3057 s / img. ETA=14:35:59
[12/31 13:55:43] d2.evaluation.evaluator INFO: Inference done 1000/16850. 3.3071 s / img. ETA=14:33:37
[12/31 13:58:28] d2.evaluation.evaluator INFO: Inference done 1050/16850. 3.3065 s / img. ETA=14:30:42
[12/31 14:01:13] d2.evaluation.evaluator INFO: Inference done 1100/16850. 3.3061 s / img. ETA=14:27:51
[12/31 14:03:58] d2.evaluation.evaluator INFO: Inference done 1150/16850. 3.3057 s / img. ETA=14:25:00
[12/31 14:06:44] d2.evaluation.evaluator INFO: Inference done 1200/16850. 3.3064 s / img. ETA=14:22:25
[12/31 14:09:29] d2.evaluation.evaluator INFO: Inference done 1250/16850. 3.3062 s / img. ETA=14:19:37
[12/31 14:12:14] d2.evaluation.evaluator INFO: Inference done 1300/16850. 3.3058 s / img. ETA=14:16:44
[12/31 14:14:59] d2.evaluation.evaluator INFO: Inference done 1350/16850. 3.3058 s / img. ETA=14:14:00
[12/31 14:17:44] d2.evaluation.evaluator INFO: Inference done 1400/16850. 3.3057 s / img. ETA=14:11:13
[12/31 14:20:29] d2.evaluation.evaluator INFO: Inference done 1450/16850. 3.3054 s / img. ETA=14:08:22
[12/31 14:23:14] d2.evaluation.evaluator INFO: Inference done 1500/16850. 3.3051 s / img. ETA=14:05:32
[12/31 14:25:59] d2.evaluation.evaluator INFO: Inference done 1550/16850. 3.3049 s / img. ETA=14:02:44
[12/31 14:28:45] d2.evaluation.evaluator INFO: Inference done 1600/16850. 3.3057 s / img. ETA=14:00:11
[12/31 14:31:31] d2.evaluation.evaluator INFO: Inference done 1650/16850. 3.3063 s / img. ETA=13:57:35
[12/31 14:34:18] d2.evaluation.evaluator INFO: Inference done 1700/16850. 3.3072 s / img. ETA=13:55:03
[12/31 14:37:04] d2.evaluation.evaluator INFO: Inference done 1750/16850. 3.3075 s / img. ETA=13:52:22
[12/31 14:39:49] d2.evaluation.evaluator INFO: Inference done 1800/16850. 3.3072 s / img. ETA=13:49:33
[12/31 14:42:34] d2.evaluation.evaluator INFO: Inference done 1850/16850. 3.3070 s / img. ETA=13:46:44
[12/31 14:45:19] d2.evaluation.evaluator INFO: Inference done 1900/16850. 3.3066 s / img. ETA=13:43:53
[12/31 14:48:04] d2.evaluation.evaluator INFO: Inference done 1950/16850. 3.3069 s / img. ETA=13:41:12
[12/31 14:50:50] d2.evaluation.evaluator INFO: Inference done 2000/16850. 3.3068 s / img. ETA=13:38:26
[12/31 14:53:36] d2.evaluation.evaluator INFO: Inference done 2050/16850. 3.3071 s / img. ETA=13:35:45
[12/31 14:56:22] d2.evaluation.evaluator INFO: Inference done 2100/16850. 3.3077 s / img. ETA=13:33:07
[12/31 14:59:07] d2.evaluation.evaluator INFO: Inference done 2150/16850. 3.3075 s / img. ETA=13:30:20
[12/31 15:01:53] d2.evaluation.evaluator INFO: Inference done 2200/16850. 3.3076 s / img. ETA=13:27:36
[12/31 15:04:39] d2.evaluation.evaluator INFO: Inference done 2250/16850. 3.3078 s / img. ETA=13:24:54
[12/31 15:07:24] d2.evaluation.evaluator INFO: Inference done 2300/16850. 3.3078 s / img. ETA=13:22:07
[12/31 15:10:09] d2.evaluation.evaluator INFO: Inference done 2350/16850. 3.3076 s / img. ETA=13:19:20
[12/31 15:12:54] d2.evaluation.evaluator INFO: Inference done 2400/16850. 3.3076 s / img. ETA=13:16:34
[12/31 15:15:40] d2.evaluation.evaluator INFO: Inference done 2450/16850. 3.3076 s / img. ETA=13:13:49
[12/31 15:18:25] d2.evaluation.evaluator INFO: Inference done 2500/16850. 3.3075 s / img. ETA=13:11:03
[12/31 15:21:10] d2.evaluation.evaluator INFO: Inference done 2550/16850. 3.3075 s / img. ETA=13:08:16
[12/31 15:23:55] d2.evaluation.evaluator INFO: Inference done 2600/16850. 3.3075 s / img. ETA=13:05:31
[12/31 15:26:41] d2.evaluation.evaluator INFO: Inference done 2650/16850. 3.3075 s / img. ETA=13:02:46
[12/31 15:29:26] d2.evaluation.evaluator INFO: Inference done 2700/16850. 3.3075 s / img. ETA=13:00:00
[12/31 15:32:11] d2.evaluation.evaluator INFO: Inference done 2750/16850. 3.3073 s / img. ETA=12:57:13
[12/31 15:34:56] d2.evaluation.evaluator INFO: Inference done 2800/16850. 3.3072 s / img. ETA=12:54:26
[12/31 15:37:42] d2.evaluation.evaluator INFO: Inference done 2850/16850. 3.3075 s / img. ETA=12:51:45
[12/31 15:40:29] d2.evaluation.evaluator INFO: Inference done 2900/16850. 3.3079 s / img. ETA=12:49:04
[12/31 15:43:15] d2.evaluation.evaluator INFO: Inference done 2950/16850. 3.3081 s / img. ETA=12:46:22
[12/31 15:46:01] d2.evaluation.evaluator INFO: Inference done 3000/16850. 3.3083 s / img. ETA=12:43:39
[12/31 15:48:46] d2.evaluation.evaluator INFO: Inference done 3050/16850. 3.3082 s / img. ETA=12:40:53
[12/31 15:51:32] d2.evaluation.evaluator INFO: Inference done 3100/16850. 3.3082 s / img. ETA=12:38:08
[12/31 15:54:17] d2.evaluation.evaluator INFO: Inference done 3150/16850. 3.3082 s / img. ETA=12:35:22
[12/31 15:57:05] d2.evaluation.evaluator INFO: Inference done 3200/16850. 3.3090 s / img. ETA=12:32:47
[12/31 15:59:51] d2.evaluation.evaluator INFO: Inference done 3250/16850. 3.3091 s / img. ETA=12:30:03
[12/31 16:02:37] d2.evaluation.evaluator INFO: Inference done 3300/16850. 3.3095 s / img. ETA=12:27:23
[12/31 16:05:25] d2.evaluation.evaluator INFO: Inference done 3350/16850. 3.3100 s / img. ETA=12:24:44
[12/31 16:08:10] d2.evaluation.evaluator INFO: Inference done 3400/16850. 3.3098 s / img. ETA=12:21:57
[12/31 16:10:56] d2.evaluation.evaluator INFO: Inference done 3450/16850. 3.3100 s / img. ETA=12:19:13
[12/31 16:13:41] d2.evaluation.evaluator INFO: Inference done 3500/16850. 3.3100 s / img. ETA=12:16:29
[12/31 16:16:26] d2.evaluation.evaluator INFO: Inference done 3550/16850. 3.3098 s / img. ETA=12:13:40
[12/31 16:19:11] d2.evaluation.evaluator INFO: Inference done 3600/16850. 3.3097 s / img. ETA=12:10:53
[12/31 16:21:56] d2.evaluation.evaluator INFO: Inference done 3650/16850. 3.3097 s / img. ETA=12:08:07
[12/31 16:24:41] d2.evaluation.evaluator INFO: Inference done 3700/16850. 3.3094 s / img. ETA=12:05:18
[12/31 16:27:26] d2.evaluation.evaluator INFO: Inference done 3750/16850. 3.3093 s / img. ETA=12:02:31
[12/31 16:30:12] d2.evaluation.evaluator INFO: Inference done 3800/16850. 3.3094 s / img. ETA=11:59:47
[12/31 16:32:57] d2.evaluation.evaluator INFO: Inference done 3850/16850. 3.3094 s / img. ETA=11:57:02
[12/31 16:35:42] d2.evaluation.evaluator INFO: Inference done 3900/16850. 3.3093 s / img. ETA=11:54:15
[12/31 16:38:27] d2.evaluation.evaluator INFO: Inference done 3950/16850. 3.3092 s / img. ETA=11:51:28
[12/31 16:41:14] d2.evaluation.evaluator INFO: Inference done 4000/16850. 3.3094 s / img. ETA=11:48:45
[12/31 16:43:59] d2.evaluation.evaluator INFO: Inference done 4050/16850. 3.3094 s / img. ETA=11:45:59
[12/31 16:46:45] d2.evaluation.evaluator INFO: Inference done 4100/16850. 3.3094 s / img. ETA=11:43:14
[12/31 16:49:33] d2.evaluation.evaluator INFO: Inference done 4150/16850. 3.3101 s / img. ETA=11:40:38
[12/31 16:52:22] d2.evaluation.evaluator INFO: Inference done 4200/16850. 3.3109 s / img. ETA=11:38:02
[12/31 16:55:10] d2.evaluation.evaluator INFO: Inference done 4250/16850. 3.3115 s / img. ETA=11:35:24
[12/31 16:57:56] d2.evaluation.evaluator INFO: Inference done 4300/16850. 3.3117 s / img. ETA=11:32:42
[12/31 17:00:42] d2.evaluation.evaluator INFO: Inference done 4350/16850. 3.3116 s / img. ETA=11:29:54
[12/31 17:03:27] d2.evaluation.evaluator INFO: Inference done 4400/16850. 3.3116 s / img. ETA=11:27:09
[12/31 17:06:12] d2.evaluation.evaluator INFO: Inference done 4450/16850. 3.3115 s / img. ETA=11:24:22
[12/31 17:08:58] d2.evaluation.evaluator INFO: Inference done 4500/16850. 3.3115 s / img. ETA=11:21:37
[12/31 17:11:43] d2.evaluation.evaluator INFO: Inference done 4550/16850. 3.3115 s / img. ETA=11:18:50
[12/31 17:14:28] d2.evaluation.evaluator INFO: Inference done 4600/16850. 3.3114 s / img. ETA=11:16:04
[12/31 17:17:14] d2.evaluation.evaluator INFO: Inference done 4650/16850. 3.3113 s / img. ETA=11:13:17
[12/31 17:20:00] d2.evaluation.evaluator INFO: Inference done 4700/16850. 3.3114 s / img. ETA=11:10:33
[12/31 17:22:45] d2.evaluation.evaluator INFO: Inference done 4750/16850. 3.3113 s / img. ETA=11:07:46
[12/31 17:25:30] d2.evaluation.evaluator INFO: Inference done 4800/16850. 3.3113 s / img. ETA=11:05:00
[12/31 17:28:16] d2.evaluation.evaluator INFO: Inference done 4850/16850. 3.3112 s / img. ETA=11:02:14
[12/31 17:31:01] d2.evaluation.evaluator INFO: Inference done 4900/16850. 3.3113 s / img. ETA=10:59:29
[12/31 17:33:47] d2.evaluation.evaluator INFO: Inference done 4950/16850. 3.3112 s / img. ETA=10:56:43
[12/31 17:36:32] d2.evaluation.evaluator INFO: Inference done 5000/16850. 3.3112 s / img. ETA=10:53:57
[12/31 17:39:18] d2.evaluation.evaluator INFO: Inference done 5050/16850. 3.3113 s / img. ETA=10:51:12
[12/31 17:42:04] d2.evaluation.evaluator INFO: Inference done 5100/16850. 3.3113 s / img. ETA=10:48:27
[12/31 17:44:50] d2.evaluation.evaluator INFO: Inference done 5150/16850. 3.3115 s / img. ETA=10:45:44
[12/31 17:47:37] d2.evaluation.evaluator INFO: Inference done 5200/16850. 3.3116 s / img. ETA=10:43:00
[12/31 17:50:23] d2.evaluation.evaluator INFO: Inference done 5250/16850. 3.3117 s / img. ETA=10:40:16
[12/31 17:53:10] d2.evaluation.evaluator INFO: Inference done 5300/16850. 3.3121 s / img. ETA=10:37:34
[12/31 17:55:58] d2.evaluation.evaluator INFO: Inference done 5350/16850. 3.3126 s / img. ETA=10:34:54
[12/31 17:58:45] d2.evaluation.evaluator INFO: Inference done 5400/16850. 3.3128 s / img. ETA=10:32:11
[12/31 18:01:33] d2.evaluation.evaluator INFO: Inference done 5450/16850. 3.3131 s / img. ETA=10:29:29
[12/31 18:04:19] d2.evaluation.evaluator INFO: Inference done 5500/16850. 3.3133 s / img. ETA=10:26:45
[12/31 18:07:06] d2.evaluation.evaluator INFO: Inference done 5550/16850. 3.3135 s / img. ETA=10:24:02
[12/31 18:08:55] detectron2 INFO: Rank of current process: 0. World size: 2
[12/31 18:08:59] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[12/31 18:08:59] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[12/31 18:08:59] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: True   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_light",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 116368  ## 46368 74368(70000 最好) 96368(8500)  116368
  BASE_LR: 0.01     ### 
  STEPS: (116068, 116268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[12/31 18:08:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_light',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 116368
  MOMENTUM: 0.9
  STEPS: (116068, 116268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: True
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[12/31 18:08:59] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[12/31 18:08:59] d2.utils.env INFO: Using a generated random seed 59935365
[12/31 18:09:03] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[12/31 18:09:03] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0084999.pth
[12/31 18:09:04] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/31 18:09:04] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/31 18:09:05] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[12/31 18:09:06] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/31 18:10:05] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4850 s / img. ETA=2:15:47
[12/31 18:10:29] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4855 s / img. ETA=2:15:32
[12/31 18:10:54] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4857 s / img. ETA=2:15:11
[12/31 18:11:18] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4858 s / img. ETA=2:14:48
[12/31 18:11:42] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4857 s / img. ETA=2:14:22
[12/31 18:12:07] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4855 s / img. ETA=2:13:55
[12/31 18:12:31] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4858 s / img. ETA=2:13:35
[12/31 18:12:55] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4860 s / img. ETA=2:13:14
[12/31 18:13:20] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4865 s / img. ETA=2:12:58
[12/31 18:13:44] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4866 s / img. ETA=2:12:35
[12/31 18:14:08] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4863 s / img. ETA=2:12:06
[12/31 18:14:33] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4864 s / img. ETA=2:11:43
[12/31 18:14:57] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4863 s / img. ETA=2:11:17
[12/31 18:15:21] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4862 s / img. ETA=2:10:51
[12/31 18:15:46] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4863 s / img. ETA=2:10:29
[12/31 18:16:10] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4863 s / img. ETA=2:10:04
[12/31 18:16:34] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4863 s / img. ETA=2:09:40
[12/31 18:16:59] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4865 s / img. ETA=2:09:20
[12/31 18:17:23] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4867 s / img. ETA=2:08:58
[12/31 18:17:48] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4868 s / img. ETA=2:08:36
[12/31 18:18:12] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4869 s / img. ETA=2:08:12
[12/31 18:18:36] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4869 s / img. ETA=2:07:48
[12/31 18:19:01] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4869 s / img. ETA=2:07:24
[12/31 18:19:25] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4868 s / img. ETA=2:06:58
[12/31 18:19:49] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4868 s / img. ETA=2:06:33
[12/31 18:20:14] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4868 s / img. ETA=2:06:09
[12/31 18:20:38] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4869 s / img. ETA=2:05:46
[12/31 18:21:03] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4869 s / img. ETA=2:05:22
[12/31 18:21:27] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4867 s / img. ETA=2:04:55
[12/31 18:21:51] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4866 s / img. ETA=2:04:29
[12/31 18:22:15] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4865 s / img. ETA=2:04:02
[12/31 18:22:39] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4865 s / img. ETA=2:03:38
[12/31 18:23:04] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4865 s / img. ETA=2:03:14
[12/31 18:23:28] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4864 s / img. ETA=2:02:49
[12/31 18:23:52] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4865 s / img. ETA=2:02:25
[12/31 18:24:16] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4864 s / img. ETA=2:02:00
[12/31 18:24:41] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4864 s / img. ETA=2:01:36
[12/31 18:25:05] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4865 s / img. ETA=2:01:13
[12/31 18:25:30] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4867 s / img. ETA=2:00:51
[12/31 18:25:54] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4866 s / img. ETA=2:00:26
[12/31 18:26:18] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4866 s / img. ETA=2:00:01
[12/31 18:26:43] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4865 s / img. ETA=1:59:36
[12/31 18:27:07] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4865 s / img. ETA=1:59:12
[12/31 18:27:31] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4865 s / img. ETA=1:58:47
[12/31 18:27:56] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4865 s / img. ETA=1:58:23
[12/31 18:28:20] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4865 s / img. ETA=1:57:58
[12/31 18:28:44] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4865 s / img. ETA=1:57:33
[12/31 18:29:08] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4864 s / img. ETA=1:57:08
[12/31 18:29:33] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4864 s / img. ETA=1:56:43
[12/31 18:29:57] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4863 s / img. ETA=1:56:18
[12/31 18:30:21] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4863 s / img. ETA=1:55:54
[12/31 18:30:45] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4863 s / img. ETA=1:55:30
[12/31 18:31:10] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4864 s / img. ETA=1:55:06
[12/31 18:31:34] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4864 s / img. ETA=1:54:42
[12/31 18:31:59] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4864 s / img. ETA=1:54:18
[12/31 18:32:23] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4864 s / img. ETA=1:53:54
[12/31 18:32:47] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4864 s / img. ETA=1:53:29
[12/31 18:33:11] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4863 s / img. ETA=1:53:03
[12/31 18:33:35] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4862 s / img. ETA=1:52:38
[12/31 18:33:59] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4862 s / img. ETA=1:52:13
[12/31 18:34:24] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4862 s / img. ETA=1:51:48
[12/31 18:34:48] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4861 s / img. ETA=1:51:24
[12/31 18:35:12] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4861 s / img. ETA=1:50:59
[12/31 18:35:36] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4861 s / img. ETA=1:50:35
[12/31 18:36:01] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4861 s / img. ETA=1:50:11
[12/31 18:36:25] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4862 s / img. ETA=1:49:47
[12/31 18:36:49] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4861 s / img. ETA=1:49:22
[12/31 18:37:14] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4862 s / img. ETA=1:48:58
[12/31 18:37:38] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4862 s / img. ETA=1:48:34
[12/31 18:38:02] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4862 s / img. ETA=1:48:10
[12/31 18:38:27] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4862 s / img. ETA=1:47:46
[12/31 18:38:51] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4862 s / img. ETA=1:47:22
[12/31 18:39:16] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4863 s / img. ETA=1:46:58
[12/31 18:39:40] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4863 s / img. ETA=1:46:35
[12/31 18:40:05] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4864 s / img. ETA=1:46:12
[12/31 18:40:29] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4865 s / img. ETA=1:45:48
[12/31 18:40:54] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4864 s / img. ETA=1:45:23
[12/31 18:41:18] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4864 s / img. ETA=1:44:59
[12/31 18:41:42] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4864 s / img. ETA=1:44:35
[12/31 18:42:07] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4864 s / img. ETA=1:44:10
[12/31 18:42:31] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4864 s / img. ETA=1:43:45
[12/31 18:42:55] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4864 s / img. ETA=1:43:21
[12/31 18:43:19] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4863 s / img. ETA=1:42:56
[12/31 18:43:43] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4863 s / img. ETA=1:42:31
[12/31 18:44:07] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4862 s / img. ETA=1:42:06
[12/31 18:44:32] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4862 s / img. ETA=1:41:41
[12/31 18:44:56] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4862 s / img. ETA=1:41:17
[12/31 18:45:20] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4861 s / img. ETA=1:40:52
[12/31 18:45:44] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4861 s / img. ETA=1:40:27
[12/31 18:46:08] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4861 s / img. ETA=1:40:02
[12/31 18:46:32] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4860 s / img. ETA=1:39:38
[12/31 18:46:57] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4860 s / img. ETA=1:39:13
[12/31 18:47:21] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4860 s / img. ETA=1:38:49
[12/31 18:47:45] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4860 s / img. ETA=1:38:25
[12/31 18:48:10] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4860 s / img. ETA=1:38:00
[12/31 18:48:34] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4860 s / img. ETA=1:37:36
[12/31 18:48:58] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4860 s / img. ETA=1:37:11
[12/31 18:49:22] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4860 s / img. ETA=1:36:47
[12/31 18:49:46] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4860 s / img. ETA=1:36:23
[12/31 18:50:11] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4860 s / img. ETA=1:35:58
[12/31 18:50:35] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4859 s / img. ETA=1:35:33
[12/31 18:50:59] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4859 s / img. ETA=1:35:09
[12/31 18:51:23] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4859 s / img. ETA=1:34:45
[12/31 18:51:48] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4859 s / img. ETA=1:34:20
[12/31 18:52:12] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4859 s / img. ETA=1:33:56
[12/31 18:52:36] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4859 s / img. ETA=1:33:31
[12/31 18:53:00] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4858 s / img. ETA=1:33:06
[12/31 18:53:24] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4858 s / img. ETA=1:32:42
[12/31 18:53:49] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4858 s / img. ETA=1:32:18
[12/31 18:54:13] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4858 s / img. ETA=1:31:53
[12/31 18:54:37] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4858 s / img. ETA=1:31:29
[12/31 18:55:01] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4858 s / img. ETA=1:31:05
[12/31 18:55:26] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4858 s / img. ETA=1:30:40
[12/31 18:55:52] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4861 s / img. ETA=1:30:19
[12/31 18:56:16] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4860 s / img. ETA=1:29:55
[12/31 18:56:40] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4860 s / img. ETA=1:29:30
[12/31 18:57:04] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4860 s / img. ETA=1:29:06
[12/31 18:57:28] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4860 s / img. ETA=1:28:41
[12/31 18:57:52] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4860 s / img. ETA=1:28:17
[12/31 18:58:16] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4859 s / img. ETA=1:27:52
[12/31 18:58:40] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4859 s / img. ETA=1:27:27
[12/31 18:59:05] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4859 s / img. ETA=1:27:02
[12/31 18:59:29] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4858 s / img. ETA=1:26:38
[12/31 18:59:53] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4858 s / img. ETA=1:26:14
[12/31 19:00:17] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4858 s / img. ETA=1:25:49
[12/31 19:00:41] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4858 s / img. ETA=1:25:25
[12/31 19:01:05] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4858 s / img. ETA=1:25:00
[12/31 19:01:30] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4857 s / img. ETA=1:24:35
[12/31 19:01:54] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4857 s / img. ETA=1:24:11
[12/31 19:02:18] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4857 s / img. ETA=1:23:46
[12/31 19:02:42] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4857 s / img. ETA=1:23:22
[12/31 19:03:06] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4856 s / img. ETA=1:22:57
[12/31 19:03:30] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4856 s / img. ETA=1:22:33
[12/31 19:03:54] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4856 s / img. ETA=1:22:08
[12/31 19:04:18] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4856 s / img. ETA=1:21:44
[12/31 19:04:43] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4855 s / img. ETA=1:21:19
[12/31 19:05:07] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4855 s / img. ETA=1:20:55
[12/31 19:05:31] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4855 s / img. ETA=1:20:30
[12/31 19:05:55] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4855 s / img. ETA=1:20:06
[12/31 19:06:19] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4855 s / img. ETA=1:19:41
[12/31 19:06:43] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4855 s / img. ETA=1:19:17
[12/31 19:07:08] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4855 s / img. ETA=1:18:53
[12/31 19:07:32] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4855 s / img. ETA=1:18:29
[12/31 19:07:56] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4855 s / img. ETA=1:18:04
[12/31 19:08:21] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4855 s / img. ETA=1:17:40
[12/31 19:08:45] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4855 s / img. ETA=1:17:16
[12/31 19:09:09] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4855 s / img. ETA=1:16:51
[12/31 19:09:33] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4854 s / img. ETA=1:16:27
[12/31 19:09:57] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4854 s / img. ETA=1:16:02
[12/31 19:10:21] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4854 s / img. ETA=1:15:38
[12/31 19:10:45] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4854 s / img. ETA=1:15:13
[12/31 19:11:10] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4854 s / img. ETA=1:14:49
[12/31 19:11:34] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4853 s / img. ETA=1:14:24
[12/31 19:11:58] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4853 s / img. ETA=1:14:00
[12/31 19:12:22] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4853 s / img. ETA=1:13:36
[12/31 19:12:46] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4853 s / img. ETA=1:13:12
[12/31 19:13:10] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4853 s / img. ETA=1:12:47
[12/31 19:13:35] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4853 s / img. ETA=1:12:23
[12/31 19:13:59] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4853 s / img. ETA=1:11:59
[12/31 19:14:23] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4853 s / img. ETA=1:11:34
[12/31 19:14:47] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4853 s / img. ETA=1:11:10
[12/31 19:15:11] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4852 s / img. ETA=1:10:45
[12/31 19:15:36] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4852 s / img. ETA=1:10:21
[12/31 19:16:00] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4852 s / img. ETA=1:09:57
[12/31 19:16:24] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4852 s / img. ETA=1:09:32
[12/31 19:16:48] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4852 s / img. ETA=1:09:08
[12/31 19:17:12] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4852 s / img. ETA=1:08:44
[12/31 19:17:36] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4852 s / img. ETA=1:08:19
[12/31 19:18:01] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4852 s / img. ETA=1:07:55
[12/31 19:18:25] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4852 s / img. ETA=1:07:31
[12/31 19:18:49] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4852 s / img. ETA=1:07:06
[12/31 19:19:13] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4852 s / img. ETA=1:06:42
[12/31 19:19:37] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4852 s / img. ETA=1:06:18
[12/31 19:20:02] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4851 s / img. ETA=1:05:53
[12/31 19:20:26] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4851 s / img. ETA=1:05:29
[12/31 19:20:50] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4851 s / img. ETA=1:05:05
[12/31 19:21:14] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4851 s / img. ETA=1:04:40
[12/31 19:21:38] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4851 s / img. ETA=1:04:16
[12/31 19:22:02] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4851 s / img. ETA=1:03:52
[12/31 19:22:27] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4851 s / img. ETA=1:03:27
[12/31 19:22:51] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4851 s / img. ETA=1:03:03
[12/31 19:23:15] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4851 s / img. ETA=1:02:39
[12/31 19:23:40] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4851 s / img. ETA=1:02:15
[12/31 19:24:04] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4851 s / img. ETA=1:01:50
[12/31 19:24:28] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4851 s / img. ETA=1:01:26
[12/31 19:24:52] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4851 s / img. ETA=1:01:02
[12/31 19:25:16] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4851 s / img. ETA=1:00:38
[12/31 19:25:41] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4851 s / img. ETA=1:00:13
[12/31 19:26:05] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4851 s / img. ETA=0:59:49
[12/31 19:26:29] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4850 s / img. ETA=0:59:25
[12/31 19:26:53] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4851 s / img. ETA=0:59:01
[12/31 19:27:17] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4851 s / img. ETA=0:58:36
[12/31 19:27:42] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4851 s / img. ETA=0:58:12
[12/31 19:28:06] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4851 s / img. ETA=0:57:48
[12/31 19:28:30] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4851 s / img. ETA=0:57:23
[12/31 19:28:54] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4850 s / img. ETA=0:56:59
[12/31 19:29:18] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4850 s / img. ETA=0:56:35
[12/31 19:29:42] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4850 s / img. ETA=0:56:10
[12/31 19:30:06] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4850 s / img. ETA=0:55:46
[12/31 19:30:31] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4850 s / img. ETA=0:55:22
[12/31 19:30:55] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4850 s / img. ETA=0:54:58
[12/31 19:31:19] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4850 s / img. ETA=0:54:33
[12/31 19:31:44] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4850 s / img. ETA=0:54:09
[12/31 19:32:08] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4850 s / img. ETA=0:53:45
[12/31 19:32:32] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4850 s / img. ETA=0:53:20
[12/31 19:32:56] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4849 s / img. ETA=0:52:56
[12/31 19:33:20] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4849 s / img. ETA=0:52:32
[12/31 19:33:44] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4849 s / img. ETA=0:52:07
[12/31 19:34:08] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4849 s / img. ETA=0:51:43
[12/31 19:34:32] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4849 s / img. ETA=0:51:19
[12/31 19:34:57] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4849 s / img. ETA=0:50:54
[12/31 19:35:21] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4849 s / img. ETA=0:50:30
[12/31 19:35:45] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4849 s / img. ETA=0:50:06
[12/31 19:36:09] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4849 s / img. ETA=0:49:41
[12/31 19:36:33] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4848 s / img. ETA=0:49:17
[12/31 19:36:57] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4848 s / img. ETA=0:48:53
[12/31 19:37:21] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4848 s / img. ETA=0:48:28
[12/31 19:37:45] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4848 s / img. ETA=0:48:04
[12/31 19:38:09] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4848 s / img. ETA=0:47:40
[12/31 19:38:34] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4848 s / img. ETA=0:47:16
[12/31 19:38:58] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4848 s / img. ETA=0:46:51
[12/31 19:39:22] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4848 s / img. ETA=0:46:27
[12/31 19:39:46] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4847 s / img. ETA=0:46:03
[12/31 19:40:10] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4847 s / img. ETA=0:45:38
[12/31 19:40:34] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4847 s / img. ETA=0:45:14
[12/31 19:40:59] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4847 s / img. ETA=0:44:50
[12/31 19:41:23] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4848 s / img. ETA=0:44:26
[12/31 19:41:47] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4848 s / img. ETA=0:44:01
[12/31 19:42:11] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4847 s / img. ETA=0:43:37
[12/31 19:42:35] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4847 s / img. ETA=0:43:13
[12/31 19:42:59] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4847 s / img. ETA=0:42:49
[12/31 19:43:24] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4847 s / img. ETA=0:42:24
[12/31 19:43:48] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4847 s / img. ETA=0:42:00
[12/31 19:44:12] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4847 s / img. ETA=0:41:36
[12/31 19:44:36] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4847 s / img. ETA=0:41:11
[12/31 19:45:00] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4847 s / img. ETA=0:40:47
[12/31 19:45:24] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4847 s / img. ETA=0:40:23
[12/31 19:45:49] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4847 s / img. ETA=0:39:59
[12/31 19:46:13] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4847 s / img. ETA=0:39:34
[12/31 19:46:37] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4847 s / img. ETA=0:39:10
[12/31 19:47:01] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4847 s / img. ETA=0:38:46
[12/31 19:47:25] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4846 s / img. ETA=0:38:22
[12/31 19:47:49] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4847 s / img. ETA=0:37:57
[12/31 19:48:14] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4847 s / img. ETA=0:37:33
[12/31 19:48:38] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4846 s / img. ETA=0:37:09
[12/31 19:49:02] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4846 s / img. ETA=0:36:45
[12/31 19:49:26] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4846 s / img. ETA=0:36:20
[12/31 19:49:50] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4846 s / img. ETA=0:35:56
[12/31 19:50:14] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4846 s / img. ETA=0:35:32
[12/31 19:50:38] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4846 s / img. ETA=0:35:07
[12/31 19:51:02] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4846 s / img. ETA=0:34:43
[12/31 19:51:26] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4846 s / img. ETA=0:34:19
[12/31 19:51:51] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4846 s / img. ETA=0:33:55
[12/31 19:52:15] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4846 s / img. ETA=0:33:30
[12/31 19:52:39] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4846 s / img. ETA=0:33:06
[12/31 19:53:03] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4845 s / img. ETA=0:32:42
[12/31 19:53:27] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4845 s / img. ETA=0:32:18
[12/31 19:53:51] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4845 s / img. ETA=0:31:53
[12/31 19:54:16] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4845 s / img. ETA=0:31:29
[12/31 19:54:40] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4845 s / img. ETA=0:31:05
[12/31 19:55:04] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4845 s / img. ETA=0:30:41
[12/31 19:55:28] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4845 s / img. ETA=0:30:17
[12/31 19:55:54] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4847 s / img. ETA=0:29:53
[12/31 19:56:19] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4847 s / img. ETA=0:29:29
[12/31 19:56:43] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4847 s / img. ETA=0:29:04
[12/31 19:57:07] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4847 s / img. ETA=0:28:40
[12/31 19:57:31] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4847 s / img. ETA=0:28:16
[12/31 19:57:55] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4847 s / img. ETA=0:27:52
[12/31 19:58:20] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4847 s / img. ETA=0:27:27
[12/31 19:58:44] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4847 s / img. ETA=0:27:03
[12/31 19:59:08] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4847 s / img. ETA=0:26:39
[12/31 19:59:32] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4847 s / img. ETA=0:26:15
[12/31 19:59:56] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4846 s / img. ETA=0:25:50
[12/31 20:00:20] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4846 s / img. ETA=0:25:26
[12/31 20:00:45] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4846 s / img. ETA=0:25:02
[12/31 20:01:09] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4846 s / img. ETA=0:24:38
[12/31 20:01:33] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4846 s / img. ETA=0:24:13
[12/31 20:01:57] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4846 s / img. ETA=0:23:49
[12/31 20:02:21] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4846 s / img. ETA=0:23:25
[12/31 20:02:45] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4846 s / img. ETA=0:23:01
[12/31 20:03:10] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4846 s / img. ETA=0:22:36
[12/31 20:03:34] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4846 s / img. ETA=0:22:12
[12/31 20:03:58] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4846 s / img. ETA=0:21:48
[12/31 20:04:22] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4846 s / img. ETA=0:21:24
[12/31 20:04:46] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4846 s / img. ETA=0:20:59
[12/31 20:05:10] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4846 s / img. ETA=0:20:35
[12/31 20:05:34] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4846 s / img. ETA=0:20:11
[12/31 20:05:59] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4846 s / img. ETA=0:19:47
[12/31 20:06:23] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4846 s / img. ETA=0:19:22
[12/31 20:06:47] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4845 s / img. ETA=0:18:58
[12/31 20:07:11] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4845 s / img. ETA=0:18:34
[12/31 20:07:35] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4845 s / img. ETA=0:18:10
[12/31 20:07:59] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4845 s / img. ETA=0:17:45
[12/31 20:08:23] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4845 s / img. ETA=0:17:21
[12/31 20:08:47] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4845 s / img. ETA=0:16:57
[12/31 20:09:11] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4845 s / img. ETA=0:16:33
[12/31 20:09:36] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4845 s / img. ETA=0:16:09
[12/31 20:10:00] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4845 s / img. ETA=0:15:44
[12/31 20:10:24] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4845 s / img. ETA=0:15:20
[12/31 20:10:48] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4845 s / img. ETA=0:14:56
[12/31 20:11:12] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4845 s / img. ETA=0:14:32
[12/31 20:11:37] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4845 s / img. ETA=0:14:07
[12/31 20:12:01] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4845 s / img. ETA=0:13:43
[12/31 20:12:25] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4845 s / img. ETA=0:13:19
[12/31 20:12:49] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4845 s / img. ETA=0:12:55
[12/31 20:13:13] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4845 s / img. ETA=0:12:30
[12/31 20:13:38] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4845 s / img. ETA=0:12:06
[12/31 20:14:02] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4845 s / img. ETA=0:11:42
[12/31 20:14:26] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4845 s / img. ETA=0:11:18
[12/31 20:14:50] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4845 s / img. ETA=0:10:54
[12/31 20:15:14] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4845 s / img. ETA=0:10:29
[12/31 20:15:38] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4845 s / img. ETA=0:10:05
[12/31 20:16:03] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4844 s / img. ETA=0:09:41
[12/31 20:16:27] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4844 s / img. ETA=0:09:17
[12/31 20:16:51] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4844 s / img. ETA=0:08:52
[12/31 20:17:15] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4844 s / img. ETA=0:08:28
[12/31 20:17:39] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4844 s / img. ETA=0:08:04
[12/31 20:18:03] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4844 s / img. ETA=0:07:40
[12/31 20:18:27] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4844 s / img. ETA=0:07:15
[12/31 20:18:52] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4844 s / img. ETA=0:06:51
[12/31 20:19:16] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4844 s / img. ETA=0:06:27
[12/31 20:19:40] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4844 s / img. ETA=0:06:03
[12/31 20:20:04] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4844 s / img. ETA=0:05:39
[12/31 20:20:28] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4844 s / img. ETA=0:05:14
[12/31 20:20:52] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4844 s / img. ETA=0:04:50
[12/31 20:21:17] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4844 s / img. ETA=0:04:26
[12/31 20:21:41] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4844 s / img. ETA=0:04:02
[12/31 20:22:05] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4844 s / img. ETA=0:03:37
[12/31 20:22:29] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4844 s / img. ETA=0:03:13
[12/31 20:22:53] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4844 s / img. ETA=0:02:49
[12/31 20:23:17] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4844 s / img. ETA=0:02:25
[12/31 20:23:41] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4844 s / img. ETA=0:02:01
[12/31 20:24:05] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4843 s / img. ETA=0:01:36
[12/31 20:24:30] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4844 s / img. ETA=0:01:12
[12/31 20:24:54] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4844 s / img. ETA=0:00:48
[12/31 20:25:18] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4844 s / img. ETA=0:00:24
[12/31 20:25:42] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4844 s / img. ETA=0:00:00
[12/31 20:25:43] d2.evaluation.evaluator INFO: Total inference time: 2:15:59 (0.484357 s / img per device, on 2 devices)
[12/31 20:25:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:15:06 (0.481233 s / img per device, on 2 devices)
[12/31 20:25:46] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[12/31 20:25:46] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[12/31 20:25:46] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[12/31 20:26:17] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[12/31 20:26:17] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[12/31 20:26:18] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[12/31 20:26:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[12/31 20:26:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[12/31 20:26:18] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[12/31 20:26:18] d2.trainer INFO: Running inference with test-time augmentation ...
[12/31 20:26:18] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[12/31 20:26:18] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[12/31 20:26:19] d2.evaluation.evaluator INFO: Start inference on 16850 images
[12/31 20:29:41] d2.evaluation.evaluator INFO: Inference done 50/16850. 3.3015 s / img. ETA=15:24:24
[12/31 20:32:26] d2.evaluation.evaluator INFO: Inference done 100/16850. 3.3022 s / img. ETA=15:21:51
[12/31 20:35:11] d2.evaluation.evaluator INFO: Inference done 150/16850. 3.3022 s / img. ETA=15:19:06
[12/31 20:37:56] d2.evaluation.evaluator INFO: Inference done 200/16850. 3.3012 s / img. ETA=15:16:04
[12/31 20:40:41] d2.evaluation.evaluator INFO: Inference done 250/16850. 3.3008 s / img. ETA=15:13:12
[12/31 20:43:27] d2.evaluation.evaluator INFO: Inference done 300/16850. 3.3037 s / img. ETA=15:11:15
[12/31 20:46:14] d2.evaluation.evaluator INFO: Inference done 350/16850. 3.3084 s / img. ETA=15:09:49
[12/31 20:49:01] d2.evaluation.evaluator INFO: Inference done 400/16850. 3.3127 s / img. ETA=15:08:14
[12/31 20:51:48] d2.evaluation.evaluator INFO: Inference done 450/16850. 3.3155 s / img. ETA=15:06:13
[12/31 20:54:34] d2.evaluation.evaluator INFO: Inference done 500/16850. 3.3169 s / img. ETA=15:03:50
[12/31 20:57:22] d2.evaluation.evaluator INFO: Inference done 550/16850. 3.3213 s / img. ETA=15:02:16
[12/31 21:00:09] d2.evaluation.evaluator INFO: Inference done 600/16850. 3.3218 s / img. ETA=14:59:39
[12/31 21:02:55] d2.evaluation.evaluator INFO: Inference done 650/16850. 3.3223 s / img. ETA=14:57:01
[12/31 21:05:42] d2.evaluation.evaluator INFO: Inference done 700/16850. 3.3234 s / img. ETA=14:54:33
[12/31 21:08:29] d2.evaluation.evaluator INFO: Inference done 750/16850. 3.3243 s / img. ETA=14:52:01
[12/31 21:11:16] d2.evaluation.evaluator INFO: Inference done 800/16850. 3.3250 s / img. ETA=14:49:26
[12/31 21:14:02] d2.evaluation.evaluator INFO: Inference done 850/16850. 3.3256 s / img. ETA=14:46:49
[12/31 21:16:49] d2.evaluation.evaluator INFO: Inference done 900/16850. 3.3258 s / img. ETA=14:44:06
[12/31 21:19:36] d2.evaluation.evaluator INFO: Inference done 950/16850. 3.3263 s / img. ETA=14:41:28
[12/31 21:22:22] d2.evaluation.evaluator INFO: Inference done 1000/16850. 3.3268 s / img. ETA=14:38:49
[12/31 21:25:09] d2.evaluation.evaluator INFO: Inference done 1050/16850. 3.3267 s / img. ETA=14:36:01
[12/31 21:27:55] d2.evaluation.evaluator INFO: Inference done 1100/16850. 3.3271 s / img. ETA=14:33:21
[12/31 21:30:42] d2.evaluation.evaluator INFO: Inference done 1150/16850. 3.3270 s / img. ETA=14:30:34
[12/31 21:33:27] d2.evaluation.evaluator INFO: Inference done 1200/16850. 3.3259 s / img. ETA=14:27:30
[12/31 21:36:12] d2.evaluation.evaluator INFO: Inference done 1250/16850. 3.3249 s / img. ETA=14:24:27
[12/31 21:38:57] d2.evaluation.evaluator INFO: Inference done 1300/16850. 3.3242 s / img. ETA=14:21:31
[12/31 21:41:42] d2.evaluation.evaluator INFO: Inference done 1350/16850. 3.3234 s / img. ETA=14:18:33
[12/31 21:44:27] d2.evaluation.evaluator INFO: Inference done 1400/16850. 3.3226 s / img. ETA=14:15:34
[12/31 21:47:12] d2.evaluation.evaluator INFO: Inference done 1450/16850. 3.3218 s / img. ETA=14:12:35
[12/31 21:49:59] d2.evaluation.evaluator INFO: Inference done 1500/16850. 3.3220 s / img. ETA=14:09:52
[12/31 21:52:45] d2.evaluation.evaluator INFO: Inference done 1550/16850. 3.3223 s / img. ETA=14:07:11
[12/31 21:55:32] d2.evaluation.evaluator INFO: Inference done 1600/16850. 3.3227 s / img. ETA=14:04:30
[12/31 21:58:20] d2.evaluation.evaluator INFO: Inference done 1650/16850. 3.3239 s / img. ETA=14:02:03
[12/31 22:01:07] d2.evaluation.evaluator INFO: Inference done 1700/16850. 3.3242 s / img. ETA=13:59:22
[12/31 22:03:53] d2.evaluation.evaluator INFO: Inference done 1750/16850. 3.3244 s / img. ETA=13:56:38
[12/31 22:06:39] d2.evaluation.evaluator INFO: Inference done 1800/16850. 3.3239 s / img. ETA=13:53:44
[12/31 22:09:23] d2.evaluation.evaluator INFO: Inference done 1850/16850. 3.3231 s / img. ETA=13:50:45
[12/31 22:12:08] d2.evaluation.evaluator INFO: Inference done 1900/16850. 3.3224 s / img. ETA=13:47:50
[12/31 22:14:54] d2.evaluation.evaluator INFO: Inference done 1950/16850. 3.3221 s / img. ETA=13:44:59
[12/31 22:17:39] d2.evaluation.evaluator INFO: Inference done 2000/16850. 3.3215 s / img. ETA=13:42:04
[12/31 22:20:24] d2.evaluation.evaluator INFO: Inference done 2050/16850. 3.3212 s / img. ETA=13:39:13
[12/31 22:23:09] d2.evaluation.evaluator INFO: Inference done 2100/16850. 3.3206 s / img. ETA=13:36:18
[12/31 22:25:54] d2.evaluation.evaluator INFO: Inference done 2150/16850. 3.3202 s / img. ETA=13:33:26
[12/31 22:28:41] d2.evaluation.evaluator INFO: Inference done 2200/16850. 3.3206 s / img. ETA=13:30:46
[12/31 22:31:27] d2.evaluation.evaluator INFO: Inference done 2250/16850. 3.3207 s / img. ETA=13:28:02
[12/31 22:34:14] d2.evaluation.evaluator INFO: Inference done 2300/16850. 3.3211 s / img. ETA=13:25:21
[12/31 22:37:01] d2.evaluation.evaluator INFO: Inference done 2350/16850. 3.3214 s / img. ETA=13:22:40
[12/31 22:39:48] d2.evaluation.evaluator INFO: Inference done 2400/16850. 3.3217 s / img. ETA=13:19:58
[12/31 22:42:35] d2.evaluation.evaluator INFO: Inference done 2450/16850. 3.3220 s / img. ETA=13:17:16
[12/31 22:45:21] d2.evaluation.evaluator INFO: Inference done 2500/16850. 3.3223 s / img. ETA=13:14:34
[12/31 22:48:08] d2.evaluation.evaluator INFO: Inference done 2550/16850. 3.3226 s / img. ETA=13:11:52
[12/31 22:50:55] d2.evaluation.evaluator INFO: Inference done 2600/16850. 3.3228 s / img. ETA=13:09:09
[12/31 22:53:42] d2.evaluation.evaluator INFO: Inference done 2650/16850. 3.3230 s / img. ETA=13:06:26
[12/31 22:56:30] d2.evaluation.evaluator INFO: Inference done 2700/16850. 3.3238 s / img. ETA=13:03:51
[12/31 22:59:15] d2.evaluation.evaluator INFO: Inference done 2750/16850. 3.3233 s / img. ETA=13:00:59
[12/31 23:02:00] d2.evaluation.evaluator INFO: Inference done 2800/16850. 3.3230 s / img. ETA=12:58:08
[12/31 23:04:46] d2.evaluation.evaluator INFO: Inference done 2850/16850. 3.3228 s / img. ETA=12:55:19
[12/31 23:07:31] d2.evaluation.evaluator INFO: Inference done 2900/16850. 3.3225 s / img. ETA=12:52:29
[12/31 23:10:16] d2.evaluation.evaluator INFO: Inference done 2950/16850. 3.3221 s / img. ETA=12:49:37
[12/31 23:13:01] d2.evaluation.evaluator INFO: Inference done 3000/16850. 3.3217 s / img. ETA=12:46:45
[12/31 23:15:46] d2.evaluation.evaluator INFO: Inference done 3050/16850. 3.3214 s / img. ETA=12:43:55
[12/31 23:18:31] d2.evaluation.evaluator INFO: Inference done 3100/16850. 3.3212 s / img. ETA=12:41:06
[12/31 23:21:17] d2.evaluation.evaluator INFO: Inference done 3150/16850. 3.3209 s / img. ETA=12:38:16
[12/31 23:24:03] d2.evaluation.evaluator INFO: Inference done 3200/16850. 3.3209 s / img. ETA=12:35:30
[12/31 23:26:48] d2.evaluation.evaluator INFO: Inference done 3250/16850. 3.3207 s / img. ETA=12:32:41
[12/31 23:29:33] d2.evaluation.evaluator INFO: Inference done 3300/16850. 3.3205 s / img. ETA=12:29:53
[12/31 23:32:21] d2.evaluation.evaluator INFO: Inference done 3350/16850. 3.3209 s / img. ETA=12:27:11
[12/31 23:35:06] d2.evaluation.evaluator INFO: Inference done 3400/16850. 3.3206 s / img. ETA=12:24:22
[12/31 23:37:52] d2.evaluation.evaluator INFO: Inference done 3450/16850. 3.3207 s / img. ETA=12:21:37
[12/31 23:40:37] d2.evaluation.evaluator INFO: Inference done 3500/16850. 3.3203 s / img. ETA=12:18:46
[12/31 23:43:22] d2.evaluation.evaluator INFO: Inference done 3550/16850. 3.3200 s / img. ETA=12:15:55
[12/31 23:46:07] d2.evaluation.evaluator INFO: Inference done 3600/16850. 3.3197 s / img. ETA=12:13:05
[12/31 23:48:52] d2.evaluation.evaluator INFO: Inference done 3650/16850. 3.3197 s / img. ETA=12:10:19
[12/31 23:51:37] d2.evaluation.evaluator INFO: Inference done 3700/16850. 3.3194 s / img. ETA=12:07:30
[12/31 23:54:22] d2.evaluation.evaluator INFO: Inference done 3750/16850. 3.3191 s / img. ETA=12:04:40
[12/31 23:57:10] d2.evaluation.evaluator INFO: Inference done 3800/16850. 3.3195 s / img. ETA=12:01:59
[12/31 23:59:55] d2.evaluation.evaluator INFO: Inference done 3850/16850. 3.3192 s / img. ETA=11:59:09
[01/01 00:02:40] d2.evaluation.evaluator INFO: Inference done 3900/16850. 3.3190 s / img. ETA=11:56:20
[01/01 00:05:26] d2.evaluation.evaluator INFO: Inference done 3950/16850. 3.3190 s / img. ETA=11:53:34
[01/01 00:08:12] d2.evaluation.evaluator INFO: Inference done 4000/16850. 3.3190 s / img. ETA=11:50:49
[01/01 00:10:58] d2.evaluation.evaluator INFO: Inference done 4050/16850. 3.3191 s / img. ETA=11:48:04
[01/01 00:13:44] d2.evaluation.evaluator INFO: Inference done 4100/16850. 3.3191 s / img. ETA=11:45:18
[01/01 00:16:30] d2.evaluation.evaluator INFO: Inference done 4150/16850. 3.3192 s / img. ETA=11:42:33
[01/01 00:19:17] d2.evaluation.evaluator INFO: Inference done 4200/16850. 3.3193 s / img. ETA=11:39:48
[01/01 00:22:02] d2.evaluation.evaluator INFO: Inference done 4250/16850. 3.3192 s / img. ETA=11:37:01
[01/01 00:24:49] d2.evaluation.evaluator INFO: Inference done 4300/16850. 3.3193 s / img. ETA=11:34:16
[01/01 00:27:35] d2.evaluation.evaluator INFO: Inference done 4350/16850. 3.3193 s / img. ETA=11:31:31
[01/01 00:30:21] d2.evaluation.evaluator INFO: Inference done 4400/16850. 3.3193 s / img. ETA=11:28:45
[01/01 00:33:07] d2.evaluation.evaluator INFO: Inference done 4450/16850. 3.3195 s / img. ETA=11:26:01
[01/01 00:35:54] d2.evaluation.evaluator INFO: Inference done 4500/16850. 3.3196 s / img. ETA=11:23:17
[01/01 00:38:40] d2.evaluation.evaluator INFO: Inference done 4550/16850. 3.3197 s / img. ETA=11:20:32
[01/01 00:41:27] d2.evaluation.evaluator INFO: Inference done 4600/16850. 3.3198 s / img. ETA=11:17:47
[01/01 00:44:13] d2.evaluation.evaluator INFO: Inference done 4650/16850. 3.3198 s / img. ETA=11:15:02
[01/01 00:46:58] d2.evaluation.evaluator INFO: Inference done 4700/16850. 3.3197 s / img. ETA=11:12:14
[01/01 00:49:44] d2.evaluation.evaluator INFO: Inference done 4750/16850. 3.3196 s / img. ETA=11:09:27
[01/01 00:52:29] d2.evaluation.evaluator INFO: Inference done 4800/16850. 3.3195 s / img. ETA=11:06:39
[01/01 00:55:15] d2.evaluation.evaluator INFO: Inference done 4850/16850. 3.3194 s / img. ETA=11:03:52
[01/01 00:58:02] d2.evaluation.evaluator INFO: Inference done 4900/16850. 3.3196 s / img. ETA=11:01:08
[01/01 01:00:47] d2.evaluation.evaluator INFO: Inference done 4950/16850. 3.3195 s / img. ETA=10:58:22
[01/01 01:03:33] d2.evaluation.evaluator INFO: Inference done 5000/16850. 3.3194 s / img. ETA=10:55:35
[01/01 01:06:18] d2.evaluation.evaluator INFO: Inference done 5050/16850. 3.3193 s / img. ETA=10:52:47
[01/01 01:09:04] d2.evaluation.evaluator INFO: Inference done 5100/16850. 3.3192 s / img. ETA=10:50:00
[01/01 01:11:50] d2.evaluation.evaluator INFO: Inference done 5150/16850. 3.3192 s / img. ETA=10:47:14
[01/01 01:14:35] d2.evaluation.evaluator INFO: Inference done 5200/16850. 3.3191 s / img. ETA=10:44:27
[01/01 01:17:20] d2.evaluation.evaluator INFO: Inference done 5250/16850. 3.3189 s / img. ETA=10:41:39
[01/01 01:20:05] d2.evaluation.evaluator INFO: Inference done 5300/16850. 3.3188 s / img. ETA=10:38:52
[01/01 01:22:50] d2.evaluation.evaluator INFO: Inference done 5350/16850. 3.3186 s / img. ETA=10:36:04
[01/01 01:25:36] d2.evaluation.evaluator INFO: Inference done 5400/16850. 3.3186 s / img. ETA=10:33:18
[01/01 01:28:23] d2.evaluation.evaluator INFO: Inference done 5450/16850. 3.3187 s / img. ETA=10:30:33
[01/01 01:31:09] d2.evaluation.evaluator INFO: Inference done 5500/16850. 3.3189 s / img. ETA=10:27:49
[01/01 01:33:56] d2.evaluation.evaluator INFO: Inference done 5550/16850. 3.3190 s / img. ETA=10:25:05
[01/01 01:36:44] d2.evaluation.evaluator INFO: Inference done 5600/16850. 3.3193 s / img. ETA=10:22:21
[01/01 01:39:30] d2.evaluation.evaluator INFO: Inference done 5650/16850. 3.3194 s / img. ETA=10:19:37
[01/01 01:42:17] d2.evaluation.evaluator INFO: Inference done 5700/16850. 3.3195 s / img. ETA=10:16:52
[01/01 01:45:04] d2.evaluation.evaluator INFO: Inference done 5750/16850. 3.3196 s / img. ETA=10:14:07
[01/01 01:47:50] d2.evaluation.evaluator INFO: Inference done 5800/16850. 3.3196 s / img. ETA=10:11:22
[01/01 01:50:37] d2.evaluation.evaluator INFO: Inference done 5850/16850. 3.3198 s / img. ETA=10:08:38
[01/01 01:53:23] d2.evaluation.evaluator INFO: Inference done 5900/16850. 3.3199 s / img. ETA=10:05:53
[01/01 01:56:11] d2.evaluation.evaluator INFO: Inference done 5950/16850. 3.3203 s / img. ETA=10:03:11
[01/01 01:58:58] d2.evaluation.evaluator INFO: Inference done 6000/16850. 3.3203 s / img. ETA=10:00:25
[01/01 02:01:43] d2.evaluation.evaluator INFO: Inference done 6050/16850. 3.3202 s / img. ETA=9:57:37
[01/01 02:04:27] d2.evaluation.evaluator INFO: Inference done 6100/16850. 3.3200 s / img. ETA=9:54:49
[01/01 02:07:13] d2.evaluation.evaluator INFO: Inference done 6150/16850. 3.3198 s / img. ETA=9:52:02
[01/01 02:09:58] d2.evaluation.evaluator INFO: Inference done 6200/16850. 3.3197 s / img. ETA=9:49:15
[01/01 02:12:43] d2.evaluation.evaluator INFO: Inference done 6250/16850. 3.3196 s / img. ETA=9:46:27
[01/01 02:15:28] d2.evaluation.evaluator INFO: Inference done 6300/16850. 3.3194 s / img. ETA=9:43:39
[01/01 02:18:13] d2.evaluation.evaluator INFO: Inference done 6350/16850. 3.3193 s / img. ETA=9:40:52
[01/01 02:20:59] d2.evaluation.evaluator INFO: Inference done 6400/16850. 3.3192 s / img. ETA=9:38:05
[01/01 02:23:45] d2.evaluation.evaluator INFO: Inference done 6450/16850. 3.3193 s / img. ETA=9:35:20
[01/01 02:26:32] d2.evaluation.evaluator INFO: Inference done 6500/16850. 3.3194 s / img. ETA=9:32:36
[01/01 02:29:18] d2.evaluation.evaluator INFO: Inference done 6550/16850. 3.3195 s / img. ETA=9:29:50
[01/01 02:32:05] d2.evaluation.evaluator INFO: Inference done 6600/16850. 3.3197 s / img. ETA=9:27:06
[01/01 02:34:53] d2.evaluation.evaluator INFO: Inference done 6650/16850. 3.3198 s / img. ETA=9:24:22
[01/01 02:37:40] d2.evaluation.evaluator INFO: Inference done 6700/16850. 3.3200 s / img. ETA=9:21:38
[01/01 02:40:27] d2.evaluation.evaluator INFO: Inference done 6750/16850. 3.3201 s / img. ETA=9:18:53
[01/01 02:43:14] d2.evaluation.evaluator INFO: Inference done 6800/16850. 3.3203 s / img. ETA=9:16:09
[01/01 02:46:01] d2.evaluation.evaluator INFO: Inference done 6850/16850. 3.3204 s / img. ETA=9:13:24
[01/01 02:48:47] d2.evaluation.evaluator INFO: Inference done 6900/16850. 3.3204 s / img. ETA=9:10:38
[01/01 02:51:32] d2.evaluation.evaluator INFO: Inference done 6950/16850. 3.3203 s / img. ETA=9:07:51
[01/01 02:54:17] d2.evaluation.evaluator INFO: Inference done 7000/16850. 3.3202 s / img. ETA=9:05:04
[01/01 02:57:04] d2.evaluation.evaluator INFO: Inference done 7050/16850. 3.3204 s / img. ETA=9:02:19
[01/01 02:59:50] d2.evaluation.evaluator INFO: Inference done 7100/16850. 3.3203 s / img. ETA=8:59:33
[01/01 03:02:36] d2.evaluation.evaluator INFO: Inference done 7150/16850. 3.3204 s / img. ETA=8:56:47
[01/01 03:05:23] d2.evaluation.evaluator INFO: Inference done 7200/16850. 3.3204 s / img. ETA=8:54:02
[01/01 03:08:09] d2.evaluation.evaluator INFO: Inference done 7250/16850. 3.3205 s / img. ETA=8:51:16
[01/01 03:10:56] d2.evaluation.evaluator INFO: Inference done 7300/16850. 3.3205 s / img. ETA=8:48:31
[01/01 03:13:42] d2.evaluation.evaluator INFO: Inference done 7350/16850. 3.3205 s / img. ETA=8:45:45
[01/01 03:16:26] d2.evaluation.evaluator INFO: Inference done 7400/16850. 3.3203 s / img. ETA=8:42:57
[01/01 03:19:11] d2.evaluation.evaluator INFO: Inference done 7450/16850. 3.3202 s / img. ETA=8:40:09
[01/01 03:21:56] d2.evaluation.evaluator INFO: Inference done 7500/16850. 3.3201 s / img. ETA=8:37:22
[01/01 03:24:41] d2.evaluation.evaluator INFO: Inference done 7550/16850. 3.3199 s / img. ETA=8:34:35
[01/01 03:27:27] d2.evaluation.evaluator INFO: Inference done 7600/16850. 3.3199 s / img. ETA=8:31:49
[01/01 03:30:14] d2.evaluation.evaluator INFO: Inference done 7650/16850. 3.3200 s / img. ETA=8:29:03
[01/01 03:33:00] d2.evaluation.evaluator INFO: Inference done 7700/16850. 3.3200 s / img. ETA=8:26:18
[01/01 03:35:46] d2.evaluation.evaluator INFO: Inference done 7750/16850. 3.3200 s / img. ETA=8:23:32
[01/01 03:38:33] d2.evaluation.evaluator INFO: Inference done 7800/16850. 3.3201 s / img. ETA=8:20:46
[01/01 03:41:19] d2.evaluation.evaluator INFO: Inference done 7850/16850. 3.3202 s / img. ETA=8:18:01
[01/01 03:44:05] d2.evaluation.evaluator INFO: Inference done 7900/16850. 3.3202 s / img. ETA=8:15:15
[01/01 03:46:52] d2.evaluation.evaluator INFO: Inference done 7950/16850. 3.3202 s / img. ETA=8:12:30
[01/01 03:49:38] d2.evaluation.evaluator INFO: Inference done 8000/16850. 3.3203 s / img. ETA=8:09:44
[01/01 03:52:25] d2.evaluation.evaluator INFO: Inference done 8050/16850. 3.3204 s / img. ETA=8:06:59
[01/01 03:55:11] d2.evaluation.evaluator INFO: Inference done 8100/16850. 3.3204 s / img. ETA=8:04:13
[01/01 03:57:58] d2.evaluation.evaluator INFO: Inference done 8150/16850. 3.3205 s / img. ETA=8:01:28
[01/01 04:00:44] d2.evaluation.evaluator INFO: Inference done 8200/16850. 3.3205 s / img. ETA=7:58:42
[01/01 04:03:31] d2.evaluation.evaluator INFO: Inference done 8250/16850. 3.3206 s / img. ETA=7:55:57
[01/01 04:06:17] d2.evaluation.evaluator INFO: Inference done 8300/16850. 3.3206 s / img. ETA=7:53:11
[01/01 04:09:03] d2.evaluation.evaluator INFO: Inference done 8350/16850. 3.3207 s / img. ETA=7:50:25
[01/01 04:11:50] d2.evaluation.evaluator INFO: Inference done 8400/16850. 3.3207 s / img. ETA=7:47:40
[01/01 04:14:36] d2.evaluation.evaluator INFO: Inference done 8450/16850. 3.3207 s / img. ETA=7:44:54
[01/01 04:17:22] d2.evaluation.evaluator INFO: Inference done 8500/16850. 3.3207 s / img. ETA=7:42:08
[01/01 04:20:08] d2.evaluation.evaluator INFO: Inference done 8550/16850. 3.3207 s / img. ETA=7:39:21
[01/01 04:22:53] d2.evaluation.evaluator INFO: Inference done 8600/16850. 3.3207 s / img. ETA=7:36:35
[01/01 04:25:39] d2.evaluation.evaluator INFO: Inference done 8650/16850. 3.3206 s / img. ETA=7:33:48
[01/01 04:28:24] d2.evaluation.evaluator INFO: Inference done 8700/16850. 3.3205 s / img. ETA=7:31:02
[01/01 04:31:09] d2.evaluation.evaluator INFO: Inference done 8750/16850. 3.3204 s / img. ETA=7:28:15
[01/01 04:33:54] d2.evaluation.evaluator INFO: Inference done 8800/16850. 3.3203 s / img. ETA=7:25:28
[01/01 04:36:39] d2.evaluation.evaluator INFO: Inference done 8850/16850. 3.3202 s / img. ETA=7:22:41
[01/01 04:39:25] d2.evaluation.evaluator INFO: Inference done 8900/16850. 3.3201 s / img. ETA=7:19:54
[01/01 04:42:10] d2.evaluation.evaluator INFO: Inference done 8950/16850. 3.3200 s / img. ETA=7:17:07
[01/01 04:44:54] d2.evaluation.evaluator INFO: Inference done 9000/16850. 3.3198 s / img. ETA=7:14:20
[01/01 04:47:40] d2.evaluation.evaluator INFO: Inference done 9050/16850. 3.3198 s / img. ETA=7:11:34
[01/01 04:50:25] d2.evaluation.evaluator INFO: Inference done 9100/16850. 3.3197 s / img. ETA=7:08:47
[01/01 04:53:10] d2.evaluation.evaluator INFO: Inference done 9150/16850. 3.3196 s / img. ETA=7:06:00
[01/01 04:55:57] d2.evaluation.evaluator INFO: Inference done 9200/16850. 3.3197 s / img. ETA=7:03:15
[01/01 04:58:42] d2.evaluation.evaluator INFO: Inference done 9250/16850. 3.3196 s / img. ETA=7:00:28
[01/01 05:01:28] d2.evaluation.evaluator INFO: Inference done 9300/16850. 3.3196 s / img. ETA=6:57:42
[01/01 05:04:13] d2.evaluation.evaluator INFO: Inference done 9350/16850. 3.3195 s / img. ETA=6:54:56
[01/01 05:06:58] d2.evaluation.evaluator INFO: Inference done 9400/16850. 3.3194 s / img. ETA=6:52:09
[01/01 05:09:43] d2.evaluation.evaluator INFO: Inference done 9450/16850. 3.3193 s / img. ETA=6:49:23
[01/01 05:12:29] d2.evaluation.evaluator INFO: Inference done 9500/16850. 3.3193 s / img. ETA=6:46:36
[01/01 05:15:13] d2.evaluation.evaluator INFO: Inference done 9550/16850. 3.3191 s / img. ETA=6:43:49
[01/01 05:17:58] d2.evaluation.evaluator INFO: Inference done 9600/16850. 3.3190 s / img. ETA=6:41:02
[01/01 05:20:43] d2.evaluation.evaluator INFO: Inference done 9650/16850. 3.3189 s / img. ETA=6:38:16
[01/01 05:23:28] d2.evaluation.evaluator INFO: Inference done 9700/16850. 3.3188 s / img. ETA=6:35:29
[01/01 05:26:13] d2.evaluation.evaluator INFO: Inference done 9750/16850. 3.3187 s / img. ETA=6:32:42
[01/01 05:28:57] d2.evaluation.evaluator INFO: Inference done 9800/16850. 3.3185 s / img. ETA=6:29:55
[01/01 05:31:42] d2.evaluation.evaluator INFO: Inference done 9850/16850. 3.3184 s / img. ETA=6:27:09
[01/01 05:34:27] d2.evaluation.evaluator INFO: Inference done 9900/16850. 3.3183 s / img. ETA=6:24:22
[01/01 05:37:11] d2.evaluation.evaluator INFO: Inference done 9950/16850. 3.3182 s / img. ETA=6:21:35
[01/01 05:39:56] d2.evaluation.evaluator INFO: Inference done 10000/16850. 3.3181 s / img. ETA=6:18:48
[01/01 05:42:43] d2.evaluation.evaluator INFO: Inference done 10050/16850. 3.3181 s / img. ETA=6:16:03
[01/01 05:45:29] d2.evaluation.evaluator INFO: Inference done 10100/16850. 3.3182 s / img. ETA=6:13:17
[01/01 05:48:16] d2.evaluation.evaluator INFO: Inference done 10150/16850. 3.3182 s / img. ETA=6:10:32
[01/01 05:51:02] d2.evaluation.evaluator INFO: Inference done 10200/16850. 3.3182 s / img. ETA=6:07:46
[01/01 05:53:48] d2.evaluation.evaluator INFO: Inference done 10250/16850. 3.3183 s / img. ETA=6:05:00
[01/01 05:56:36] d2.evaluation.evaluator INFO: Inference done 10300/16850. 3.3185 s / img. ETA=6:02:16
[01/01 05:59:22] d2.evaluation.evaluator INFO: Inference done 10350/16850. 3.3185 s / img. ETA=5:59:30
[01/01 06:02:08] d2.evaluation.evaluator INFO: Inference done 10400/16850. 3.3185 s / img. ETA=5:56:44
[01/01 06:04:55] d2.evaluation.evaluator INFO: Inference done 10450/16850. 3.3186 s / img. ETA=5:53:58
[01/01 06:07:41] d2.evaluation.evaluator INFO: Inference done 10500/16850. 3.3186 s / img. ETA=5:51:12
[01/01 06:10:27] d2.evaluation.evaluator INFO: Inference done 10550/16850. 3.3186 s / img. ETA=5:48:27
[01/01 06:13:13] d2.evaluation.evaluator INFO: Inference done 10600/16850. 3.3186 s / img. ETA=5:45:41
[01/01 06:15:59] d2.evaluation.evaluator INFO: Inference done 10650/16850. 3.3186 s / img. ETA=5:42:55
[01/01 06:18:45] d2.evaluation.evaluator INFO: Inference done 10700/16850. 3.3187 s / img. ETA=5:40:09
[01/01 06:21:32] d2.evaluation.evaluator INFO: Inference done 10750/16850. 3.3187 s / img. ETA=5:37:24
[01/01 06:24:18] d2.evaluation.evaluator INFO: Inference done 10800/16850. 3.3187 s / img. ETA=5:34:38
[01/01 06:27:03] d2.evaluation.evaluator INFO: Inference done 10850/16850. 3.3187 s / img. ETA=5:31:52
[01/01 06:29:50] d2.evaluation.evaluator INFO: Inference done 10900/16850. 3.3187 s / img. ETA=5:29:06
[01/01 06:32:36] d2.evaluation.evaluator INFO: Inference done 10950/16850. 3.3187 s / img. ETA=5:26:20
[01/01 06:35:21] d2.evaluation.evaluator INFO: Inference done 11000/16850. 3.3187 s / img. ETA=5:23:34
[01/01 06:38:07] d2.evaluation.evaluator INFO: Inference done 11050/16850. 3.3187 s / img. ETA=5:20:48
[01/01 06:40:54] d2.evaluation.evaluator INFO: Inference done 11100/16850. 3.3188 s / img. ETA=5:18:02
[01/01 06:43:40] d2.evaluation.evaluator INFO: Inference done 11150/16850. 3.3188 s / img. ETA=5:15:17
[01/01 06:46:27] d2.evaluation.evaluator INFO: Inference done 11200/16850. 3.3188 s / img. ETA=5:12:31
[01/01 06:49:13] d2.evaluation.evaluator INFO: Inference done 11250/16850. 3.3188 s / img. ETA=5:09:45
[01/01 06:51:59] d2.evaluation.evaluator INFO: Inference done 11300/16850. 3.3189 s / img. ETA=5:06:59
[01/01 06:54:45] d2.evaluation.evaluator INFO: Inference done 11350/16850. 3.3189 s / img. ETA=5:04:13
[01/01 06:57:32] d2.evaluation.evaluator INFO: Inference done 11400/16850. 3.3190 s / img. ETA=5:01:28
[01/01 07:00:18] d2.evaluation.evaluator INFO: Inference done 11450/16850. 3.3190 s / img. ETA=4:58:42
[01/01 07:03:03] d2.evaluation.evaluator INFO: Inference done 11500/16850. 3.3189 s / img. ETA=4:55:56
[01/01 07:05:48] d2.evaluation.evaluator INFO: Inference done 11550/16850. 3.3188 s / img. ETA=4:53:09
[01/01 07:08:34] d2.evaluation.evaluator INFO: Inference done 11600/16850. 3.3188 s / img. ETA=4:50:23
[01/01 07:11:19] d2.evaluation.evaluator INFO: Inference done 11650/16850. 3.3187 s / img. ETA=4:47:37
[01/01 07:14:04] d2.evaluation.evaluator INFO: Inference done 11700/16850. 3.3187 s / img. ETA=4:44:51
[01/01 07:16:50] d2.evaluation.evaluator INFO: Inference done 11750/16850. 3.3186 s / img. ETA=4:42:05
[01/01 07:19:35] d2.evaluation.evaluator INFO: Inference done 11800/16850. 3.3186 s / img. ETA=4:39:18
[01/01 07:22:20] d2.evaluation.evaluator INFO: Inference done 11850/16850. 3.3185 s / img. ETA=4:36:32
[01/01 07:25:06] d2.evaluation.evaluator INFO: Inference done 11900/16850. 3.3185 s / img. ETA=4:33:46
[01/01 07:27:52] d2.evaluation.evaluator INFO: Inference done 11950/16850. 3.3185 s / img. ETA=4:31:00
[01/01 07:30:38] d2.evaluation.evaluator INFO: Inference done 12000/16850. 3.3185 s / img. ETA=4:28:14
[01/01 07:33:24] d2.evaluation.evaluator INFO: Inference done 12050/16850. 3.3185 s / img. ETA=4:25:29
[01/01 07:36:11] d2.evaluation.evaluator INFO: Inference done 12100/16850. 3.3186 s / img. ETA=4:22:43
[01/01 07:38:57] d2.evaluation.evaluator INFO: Inference done 12150/16850. 3.3186 s / img. ETA=4:19:57
[01/01 07:41:43] d2.evaluation.evaluator INFO: Inference done 12200/16850. 3.3186 s / img. ETA=4:17:11
[01/01 07:44:30] d2.evaluation.evaluator INFO: Inference done 12250/16850. 3.3187 s / img. ETA=4:14:25
[01/01 07:47:15] d2.evaluation.evaluator INFO: Inference done 12300/16850. 3.3187 s / img. ETA=4:11:39
[01/01 07:50:02] d2.evaluation.evaluator INFO: Inference done 12350/16850. 3.3187 s / img. ETA=4:08:54
[01/01 07:52:48] d2.evaluation.evaluator INFO: Inference done 12400/16850. 3.3187 s / img. ETA=4:06:08
[01/01 07:55:35] d2.evaluation.evaluator INFO: Inference done 12450/16850. 3.3188 s / img. ETA=4:03:22
[01/01 07:58:22] d2.evaluation.evaluator INFO: Inference done 12500/16850. 3.3189 s / img. ETA=4:00:37
[01/01 08:01:08] d2.evaluation.evaluator INFO: Inference done 12550/16850. 3.3189 s / img. ETA=3:57:51
[01/01 08:03:53] d2.evaluation.evaluator INFO: Inference done 12600/16850. 3.3188 s / img. ETA=3:55:05
[01/01 08:06:39] d2.evaluation.evaluator INFO: Inference done 12650/16850. 3.3188 s / img. ETA=3:52:19
[01/01 08:09:24] d2.evaluation.evaluator INFO: Inference done 12700/16850. 3.3188 s / img. ETA=3:49:32
[01/01 08:12:09] d2.evaluation.evaluator INFO: Inference done 12750/16850. 3.3187 s / img. ETA=3:46:46
[01/01 08:14:55] d2.evaluation.evaluator INFO: Inference done 12800/16850. 3.3187 s / img. ETA=3:44:00
[01/01 08:17:41] d2.evaluation.evaluator INFO: Inference done 12850/16850. 3.3187 s / img. ETA=3:41:14
[01/01 08:20:28] d2.evaluation.evaluator INFO: Inference done 12900/16850. 3.3188 s / img. ETA=3:38:29
[01/01 08:23:14] d2.evaluation.evaluator INFO: Inference done 12950/16850. 3.3188 s / img. ETA=3:35:43
[01/01 08:26:00] d2.evaluation.evaluator INFO: Inference done 13000/16850. 3.3188 s / img. ETA=3:32:57
[01/01 08:28:46] d2.evaluation.evaluator INFO: Inference done 13050/16850. 3.3188 s / img. ETA=3:30:11
[01/01 08:31:32] d2.evaluation.evaluator INFO: Inference done 13100/16850. 3.3188 s / img. ETA=3:27:25
[01/01 08:34:18] d2.evaluation.evaluator INFO: Inference done 13150/16850. 3.3188 s / img. ETA=3:24:39
[01/01 08:37:05] d2.evaluation.evaluator INFO: Inference done 13200/16850. 3.3189 s / img. ETA=3:21:53
[01/01 08:39:50] d2.evaluation.evaluator INFO: Inference done 13250/16850. 3.3188 s / img. ETA=3:19:07
[01/01 08:42:35] d2.evaluation.evaluator INFO: Inference done 13300/16850. 3.3188 s / img. ETA=3:16:21
[01/01 08:45:20] d2.evaluation.evaluator INFO: Inference done 13350/16850. 3.3187 s / img. ETA=3:13:35
[01/01 08:48:05] d2.evaluation.evaluator INFO: Inference done 13400/16850. 3.3186 s / img. ETA=3:10:49
[01/01 08:50:50] d2.evaluation.evaluator INFO: Inference done 13450/16850. 3.3185 s / img. ETA=3:08:03
[01/01 08:53:36] d2.evaluation.evaluator INFO: Inference done 13500/16850. 3.3185 s / img. ETA=3:05:17
[01/01 08:56:23] d2.evaluation.evaluator INFO: Inference done 13550/16850. 3.3186 s / img. ETA=3:02:31
[01/01 08:59:08] d2.evaluation.evaluator INFO: Inference done 13600/16850. 3.3185 s / img. ETA=2:59:45
[01/01 09:01:52] d2.evaluation.evaluator INFO: Inference done 13650/16850. 3.3184 s / img. ETA=2:56:58
[01/01 09:04:37] d2.evaluation.evaluator INFO: Inference done 13700/16850. 3.3183 s / img. ETA=2:54:12
[01/01 09:07:22] d2.evaluation.evaluator INFO: Inference done 13750/16850. 3.3183 s / img. ETA=2:51:26
[01/01 09:10:07] d2.evaluation.evaluator INFO: Inference done 13800/16850. 3.3182 s / img. ETA=2:48:40
[01/01 09:12:53] d2.evaluation.evaluator INFO: Inference done 13850/16850. 3.3182 s / img. ETA=2:45:54
[01/01 09:15:39] d2.evaluation.evaluator INFO: Inference done 13900/16850. 3.3182 s / img. ETA=2:43:08
[01/01 09:18:24] d2.evaluation.evaluator INFO: Inference done 13950/16850. 3.3182 s / img. ETA=2:40:22
[01/01 09:21:10] d2.evaluation.evaluator INFO: Inference done 14000/16850. 3.3182 s / img. ETA=2:37:36
[01/01 09:23:56] d2.evaluation.evaluator INFO: Inference done 14050/16850. 3.3182 s / img. ETA=2:34:50
[01/01 09:26:42] d2.evaluation.evaluator INFO: Inference done 14100/16850. 3.3182 s / img. ETA=2:32:05
[01/01 09:29:28] d2.evaluation.evaluator INFO: Inference done 14150/16850. 3.3182 s / img. ETA=2:29:19
[01/01 09:32:14] d2.evaluation.evaluator INFO: Inference done 14200/16850. 3.3182 s / img. ETA=2:26:33
[01/01 09:35:00] d2.evaluation.evaluator INFO: Inference done 14250/16850. 3.3182 s / img. ETA=2:23:47
[01/01 09:37:46] d2.evaluation.evaluator INFO: Inference done 14300/16850. 3.3182 s / img. ETA=2:21:01
[01/01 09:40:33] d2.evaluation.evaluator INFO: Inference done 14350/16850. 3.3183 s / img. ETA=2:18:15
[01/01 09:43:19] d2.evaluation.evaluator INFO: Inference done 14400/16850. 3.3183 s / img. ETA=2:15:29
[01/01 09:46:05] d2.evaluation.evaluator INFO: Inference done 14450/16850. 3.3183 s / img. ETA=2:12:43
[01/01 09:48:50] d2.evaluation.evaluator INFO: Inference done 14500/16850. 3.3183 s / img. ETA=2:09:57
[01/01 09:51:36] d2.evaluation.evaluator INFO: Inference done 14550/16850. 3.3183 s / img. ETA=2:07:12
[01/01 09:54:22] d2.evaluation.evaluator INFO: Inference done 14600/16850. 3.3183 s / img. ETA=2:04:26
[01/01 09:57:10] d2.evaluation.evaluator INFO: Inference done 14650/16850. 3.3184 s / img. ETA=2:01:40
[01/01 09:59:55] d2.evaluation.evaluator INFO: Inference done 14700/16850. 3.3183 s / img. ETA=1:58:54
[01/01 10:02:40] d2.evaluation.evaluator INFO: Inference done 14750/16850. 3.3182 s / img. ETA=1:56:08
[01/01 10:05:25] d2.evaluation.evaluator INFO: Inference done 14800/16850. 3.3182 s / img. ETA=1:53:22
[01/01 10:08:09] d2.evaluation.evaluator INFO: Inference done 14850/16850. 3.3181 s / img. ETA=1:50:36
[01/01 10:10:55] d2.evaluation.evaluator INFO: Inference done 14900/16850. 3.3180 s / img. ETA=1:47:50
[01/01 10:13:39] d2.evaluation.evaluator INFO: Inference done 14950/16850. 3.3180 s / img. ETA=1:45:04
[01/01 10:16:24] d2.evaluation.evaluator INFO: Inference done 15000/16850. 3.3179 s / img. ETA=1:42:18
[01/01 10:19:09] d2.evaluation.evaluator INFO: Inference done 15050/16850. 3.3178 s / img. ETA=1:39:32
[01/01 10:21:54] d2.evaluation.evaluator INFO: Inference done 15100/16850. 3.3178 s / img. ETA=1:36:46
[01/01 10:24:39] d2.evaluation.evaluator INFO: Inference done 15150/16850. 3.3177 s / img. ETA=1:34:00
[01/01 10:27:24] d2.evaluation.evaluator INFO: Inference done 15200/16850. 3.3176 s / img. ETA=1:31:14
[01/01 10:30:09] d2.evaluation.evaluator INFO: Inference done 15250/16850. 3.3176 s / img. ETA=1:28:28
[01/01 10:32:55] d2.evaluation.evaluator INFO: Inference done 15300/16850. 3.3176 s / img. ETA=1:25:42
[01/01 10:35:41] d2.evaluation.evaluator INFO: Inference done 15350/16850. 3.3176 s / img. ETA=1:22:56
[01/01 10:38:26] d2.evaluation.evaluator INFO: Inference done 15400/16850. 3.3176 s / img. ETA=1:20:10
[01/01 10:41:12] d2.evaluation.evaluator INFO: Inference done 15450/16850. 3.3176 s / img. ETA=1:17:24
[01/01 10:43:58] d2.evaluation.evaluator INFO: Inference done 15500/16850. 3.3175 s / img. ETA=1:14:38
[01/01 10:46:42] d2.evaluation.evaluator INFO: Inference done 15550/16850. 3.3175 s / img. ETA=1:11:52
[01/01 10:49:27] d2.evaluation.evaluator INFO: Inference done 15600/16850. 3.3174 s / img. ETA=1:09:06
[01/01 10:52:12] d2.evaluation.evaluator INFO: Inference done 15650/16850. 3.3173 s / img. ETA=1:06:20
[01/01 10:54:56] d2.evaluation.evaluator INFO: Inference done 15700/16850. 3.3172 s / img. ETA=1:03:34
[01/01 10:57:44] d2.evaluation.evaluator INFO: Inference done 15750/16850. 3.3174 s / img. ETA=1:00:49
[01/01 11:00:30] d2.evaluation.evaluator INFO: Inference done 15800/16850. 3.3174 s / img. ETA=0:58:03
[01/01 11:03:16] d2.evaluation.evaluator INFO: Inference done 15850/16850. 3.3174 s / img. ETA=0:55:17
[01/01 11:06:02] d2.evaluation.evaluator INFO: Inference done 15900/16850. 3.3174 s / img. ETA=0:52:31
[01/01 11:08:48] d2.evaluation.evaluator INFO: Inference done 15950/16850. 3.3174 s / img. ETA=0:49:45
[01/01 11:11:34] d2.evaluation.evaluator INFO: Inference done 16000/16850. 3.3174 s / img. ETA=0:46:59
[01/01 11:14:20] d2.evaluation.evaluator INFO: Inference done 16050/16850. 3.3174 s / img. ETA=0:44:13
[01/01 11:17:07] d2.evaluation.evaluator INFO: Inference done 16100/16850. 3.3175 s / img. ETA=0:41:28
[01/01 11:19:53] d2.evaluation.evaluator INFO: Inference done 16150/16850. 3.3175 s / img. ETA=0:38:42
[01/01 11:22:39] d2.evaluation.evaluator INFO: Inference done 16200/16850. 3.3175 s / img. ETA=0:35:56
[01/01 11:25:24] d2.evaluation.evaluator INFO: Inference done 16250/16850. 3.3174 s / img. ETA=0:33:10
[01/01 11:28:09] d2.evaluation.evaluator INFO: Inference done 16300/16850. 3.3174 s / img. ETA=0:30:24
[01/01 11:30:54] d2.evaluation.evaluator INFO: Inference done 16350/16850. 3.3173 s / img. ETA=0:27:38
[01/01 11:33:40] d2.evaluation.evaluator INFO: Inference done 16400/16850. 3.3173 s / img. ETA=0:24:52
[01/01 11:36:25] d2.evaluation.evaluator INFO: Inference done 16450/16850. 3.3173 s / img. ETA=0:22:06
[01/01 11:39:10] d2.evaluation.evaluator INFO: Inference done 16500/16850. 3.3172 s / img. ETA=0:19:21
[01/01 11:41:55] d2.evaluation.evaluator INFO: Inference done 16550/16850. 3.3172 s / img. ETA=0:16:35
[01/01 11:44:40] d2.evaluation.evaluator INFO: Inference done 16600/16850. 3.3171 s / img. ETA=0:13:49
[01/01 11:47:26] d2.evaluation.evaluator INFO: Inference done 16650/16850. 3.3171 s / img. ETA=0:11:03
[01/01 11:50:12] d2.evaluation.evaluator INFO: Inference done 16700/16850. 3.3171 s / img. ETA=0:08:17
[01/01 11:52:58] d2.evaluation.evaluator INFO: Inference done 16750/16850. 3.3172 s / img. ETA=0:05:31
[01/01 11:55:44] d2.evaluation.evaluator INFO: Inference done 16800/16850. 3.3172 s / img. ETA=0:02:45
[01/01 11:58:30] d2.evaluation.evaluator INFO: Inference done 16850/16850. 3.3172 s / img. ETA=0:00:00
[01/01 11:58:30] d2.evaluation.evaluator INFO: Total inference time: 15:31:17 (3.317127 s / img per device, on 2 devices)
[01/01 11:58:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 15:30:25 (3.314077 s / img per device, on 2 devices)
[01/01 11:59:15] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/01 11:59:15] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference_TTA/my_dataset_test.json
[01/01 11:59:17] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/01 11:59:56] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[01/01 11:59:56] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[01/01 11:59:57] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[01/01 11:59:57] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/01 11:59:57] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/01 11:59:57] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[01/04 23:45:12] detectron2 INFO: Rank of current process: 0. World size: 2
[01/04 23:45:35] detectron2 INFO: Rank of current process: 0. World size: 2
[01/04 23:45:38] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/04 23:45:38] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/04 23:45:38] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: True   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small",)
  TEST: ("my_dataset_val_small",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 138368  ## 46368 74368(70000 最好) 96368(8500)  116368 138368
  BASE_LR: 0.01     ### 
  STEPS: (138068, 138268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/04 23:45:38] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_small',)
  TRAIN: ('my_dataset_train_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 138368
  MOMENTUM: 0.9
  STEPS: (138068, 138268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: True
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/04 23:45:39] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/04 23:45:39] d2.utils.env INFO: Using a generated random seed 39080439
[01/04 23:45:42] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/04 23:50:51] detectron2 INFO: Rank of current process: 0. World size: 2
[01/04 23:50:55] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/04 23:50:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/04 23:50:55] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: True   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small",)
  TEST: ("my_dataset_val_small",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 138368  ## 46368 74368(70000 最好) 96368(8500)  116368 138368
  BASE_LR: 0.01     ### 
  STEPS: (138068, 138268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/04 23:50:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_small',)
  TRAIN: ('my_dataset_train_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 138368
  MOMENTUM: 0.9
  STEPS: (138068, 138268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: True
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/04 23:50:55] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/04 23:50:55] d2.utils.env INFO: Using a generated random seed 55754180
[01/04 23:50:58] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/04 23:54:42] detectron2 INFO: Rank of current process: 0. World size: 2
[01/04 23:54:46] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/04 23:54:46] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/04 23:54:46] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: True   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small",)
  TEST: ("my_dataset_val_small",)  # my_dataset_val_light my_dataset_test 
SOLVER:
  MAX_ITER: 138368  ## 46368 74368(70000 最好) 96368(8500)  116368 138368
  BASE_LR: 0.01     ### 
  STEPS: (138068, 138268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/04 23:54:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_small',)
  TRAIN: ('my_dataset_train_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 138368
  MOMENTUM: 0.9
  STEPS: (138068, 138268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: True
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/04 23:54:46] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/04 23:54:46] d2.utils.env INFO: Using a generated random seed 46903481
[01/04 23:54:50] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/04 23:54:50] d2.data.datasets.coco INFO: Loaded 7815 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_small.json
[01/04 23:54:50] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 2895         |   ASC-US   | 2490         |    HSIL     | 2074         |
|    LSIL    | 2389         |  Candida   | 1207         | Trichomonas | 6265         |
|            |              |            |              |             |              |
|   total    | 17320        |            |              |             |              |[0m
[01/04 23:54:50] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[01/04 23:54:50] d2.data.build INFO: Using training sampler TrainingSampler
[01/04 23:56:01] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0114999.pth
[01/04 23:56:02] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0114999.pth
[01/04 23:56:03] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0114999.pth
[01/04 23:56:03] d2.engine.train_loop INFO: Starting training from iteration 115000
[01/04 23:57:05] d2.utils.events INFO: eta: 20:15:23  iter: 115019  total_loss: 0.555  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0990  data_time: 0.0030  lr: 0.000100  max_mem: 8578M
[01/04 23:58:07] d2.utils.events INFO: eta: 19:45:29  iter: 115039  total_loss: 0.823  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0817  data_time: 0.0022  lr: 0.000100  max_mem: 8578M
[01/04 23:59:09] d2.utils.events INFO: eta: 19:44:28  iter: 115059  total_loss: 0.648  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.1029  data_time: 0.0022  lr: 0.000100  max_mem: 8578M
[01/05 00:00:10] d2.utils.events INFO: eta: 19:42:53  iter: 115079  total_loss: 0.502  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0882  data_time: 0.0024  lr: 0.000100  max_mem: 8578M
[01/05 00:01:11] d2.utils.events INFO: eta: 19:42:23  iter: 115099  total_loss: 0.759  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0025  lr: 0.000100  max_mem: 8578M
[01/05 00:02:12] d2.utils.events INFO: eta: 19:41:20  iter: 115119  total_loss: 0.840  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.098  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0689  data_time: 0.0029  lr: 0.000100  max_mem: 8578M
[01/05 00:03:12] d2.utils.events INFO: eta: 19:39:55  iter: 115139  total_loss: 0.594  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0609  data_time: 0.0029  lr: 0.000100  max_mem: 8578M
[01/05 00:04:14] d2.utils.events INFO: eta: 19:38:57  iter: 115159  total_loss: 0.777  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.324  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0649  data_time: 0.0025  lr: 0.000100  max_mem: 8676M
[01/05 00:05:15] d2.utils.events INFO: eta: 19:37:58  iter: 115179  total_loss: 0.676  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0658  data_time: 0.0032  lr: 0.000100  max_mem: 8676M
[01/05 00:06:17] d2.utils.events INFO: eta: 19:37:04  iter: 115199  total_loss: 0.633  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 3.0650  data_time: 0.0029  lr: 0.000100  max_mem: 8676M
[01/05 00:07:19] d2.utils.events INFO: eta: 19:36:12  iter: 115219  total_loss: 1.042  loss_cls_stage0: 0.083  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.101  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0699  data_time: 0.0027  lr: 0.000100  max_mem: 8676M
[01/05 00:08:21] d2.utils.events INFO: eta: 19:35:14  iter: 115239  total_loss: 0.771  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0726  data_time: 0.0026  lr: 0.000100  max_mem: 8676M
[01/05 00:09:21] d2.utils.events INFO: eta: 19:33:55  iter: 115259  total_loss: 0.510  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0665  data_time: 0.0023  lr: 0.000100  max_mem: 8676M
[01/05 00:10:22] d2.utils.events INFO: eta: 19:32:56  iter: 115279  total_loss: 0.823  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.364  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0650  data_time: 0.0024  lr: 0.000100  max_mem: 8676M
[01/05 00:11:23] d2.utils.events INFO: eta: 19:31:52  iter: 115299  total_loss: 0.924  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.379  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0644  data_time: 0.0027  lr: 0.000100  max_mem: 8676M
[01/05 00:12:24] d2.utils.events INFO: eta: 19:30:51  iter: 115319  total_loss: 0.881  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 3.0622  data_time: 0.0020  lr: 0.000100  max_mem: 8676M
[01/05 00:13:24] d2.utils.events INFO: eta: 19:29:46  iter: 115339  total_loss: 0.986  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.109  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.235  loss_cls_stage2: 0.109  loss_box_reg_stage2: 0.351  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0606  data_time: 0.0024  lr: 0.000100  max_mem: 8676M
[01/05 00:14:27] d2.utils.events INFO: eta: 19:28:50  iter: 115359  total_loss: 0.819  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0650  data_time: 0.0023  lr: 0.000100  max_mem: 8676M
[01/05 00:15:28] d2.utils.events INFO: eta: 19:27:51  iter: 115379  total_loss: 0.988  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.264  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.344  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0029  lr: 0.000100  max_mem: 8676M
[01/05 00:16:29] d2.utils.events INFO: eta: 19:26:48  iter: 115399  total_loss: 0.820  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0024  lr: 0.000100  max_mem: 8676M
[01/05 00:17:30] d2.utils.events INFO: eta: 19:25:45  iter: 115419  total_loss: 0.770  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0610  data_time: 0.0022  lr: 0.000100  max_mem: 8676M
[01/05 00:18:32] d2.utils.events INFO: eta: 19:24:45  iter: 115439  total_loss: 0.802  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0631  data_time: 0.0022  lr: 0.000100  max_mem: 8676M
[01/05 00:19:34] d2.utils.events INFO: eta: 19:23:44  iter: 115459  total_loss: 0.693  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0649  data_time: 0.0021  lr: 0.000100  max_mem: 8676M
[01/05 00:20:34] d2.utils.events INFO: eta: 19:22:40  iter: 115479  total_loss: 0.656  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0627  data_time: 0.0026  lr: 0.000100  max_mem: 8676M
[01/05 00:21:36] d2.utils.events INFO: eta: 19:21:40  iter: 115499  total_loss: 0.874  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0643  data_time: 0.0021  lr: 0.000100  max_mem: 8676M
[01/05 00:22:38] d2.utils.events INFO: eta: 19:20:38  iter: 115519  total_loss: 0.670  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0653  data_time: 0.0028  lr: 0.000100  max_mem: 8676M
[01/05 00:23:39] d2.utils.events INFO: eta: 19:19:36  iter: 115539  total_loss: 0.889  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0647  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:24:40] d2.utils.events INFO: eta: 19:18:32  iter: 115559  total_loss: 0.817  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0639  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:25:41] d2.utils.events INFO: eta: 19:17:29  iter: 115579  total_loss: 0.777  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0636  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:26:43] d2.utils.events INFO: eta: 19:16:34  iter: 115599  total_loss: 0.936  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.258  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0652  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 00:27:44] d2.utils.events INFO: eta: 19:15:34  iter: 115619  total_loss: 0.713  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0644  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 00:28:46] d2.utils.events INFO: eta: 19:14:40  iter: 115639  total_loss: 0.768  loss_cls_stage0: 0.087  loss_box_reg_stage0: 0.111  loss_cls_stage1: 0.085  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0657  data_time: 0.0021  lr: 0.000100  max_mem: 8790M
[01/05 00:29:47] d2.utils.events INFO: eta: 19:13:35  iter: 115659  total_loss: 0.741  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0642  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:30:47] d2.utils.events INFO: eta: 19:12:29  iter: 115679  total_loss: 0.886  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0628  data_time: 0.0034  lr: 0.000100  max_mem: 8790M
[01/05 00:31:48] d2.utils.events INFO: eta: 19:11:25  iter: 115699  total_loss: 0.862  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0626  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:32:49] d2.utils.events INFO: eta: 19:10:23  iter: 115719  total_loss: 0.652  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0613  data_time: 0.0030  lr: 0.000100  max_mem: 8790M
[01/05 00:33:49] d2.utils.events INFO: eta: 19:09:23  iter: 115739  total_loss: 0.623  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0608  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:34:51] d2.utils.events INFO: eta: 19:08:22  iter: 115759  total_loss: 0.614  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0617  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 00:35:54] d2.utils.events INFO: eta: 19:07:25  iter: 115779  total_loss: 0.832  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0633  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:36:56] d2.utils.events INFO: eta: 19:06:22  iter: 115799  total_loss: 0.994  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0639  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 00:37:56] d2.utils.events INFO: eta: 19:05:19  iter: 115819  total_loss: 0.762  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 00:38:57] d2.utils.events INFO: eta: 19:04:16  iter: 115839  total_loss: 0.696  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0630  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 00:40:00] d2.utils.events INFO: eta: 19:03:20  iter: 115859  total_loss: 0.756  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0649  data_time: 0.0032  lr: 0.000100  max_mem: 8790M
[01/05 00:41:02] d2.utils.events INFO: eta: 19:02:17  iter: 115879  total_loss: 0.941  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.248  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0649  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 00:42:04] d2.utils.events INFO: eta: 19:01:15  iter: 115899  total_loss: 0.812  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0657  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 00:43:06] d2.utils.events INFO: eta: 19:00:15  iter: 115919  total_loss: 1.121  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.113  loss_cls_stage1: 0.095  loss_box_reg_stage1: 0.251  loss_cls_stage2: 0.098  loss_box_reg_stage2: 0.359  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0667  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 00:44:09] d2.utils.events INFO: eta: 18:59:15  iter: 115939  total_loss: 0.639  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0679  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:45:12] d2.utils.events INFO: eta: 18:58:18  iter: 115959  total_loss: 0.655  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0702  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:46:14] d2.utils.events INFO: eta: 18:57:18  iter: 115979  total_loss: 0.767  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0707  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 00:47:16] d2.utils.events INFO: eta: 18:56:19  iter: 115999  total_loss: 0.735  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0711  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 00:48:19] d2.utils.events INFO: eta: 18:55:23  iter: 116019  total_loss: 0.737  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0730  data_time: 0.0021  lr: 0.000100  max_mem: 8790M
[01/05 00:49:20] d2.utils.events INFO: eta: 18:54:21  iter: 116039  total_loss: 0.783  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0723  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:50:19] d2.utils.events INFO: eta: 18:53:12  iter: 116059  total_loss: 0.548  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.040  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0702  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:51:20] d2.utils.events INFO: eta: 18:52:11  iter: 116079  total_loss: 0.795  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0698  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 00:52:21] d2.utils.events INFO: eta: 18:51:06  iter: 116099  total_loss: 0.588  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0692  data_time: 0.0029  lr: 0.000100  max_mem: 8790M
[01/05 00:53:22] d2.utils.events INFO: eta: 18:50:01  iter: 116119  total_loss: 0.814  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0690  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 00:54:23] d2.utils.events INFO: eta: 18:49:00  iter: 116139  total_loss: 0.664  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0688  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:55:24] d2.utils.events INFO: eta: 18:47:53  iter: 116159  total_loss: 0.699  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0681  data_time: 0.0029  lr: 0.000100  max_mem: 8790M
[01/05 00:56:27] d2.utils.events INFO: eta: 18:46:52  iter: 116179  total_loss: 0.711  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0693  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:57:27] d2.utils.events INFO: eta: 18:45:49  iter: 116199  total_loss: 0.695  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0685  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 00:58:29] d2.utils.events INFO: eta: 18:44:44  iter: 116219  total_loss: 0.705  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0688  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 00:59:30] d2.utils.events INFO: eta: 18:43:40  iter: 116239  total_loss: 0.555  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0684  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:00:32] d2.utils.events INFO: eta: 18:42:46  iter: 116259  total_loss: 0.829  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0685  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 01:01:31] d2.utils.events INFO: eta: 18:41:42  iter: 116279  total_loss: 0.672  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0674  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:02:34] d2.utils.events INFO: eta: 18:40:45  iter: 116299  total_loss: 0.696  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0680  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:03:36] d2.utils.events INFO: eta: 18:39:43  iter: 116319  total_loss: 0.581  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0683  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:04:37] d2.utils.events INFO: eta: 18:38:44  iter: 116339  total_loss: 0.927  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.096  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0682  data_time: 0.0028  lr: 0.000100  max_mem: 8790M
[01/05 01:05:38] d2.utils.events INFO: eta: 18:37:39  iter: 116359  total_loss: 0.621  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0681  data_time: 0.0031  lr: 0.000100  max_mem: 8790M
[01/05 01:06:40] d2.utils.events INFO: eta: 18:36:38  iter: 116379  total_loss: 0.828  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0687  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 01:07:42] d2.utils.events INFO: eta: 18:35:41  iter: 116399  total_loss: 0.728  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0692  data_time: 0.0030  lr: 0.000100  max_mem: 8790M
[01/05 01:08:43] d2.utils.events INFO: eta: 18:34:37  iter: 116419  total_loss: 0.717  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0685  data_time: 0.0021  lr: 0.000100  max_mem: 8790M
[01/05 01:09:44] d2.utils.events INFO: eta: 18:33:38  iter: 116439  total_loss: 0.650  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0685  data_time: 0.0028  lr: 0.000100  max_mem: 8790M
[01/05 01:10:46] d2.utils.events INFO: eta: 18:32:36  iter: 116459  total_loss: 0.731  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0685  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:11:47] d2.utils.events INFO: eta: 18:31:39  iter: 116479  total_loss: 0.910  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0689  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:12:49] d2.utils.events INFO: eta: 18:30:37  iter: 116499  total_loss: 0.838  loss_cls_stage0: 0.078  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.094  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0690  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:13:51] d2.utils.events INFO: eta: 18:29:36  iter: 116519  total_loss: 0.784  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0690  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:14:51] d2.utils.events INFO: eta: 18:28:35  iter: 116539  total_loss: 0.722  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0686  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:15:54] d2.utils.events INFO: eta: 18:27:41  iter: 116559  total_loss: 0.784  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0696  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:16:56] d2.utils.events INFO: eta: 18:26:42  iter: 116579  total_loss: 0.967  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0699  data_time: 0.0029  lr: 0.000100  max_mem: 8790M
[01/05 01:17:57] d2.utils.events INFO: eta: 18:25:32  iter: 116599  total_loss: 0.838  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0697  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:18:57] d2.utils.events INFO: eta: 18:24:31  iter: 116619  total_loss: 0.665  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0688  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:19:58] d2.utils.events INFO: eta: 18:23:24  iter: 116639  total_loss: 0.847  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0683  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 01:21:00] d2.utils.events INFO: eta: 18:22:26  iter: 116659  total_loss: 0.822  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0688  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:22:01] d2.utils.events INFO: eta: 18:21:26  iter: 116679  total_loss: 0.669  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0683  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:23:02] d2.utils.events INFO: eta: 18:20:25  iter: 116699  total_loss: 0.861  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0682  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:24:03] d2.utils.events INFO: eta: 18:19:24  iter: 116719  total_loss: 0.857  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0683  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:25:06] d2.utils.events INFO: eta: 18:18:23  iter: 116739  total_loss: 0.940  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0688  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:26:07] d2.utils.events INFO: eta: 18:17:20  iter: 116759  total_loss: 0.738  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0688  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:27:07] d2.utils.events INFO: eta: 18:16:10  iter: 116779  total_loss: 0.847  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0680  data_time: 0.0020  lr: 0.000100  max_mem: 8790M
[01/05 01:28:09] d2.utils.events INFO: eta: 18:15:08  iter: 116799  total_loss: 0.809  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.007  loss_rpn_loc: 0.008  time: 3.0680  data_time: 0.0021  lr: 0.000100  max_mem: 8790M
[01/05 01:29:08] d2.utils.events INFO: eta: 18:14:04  iter: 116819  total_loss: 0.630  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0670  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:30:08] d2.utils.events INFO: eta: 18:12:59  iter: 116839  total_loss: 0.841  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0663  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 01:31:09] d2.utils.events INFO: eta: 18:11:42  iter: 116859  total_loss: 0.746  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0661  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:32:11] d2.utils.events INFO: eta: 18:10:41  iter: 116879  total_loss: 0.682  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0665  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:33:13] d2.utils.events INFO: eta: 18:09:42  iter: 116899  total_loss: 1.012  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.264  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.372  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0667  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:34:13] d2.utils.events INFO: eta: 18:08:37  iter: 116919  total_loss: 0.673  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0661  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:35:14] d2.utils.events INFO: eta: 18:07:36  iter: 116939  total_loss: 0.650  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0661  data_time: 0.0031  lr: 0.000100  max_mem: 8790M
[01/05 01:36:17] d2.utils.events INFO: eta: 18:06:30  iter: 116959  total_loss: 0.804  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0666  data_time: 0.0021  lr: 0.000100  max_mem: 8790M
[01/05 01:37:18] d2.utils.events INFO: eta: 18:05:28  iter: 116979  total_loss: 0.654  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0663  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 01:38:19] d2.utils.events INFO: eta: 18:04:24  iter: 116999  total_loss: 0.886  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.332  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0665  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 01:39:20] d2.utils.events INFO: eta: 18:03:19  iter: 117019  total_loss: 0.566  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.114  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0661  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:40:20] d2.utils.events INFO: eta: 18:02:17  iter: 117039  total_loss: 0.870  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.080  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.101  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0657  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:41:22] d2.utils.events INFO: eta: 18:01:18  iter: 117059  total_loss: 0.811  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0658  data_time: 0.0026  lr: 0.000100  max_mem: 8790M
[01/05 01:42:24] d2.utils.events INFO: eta: 18:00:21  iter: 117079  total_loss: 0.894  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.372  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0661  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:43:25] d2.utils.events INFO: eta: 17:59:20  iter: 117099  total_loss: 0.873  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.117  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0661  data_time: 0.0028  lr: 0.000100  max_mem: 8790M
[01/05 01:44:26] d2.utils.events INFO: eta: 17:58:17  iter: 117119  total_loss: 0.736  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0658  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:45:27] d2.utils.events INFO: eta: 17:57:18  iter: 117139  total_loss: 0.604  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0657  data_time: 0.0024  lr: 0.000100  max_mem: 8790M
[01/05 01:46:28] d2.utils.events INFO: eta: 17:56:28  iter: 117159  total_loss: 0.705  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0657  data_time: 0.0031  lr: 0.000100  max_mem: 8790M
[01/05 01:47:29] d2.utils.events INFO: eta: 17:55:14  iter: 117179  total_loss: 0.738  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0653  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 01:48:30] d2.utils.events INFO: eta: 17:54:18  iter: 117199  total_loss: 0.862  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0652  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 01:49:32] d2.utils.events INFO: eta: 17:53:21  iter: 117219  total_loss: 0.631  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0652  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:50:32] d2.utils.events INFO: eta: 17:52:17  iter: 117239  total_loss: 1.014  loss_cls_stage0: 0.089  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.093  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.111  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0650  data_time: 0.0028  lr: 0.000100  max_mem: 8790M
[01/05 01:51:32] d2.utils.events INFO: eta: 17:51:10  iter: 117259  total_loss: 0.807  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0645  data_time: 0.0025  lr: 0.000100  max_mem: 8790M
[01/05 01:52:33] d2.utils.events INFO: eta: 17:50:07  iter: 117279  total_loss: 0.625  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0640  data_time: 0.0027  lr: 0.000100  max_mem: 8790M
[01/05 01:53:35] d2.utils.events INFO: eta: 17:49:08  iter: 117299  total_loss: 0.766  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0644  data_time: 0.0023  lr: 0.000100  max_mem: 8790M
[01/05 01:54:37] d2.utils.events INFO: eta: 17:48:08  iter: 117319  total_loss: 0.866  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0646  data_time: 0.0020  lr: 0.000100  max_mem: 8790M
[01/05 01:55:40] d2.utils.events INFO: eta: 17:47:09  iter: 117339  total_loss: 0.843  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0656  data_time: 0.0022  lr: 0.000100  max_mem: 8790M
[01/05 01:56:42] d2.utils.events INFO: eta: 17:46:11  iter: 117359  total_loss: 0.607  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0659  data_time: 0.0029  lr: 0.000100  max_mem: 8790M
[01/05 01:57:45] d2.utils.events INFO: eta: 17:45:10  iter: 117379  total_loss: 0.626  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0664  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 01:58:46] d2.utils.events INFO: eta: 17:44:04  iter: 117399  total_loss: 0.869  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 3.0663  data_time: 0.0026  lr: 0.000100  max_mem: 8877M
[01/05 01:59:48] d2.utils.events INFO: eta: 17:43:05  iter: 117419  total_loss: 0.956  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.111  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  time: 3.0665  data_time: 0.0020  lr: 0.000100  max_mem: 8877M
[01/05 02:00:49] d2.utils.events INFO: eta: 17:42:02  iter: 117439  total_loss: 0.559  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0665  data_time: 0.0020  lr: 0.000100  max_mem: 8877M
[01/05 02:01:52] d2.utils.events INFO: eta: 17:41:02  iter: 117459  total_loss: 0.767  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0669  data_time: 0.0026  lr: 0.000100  max_mem: 8877M
[01/05 02:02:54] d2.utils.events INFO: eta: 17:39:59  iter: 117479  total_loss: 0.717  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0673  data_time: 0.0024  lr: 0.000100  max_mem: 8877M
[01/05 02:03:55] d2.utils.events INFO: eta: 17:38:57  iter: 117499  total_loss: 0.572  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0670  data_time: 0.0021  lr: 0.000100  max_mem: 8877M
[01/05 02:04:55] d2.utils.events INFO: eta: 17:37:53  iter: 117519  total_loss: 0.634  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0665  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:05:56] d2.utils.events INFO: eta: 17:36:54  iter: 117539  total_loss: 0.893  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0664  data_time: 0.0028  lr: 0.000100  max_mem: 8877M
[01/05 02:06:58] d2.utils.events INFO: eta: 17:35:51  iter: 117559  total_loss: 0.698  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0667  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:08:00] d2.utils.events INFO: eta: 17:34:48  iter: 117579  total_loss: 0.574  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0669  data_time: 0.0023  lr: 0.000100  max_mem: 8877M
[01/05 02:09:01] d2.utils.events INFO: eta: 17:33:46  iter: 117599  total_loss: 0.844  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0667  data_time: 0.0023  lr: 0.000100  max_mem: 8877M
[01/05 02:10:03] d2.utils.events INFO: eta: 17:32:47  iter: 117619  total_loss: 0.839  loss_cls_stage0: 0.087  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.097  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0669  data_time: 0.0021  lr: 0.000100  max_mem: 8877M
[01/05 02:11:04] d2.utils.events INFO: eta: 17:31:51  iter: 117639  total_loss: 0.754  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0668  data_time: 0.0023  lr: 0.000100  max_mem: 8877M
[01/05 02:12:03] d2.utils.events INFO: eta: 17:30:42  iter: 117659  total_loss: 0.721  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0662  data_time: 0.0023  lr: 0.000100  max_mem: 8877M
[01/05 02:13:05] d2.utils.events INFO: eta: 17:29:42  iter: 117679  total_loss: 0.671  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0663  data_time: 0.0024  lr: 0.000100  max_mem: 8877M
[01/05 02:14:06] d2.utils.events INFO: eta: 17:28:42  iter: 117699  total_loss: 0.824  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0662  data_time: 0.0027  lr: 0.000100  max_mem: 8877M
[01/05 02:15:08] d2.utils.events INFO: eta: 17:27:44  iter: 117719  total_loss: 0.692  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0663  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:16:10] d2.utils.events INFO: eta: 17:26:43  iter: 117739  total_loss: 0.944  loss_cls_stage0: 0.089  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.106  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.128  loss_box_reg_stage2: 0.326  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0667  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:17:11] d2.utils.events INFO: eta: 17:25:46  iter: 117759  total_loss: 0.703  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0665  data_time: 0.0021  lr: 0.000100  max_mem: 8877M
[01/05 02:18:12] d2.utils.events INFO: eta: 17:24:47  iter: 117779  total_loss: 0.561  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0665  data_time: 0.0032  lr: 0.000100  max_mem: 8877M
[01/05 02:19:15] d2.utils.events INFO: eta: 17:23:47  iter: 117799  total_loss: 0.717  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0668  data_time: 0.0021  lr: 0.000100  max_mem: 8877M
[01/05 02:20:17] d2.utils.events INFO: eta: 17:22:58  iter: 117819  total_loss: 0.787  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0673  data_time: 0.0022  lr: 0.000100  max_mem: 8877M
[01/05 02:21:19] d2.utils.events INFO: eta: 17:22:02  iter: 117839  total_loss: 0.827  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0675  data_time: 0.0024  lr: 0.000100  max_mem: 8877M
[01/05 02:22:20] d2.utils.events INFO: eta: 17:21:01  iter: 117859  total_loss: 0.805  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0672  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:23:23] d2.utils.events INFO: eta: 17:20:04  iter: 117879  total_loss: 0.853  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0676  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:24:25] d2.utils.events INFO: eta: 17:19:04  iter: 117899  total_loss: 0.742  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0678  data_time: 0.0021  lr: 0.000100  max_mem: 8877M
[01/05 02:25:28] d2.utils.events INFO: eta: 17:18:11  iter: 117919  total_loss: 0.558  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0684  data_time: 0.0022  lr: 0.000100  max_mem: 8877M
[01/05 02:26:29] d2.utils.events INFO: eta: 17:17:09  iter: 117939  total_loss: 0.662  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0683  data_time: 0.0026  lr: 0.000100  max_mem: 8877M
[01/05 02:27:30] d2.utils.events INFO: eta: 17:16:05  iter: 117959  total_loss: 0.786  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0683  data_time: 0.0023  lr: 0.000100  max_mem: 8877M
[01/05 02:28:32] d2.utils.events INFO: eta: 17:15:07  iter: 117979  total_loss: 0.793  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.347  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0684  data_time: 0.0026  lr: 0.000100  max_mem: 8877M
[01/05 02:29:31] d2.utils.events INFO: eta: 17:14:02  iter: 117999  total_loss: 0.530  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0677  data_time: 0.0025  lr: 0.000100  max_mem: 8877M
[01/05 02:30:31] d2.utils.events INFO: eta: 17:12:59  iter: 118019  total_loss: 0.739  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0673  data_time: 0.0027  lr: 0.000100  max_mem: 8877M
[01/05 02:31:34] d2.utils.events INFO: eta: 17:12:08  iter: 118039  total_loss: 0.885  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.344  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0678  data_time: 0.0024  lr: 0.000100  max_mem: 8877M
[01/05 02:32:35] d2.utils.events INFO: eta: 17:11:10  iter: 118059  total_loss: 0.815  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0677  data_time: 0.0022  lr: 0.000100  max_mem: 8877M
[01/05 02:33:35] d2.utils.events INFO: eta: 17:10:04  iter: 118079  total_loss: 0.804  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.358  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0673  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 02:34:37] d2.utils.events INFO: eta: 17:09:06  iter: 118099  total_loss: 0.754  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0673  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 02:35:39] d2.utils.events INFO: eta: 17:08:10  iter: 118119  total_loss: 0.939  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.087  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.104  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0675  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 02:36:41] d2.utils.events INFO: eta: 17:07:14  iter: 118139  total_loss: 0.594  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0678  data_time: 0.0028  lr: 0.000100  max_mem: 8920M
[01/05 02:37:43] d2.utils.events INFO: eta: 17:06:15  iter: 118159  total_loss: 0.794  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0678  data_time: 0.0029  lr: 0.000100  max_mem: 8920M
[01/05 02:38:45] d2.utils.events INFO: eta: 17:05:22  iter: 118179  total_loss: 0.896  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0680  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 02:39:46] d2.utils.events INFO: eta: 17:04:18  iter: 118199  total_loss: 0.755  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0679  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 02:40:46] d2.utils.events INFO: eta: 17:03:11  iter: 118219  total_loss: 0.770  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0675  data_time: 0.0027  lr: 0.000100  max_mem: 8920M
[01/05 02:41:49] d2.utils.events INFO: eta: 17:02:14  iter: 118239  total_loss: 0.703  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0680  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 02:42:49] d2.utils.events INFO: eta: 17:01:18  iter: 118259  total_loss: 0.803  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0678  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 02:43:51] d2.utils.events INFO: eta: 17:00:18  iter: 118279  total_loss: 0.791  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0679  data_time: 0.0027  lr: 0.000100  max_mem: 8920M
[01/05 02:44:53] d2.utils.events INFO: eta: 16:59:16  iter: 118299  total_loss: 0.911  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0680  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 02:45:54] d2.utils.events INFO: eta: 16:58:14  iter: 118319  total_loss: 0.784  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.361  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0680  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 02:46:57] d2.utils.events INFO: eta: 16:57:14  iter: 118339  total_loss: 0.905  loss_cls_stage0: 0.080  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.096  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.103  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0683  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 02:47:59] d2.utils.events INFO: eta: 16:56:17  iter: 118359  total_loss: 0.848  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 3.0685  data_time: 0.0025  lr: 0.000100  max_mem: 8920M
[01/05 02:48:58] d2.utils.events INFO: eta: 16:55:09  iter: 118379  total_loss: 0.896  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0680  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 02:49:59] d2.utils.events INFO: eta: 16:54:10  iter: 118399  total_loss: 0.644  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0678  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 02:51:01] d2.utils.events INFO: eta: 16:53:09  iter: 118419  total_loss: 0.724  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0679  data_time: 0.0021  lr: 0.000100  max_mem: 8920M
[01/05 02:52:03] d2.utils.events INFO: eta: 16:52:12  iter: 118439  total_loss: 0.846  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0683  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 02:53:04] d2.utils.events INFO: eta: 16:51:08  iter: 118459  total_loss: 0.666  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0681  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 02:54:05] d2.utils.events INFO: eta: 16:50:06  iter: 118479  total_loss: 0.845  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0678  data_time: 0.0020  lr: 0.000100  max_mem: 8920M
[01/05 02:55:05] d2.utils.events INFO: eta: 16:49:05  iter: 118499  total_loss: 0.831  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0675  data_time: 0.0027  lr: 0.000100  max_mem: 8920M
[01/05 02:56:08] d2.utils.events INFO: eta: 16:48:09  iter: 118519  total_loss: 0.790  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0680  data_time: 0.0025  lr: 0.000100  max_mem: 8920M
[01/05 02:57:11] d2.utils.events INFO: eta: 16:47:12  iter: 118539  total_loss: 0.837  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0684  data_time: 0.0027  lr: 0.000100  max_mem: 8920M
[01/05 02:58:12] d2.utils.events INFO: eta: 16:46:06  iter: 118559  total_loss: 0.839  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0682  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 02:59:13] d2.utils.events INFO: eta: 16:45:04  iter: 118579  total_loss: 0.824  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0682  data_time: 0.0029  lr: 0.000100  max_mem: 8920M
[01/05 03:00:15] d2.utils.events INFO: eta: 16:44:07  iter: 118599  total_loss: 0.697  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0685  data_time: 0.0029  lr: 0.000100  max_mem: 8920M
[01/05 03:01:17] d2.utils.events INFO: eta: 16:43:06  iter: 118619  total_loss: 0.901  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 3.0685  data_time: 0.0028  lr: 0.000100  max_mem: 8920M
[01/05 03:02:19] d2.utils.events INFO: eta: 16:42:10  iter: 118639  total_loss: 0.700  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0686  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 03:03:19] d2.utils.events INFO: eta: 16:41:11  iter: 118659  total_loss: 0.789  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0683  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 03:04:20] d2.utils.events INFO: eta: 16:40:13  iter: 118679  total_loss: 0.725  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0682  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:05:20] d2.utils.events INFO: eta: 16:39:11  iter: 118699  total_loss: 0.753  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0680  data_time: 0.0028  lr: 0.000100  max_mem: 8920M
[01/05 03:06:23] d2.utils.events INFO: eta: 16:38:11  iter: 118719  total_loss: 0.596  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0682  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:07:23] d2.utils.events INFO: eta: 16:37:05  iter: 118739  total_loss: 0.837  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0679  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:08:24] d2.utils.events INFO: eta: 16:36:02  iter: 118759  total_loss: 0.811  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0679  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 03:09:24] d2.utils.events INFO: eta: 16:34:59  iter: 118779  total_loss: 0.783  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0675  data_time: 0.0025  lr: 0.000100  max_mem: 8920M
[01/05 03:10:25] d2.utils.events INFO: eta: 16:33:58  iter: 118799  total_loss: 1.068  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.114  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.269  loss_cls_stage2: 0.094  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.004  loss_rpn_loc: 0.012  time: 3.0674  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:11:27] d2.utils.events INFO: eta: 16:32:54  iter: 118819  total_loss: 0.758  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0675  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 03:12:29] d2.utils.events INFO: eta: 16:31:52  iter: 118839  total_loss: 0.727  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0676  data_time: 0.0029  lr: 0.000100  max_mem: 8920M
[01/05 03:13:31] d2.utils.events INFO: eta: 16:30:57  iter: 118859  total_loss: 0.559  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0678  data_time: 0.0021  lr: 0.000100  max_mem: 8920M
[01/05 03:14:32] d2.utils.events INFO: eta: 16:29:50  iter: 118879  total_loss: 0.616  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0676  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:15:33] d2.utils.events INFO: eta: 16:28:47  iter: 118899  total_loss: 0.842  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0676  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 03:16:35] d2.utils.events INFO: eta: 16:27:45  iter: 118919  total_loss: 0.902  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0677  data_time: 0.0028  lr: 0.000100  max_mem: 8920M
[01/05 03:17:35] d2.utils.events INFO: eta: 16:26:39  iter: 118939  total_loss: 0.743  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0674  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 03:18:36] d2.utils.events INFO: eta: 16:25:38  iter: 118959  total_loss: 0.525  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0674  data_time: 0.0021  lr: 0.000100  max_mem: 8920M
[01/05 03:19:37] d2.utils.events INFO: eta: 16:24:37  iter: 118979  total_loss: 0.819  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0673  data_time: 0.0027  lr: 0.000100  max_mem: 8920M
[01/05 03:20:39] d2.utils.events INFO: eta: 16:23:37  iter: 118999  total_loss: 0.748  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0674  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 03:21:40] d2.utils.events INFO: eta: 16:22:39  iter: 119019  total_loss: 0.742  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0673  data_time: 0.0021  lr: 0.000100  max_mem: 8920M
[01/05 03:22:41] d2.utils.events INFO: eta: 16:21:34  iter: 119039  total_loss: 0.666  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0672  data_time: 0.0025  lr: 0.000100  max_mem: 8920M
[01/05 03:23:43] d2.utils.events INFO: eta: 16:20:34  iter: 119059  total_loss: 0.599  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0674  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:24:44] d2.utils.events INFO: eta: 16:19:35  iter: 119079  total_loss: 0.803  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0672  data_time: 0.0027  lr: 0.000100  max_mem: 8920M
[01/05 03:25:45] d2.utils.events INFO: eta: 16:18:34  iter: 119099  total_loss: 0.720  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0672  data_time: 0.0030  lr: 0.000100  max_mem: 8920M
[01/05 03:26:47] d2.utils.events INFO: eta: 16:17:33  iter: 119119  total_loss: 0.815  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.006  loss_rpn_loc: 0.008  time: 3.0673  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 03:27:49] d2.utils.events INFO: eta: 16:16:32  iter: 119139  total_loss: 0.813  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0676  data_time: 0.0028  lr: 0.000100  max_mem: 8920M
[01/05 03:28:53] d2.utils.events INFO: eta: 16:15:31  iter: 119159  total_loss: 0.844  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0680  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:29:54] d2.utils.events INFO: eta: 16:14:28  iter: 119179  total_loss: 0.910  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.089  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.104  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  time: 3.0680  data_time: 0.0028  lr: 0.000100  max_mem: 8920M
[01/05 03:30:55] d2.utils.events INFO: eta: 16:13:26  iter: 119199  total_loss: 0.617  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0680  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 03:31:56] d2.utils.events INFO: eta: 16:12:26  iter: 119219  total_loss: 0.719  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0677  data_time: 0.0023  lr: 0.000100  max_mem: 8920M
[01/05 03:32:56] d2.utils.events INFO: eta: 16:11:22  iter: 119239  total_loss: 0.904  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.240  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0674  data_time: 0.0021  lr: 0.000100  max_mem: 8920M
[01/05 03:33:58] d2.utils.events INFO: eta: 16:10:24  iter: 119259  total_loss: 0.974  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0676  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 03:34:59] d2.utils.events INFO: eta: 16:09:24  iter: 119279  total_loss: 0.792  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0676  data_time: 0.0022  lr: 0.000100  max_mem: 8920M
[01/05 03:36:01] d2.utils.events INFO: eta: 16:08:23  iter: 119299  total_loss: 0.726  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0677  data_time: 0.0030  lr: 0.000100  max_mem: 8920M
[01/05 03:37:02] d2.utils.events INFO: eta: 16:07:25  iter: 119319  total_loss: 0.718  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0677  data_time: 0.0026  lr: 0.000100  max_mem: 8920M
[01/05 03:38:04] d2.utils.events INFO: eta: 16:06:21  iter: 119339  total_loss: 0.706  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0677  data_time: 0.0024  lr: 0.000100  max_mem: 8920M
[01/05 03:39:05] d2.utils.events INFO: eta: 16:05:17  iter: 119359  total_loss: 0.682  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0677  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:40:07] d2.utils.events INFO: eta: 16:04:19  iter: 119379  total_loss: 0.767  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0677  data_time: 0.0035  lr: 0.000100  max_mem: 9124M
[01/05 03:41:08] d2.utils.events INFO: eta: 16:03:20  iter: 119399  total_loss: 0.628  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0677  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:42:08] d2.utils.events INFO: eta: 16:02:16  iter: 119419  total_loss: 0.791  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0674  data_time: 0.0029  lr: 0.000100  max_mem: 9124M
[01/05 03:43:11] d2.utils.events INFO: eta: 16:01:14  iter: 119439  total_loss: 0.626  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0677  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 03:44:12] d2.utils.events INFO: eta: 16:00:13  iter: 119459  total_loss: 0.618  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0676  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:45:13] d2.utils.events INFO: eta: 15:59:13  iter: 119479  total_loss: 0.648  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0676  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:46:13] d2.utils.events INFO: eta: 15:58:09  iter: 119499  total_loss: 0.645  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0673  data_time: 0.0020  lr: 0.000100  max_mem: 9124M
[01/05 03:47:15] d2.utils.events INFO: eta: 15:57:03  iter: 119519  total_loss: 0.765  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0673  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 03:48:16] d2.utils.events INFO: eta: 15:56:02  iter: 119539  total_loss: 0.944  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.273  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.368  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0673  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 03:49:18] d2.utils.events INFO: eta: 15:55:04  iter: 119559  total_loss: 0.662  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0674  data_time: 0.0030  lr: 0.000100  max_mem: 9124M
[01/05 03:50:18] d2.utils.events INFO: eta: 15:53:59  iter: 119579  total_loss: 0.680  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0673  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:51:21] d2.utils.events INFO: eta: 15:52:56  iter: 119599  total_loss: 0.728  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0674  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 03:52:21] d2.utils.events INFO: eta: 15:51:55  iter: 119619  total_loss: 0.563  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0672  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 03:53:23] d2.utils.events INFO: eta: 15:50:54  iter: 119639  total_loss: 0.715  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0674  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 03:54:25] d2.utils.events INFO: eta: 15:49:54  iter: 119659  total_loss: 0.767  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0676  data_time: 0.0031  lr: 0.000100  max_mem: 9124M
[01/05 03:55:27] d2.utils.events INFO: eta: 15:48:53  iter: 119679  total_loss: 0.826  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0675  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 03:56:29] d2.utils.events INFO: eta: 15:47:59  iter: 119699  total_loss: 0.985  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.380  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0678  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:57:31] d2.utils.events INFO: eta: 15:46:54  iter: 119719  total_loss: 0.747  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0680  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 03:58:33] d2.utils.events INFO: eta: 15:46:01  iter: 119739  total_loss: 0.712  loss_cls_stage0: 0.078  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0679  data_time: 0.0020  lr: 0.000100  max_mem: 9124M
[01/05 03:59:34] d2.utils.events INFO: eta: 15:45:01  iter: 119759  total_loss: 0.802  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.081  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0679  data_time: 0.0027  lr: 0.000100  max_mem: 9124M
[01/05 04:00:34] d2.utils.events INFO: eta: 15:43:59  iter: 119779  total_loss: 0.722  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0675  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 04:01:34] d2.utils.events INFO: eta: 15:42:53  iter: 119799  total_loss: 0.805  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.114  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0674  data_time: 0.0027  lr: 0.000100  max_mem: 9124M
[01/05 04:02:35] d2.utils.events INFO: eta: 15:41:52  iter: 119819  total_loss: 0.532  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0673  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 04:03:38] d2.utils.events INFO: eta: 15:41:00  iter: 119839  total_loss: 0.941  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0676  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:04:39] d2.utils.events INFO: eta: 15:39:49  iter: 119859  total_loss: 0.879  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0676  data_time: 0.0027  lr: 0.000100  max_mem: 9124M
[01/05 04:05:40] d2.utils.events INFO: eta: 15:38:55  iter: 119879  total_loss: 0.669  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0675  data_time: 0.0026  lr: 0.000100  max_mem: 9124M
[01/05 04:06:41] d2.utils.events INFO: eta: 15:37:58  iter: 119899  total_loss: 0.589  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0674  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 04:07:41] d2.utils.events INFO: eta: 15:36:46  iter: 119919  total_loss: 0.704  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0671  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 04:08:42] d2.utils.events INFO: eta: 15:35:52  iter: 119939  total_loss: 0.543  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0670  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:09:43] d2.utils.events INFO: eta: 15:34:51  iter: 119959  total_loss: 0.781  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0668  data_time: 0.0027  lr: 0.000100  max_mem: 9124M
[01/05 04:10:44] d2.utils.events INFO: eta: 15:33:43  iter: 119979  total_loss: 0.752  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0668  data_time: 0.0031  lr: 0.000100  max_mem: 9124M
[01/05 04:11:45] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0119999.pth
[01/05 04:11:51] d2.data.datasets.coco INFO: Loaded 1200 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small.json
[01/05 04:11:51] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 433          |   ASC-US   | 417          |    HSIL     | 306          |
|    LSIL    | 403          |  Candida   | 178          | Trichomonas | 992          |
|            |              |            |              |             |              |
|   total    | 2729         |            |              |             |              |[0m
[01/05 04:11:51] d2.evaluation.evaluator INFO: Start inference on 600 images
[01/05 04:12:55] d2.evaluation.evaluator INFO: Inference done 50/600. 0.4833 s / img. ETA=0:04:25
[01/05 04:13:20] d2.evaluation.evaluator INFO: Inference done 100/600. 0.4832 s / img. ETA=0:04:01
[01/05 04:13:44] d2.evaluation.evaluator INFO: Inference done 150/600. 0.4832 s / img. ETA=0:03:37
[01/05 04:14:08] d2.evaluation.evaluator INFO: Inference done 200/600. 0.4830 s / img. ETA=0:03:13
[01/05 04:14:32] d2.evaluation.evaluator INFO: Inference done 250/600. 0.4831 s / img. ETA=0:02:49
[01/05 04:14:56] d2.evaluation.evaluator INFO: Inference done 300/600. 0.4832 s / img. ETA=0:02:24
[01/05 04:15:21] d2.evaluation.evaluator INFO: Inference done 350/600. 0.4835 s / img. ETA=0:02:00
[01/05 04:15:45] d2.evaluation.evaluator INFO: Inference done 400/600. 0.4838 s / img. ETA=0:01:36
[01/05 04:16:09] d2.evaluation.evaluator INFO: Inference done 450/600. 0.4837 s / img. ETA=0:01:12
[01/05 04:16:33] d2.evaluation.evaluator INFO: Inference done 500/600. 0.4837 s / img. ETA=0:00:48
[01/05 04:16:57] d2.evaluation.evaluator INFO: Inference done 550/600. 0.4837 s / img. ETA=0:00:24
[01/05 04:17:21] d2.evaluation.evaluator INFO: Inference done 600/600. 0.4836 s / img. ETA=0:00:00
[01/05 04:17:22] d2.evaluation.evaluator INFO: Total inference time: 0:04:47 (0.482353 s / img per device, on 2 devices)
[01/05 04:17:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:45 (0.480602 s / img per device, on 2 devices)
[01/05 04:17:22] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/05 04:17:22] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small.json
[01/05 04:17:22] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/05 04:17:25] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.590 | 79.310 | 64.972 | 42.761 | 50.684 | 60.330 |
[01/05 04:17:25] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 58.410 | ASC-US     | 60.818 | HSIL        | 72.556 |
| LSIL       | 71.884 | Candida    | 54.369 | Trichomonas | 27.504 |
[01/05 04:17:25] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small in csv format:
[01/05 04:17:25] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/05 04:17:25] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/05 04:17:25] d2.evaluation.testing INFO: copypaste: 57.5899,79.3103,64.9718,42.7611,50.6837,60.3303
[01/05 04:17:25] d2.utils.events INFO: eta: 15:32:44  iter: 119999  total_loss: 0.886  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0668  data_time: 0.0026  lr: 0.000100  max_mem: 9124M
[01/05 04:18:26] d2.utils.events INFO: eta: 15:31:39  iter: 120019  total_loss: 0.699  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0667  data_time: 0.0026  lr: 0.000100  max_mem: 9124M
[01/05 04:19:27] d2.utils.events INFO: eta: 15:30:42  iter: 120039  total_loss: 0.679  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0666  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 04:20:28] d2.utils.events INFO: eta: 15:29:37  iter: 120059  total_loss: 0.868  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0666  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:21:30] d2.utils.events INFO: eta: 15:28:34  iter: 120079  total_loss: 0.756  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0667  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:22:31] d2.utils.events INFO: eta: 15:27:34  iter: 120099  total_loss: 0.711  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:23:33] d2.utils.events INFO: eta: 15:26:32  iter: 120119  total_loss: 0.795  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0667  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 04:24:35] d2.utils.events INFO: eta: 15:25:27  iter: 120139  total_loss: 0.684  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0668  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:25:37] d2.utils.events INFO: eta: 15:24:29  iter: 120159  total_loss: 0.711  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0671  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:26:39] d2.utils.events INFO: eta: 15:23:28  iter: 120179  total_loss: 0.706  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0671  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:27:39] d2.utils.events INFO: eta: 15:22:27  iter: 120199  total_loss: 0.805  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0670  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:28:40] d2.utils.events INFO: eta: 15:21:22  iter: 120219  total_loss: 0.873  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0667  data_time: 0.0020  lr: 0.000100  max_mem: 9124M
[01/05 04:29:41] d2.utils.events INFO: eta: 15:20:25  iter: 120239  total_loss: 0.622  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:30:41] d2.utils.events INFO: eta: 15:19:18  iter: 120259  total_loss: 0.724  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0664  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:31:41] d2.utils.events INFO: eta: 15:18:16  iter: 120279  total_loss: 0.813  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 04:32:42] d2.utils.events INFO: eta: 15:17:11  iter: 120299  total_loss: 0.799  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0662  data_time: 0.0020  lr: 0.000100  max_mem: 9124M
[01/05 04:33:44] d2.utils.events INFO: eta: 15:16:10  iter: 120319  total_loss: 0.663  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0662  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:34:47] d2.utils.events INFO: eta: 15:15:14  iter: 120339  total_loss: 0.748  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0665  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:35:49] d2.utils.events INFO: eta: 15:14:13  iter: 120359  total_loss: 0.841  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0667  data_time: 0.0026  lr: 0.000100  max_mem: 9124M
[01/05 04:36:50] d2.utils.events INFO: eta: 15:13:13  iter: 120379  total_loss: 0.623  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0667  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:37:52] d2.utils.events INFO: eta: 15:12:10  iter: 120399  total_loss: 0.925  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0668  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:38:54] d2.utils.events INFO: eta: 15:11:09  iter: 120419  total_loss: 0.491  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0669  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:39:55] d2.utils.events INFO: eta: 15:10:06  iter: 120439  total_loss: 0.647  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0668  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:40:56] d2.utils.events INFO: eta: 15:09:04  iter: 120459  total_loss: 0.824  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0667  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:41:57] d2.utils.events INFO: eta: 15:08:01  iter: 120479  total_loss: 0.774  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:42:59] d2.utils.events INFO: eta: 15:07:03  iter: 120499  total_loss: 0.618  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0667  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 04:44:00] d2.utils.events INFO: eta: 15:06:02  iter: 120519  total_loss: 0.586  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0667  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:45:03] d2.utils.events INFO: eta: 15:05:01  iter: 120539  total_loss: 0.858  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0669  data_time: 0.0020  lr: 0.000100  max_mem: 9124M
[01/05 04:46:05] d2.utils.events INFO: eta: 15:04:03  iter: 120559  total_loss: 0.655  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0672  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:47:07] d2.utils.events INFO: eta: 15:03:02  iter: 120579  total_loss: 0.594  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0672  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 04:48:07] d2.utils.events INFO: eta: 15:01:58  iter: 120599  total_loss: 0.638  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0670  data_time: 0.0020  lr: 0.000100  max_mem: 9124M
[01/05 04:49:08] d2.utils.events INFO: eta: 15:00:57  iter: 120619  total_loss: 0.606  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0670  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:50:10] d2.utils.events INFO: eta: 14:59:53  iter: 120639  total_loss: 0.498  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0670  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:51:11] d2.utils.events INFO: eta: 14:58:52  iter: 120659  total_loss: 0.658  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.121  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0669  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:52:12] d2.utils.events INFO: eta: 14:57:53  iter: 120679  total_loss: 0.566  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0669  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 04:53:14] d2.utils.events INFO: eta: 14:56:49  iter: 120699  total_loss: 0.751  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.331  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0669  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 04:54:16] d2.utils.events INFO: eta: 14:55:48  iter: 120719  total_loss: 0.691  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0670  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:55:16] d2.utils.events INFO: eta: 14:54:46  iter: 120739  total_loss: 0.756  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0668  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 04:56:19] d2.utils.events INFO: eta: 14:53:47  iter: 120759  total_loss: 0.686  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0672  data_time: 0.0025  lr: 0.000100  max_mem: 9124M
[01/05 04:57:22] d2.utils.events INFO: eta: 14:52:49  iter: 120779  total_loss: 0.828  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0674  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:58:22] d2.utils.events INFO: eta: 14:51:45  iter: 120799  total_loss: 0.703  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0672  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 04:59:22] d2.utils.events INFO: eta: 14:50:42  iter: 120819  total_loss: 0.791  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0670  data_time: 0.0021  lr: 0.000100  max_mem: 9124M
[01/05 05:00:23] d2.utils.events INFO: eta: 14:49:38  iter: 120839  total_loss: 0.615  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0669  data_time: 0.0024  lr: 0.000100  max_mem: 9124M
[01/05 05:01:26] d2.utils.events INFO: eta: 14:48:40  iter: 120859  total_loss: 0.745  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0671  data_time: 0.0023  lr: 0.000100  max_mem: 9124M
[01/05 05:02:27] d2.utils.events INFO: eta: 14:47:37  iter: 120879  total_loss: 0.727  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0672  data_time: 0.0022  lr: 0.000100  max_mem: 9124M
[01/05 05:03:30] d2.utils.events INFO: eta: 14:46:38  iter: 120899  total_loss: 0.706  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0673  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 05:04:31] d2.utils.events INFO: eta: 14:45:36  iter: 120919  total_loss: 0.667  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0673  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:05:32] d2.utils.events INFO: eta: 14:44:35  iter: 120939  total_loss: 0.669  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0672  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:06:34] d2.utils.events INFO: eta: 14:43:35  iter: 120959  total_loss: 0.714  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0674  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:07:35] d2.utils.events INFO: eta: 14:42:35  iter: 120979  total_loss: 0.743  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0672  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 05:08:35] d2.utils.events INFO: eta: 14:41:30  iter: 120999  total_loss: 0.700  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0671  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:09:36] d2.utils.events INFO: eta: 14:40:27  iter: 121019  total_loss: 0.856  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0669  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 05:10:38] d2.utils.events INFO: eta: 14:39:25  iter: 121039  total_loss: 0.599  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0671  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:11:39] d2.utils.events INFO: eta: 14:38:26  iter: 121059  total_loss: 0.749  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 3.0671  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 05:12:41] d2.utils.events INFO: eta: 14:37:27  iter: 121079  total_loss: 0.645  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0672  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:13:43] d2.utils.events INFO: eta: 14:36:22  iter: 121099  total_loss: 0.790  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0672  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 05:14:45] d2.utils.events INFO: eta: 14:35:22  iter: 121119  total_loss: 0.611  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0674  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:15:46] d2.utils.events INFO: eta: 14:34:15  iter: 121139  total_loss: 0.808  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0673  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:16:47] d2.utils.events INFO: eta: 14:33:09  iter: 121159  total_loss: 0.697  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0673  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 05:17:49] d2.utils.events INFO: eta: 14:32:06  iter: 121179  total_loss: 0.890  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0673  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 05:18:50] d2.utils.events INFO: eta: 14:31:05  iter: 121199  total_loss: 0.672  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0673  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:19:52] d2.utils.events INFO: eta: 14:30:08  iter: 121219  total_loss: 0.712  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0673  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 05:20:51] d2.utils.events INFO: eta: 14:29:03  iter: 121239  total_loss: 0.595  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0670  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:21:51] d2.utils.events INFO: eta: 14:28:02  iter: 121259  total_loss: 0.608  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0668  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:22:53] d2.utils.events INFO: eta: 14:27:05  iter: 121279  total_loss: 0.709  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0669  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:23:55] d2.utils.events INFO: eta: 14:26:02  iter: 121299  total_loss: 0.656  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0670  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:24:56] d2.utils.events INFO: eta: 14:24:56  iter: 121319  total_loss: 0.791  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0669  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 05:25:57] d2.utils.events INFO: eta: 14:23:50  iter: 121339  total_loss: 0.544  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0668  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:26:57] d2.utils.events INFO: eta: 14:22:41  iter: 121359  total_loss: 0.580  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0667  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:27:58] d2.utils.events INFO: eta: 14:21:39  iter: 121379  total_loss: 1.011  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.097  loss_box_reg_stage1: 0.244  loss_cls_stage2: 0.101  loss_box_reg_stage2: 0.375  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0666  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:28:59] d2.utils.events INFO: eta: 14:20:38  iter: 121399  total_loss: 0.829  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.008  loss_rpn_loc: 0.007  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:30:01] d2.utils.events INFO: eta: 14:19:37  iter: 121419  total_loss: 0.799  loss_cls_stage0: 0.083  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.091  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0666  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:31:02] d2.utils.events INFO: eta: 14:18:34  iter: 121439  total_loss: 0.714  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0666  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 05:32:04] d2.utils.events INFO: eta: 14:17:33  iter: 121459  total_loss: 0.901  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0666  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:33:03] d2.utils.events INFO: eta: 14:16:31  iter: 121479  total_loss: 0.741  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0663  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:34:05] d2.utils.events INFO: eta: 14:15:29  iter: 121499  total_loss: 0.766  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0664  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 05:35:07] d2.utils.events INFO: eta: 14:14:30  iter: 121519  total_loss: 0.724  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:36:09] d2.utils.events INFO: eta: 14:13:26  iter: 121539  total_loss: 0.739  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:37:10] d2.utils.events INFO: eta: 14:12:23  iter: 121559  total_loss: 0.941  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.344  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0665  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:38:11] d2.utils.events INFO: eta: 14:11:22  iter: 121579  total_loss: 0.638  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0665  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 05:39:13] d2.utils.events INFO: eta: 14:10:26  iter: 121599  total_loss: 0.685  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0666  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 05:40:15] d2.utils.events INFO: eta: 14:09:26  iter: 121619  total_loss: 0.642  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0667  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:41:17] d2.utils.events INFO: eta: 14:08:26  iter: 121639  total_loss: 0.769  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0667  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 05:42:17] d2.utils.events INFO: eta: 14:07:24  iter: 121659  total_loss: 0.469  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:43:17] d2.utils.events INFO: eta: 14:06:19  iter: 121679  total_loss: 0.730  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:44:18] d2.utils.events INFO: eta: 14:05:18  iter: 121699  total_loss: 0.581  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0662  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 05:45:19] d2.utils.events INFO: eta: 14:04:17  iter: 121719  total_loss: 0.803  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:46:21] d2.utils.events INFO: eta: 14:03:20  iter: 121739  total_loss: 0.843  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:47:23] d2.utils.events INFO: eta: 14:02:16  iter: 121759  total_loss: 0.817  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 3.0664  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 05:48:24] d2.utils.events INFO: eta: 14:01:11  iter: 121779  total_loss: 0.862  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0664  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:49:24] d2.utils.events INFO: eta: 14:00:11  iter: 121799  total_loss: 0.688  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0662  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:50:26] d2.utils.events INFO: eta: 13:59:09  iter: 121819  total_loss: 0.959  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0663  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:51:27] d2.utils.events INFO: eta: 13:58:08  iter: 121839  total_loss: 0.719  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0662  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:52:29] d2.utils.events INFO: eta: 13:57:07  iter: 121859  total_loss: 0.771  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:53:29] d2.utils.events INFO: eta: 13:56:06  iter: 121879  total_loss: 0.639  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0662  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:54:31] d2.utils.events INFO: eta: 13:55:06  iter: 121899  total_loss: 0.829  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 05:55:34] d2.utils.events INFO: eta: 13:54:05  iter: 121919  total_loss: 0.599  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0665  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 05:56:36] d2.utils.events INFO: eta: 13:53:07  iter: 121939  total_loss: 0.805  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:57:38] d2.utils.events INFO: eta: 13:52:05  iter: 121959  total_loss: 0.760  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0666  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 05:58:38] d2.utils.events INFO: eta: 13:51:04  iter: 121979  total_loss: 0.873  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0665  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 05:59:38] d2.utils.events INFO: eta: 13:50:03  iter: 121999  total_loss: 0.833  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:00:39] d2.utils.events INFO: eta: 13:49:04  iter: 122019  total_loss: 0.834  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0662  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:01:41] d2.utils.events INFO: eta: 13:48:02  iter: 122039  total_loss: 0.682  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0663  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:02:42] d2.utils.events INFO: eta: 13:46:59  iter: 122059  total_loss: 0.579  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0662  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:03:42] d2.utils.events INFO: eta: 13:45:56  iter: 122079  total_loss: 0.875  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.341  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0660  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:04:45] d2.utils.events INFO: eta: 13:44:58  iter: 122099  total_loss: 0.765  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0663  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:05:47] d2.utils.events INFO: eta: 13:43:59  iter: 122119  total_loss: 0.938  loss_cls_stage0: 0.083  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0663  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:06:49] d2.utils.events INFO: eta: 13:43:00  iter: 122139  total_loss: 0.825  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0664  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:07:51] d2.utils.events INFO: eta: 13:42:02  iter: 122159  total_loss: 0.962  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.266  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.382  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0666  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 06:08:53] d2.utils.events INFO: eta: 13:41:01  iter: 122179  total_loss: 0.919  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0666  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:09:54] d2.utils.events INFO: eta: 13:39:58  iter: 122199  total_loss: 0.647  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 3.0665  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 06:10:55] d2.utils.events INFO: eta: 13:38:55  iter: 122219  total_loss: 0.740  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0665  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 06:11:55] d2.utils.events INFO: eta: 13:37:56  iter: 122239  total_loss: 0.728  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0664  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:12:55] d2.utils.events INFO: eta: 13:36:55  iter: 122259  total_loss: 0.589  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0662  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:13:57] d2.utils.events INFO: eta: 13:35:55  iter: 122279  total_loss: 0.637  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0662  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:14:58] d2.utils.events INFO: eta: 13:34:53  iter: 122299  total_loss: 0.655  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0662  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:16:00] d2.utils.events INFO: eta: 13:33:54  iter: 122319  total_loss: 0.834  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0663  data_time: 0.0028  lr: 0.000100  max_mem: 9264M
[01/05 06:17:00] d2.utils.events INFO: eta: 13:32:53  iter: 122339  total_loss: 0.969  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.096  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.110  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0661  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 06:18:01] d2.utils.events INFO: eta: 13:31:54  iter: 122359  total_loss: 0.806  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0660  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:19:00] d2.utils.events INFO: eta: 13:30:52  iter: 122379  total_loss: 0.832  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0658  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:20:02] d2.utils.events INFO: eta: 13:29:52  iter: 122399  total_loss: 0.737  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0658  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:21:03] d2.utils.events INFO: eta: 13:28:53  iter: 122419  total_loss: 0.743  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0658  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 06:22:04] d2.utils.events INFO: eta: 13:27:54  iter: 122439  total_loss: 0.803  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0657  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:23:06] d2.utils.events INFO: eta: 13:26:56  iter: 122459  total_loss: 0.739  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0658  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:24:08] d2.utils.events INFO: eta: 13:26:03  iter: 122479  total_loss: 0.734  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0659  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:25:09] d2.utils.events INFO: eta: 13:24:58  iter: 122499  total_loss: 0.678  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0659  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:26:10] d2.utils.events INFO: eta: 13:23:57  iter: 122519  total_loss: 0.913  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.362  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0659  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:27:11] d2.utils.events INFO: eta: 13:22:53  iter: 122539  total_loss: 0.619  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0658  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:28:13] d2.utils.events INFO: eta: 13:21:52  iter: 122559  total_loss: 0.764  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0658  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:29:13] d2.utils.events INFO: eta: 13:20:51  iter: 122579  total_loss: 0.513  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0657  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:30:14] d2.utils.events INFO: eta: 13:19:47  iter: 122599  total_loss: 0.803  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0656  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:31:16] d2.utils.events INFO: eta: 13:18:44  iter: 122619  total_loss: 0.761  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0657  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:32:17] d2.utils.events INFO: eta: 13:17:41  iter: 122639  total_loss: 0.884  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.355  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0656  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 06:33:18] d2.utils.events INFO: eta: 13:16:42  iter: 122659  total_loss: 0.877  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.113  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.250  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0657  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:34:20] d2.utils.events INFO: eta: 13:15:43  iter: 122679  total_loss: 0.680  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0657  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:35:20] d2.utils.events INFO: eta: 13:14:40  iter: 122699  total_loss: 0.677  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0655  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:36:20] d2.utils.events INFO: eta: 13:13:36  iter: 122719  total_loss: 0.860  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0654  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:37:21] d2.utils.events INFO: eta: 13:12:34  iter: 122739  total_loss: 0.789  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0654  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:38:23] d2.utils.events INFO: eta: 13:11:33  iter: 122759  total_loss: 0.771  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0654  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:39:23] d2.utils.events INFO: eta: 13:10:33  iter: 122779  total_loss: 0.800  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0653  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:40:25] d2.utils.events INFO: eta: 13:09:33  iter: 122799  total_loss: 0.776  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0654  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:41:26] d2.utils.events INFO: eta: 13:08:32  iter: 122819  total_loss: 0.695  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0652  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:42:27] d2.utils.events INFO: eta: 13:07:31  iter: 122839  total_loss: 0.711  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0652  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:43:29] d2.utils.events INFO: eta: 13:06:30  iter: 122859  total_loss: 0.757  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0653  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 06:44:30] d2.utils.events INFO: eta: 13:05:29  iter: 122879  total_loss: 0.918  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.367  loss_rpn_cls: 0.000  loss_rpn_loc: 0.007  time: 3.0653  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:45:31] d2.utils.events INFO: eta: 13:04:26  iter: 122899  total_loss: 0.857  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.361  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0652  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 06:46:32] d2.utils.events INFO: eta: 13:03:25  iter: 122919  total_loss: 0.685  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0652  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:47:33] d2.utils.events INFO: eta: 13:02:17  iter: 122939  total_loss: 0.744  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  time: 3.0652  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:48:36] d2.utils.events INFO: eta: 13:01:21  iter: 122959  total_loss: 0.703  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0653  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:49:37] d2.utils.events INFO: eta: 13:00:22  iter: 122979  total_loss: 0.686  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0653  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:50:37] d2.utils.events INFO: eta: 12:59:24  iter: 122999  total_loss: 0.647  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0652  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:51:39] d2.utils.events INFO: eta: 12:58:23  iter: 123019  total_loss: 0.683  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0652  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:52:39] d2.utils.events INFO: eta: 12:57:22  iter: 123039  total_loss: 0.564  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0651  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 06:53:41] d2.utils.events INFO: eta: 12:56:24  iter: 123059  total_loss: 0.652  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0651  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:54:41] d2.utils.events INFO: eta: 12:55:23  iter: 123079  total_loss: 0.512  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.120  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0650  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 06:55:44] d2.utils.events INFO: eta: 12:54:20  iter: 123099  total_loss: 0.773  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0652  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 06:56:45] d2.utils.events INFO: eta: 12:53:14  iter: 123119  total_loss: 0.765  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0651  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 06:57:46] d2.utils.events INFO: eta: 12:52:07  iter: 123139  total_loss: 0.729  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0651  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 06:58:47] d2.utils.events INFO: eta: 12:51:04  iter: 123159  total_loss: 0.633  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0651  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 06:59:48] d2.utils.events INFO: eta: 12:50:02  iter: 123179  total_loss: 0.644  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0650  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:00:50] d2.utils.events INFO: eta: 12:49:03  iter: 123199  total_loss: 0.652  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0651  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:01:51] d2.utils.events INFO: eta: 12:48:02  iter: 123219  total_loss: 0.699  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0651  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:02:53] d2.utils.events INFO: eta: 12:47:05  iter: 123239  total_loss: 0.670  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0651  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:03:53] d2.utils.events INFO: eta: 12:46:03  iter: 123259  total_loss: 0.694  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0650  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:04:55] d2.utils.events INFO: eta: 12:45:01  iter: 123279  total_loss: 0.867  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0650  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:05:57] d2.utils.events INFO: eta: 12:44:03  iter: 123299  total_loss: 0.665  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0651  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:06:59] d2.utils.events INFO: eta: 12:42:56  iter: 123319  total_loss: 0.700  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0652  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:08:00] d2.utils.events INFO: eta: 12:41:57  iter: 123339  total_loss: 0.687  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0651  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 07:09:03] d2.utils.events INFO: eta: 12:41:05  iter: 123359  total_loss: 0.665  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0653  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:10:04] d2.utils.events INFO: eta: 12:40:07  iter: 123379  total_loss: 0.713  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0653  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:11:05] d2.utils.events INFO: eta: 12:39:04  iter: 123399  total_loss: 0.761  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0653  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:12:05] d2.utils.events INFO: eta: 12:37:58  iter: 123419  total_loss: 0.565  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0652  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:13:07] d2.utils.events INFO: eta: 12:37:01  iter: 123439  total_loss: 0.667  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0652  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 07:14:08] d2.utils.events INFO: eta: 12:35:58  iter: 123459  total_loss: 0.684  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0651  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 07:15:08] d2.utils.events INFO: eta: 12:34:56  iter: 123479  total_loss: 0.764  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0651  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:16:09] d2.utils.events INFO: eta: 12:33:59  iter: 123499  total_loss: 0.549  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0650  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:17:11] d2.utils.events INFO: eta: 12:32:55  iter: 123519  total_loss: 0.586  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0651  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:18:14] d2.utils.events INFO: eta: 12:31:56  iter: 123539  total_loss: 0.824  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0652  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:19:15] d2.utils.events INFO: eta: 12:30:54  iter: 123559  total_loss: 0.678  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0652  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:20:16] d2.utils.events INFO: eta: 12:29:53  iter: 123579  total_loss: 0.648  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0652  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 07:21:18] d2.utils.events INFO: eta: 12:28:53  iter: 123599  total_loss: 0.764  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0652  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:22:20] d2.utils.events INFO: eta: 12:27:54  iter: 123619  total_loss: 0.666  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0654  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:23:22] d2.utils.events INFO: eta: 12:26:54  iter: 123639  total_loss: 0.932  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0654  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:24:22] d2.utils.events INFO: eta: 12:25:53  iter: 123659  total_loss: 0.755  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0653  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:25:24] d2.utils.events INFO: eta: 12:24:52  iter: 123679  total_loss: 0.758  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0653  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:26:24] d2.utils.events INFO: eta: 12:23:51  iter: 123699  total_loss: 0.765  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.246  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0651  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:27:23] d2.utils.events INFO: eta: 12:22:51  iter: 123719  total_loss: 0.746  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0649  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:28:24] d2.utils.events INFO: eta: 12:21:55  iter: 123739  total_loss: 0.643  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0649  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:29:25] d2.utils.events INFO: eta: 12:20:49  iter: 123759  total_loss: 0.796  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0648  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:30:26] d2.utils.events INFO: eta: 12:19:49  iter: 123779  total_loss: 0.592  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0648  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:31:26] d2.utils.events INFO: eta: 12:18:44  iter: 123799  total_loss: 0.671  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0647  data_time: 0.0031  lr: 0.000100  max_mem: 9264M
[01/05 07:32:27] d2.utils.events INFO: eta: 12:17:46  iter: 123819  total_loss: 0.777  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0647  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:33:30] d2.utils.events INFO: eta: 12:16:49  iter: 123839  total_loss: 0.600  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0648  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:34:30] d2.utils.events INFO: eta: 12:15:47  iter: 123859  total_loss: 0.934  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0646  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 07:35:31] d2.utils.events INFO: eta: 12:14:46  iter: 123879  total_loss: 0.543  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0646  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 07:36:31] d2.utils.events INFO: eta: 12:13:45  iter: 123899  total_loss: 0.776  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0645  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 07:37:32] d2.utils.events INFO: eta: 12:12:43  iter: 123919  total_loss: 0.609  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0644  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:38:34] d2.utils.events INFO: eta: 12:11:42  iter: 123939  total_loss: 0.608  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0645  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 07:39:36] d2.utils.events INFO: eta: 12:10:40  iter: 123959  total_loss: 0.604  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0646  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:40:37] d2.utils.events INFO: eta: 12:09:39  iter: 123979  total_loss: 0.609  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0646  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:41:39] d2.utils.events INFO: eta: 12:08:38  iter: 123999  total_loss: 0.717  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0646  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:42:39] d2.utils.events INFO: eta: 12:07:37  iter: 124019  total_loss: 0.799  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0645  data_time: 0.0030  lr: 0.000100  max_mem: 9264M
[01/05 07:43:42] d2.utils.events INFO: eta: 12:06:39  iter: 124039  total_loss: 0.724  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0646  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 07:44:43] d2.utils.events INFO: eta: 12:05:36  iter: 124059  total_loss: 0.663  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0646  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:45:44] d2.utils.events INFO: eta: 12:04:35  iter: 124079  total_loss: 0.683  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0646  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:46:45] d2.utils.events INFO: eta: 12:03:31  iter: 124099  total_loss: 0.973  loss_cls_stage0: 0.087  loss_box_reg_stage0: 0.116  loss_cls_stage1: 0.094  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.105  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  time: 3.0645  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 07:47:47] d2.utils.events INFO: eta: 12:02:34  iter: 124119  total_loss: 0.974  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.251  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.410  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0647  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:48:48] d2.utils.events INFO: eta: 12:01:32  iter: 124139  total_loss: 0.671  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0645  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:49:49] d2.utils.events INFO: eta: 12:00:34  iter: 124159  total_loss: 0.668  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0646  data_time: 0.0033  lr: 0.000100  max_mem: 9264M
[01/05 07:50:52] d2.utils.events INFO: eta: 11:59:36  iter: 124179  total_loss: 0.745  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0647  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:51:53] d2.utils.events INFO: eta: 11:58:33  iter: 124199  total_loss: 0.640  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0647  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:52:54] d2.utils.events INFO: eta: 11:57:33  iter: 124219  total_loss: 0.664  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0646  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:53:55] d2.utils.events INFO: eta: 11:56:30  iter: 124239  total_loss: 0.724  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0646  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 07:54:57] d2.utils.events INFO: eta: 11:55:33  iter: 124259  total_loss: 0.728  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0647  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 07:55:58] d2.utils.events INFO: eta: 11:54:30  iter: 124279  total_loss: 0.761  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0647  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:56:58] d2.utils.events INFO: eta: 11:53:26  iter: 124299  total_loss: 0.742  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 3.0646  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 07:57:59] d2.utils.events INFO: eta: 11:52:25  iter: 124319  total_loss: 0.583  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0645  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 07:59:00] d2.utils.events INFO: eta: 11:51:26  iter: 124339  total_loss: 0.725  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0645  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:00:02] d2.utils.events INFO: eta: 11:50:22  iter: 124359  total_loss: 0.927  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.111  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.260  loss_cls_stage2: 0.088  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0646  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:01:06] d2.utils.events INFO: eta: 11:49:23  iter: 124379  total_loss: 0.596  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0648  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:02:06] d2.utils.events INFO: eta: 11:48:21  iter: 124399  total_loss: 0.445  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0647  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:03:08] d2.utils.events INFO: eta: 11:47:21  iter: 124419  total_loss: 0.803  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0648  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:04:07] d2.utils.events INFO: eta: 11:46:17  iter: 124439  total_loss: 0.487  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.139  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0645  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:05:08] d2.utils.events INFO: eta: 11:45:16  iter: 124459  total_loss: 0.790  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0645  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 08:06:09] d2.utils.events INFO: eta: 11:44:10  iter: 124479  total_loss: 0.729  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0644  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 08:07:09] d2.utils.events INFO: eta: 11:43:03  iter: 124499  total_loss: 0.666  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0643  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:08:10] d2.utils.events INFO: eta: 11:42:02  iter: 124519  total_loss: 0.747  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.006  loss_rpn_loc: 0.005  time: 3.0643  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 08:09:12] d2.utils.events INFO: eta: 11:40:59  iter: 124539  total_loss: 0.807  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0643  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:10:13] d2.utils.events INFO: eta: 11:39:58  iter: 124559  total_loss: 0.757  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0643  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:11:14] d2.utils.events INFO: eta: 11:38:59  iter: 124579  total_loss: 0.784  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0643  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 08:12:16] d2.utils.events INFO: eta: 11:37:55  iter: 124599  total_loss: 0.649  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0643  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 08:13:17] d2.utils.events INFO: eta: 11:36:51  iter: 124619  total_loss: 0.841  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0643  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 08:14:17] d2.utils.events INFO: eta: 11:35:48  iter: 124639  total_loss: 0.736  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0642  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 08:15:18] d2.utils.events INFO: eta: 11:34:48  iter: 124659  total_loss: 0.629  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0641  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:16:20] d2.utils.events INFO: eta: 11:33:48  iter: 124679  total_loss: 0.601  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0642  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 08:17:22] d2.utils.events INFO: eta: 11:32:53  iter: 124699  total_loss: 0.779  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0643  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:18:23] d2.utils.events INFO: eta: 11:31:52  iter: 124719  total_loss: 0.823  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0642  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:19:24] d2.utils.events INFO: eta: 11:30:49  iter: 124739  total_loss: 0.534  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0642  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:20:26] d2.utils.events INFO: eta: 11:29:58  iter: 124759  total_loss: 0.958  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.331  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0643  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:21:28] d2.utils.events INFO: eta: 11:28:55  iter: 124779  total_loss: 0.746  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0643  data_time: 0.0028  lr: 0.000100  max_mem: 9264M
[01/05 08:22:28] d2.utils.events INFO: eta: 11:27:50  iter: 124799  total_loss: 0.755  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0642  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:23:29] d2.utils.events INFO: eta: 11:26:48  iter: 124819  total_loss: 0.900  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0642  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 08:24:29] d2.utils.events INFO: eta: 11:25:41  iter: 124839  total_loss: 0.821  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0641  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:25:31] d2.utils.events INFO: eta: 11:24:40  iter: 124859  total_loss: 0.712  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0641  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:26:31] d2.utils.events INFO: eta: 11:23:39  iter: 124879  total_loss: 0.574  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0640  data_time: 0.0029  lr: 0.000100  max_mem: 9264M
[01/05 08:27:34] d2.utils.events INFO: eta: 11:22:38  iter: 124899  total_loss: 0.779  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0641  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:28:35] d2.utils.events INFO: eta: 11:21:38  iter: 124919  total_loss: 0.801  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0641  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 08:29:37] d2.utils.events INFO: eta: 11:20:39  iter: 124939  total_loss: 0.663  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0642  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 08:30:37] d2.utils.events INFO: eta: 11:19:36  iter: 124959  total_loss: 0.694  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0641  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:31:37] d2.utils.events INFO: eta: 11:18:35  iter: 124979  total_loss: 0.677  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0639  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:32:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0124999.pth
[01/05 08:32:43] d2.data.datasets.coco INFO: Loaded 1200 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small.json
[01/05 08:32:43] d2.evaluation.evaluator INFO: Start inference on 600 images
[01/05 08:33:48] d2.evaluation.evaluator INFO: Inference done 50/600. 0.4799 s / img. ETA=0:04:23
[01/05 08:34:12] d2.evaluation.evaluator INFO: Inference done 100/600. 0.4803 s / img. ETA=0:04:00
[01/05 08:34:36] d2.evaluation.evaluator INFO: Inference done 150/600. 0.4806 s / img. ETA=0:03:36
[01/05 08:35:00] d2.evaluation.evaluator INFO: Inference done 200/600. 0.4806 s / img. ETA=0:03:12
[01/05 08:35:24] d2.evaluation.evaluator INFO: Inference done 250/600. 0.4806 s / img. ETA=0:02:48
[01/05 08:35:48] d2.evaluation.evaluator INFO: Inference done 300/600. 0.4806 s / img. ETA=0:02:24
[01/05 08:36:12] d2.evaluation.evaluator INFO: Inference done 350/600. 0.4806 s / img. ETA=0:02:00
[01/05 08:36:36] d2.evaluation.evaluator INFO: Inference done 400/600. 0.4807 s / img. ETA=0:01:36
[01/05 08:37:00] d2.evaluation.evaluator INFO: Inference done 450/600. 0.4806 s / img. ETA=0:01:12
[01/05 08:37:24] d2.evaluation.evaluator INFO: Inference done 500/600. 0.4806 s / img. ETA=0:00:48
[01/05 08:37:48] d2.evaluation.evaluator INFO: Inference done 550/600. 0.4806 s / img. ETA=0:00:24
[01/05 08:38:12] d2.evaluation.evaluator INFO: Inference done 600/600. 0.4806 s / img. ETA=0:00:00
[01/05 08:38:12] d2.evaluation.evaluator INFO: Total inference time: 0:04:46 (0.480672 s / img per device, on 2 devices)
[01/05 08:38:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:44 (0.477461 s / img per device, on 2 devices)
[01/05 08:38:13] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/05 08:38:13] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small.json
[01/05 08:38:13] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/05 08:38:16] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.557 | 79.680 | 64.850 | 41.929 | 51.341 | 59.768 |
[01/05 08:38:16] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 59.389 | ASC-US     | 59.905 | HSIL        | 73.895 |
| LSIL       | 72.099 | Candida    | 52.403 | Trichomonas | 27.650 |
[01/05 08:38:16] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small in csv format:
[01/05 08:38:16] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/05 08:38:16] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/05 08:38:16] d2.evaluation.testing INFO: copypaste: 57.5567,79.6801,64.8501,41.9290,51.3413,59.7680
[01/05 08:38:16] d2.utils.events INFO: eta: 11:17:32  iter: 124999  total_loss: 0.791  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.177  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0639  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 08:39:16] d2.utils.events INFO: eta: 11:16:33  iter: 125019  total_loss: 0.796  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.097  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0637  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:40:17] d2.utils.events INFO: eta: 11:15:27  iter: 125039  total_loss: 0.791  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0637  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:41:18] d2.utils.events INFO: eta: 11:14:26  iter: 125059  total_loss: 0.587  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0636  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 08:42:18] d2.utils.events INFO: eta: 11:13:29  iter: 125079  total_loss: 0.637  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0636  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:43:19] d2.utils.events INFO: eta: 11:12:30  iter: 125099  total_loss: 0.933  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.251  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0635  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:44:21] d2.utils.events INFO: eta: 11:11:29  iter: 125119  total_loss: 0.863  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.235  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0636  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:45:22] d2.utils.events INFO: eta: 11:10:27  iter: 125139  total_loss: 0.649  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0636  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:46:23] d2.utils.events INFO: eta: 11:09:25  iter: 125159  total_loss: 0.925  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.113  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0635  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:47:25] d2.utils.events INFO: eta: 11:08:24  iter: 125179  total_loss: 0.887  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0636  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:48:25] d2.utils.events INFO: eta: 11:07:24  iter: 125199  total_loss: 0.647  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0635  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 08:49:26] d2.utils.events INFO: eta: 11:06:22  iter: 125219  total_loss: 0.640  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0635  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 08:50:28] d2.utils.events INFO: eta: 11:05:25  iter: 125239  total_loss: 0.914  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.083  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0635  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 08:51:29] d2.utils.events INFO: eta: 11:04:25  iter: 125259  total_loss: 0.793  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0635  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:52:32] d2.utils.events INFO: eta: 11:03:32  iter: 125279  total_loss: 0.619  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0636  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:53:33] d2.utils.events INFO: eta: 11:02:31  iter: 125299  total_loss: 0.852  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0636  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 08:54:33] d2.utils.events INFO: eta: 11:01:33  iter: 125319  total_loss: 0.824  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0635  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 08:55:35] d2.utils.events INFO: eta: 11:00:30  iter: 125339  total_loss: 0.781  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0636  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 08:56:37] d2.utils.events INFO: eta: 10:59:30  iter: 125359  total_loss: 0.655  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0636  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:57:37] d2.utils.events INFO: eta: 10:58:23  iter: 125379  total_loss: 0.881  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.246  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.008  loss_rpn_loc: 0.008  time: 3.0635  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 08:58:38] d2.utils.events INFO: eta: 10:57:24  iter: 125399  total_loss: 0.720  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0635  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 08:59:39] d2.utils.events INFO: eta: 10:56:22  iter: 125419  total_loss: 0.734  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.324  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0635  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:00:41] d2.utils.events INFO: eta: 10:55:25  iter: 125439  total_loss: 0.789  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0635  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:01:42] d2.utils.events INFO: eta: 10:54:24  iter: 125459  total_loss: 0.897  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0635  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:02:43] d2.utils.events INFO: eta: 10:53:21  iter: 125479  total_loss: 0.685  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0635  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:03:44] d2.utils.events INFO: eta: 10:52:28  iter: 125499  total_loss: 0.706  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0635  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:04:45] d2.utils.events INFO: eta: 10:51:27  iter: 125519  total_loss: 0.859  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0634  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:05:46] d2.utils.events INFO: eta: 10:50:27  iter: 125539  total_loss: 0.922  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0634  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:06:48] d2.utils.events INFO: eta: 10:49:28  iter: 125559  total_loss: 0.837  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0634  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:07:49] d2.utils.events INFO: eta: 10:48:26  iter: 125579  total_loss: 0.792  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0634  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:08:50] d2.utils.events INFO: eta: 10:47:23  iter: 125599  total_loss: 0.660  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0633  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 09:09:50] d2.utils.events INFO: eta: 10:46:20  iter: 125619  total_loss: 0.649  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0633  data_time: 0.0035  lr: 0.000100  max_mem: 9264M
[01/05 09:10:51] d2.utils.events INFO: eta: 10:45:20  iter: 125639  total_loss: 0.710  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0632  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 09:11:52] d2.utils.events INFO: eta: 10:44:20  iter: 125659  total_loss: 0.716  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0632  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:12:53] d2.utils.events INFO: eta: 10:43:21  iter: 125679  total_loss: 0.655  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0632  data_time: 0.0019  lr: 0.000100  max_mem: 9264M
[01/05 09:13:55] d2.utils.events INFO: eta: 10:42:19  iter: 125699  total_loss: 0.799  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  time: 3.0632  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:14:56] d2.utils.events INFO: eta: 10:41:22  iter: 125719  total_loss: 0.720  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0632  data_time: 0.0028  lr: 0.000100  max_mem: 9264M
[01/05 09:15:56] d2.utils.events INFO: eta: 10:40:16  iter: 125739  total_loss: 0.694  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0631  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:16:59] d2.utils.events INFO: eta: 10:39:15  iter: 125759  total_loss: 0.693  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0632  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:18:00] d2.utils.events INFO: eta: 10:38:14  iter: 125779  total_loss: 0.898  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0633  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:19:02] d2.utils.events INFO: eta: 10:37:15  iter: 125799  total_loss: 0.673  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0633  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:20:02] d2.utils.events INFO: eta: 10:36:12  iter: 125819  total_loss: 0.691  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0632  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:21:03] d2.utils.events INFO: eta: 10:35:14  iter: 125839  total_loss: 0.721  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0632  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:22:04] d2.utils.events INFO: eta: 10:34:11  iter: 125859  total_loss: 0.665  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0631  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:23:05] d2.utils.events INFO: eta: 10:33:12  iter: 125879  total_loss: 0.679  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0631  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 09:24:07] d2.utils.events INFO: eta: 10:32:11  iter: 125899  total_loss: 0.909  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0631  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 09:25:07] d2.utils.events INFO: eta: 10:31:09  iter: 125919  total_loss: 0.679  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0630  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:26:08] d2.utils.events INFO: eta: 10:30:06  iter: 125939  total_loss: 0.928  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0630  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:27:09] d2.utils.events INFO: eta: 10:29:07  iter: 125959  total_loss: 0.788  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0630  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:28:11] d2.utils.events INFO: eta: 10:28:07  iter: 125979  total_loss: 0.717  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0630  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:29:12] d2.utils.events INFO: eta: 10:27:08  iter: 125999  total_loss: 0.497  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.002  time: 3.0630  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 09:30:12] d2.utils.events INFO: eta: 10:26:06  iter: 126019  total_loss: 0.628  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0629  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 09:31:13] d2.utils.events INFO: eta: 10:25:06  iter: 126039  total_loss: 0.512  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0629  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 09:32:14] d2.utils.events INFO: eta: 10:24:05  iter: 126059  total_loss: 0.666  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0629  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:33:14] d2.utils.events INFO: eta: 10:23:03  iter: 126079  total_loss: 0.741  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0628  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:34:15] d2.utils.events INFO: eta: 10:22:03  iter: 126099  total_loss: 0.696  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0627  data_time: 0.0027  lr: 0.000100  max_mem: 9264M
[01/05 09:35:16] d2.utils.events INFO: eta: 10:20:59  iter: 126119  total_loss: 0.788  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.088  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0627  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:36:18] d2.utils.events INFO: eta: 10:20:01  iter: 126139  total_loss: 0.625  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0627  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:37:18] d2.utils.events INFO: eta: 10:18:59  iter: 126159  total_loss: 0.706  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0626  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:38:19] d2.utils.events INFO: eta: 10:17:58  iter: 126179  total_loss: 0.756  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:39:20] d2.utils.events INFO: eta: 10:16:56  iter: 126199  total_loss: 0.751  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:40:23] d2.utils.events INFO: eta: 10:15:57  iter: 126219  total_loss: 0.685  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0627  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 09:41:24] d2.utils.events INFO: eta: 10:14:55  iter: 126239  total_loss: 0.674  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0627  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:42:25] d2.utils.events INFO: eta: 10:13:52  iter: 126259  total_loss: 0.783  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0627  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 09:43:26] d2.utils.events INFO: eta: 10:12:44  iter: 126279  total_loss: 0.876  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 09:44:27] d2.utils.events INFO: eta: 10:11:45  iter: 126299  total_loss: 0.747  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0627  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:45:29] d2.utils.events INFO: eta: 10:10:47  iter: 126319  total_loss: 0.930  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0627  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:46:31] d2.utils.events INFO: eta: 10:09:44  iter: 126339  total_loss: 0.848  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0627  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:47:31] d2.utils.events INFO: eta: 10:08:41  iter: 126359  total_loss: 0.782  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.008  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:48:33] d2.utils.events INFO: eta: 10:07:41  iter: 126379  total_loss: 0.624  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0627  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 09:49:33] d2.utils.events INFO: eta: 10:06:43  iter: 126399  total_loss: 0.457  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.093  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.153  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0626  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:50:34] d2.utils.events INFO: eta: 10:05:42  iter: 126419  total_loss: 0.835  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0626  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 09:51:36] d2.utils.events INFO: eta: 10:04:45  iter: 126439  total_loss: 0.754  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0627  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:52:39] d2.utils.events INFO: eta: 10:03:47  iter: 126459  total_loss: 0.713  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0627  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 09:53:40] d2.utils.events INFO: eta: 10:02:47  iter: 126479  total_loss: 0.801  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0628  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 09:54:41] d2.utils.events INFO: eta: 10:01:44  iter: 126499  total_loss: 0.793  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:55:43] d2.utils.events INFO: eta: 10:00:44  iter: 126519  total_loss: 0.820  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 09:56:45] d2.utils.events INFO: eta: 9:59:43  iter: 126539  total_loss: 0.766  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0628  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 09:57:45] d2.utils.events INFO: eta: 9:58:40  iter: 126559  total_loss: 0.698  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0627  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 09:58:46] d2.utils.events INFO: eta: 9:57:40  iter: 126579  total_loss: 0.721  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0627  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 09:59:48] d2.utils.events INFO: eta: 9:56:42  iter: 126599  total_loss: 0.619  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0628  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:00:49] d2.utils.events INFO: eta: 9:55:41  iter: 126619  total_loss: 0.720  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0628  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:01:51] d2.utils.events INFO: eta: 9:54:41  iter: 126639  total_loss: 0.751  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0628  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:02:53] d2.utils.events INFO: eta: 9:53:40  iter: 126659  total_loss: 0.688  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0629  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:03:55] d2.utils.events INFO: eta: 9:52:39  iter: 126679  total_loss: 0.812  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0629  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:04:57] d2.utils.events INFO: eta: 9:51:39  iter: 126699  total_loss: 0.906  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.370  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 3.0630  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:05:57] d2.utils.events INFO: eta: 9:50:36  iter: 126719  total_loss: 0.877  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0629  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:06:58] d2.utils.events INFO: eta: 9:49:35  iter: 126739  total_loss: 0.641  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0629  data_time: 0.0029  lr: 0.000100  max_mem: 9264M
[01/05 10:08:01] d2.utils.events INFO: eta: 9:48:35  iter: 126759  total_loss: 0.741  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0630  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:09:03] d2.utils.events INFO: eta: 9:47:36  iter: 126779  total_loss: 0.829  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0630  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:10:03] d2.utils.events INFO: eta: 9:46:36  iter: 126799  total_loss: 0.616  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0630  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:11:03] d2.utils.events INFO: eta: 9:45:34  iter: 126819  total_loss: 0.586  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:12:03] d2.utils.events INFO: eta: 9:44:32  iter: 126839  total_loss: 0.800  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0030  lr: 0.000100  max_mem: 9264M
[01/05 10:13:05] d2.utils.events INFO: eta: 9:43:33  iter: 126859  total_loss: 0.770  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0628  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:14:06] d2.utils.events INFO: eta: 9:42:33  iter: 126879  total_loss: 0.630  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0628  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:15:07] d2.utils.events INFO: eta: 9:41:32  iter: 126899  total_loss: 0.766  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0628  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:16:09] d2.utils.events INFO: eta: 9:40:32  iter: 126919  total_loss: 0.454  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.122  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:17:12] d2.utils.events INFO: eta: 9:39:34  iter: 126939  total_loss: 0.720  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0629  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 10:18:13] d2.utils.events INFO: eta: 9:38:34  iter: 126959  total_loss: 0.695  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0629  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:19:15] d2.utils.events INFO: eta: 9:37:33  iter: 126979  total_loss: 0.694  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0630  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:20:16] d2.utils.events INFO: eta: 9:36:33  iter: 126999  total_loss: 0.715  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0630  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:21:17] d2.utils.events INFO: eta: 9:35:32  iter: 127019  total_loss: 0.668  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0629  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 10:22:18] d2.utils.events INFO: eta: 9:34:30  iter: 127039  total_loss: 0.533  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0629  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:23:19] d2.utils.events INFO: eta: 9:33:33  iter: 127059  total_loss: 0.555  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0629  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:24:20] d2.utils.events INFO: eta: 9:32:31  iter: 127079  total_loss: 0.946  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 3.0629  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:25:20] d2.utils.events INFO: eta: 9:31:28  iter: 127099  total_loss: 0.654  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0627  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 10:26:22] d2.utils.events INFO: eta: 9:30:30  iter: 127119  total_loss: 0.816  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0628  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:27:23] d2.utils.events INFO: eta: 9:29:26  iter: 127139  total_loss: 0.702  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:28:24] d2.utils.events INFO: eta: 9:28:26  iter: 127159  total_loss: 0.800  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.365  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0628  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:29:26] d2.utils.events INFO: eta: 9:27:28  iter: 127179  total_loss: 0.772  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0628  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:30:28] d2.utils.events INFO: eta: 9:26:28  iter: 127199  total_loss: 0.740  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0629  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:31:29] d2.utils.events INFO: eta: 9:25:26  iter: 127219  total_loss: 0.680  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 3.0628  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:32:30] d2.utils.events INFO: eta: 9:24:24  iter: 127239  total_loss: 0.721  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0629  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:33:31] d2.utils.events INFO: eta: 9:23:23  iter: 127259  total_loss: 0.555  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0628  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:34:31] d2.utils.events INFO: eta: 9:22:23  iter: 127279  total_loss: 0.734  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0627  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:35:32] d2.utils.events INFO: eta: 9:21:20  iter: 127299  total_loss: 0.626  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0627  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:36:33] d2.utils.events INFO: eta: 9:20:18  iter: 127319  total_loss: 0.715  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0627  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:37:34] d2.utils.events INFO: eta: 9:19:17  iter: 127339  total_loss: 0.863  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:38:35] d2.utils.events INFO: eta: 9:18:20  iter: 127359  total_loss: 0.821  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0626  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:39:36] d2.utils.events INFO: eta: 9:17:17  iter: 127379  total_loss: 0.659  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 10:40:36] d2.utils.events INFO: eta: 9:16:15  iter: 127399  total_loss: 0.870  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.326  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:41:38] d2.utils.events INFO: eta: 9:15:16  iter: 127419  total_loss: 0.718  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:42:39] d2.utils.events INFO: eta: 9:14:12  iter: 127439  total_loss: 0.749  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:43:40] d2.utils.events INFO: eta: 9:13:09  iter: 127459  total_loss: 0.691  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:44:41] d2.utils.events INFO: eta: 9:12:08  iter: 127479  total_loss: 0.681  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:45:42] d2.utils.events INFO: eta: 9:11:07  iter: 127499  total_loss: 0.705  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:46:44] d2.utils.events INFO: eta: 9:10:09  iter: 127519  total_loss: 0.733  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:47:45] d2.utils.events INFO: eta: 9:09:07  iter: 127539  total_loss: 0.546  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:48:45] d2.utils.events INFO: eta: 9:08:06  iter: 127559  total_loss: 0.655  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:49:47] d2.utils.events INFO: eta: 9:07:06  iter: 127579  total_loss: 0.532  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 10:50:49] d2.utils.events INFO: eta: 9:06:04  iter: 127599  total_loss: 0.713  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:51:49] d2.utils.events INFO: eta: 9:05:05  iter: 127619  total_loss: 0.606  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0026  lr: 0.000100  max_mem: 9264M
[01/05 10:52:51] d2.utils.events INFO: eta: 9:04:03  iter: 127639  total_loss: 0.850  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0020  lr: 0.000100  max_mem: 9264M
[01/05 10:53:52] d2.utils.events INFO: eta: 9:03:03  iter: 127659  total_loss: 0.943  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.392  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:54:53] d2.utils.events INFO: eta: 9:02:02  iter: 127679  total_loss: 0.720  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 10:55:56] d2.utils.events INFO: eta: 9:01:01  iter: 127699  total_loss: 0.729  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:56:58] d2.utils.events INFO: eta: 9:00:05  iter: 127719  total_loss: 0.748  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 10:57:59] d2.utils.events INFO: eta: 8:59:07  iter: 127739  total_loss: 0.666  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 10:59:00] d2.utils.events INFO: eta: 8:58:04  iter: 127759  total_loss: 0.674  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 11:00:00] d2.utils.events INFO: eta: 8:57:03  iter: 127779  total_loss: 0.829  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.082  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 11:01:02] d2.utils.events INFO: eta: 8:56:02  iter: 127799  total_loss: 0.748  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.343  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0023  lr: 0.000100  max_mem: 9264M
[01/05 11:02:03] d2.utils.events INFO: eta: 8:55:04  iter: 127819  total_loss: 0.706  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 11:03:04] d2.utils.events INFO: eta: 8:54:02  iter: 127839  total_loss: 0.784  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 11:04:05] d2.utils.events INFO: eta: 8:53:02  iter: 127859  total_loss: 0.746  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0625  data_time: 0.0025  lr: 0.000100  max_mem: 9264M
[01/05 11:05:06] d2.utils.events INFO: eta: 8:52:01  iter: 127879  total_loss: 0.878  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 11:06:07] d2.utils.events INFO: eta: 8:51:00  iter: 127899  total_loss: 0.599  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 11:07:08] d2.utils.events INFO: eta: 8:49:59  iter: 127919  total_loss: 0.621  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.006  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 11:08:09] d2.utils.events INFO: eta: 8:48:56  iter: 127939  total_loss: 0.752  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0028  lr: 0.000100  max_mem: 9264M
[01/05 11:09:11] d2.utils.events INFO: eta: 8:47:55  iter: 127959  total_loss: 0.779  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 11:10:12] d2.utils.events INFO: eta: 8:46:54  iter: 127979  total_loss: 0.896  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.333  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9264M
[01/05 11:11:13] d2.utils.events INFO: eta: 8:45:55  iter: 127999  total_loss: 0.593  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9264M
[01/05 11:12:15] d2.utils.events INFO: eta: 8:44:55  iter: 128019  total_loss: 0.917  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.249  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.369  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9264M
[01/05 11:13:18] d2.utils.events INFO: eta: 8:43:55  iter: 128039  total_loss: 0.641  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 11:14:19] d2.utils.events INFO: eta: 8:42:53  iter: 128059  total_loss: 0.610  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:15:19] d2.utils.events INFO: eta: 8:41:52  iter: 128079  total_loss: 0.600  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 11:16:19] d2.utils.events INFO: eta: 8:40:52  iter: 128099  total_loss: 0.882  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0623  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:17:19] d2.utils.events INFO: eta: 8:39:44  iter: 128119  total_loss: 0.714  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0622  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:18:21] d2.utils.events INFO: eta: 8:38:50  iter: 128139  total_loss: 0.655  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:19:21] d2.utils.events INFO: eta: 8:37:48  iter: 128159  total_loss: 0.693  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0622  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:20:22] d2.utils.events INFO: eta: 8:36:44  iter: 128179  total_loss: 0.663  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0622  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 11:21:24] d2.utils.events INFO: eta: 8:35:40  iter: 128199  total_loss: 1.017  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.121  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.292  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0622  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:22:26] d2.utils.events INFO: eta: 8:34:43  iter: 128219  total_loss: 0.916  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:23:28] d2.utils.events INFO: eta: 8:33:43  iter: 128239  total_loss: 0.596  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:24:29] d2.utils.events INFO: eta: 8:32:42  iter: 128259  total_loss: 0.489  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:25:31] d2.utils.events INFO: eta: 8:31:44  iter: 128279  total_loss: 0.824  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 11:26:32] d2.utils.events INFO: eta: 8:30:43  iter: 128299  total_loss: 0.783  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 11:27:34] d2.utils.events INFO: eta: 8:29:43  iter: 128319  total_loss: 0.780  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0625  data_time: 0.0027  lr: 0.000100  max_mem: 9284M
[01/05 11:28:35] d2.utils.events INFO: eta: 8:28:41  iter: 128339  total_loss: 0.832  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:29:36] d2.utils.events INFO: eta: 8:27:40  iter: 128359  total_loss: 0.759  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 11:30:37] d2.utils.events INFO: eta: 8:26:39  iter: 128379  total_loss: 0.804  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.007  loss_rpn_loc: 0.008  time: 3.0624  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 11:31:40] d2.utils.events INFO: eta: 8:25:40  iter: 128399  total_loss: 0.608  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:32:39] d2.utils.events INFO: eta: 8:24:38  iter: 128419  total_loss: 0.836  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:33:41] d2.utils.events INFO: eta: 8:23:38  iter: 128439  total_loss: 0.692  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:34:42] d2.utils.events INFO: eta: 8:22:36  iter: 128459  total_loss: 1.051  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:35:42] d2.utils.events INFO: eta: 8:21:34  iter: 128479  total_loss: 0.610  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:36:45] d2.utils.events INFO: eta: 8:20:35  iter: 128499  total_loss: 0.753  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:37:46] d2.utils.events INFO: eta: 8:19:34  iter: 128519  total_loss: 0.851  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:38:48] d2.utils.events INFO: eta: 8:18:35  iter: 128539  total_loss: 0.579  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 11:39:50] d2.utils.events INFO: eta: 8:17:35  iter: 128559  total_loss: 0.921  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.241  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.343  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:40:50] d2.utils.events INFO: eta: 8:16:34  iter: 128579  total_loss: 0.632  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:41:53] d2.utils.events INFO: eta: 8:15:33  iter: 128599  total_loss: 0.776  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:42:53] d2.utils.events INFO: eta: 8:14:31  iter: 128619  total_loss: 0.778  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:43:55] d2.utils.events INFO: eta: 8:13:34  iter: 128639  total_loss: 0.847  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.006  loss_rpn_loc: 0.008  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:44:54] d2.utils.events INFO: eta: 8:12:29  iter: 128659  total_loss: 0.527  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0623  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:45:55] d2.utils.events INFO: eta: 8:11:27  iter: 128679  total_loss: 0.653  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0623  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 11:46:56] d2.utils.events INFO: eta: 8:10:26  iter: 128699  total_loss: 0.888  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 11:47:58] d2.utils.events INFO: eta: 8:09:24  iter: 128719  total_loss: 0.720  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.078  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:49:00] d2.utils.events INFO: eta: 8:08:23  iter: 128739  total_loss: 0.703  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:50:00] d2.utils.events INFO: eta: 8:07:22  iter: 128759  total_loss: 0.659  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0623  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 11:51:02] d2.utils.events INFO: eta: 8:06:21  iter: 128779  total_loss: 0.753  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 11:52:04] d2.utils.events INFO: eta: 8:05:20  iter: 128799  total_loss: 0.816  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0623  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 11:53:04] d2.utils.events INFO: eta: 8:04:20  iter: 128819  total_loss: 0.652  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:54:05] d2.utils.events INFO: eta: 8:03:18  iter: 128839  total_loss: 0.572  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 11:55:06] d2.utils.events INFO: eta: 8:02:17  iter: 128859  total_loss: 0.727  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 11:56:09] d2.utils.events INFO: eta: 8:01:16  iter: 128879  total_loss: 0.630  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:57:10] d2.utils.events INFO: eta: 8:00:15  iter: 128899  total_loss: 0.931  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 11:58:12] d2.utils.events INFO: eta: 7:59:16  iter: 128919  total_loss: 0.714  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 11:59:14] d2.utils.events INFO: eta: 7:58:15  iter: 128939  total_loss: 0.714  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 12:00:14] d2.utils.events INFO: eta: 7:57:14  iter: 128959  total_loss: 0.715  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 12:01:16] d2.utils.events INFO: eta: 7:56:13  iter: 128979  total_loss: 0.639  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:02:18] d2.utils.events INFO: eta: 7:55:12  iter: 128999  total_loss: 0.776  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:03:21] d2.utils.events INFO: eta: 7:54:15  iter: 129019  total_loss: 0.689  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0626  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 12:04:21] d2.utils.events INFO: eta: 7:53:14  iter: 129039  total_loss: 0.706  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:05:22] d2.utils.events INFO: eta: 7:52:13  iter: 129059  total_loss: 0.602  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:06:22] d2.utils.events INFO: eta: 7:51:12  iter: 129079  total_loss: 0.640  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:07:23] d2.utils.events INFO: eta: 7:50:11  iter: 129099  total_loss: 0.822  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0623  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:08:24] d2.utils.events INFO: eta: 7:49:14  iter: 129119  total_loss: 0.965  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.272  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.372  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0624  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:09:25] d2.utils.events INFO: eta: 7:48:09  iter: 129139  total_loss: 0.933  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0623  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:10:27] d2.utils.events INFO: eta: 7:47:11  iter: 129159  total_loss: 0.679  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 12:11:29] d2.utils.events INFO: eta: 7:46:13  iter: 129179  total_loss: 0.761  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0624  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:12:30] d2.utils.events INFO: eta: 7:45:11  iter: 129199  total_loss: 0.678  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 12:13:31] d2.utils.events INFO: eta: 7:44:07  iter: 129219  total_loss: 0.631  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:14:34] d2.utils.events INFO: eta: 7:43:06  iter: 129239  total_loss: 0.739  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:15:34] d2.utils.events INFO: eta: 7:42:06  iter: 129259  total_loss: 0.701  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:16:36] d2.utils.events INFO: eta: 7:41:01  iter: 129279  total_loss: 0.737  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0625  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 12:17:37] d2.utils.events INFO: eta: 7:40:00  iter: 129299  total_loss: 0.660  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:18:39] d2.utils.events INFO: eta: 7:39:01  iter: 129319  total_loss: 0.740  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0625  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:19:41] d2.utils.events INFO: eta: 7:38:05  iter: 129339  total_loss: 0.929  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0626  data_time: 0.0019  lr: 0.000100  max_mem: 9284M
[01/05 12:20:43] d2.utils.events INFO: eta: 7:37:05  iter: 129359  total_loss: 0.812  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:21:43] d2.utils.events INFO: eta: 7:36:03  iter: 129379  total_loss: 0.725  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 3.0625  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:22:45] d2.utils.events INFO: eta: 7:35:03  iter: 129399  total_loss: 0.820  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:23:47] d2.utils.events INFO: eta: 7:34:04  iter: 129419  total_loss: 1.192  loss_cls_stage0: 0.075  loss_box_reg_stage0: 0.139  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.288  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.385  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 3.0626  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:24:48] d2.utils.events INFO: eta: 7:33:03  iter: 129439  total_loss: 0.652  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0030  lr: 0.000100  max_mem: 9284M
[01/05 12:25:50] d2.utils.events INFO: eta: 7:32:02  iter: 129459  total_loss: 0.971  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.240  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.363  loss_rpn_cls: 0.007  loss_rpn_loc: 0.009  time: 3.0626  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 12:26:51] d2.utils.events INFO: eta: 7:31:03  iter: 129479  total_loss: 0.587  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0626  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:27:52] d2.utils.events INFO: eta: 7:30:01  iter: 129499  total_loss: 0.780  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.350  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:28:54] d2.utils.events INFO: eta: 7:29:01  iter: 129519  total_loss: 0.902  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.109  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0626  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 12:29:56] d2.utils.events INFO: eta: 7:28:00  iter: 129539  total_loss: 0.746  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0627  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:30:58] d2.utils.events INFO: eta: 7:26:59  iter: 129559  total_loss: 0.872  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.240  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0627  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:31:59] d2.utils.events INFO: eta: 7:25:59  iter: 129579  total_loss: 0.514  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0627  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:32:58] d2.utils.events INFO: eta: 7:24:56  iter: 129599  total_loss: 0.748  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:34:00] d2.utils.events INFO: eta: 7:23:56  iter: 129619  total_loss: 0.850  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0626  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:35:01] d2.utils.events INFO: eta: 7:22:53  iter: 129639  total_loss: 0.626  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  time: 3.0626  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 12:36:02] d2.utils.events INFO: eta: 7:21:53  iter: 129659  total_loss: 0.621  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0626  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 12:37:02] d2.utils.events INFO: eta: 7:20:51  iter: 129679  total_loss: 0.768  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:38:03] d2.utils.events INFO: eta: 7:19:50  iter: 129699  total_loss: 0.680  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:39:04] d2.utils.events INFO: eta: 7:18:49  iter: 129719  total_loss: 0.786  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:40:05] d2.utils.events INFO: eta: 7:17:47  iter: 129739  total_loss: 0.542  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:41:06] d2.utils.events INFO: eta: 7:16:45  iter: 129759  total_loss: 0.632  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:42:08] d2.utils.events INFO: eta: 7:15:46  iter: 129779  total_loss: 0.698  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:43:10] d2.utils.events INFO: eta: 7:14:44  iter: 129799  total_loss: 0.712  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0035  lr: 0.000100  max_mem: 9284M
[01/05 12:44:11] d2.utils.events INFO: eta: 7:13:43  iter: 129819  total_loss: 0.652  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 12:45:11] d2.utils.events INFO: eta: 7:12:43  iter: 129839  total_loss: 0.678  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:46:13] d2.utils.events INFO: eta: 7:11:43  iter: 129859  total_loss: 0.898  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:47:15] d2.utils.events INFO: eta: 7:10:43  iter: 129879  total_loss: 0.610  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 12:48:17] d2.utils.events INFO: eta: 7:09:43  iter: 129899  total_loss: 0.738  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 12:49:18] d2.utils.events INFO: eta: 7:08:40  iter: 129919  total_loss: 0.811  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:50:19] d2.utils.events INFO: eta: 7:07:39  iter: 129939  total_loss: 0.599  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:51:20] d2.utils.events INFO: eta: 7:06:39  iter: 129959  total_loss: 0.694  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 12:52:21] d2.utils.events INFO: eta: 7:05:38  iter: 129979  total_loss: 0.651  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 12:53:23] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0129999.pth
[01/05 12:53:29] d2.data.datasets.coco INFO: Loaded 1200 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small.json
[01/05 12:53:29] d2.evaluation.evaluator INFO: Start inference on 600 images
[01/05 12:54:33] d2.evaluation.evaluator INFO: Inference done 50/600. 0.4787 s / img. ETA=0:04:23
[01/05 12:54:57] d2.evaluation.evaluator INFO: Inference done 100/600. 0.4792 s / img. ETA=0:03:59
[01/05 12:55:21] d2.evaluation.evaluator INFO: Inference done 150/600. 0.4794 s / img. ETA=0:03:35
[01/05 12:55:47] d2.evaluation.evaluator INFO: Inference done 200/600. 0.4891 s / img. ETA=0:03:15
[01/05 12:56:11] d2.evaluation.evaluator INFO: Inference done 250/600. 0.4872 s / img. ETA=0:02:50
[01/05 12:56:35] d2.evaluation.evaluator INFO: Inference done 300/600. 0.4862 s / img. ETA=0:02:25
[01/05 12:56:59] d2.evaluation.evaluator INFO: Inference done 350/600. 0.4852 s / img. ETA=0:02:01
[01/05 12:57:23] d2.evaluation.evaluator INFO: Inference done 400/600. 0.4844 s / img. ETA=0:01:36
[01/05 12:57:47] d2.evaluation.evaluator INFO: Inference done 450/600. 0.4839 s / img. ETA=0:01:12
[01/05 12:58:11] d2.evaluation.evaluator INFO: Inference done 500/600. 0.4836 s / img. ETA=0:00:48
[01/05 12:58:35] d2.evaluation.evaluator INFO: Inference done 550/600. 0.4831 s / img. ETA=0:00:24
[01/05 12:58:59] d2.evaluation.evaluator INFO: Inference done 600/600. 0.4829 s / img. ETA=0:00:00
[01/05 12:58:59] d2.evaluation.evaluator INFO: Total inference time: 0:04:47 (0.482353 s / img per device, on 2 devices)
[01/05 12:58:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:44 (0.478372 s / img per device, on 2 devices)
[01/05 12:58:59] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/05 12:58:59] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small.json
[01/05 12:58:59] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/05 12:59:02] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 56.643 | 78.790 | 64.412 | 44.806 | 50.546 | 58.753 |
[01/05 12:59:02] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 58.329 | ASC-US     | 59.195 | HSIL        | 71.799 |
| LSIL       | 69.941 | Candida    | 52.777 | Trichomonas | 27.814 |
[01/05 12:59:02] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small in csv format:
[01/05 12:59:02] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/05 12:59:02] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/05 12:59:02] d2.evaluation.testing INFO: copypaste: 56.6425,78.7896,64.4124,44.8056,50.5461,58.7526
[01/05 12:59:02] d2.utils.events INFO: eta: 7:04:35  iter: 129999  total_loss: 0.640  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0625  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:00:03] d2.utils.events INFO: eta: 7:03:32  iter: 130019  total_loss: 0.593  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0625  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 13:01:03] d2.utils.events INFO: eta: 7:02:29  iter: 130039  total_loss: 0.687  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0036  lr: 0.000100  max_mem: 9284M
[01/05 13:02:05] d2.utils.events INFO: eta: 7:01:28  iter: 130059  total_loss: 0.797  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0625  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:03:06] d2.utils.events INFO: eta: 7:00:26  iter: 130079  total_loss: 0.788  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0624  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:04:06] d2.utils.events INFO: eta: 6:59:27  iter: 130099  total_loss: 0.822  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0624  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:05:07] d2.utils.events INFO: eta: 6:58:28  iter: 130119  total_loss: 0.913  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0624  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:06:07] d2.utils.events INFO: eta: 6:57:26  iter: 130139  total_loss: 0.754  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:07:09] d2.utils.events INFO: eta: 6:56:25  iter: 130159  total_loss: 0.742  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0623  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:08:11] d2.utils.events INFO: eta: 6:55:24  iter: 130179  total_loss: 0.802  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:09:12] d2.utils.events INFO: eta: 6:54:24  iter: 130199  total_loss: 0.651  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:10:13] d2.utils.events INFO: eta: 6:53:23  iter: 130219  total_loss: 0.638  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0623  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:11:14] d2.utils.events INFO: eta: 6:52:19  iter: 130239  total_loss: 0.887  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.240  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.387  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0623  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:12:15] d2.utils.events INFO: eta: 6:51:19  iter: 130259  total_loss: 0.851  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0623  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:13:16] d2.utils.events INFO: eta: 6:50:17  iter: 130279  total_loss: 0.685  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0622  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:14:17] d2.utils.events INFO: eta: 6:49:16  iter: 130299  total_loss: 0.586  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0622  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 13:15:17] d2.utils.events INFO: eta: 6:48:13  iter: 130319  total_loss: 0.575  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0622  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:16:18] d2.utils.events INFO: eta: 6:47:12  iter: 130339  total_loss: 0.682  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0622  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:17:18] d2.utils.events INFO: eta: 6:46:10  iter: 130359  total_loss: 0.513  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 3.0621  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:18:19] d2.utils.events INFO: eta: 6:45:09  iter: 130379  total_loss: 0.746  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0621  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:19:21] d2.utils.events INFO: eta: 6:44:05  iter: 130399  total_loss: 0.591  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0621  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:20:21] d2.utils.events INFO: eta: 6:43:02  iter: 130419  total_loss: 0.609  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:21:23] d2.utils.events INFO: eta: 6:42:03  iter: 130439  total_loss: 0.678  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.176  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0621  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 13:22:26] d2.utils.events INFO: eta: 6:41:02  iter: 130459  total_loss: 0.701  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0621  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:23:27] d2.utils.events INFO: eta: 6:40:01  iter: 130479  total_loss: 0.755  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:24:28] d2.utils.events INFO: eta: 6:39:01  iter: 130499  total_loss: 0.798  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0622  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 13:25:30] d2.utils.events INFO: eta: 6:38:00  iter: 130519  total_loss: 0.647  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0622  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 13:26:30] d2.utils.events INFO: eta: 6:36:58  iter: 130539  total_loss: 0.663  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:27:31] d2.utils.events INFO: eta: 6:35:57  iter: 130559  total_loss: 0.648  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:28:33] d2.utils.events INFO: eta: 6:34:55  iter: 130579  total_loss: 0.684  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:29:34] d2.utils.events INFO: eta: 6:33:55  iter: 130599  total_loss: 0.858  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:30:34] d2.utils.events INFO: eta: 6:32:53  iter: 130619  total_loss: 0.755  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:31:35] d2.utils.events INFO: eta: 6:31:53  iter: 130639  total_loss: 0.588  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:32:37] d2.utils.events INFO: eta: 6:30:52  iter: 130659  total_loss: 0.547  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.181  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:33:38] d2.utils.events INFO: eta: 6:29:51  iter: 130679  total_loss: 0.625  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:34:40] d2.utils.events INFO: eta: 6:28:51  iter: 130699  total_loss: 0.654  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 13:35:42] d2.utils.events INFO: eta: 6:27:50  iter: 130719  total_loss: 0.740  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:36:43] d2.utils.events INFO: eta: 6:26:49  iter: 130739  total_loss: 0.972  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.110  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 13:37:43] d2.utils.events INFO: eta: 6:25:48  iter: 130759  total_loss: 0.770  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 13:38:45] d2.utils.events INFO: eta: 6:24:48  iter: 130779  total_loss: 0.675  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 13:39:47] d2.utils.events INFO: eta: 6:23:48  iter: 130799  total_loss: 0.579  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 13:40:48] d2.utils.events INFO: eta: 6:22:47  iter: 130819  total_loss: 0.795  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.240  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:41:49] d2.utils.events INFO: eta: 6:21:47  iter: 130839  total_loss: 0.577  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 13:42:50] d2.utils.events INFO: eta: 6:20:44  iter: 130859  total_loss: 0.688  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:43:50] d2.utils.events INFO: eta: 6:19:43  iter: 130879  total_loss: 0.912  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.246  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:44:52] d2.utils.events INFO: eta: 6:18:43  iter: 130899  total_loss: 0.702  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:45:53] d2.utils.events INFO: eta: 6:17:42  iter: 130919  total_loss: 0.603  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:46:55] d2.utils.events INFO: eta: 6:16:41  iter: 130939  total_loss: 0.842  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:47:57] d2.utils.events INFO: eta: 6:15:41  iter: 130959  total_loss: 0.862  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 13:48:58] d2.utils.events INFO: eta: 6:14:40  iter: 130979  total_loss: 0.862  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.360  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:50:00] d2.utils.events INFO: eta: 6:13:39  iter: 130999  total_loss: 0.624  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 13:51:00] d2.utils.events INFO: eta: 6:12:37  iter: 131019  total_loss: 0.599  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 13:52:00] d2.utils.events INFO: eta: 6:11:36  iter: 131039  total_loss: 0.631  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 13:53:02] d2.utils.events INFO: eta: 6:10:35  iter: 131059  total_loss: 0.671  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:54:03] d2.utils.events INFO: eta: 6:09:35  iter: 131079  total_loss: 0.695  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 13:55:05] d2.utils.events INFO: eta: 6:08:36  iter: 131099  total_loss: 0.728  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.005  loss_rpn_loc: 0.011  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:56:08] d2.utils.events INFO: eta: 6:07:35  iter: 131119  total_loss: 0.609  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0621  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:57:09] d2.utils.events INFO: eta: 6:06:34  iter: 131139  total_loss: 0.760  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 13:58:11] d2.utils.events INFO: eta: 6:05:33  iter: 131159  total_loss: 0.748  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0622  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 13:59:12] d2.utils.events INFO: eta: 6:04:32  iter: 131179  total_loss: 0.723  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0622  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:00:14] d2.utils.events INFO: eta: 6:03:34  iter: 131199  total_loss: 0.644  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0622  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:01:14] d2.utils.events INFO: eta: 6:02:32  iter: 131219  total_loss: 0.602  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 14:02:16] d2.utils.events INFO: eta: 6:01:31  iter: 131239  total_loss: 0.684  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0622  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 14:03:16] d2.utils.events INFO: eta: 6:00:28  iter: 131259  total_loss: 0.726  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:04:16] d2.utils.events INFO: eta: 5:59:28  iter: 131279  total_loss: 0.822  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:05:17] d2.utils.events INFO: eta: 5:58:30  iter: 131299  total_loss: 0.512  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.173  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0620  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:06:18] d2.utils.events INFO: eta: 5:57:30  iter: 131319  total_loss: 0.769  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:07:19] d2.utils.events INFO: eta: 5:56:29  iter: 131339  total_loss: 0.774  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0620  data_time: 0.0019  lr: 0.000100  max_mem: 9284M
[01/05 14:08:21] d2.utils.events INFO: eta: 5:55:29  iter: 131359  total_loss: 0.744  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0032  lr: 0.000100  max_mem: 9284M
[01/05 14:09:21] d2.utils.events INFO: eta: 5:54:28  iter: 131379  total_loss: 0.588  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0027  lr: 0.000100  max_mem: 9284M
[01/05 14:10:24] d2.utils.events INFO: eta: 5:53:29  iter: 131399  total_loss: 0.820  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0620  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 14:11:25] d2.utils.events INFO: eta: 5:52:28  iter: 131419  total_loss: 0.668  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:12:26] d2.utils.events INFO: eta: 5:51:27  iter: 131439  total_loss: 0.921  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0620  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:13:26] d2.utils.events INFO: eta: 5:50:24  iter: 131459  total_loss: 0.588  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:14:28] d2.utils.events INFO: eta: 5:49:23  iter: 131479  total_loss: 0.564  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 14:15:29] d2.utils.events INFO: eta: 5:48:21  iter: 131499  total_loss: 0.617  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:16:30] d2.utils.events INFO: eta: 5:47:21  iter: 131519  total_loss: 0.716  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:17:31] d2.utils.events INFO: eta: 5:46:20  iter: 131539  total_loss: 0.805  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:18:32] d2.utils.events INFO: eta: 5:45:15  iter: 131559  total_loss: 0.733  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 14:19:33] d2.utils.events INFO: eta: 5:44:15  iter: 131579  total_loss: 0.832  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:20:35] d2.utils.events INFO: eta: 5:43:18  iter: 131599  total_loss: 0.614  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:21:37] d2.utils.events INFO: eta: 5:42:18  iter: 131619  total_loss: 0.612  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 14:22:38] d2.utils.events INFO: eta: 5:41:18  iter: 131639  total_loss: 0.754  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:23:39] d2.utils.events INFO: eta: 5:40:16  iter: 131659  total_loss: 0.740  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:24:39] d2.utils.events INFO: eta: 5:39:16  iter: 131679  total_loss: 0.784  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:25:41] d2.utils.events INFO: eta: 5:38:15  iter: 131699  total_loss: 0.774  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:26:42] d2.utils.events INFO: eta: 5:37:14  iter: 131719  total_loss: 0.651  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:27:43] d2.utils.events INFO: eta: 5:36:14  iter: 131739  total_loss: 0.841  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.344  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:28:43] d2.utils.events INFO: eta: 5:35:13  iter: 131759  total_loss: 0.790  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:29:44] d2.utils.events INFO: eta: 5:34:12  iter: 131779  total_loss: 0.668  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:30:43] d2.utils.events INFO: eta: 5:33:08  iter: 131799  total_loss: 0.735  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:31:44] d2.utils.events INFO: eta: 5:32:07  iter: 131819  total_loss: 0.826  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  time: 3.0616  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:32:45] d2.utils.events INFO: eta: 5:31:05  iter: 131839  total_loss: 0.744  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 14:33:48] d2.utils.events INFO: eta: 5:30:07  iter: 131859  total_loss: 0.694  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:34:50] d2.utils.events INFO: eta: 5:29:07  iter: 131879  total_loss: 0.803  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:35:51] d2.utils.events INFO: eta: 5:28:06  iter: 131899  total_loss: 0.696  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:36:51] d2.utils.events INFO: eta: 5:27:01  iter: 131919  total_loss: 0.736  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:37:52] d2.utils.events INFO: eta: 5:26:00  iter: 131939  total_loss: 0.779  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:38:54] d2.utils.events INFO: eta: 5:24:59  iter: 131959  total_loss: 0.588  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0617  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 14:39:55] d2.utils.events INFO: eta: 5:23:57  iter: 131979  total_loss: 0.667  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 14:40:56] d2.utils.events INFO: eta: 5:22:56  iter: 131999  total_loss: 0.663  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:41:57] d2.utils.events INFO: eta: 5:21:57  iter: 132019  total_loss: 0.800  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:42:59] d2.utils.events INFO: eta: 5:20:57  iter: 132039  total_loss: 0.694  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:44:01] d2.utils.events INFO: eta: 5:19:58  iter: 132059  total_loss: 0.725  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:45:02] d2.utils.events INFO: eta: 5:18:58  iter: 132079  total_loss: 0.702  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:46:03] d2.utils.events INFO: eta: 5:17:56  iter: 132099  total_loss: 0.844  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.341  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:47:03] d2.utils.events INFO: eta: 5:16:53  iter: 132119  total_loss: 0.663  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:48:04] d2.utils.events INFO: eta: 5:15:54  iter: 132139  total_loss: 0.588  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 14:49:06] d2.utils.events INFO: eta: 5:14:52  iter: 132159  total_loss: 0.543  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:50:09] d2.utils.events INFO: eta: 5:13:53  iter: 132179  total_loss: 0.847  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.326  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:51:09] d2.utils.events INFO: eta: 5:12:50  iter: 132199  total_loss: 0.703  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:52:10] d2.utils.events INFO: eta: 5:11:50  iter: 132219  total_loss: 0.614  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:53:11] d2.utils.events INFO: eta: 5:10:49  iter: 132239  total_loss: 0.750  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:54:11] d2.utils.events INFO: eta: 5:09:49  iter: 132259  total_loss: 0.691  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 14:55:13] d2.utils.events INFO: eta: 5:08:48  iter: 132279  total_loss: 0.635  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 14:56:15] d2.utils.events INFO: eta: 5:07:46  iter: 132299  total_loss: 0.613  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 14:57:17] d2.utils.events INFO: eta: 5:06:47  iter: 132319  total_loss: 0.810  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 14:58:18] d2.utils.events INFO: eta: 5:05:46  iter: 132339  total_loss: 0.570  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 14:59:19] d2.utils.events INFO: eta: 5:04:45  iter: 132359  total_loss: 0.725  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:00:19] d2.utils.events INFO: eta: 5:03:42  iter: 132379  total_loss: 0.472  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.113  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 15:01:21] d2.utils.events INFO: eta: 5:02:41  iter: 132399  total_loss: 0.812  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0616  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:02:22] d2.utils.events INFO: eta: 5:01:40  iter: 132419  total_loss: 0.633  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:03:24] d2.utils.events INFO: eta: 5:00:40  iter: 132439  total_loss: 0.750  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:04:26] d2.utils.events INFO: eta: 4:59:40  iter: 132459  total_loss: 0.908  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 15:05:27] d2.utils.events INFO: eta: 4:58:40  iter: 132479  total_loss: 0.776  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:06:28] d2.utils.events INFO: eta: 4:57:40  iter: 132499  total_loss: 0.624  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:07:31] d2.utils.events INFO: eta: 4:56:39  iter: 132519  total_loss: 0.738  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:08:34] d2.utils.events INFO: eta: 4:55:39  iter: 132539  total_loss: 0.733  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:09:35] d2.utils.events INFO: eta: 4:54:39  iter: 132559  total_loss: 0.623  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:10:36] d2.utils.events INFO: eta: 4:53:37  iter: 132579  total_loss: 0.729  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:11:35] d2.utils.events INFO: eta: 4:52:35  iter: 132599  total_loss: 0.761  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:12:37] d2.utils.events INFO: eta: 4:51:33  iter: 132619  total_loss: 0.701  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:13:37] d2.utils.events INFO: eta: 4:50:31  iter: 132639  total_loss: 0.741  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 15:14:37] d2.utils.events INFO: eta: 4:49:30  iter: 132659  total_loss: 0.653  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:15:39] d2.utils.events INFO: eta: 4:48:31  iter: 132679  total_loss: 0.747  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:16:41] d2.utils.events INFO: eta: 4:47:30  iter: 132699  total_loss: 0.680  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:17:43] d2.utils.events INFO: eta: 4:46:28  iter: 132719  total_loss: 0.817  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:18:44] d2.utils.events INFO: eta: 4:45:27  iter: 132739  total_loss: 0.682  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:19:47] d2.utils.events INFO: eta: 4:44:29  iter: 132759  total_loss: 0.766  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:20:48] d2.utils.events INFO: eta: 4:43:27  iter: 132779  total_loss: 0.768  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:21:49] d2.utils.events INFO: eta: 4:42:27  iter: 132799  total_loss: 0.587  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:22:51] d2.utils.events INFO: eta: 4:41:26  iter: 132819  total_loss: 0.614  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:23:52] d2.utils.events INFO: eta: 4:40:25  iter: 132839  total_loss: 0.649  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:24:52] d2.utils.events INFO: eta: 4:39:24  iter: 132859  total_loss: 0.609  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:25:55] d2.utils.events INFO: eta: 4:38:24  iter: 132879  total_loss: 0.606  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:26:57] d2.utils.events INFO: eta: 4:37:23  iter: 132899  total_loss: 0.728  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:27:59] d2.utils.events INFO: eta: 4:36:22  iter: 132919  total_loss: 0.730  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:28:58] d2.utils.events INFO: eta: 4:35:22  iter: 132939  total_loss: 0.666  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:30:00] d2.utils.events INFO: eta: 4:34:21  iter: 132959  total_loss: 0.657  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:31:01] d2.utils.events INFO: eta: 4:33:22  iter: 132979  total_loss: 0.672  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:32:02] d2.utils.events INFO: eta: 4:32:21  iter: 132999  total_loss: 0.636  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.007  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:33:03] d2.utils.events INFO: eta: 4:31:19  iter: 133019  total_loss: 0.631  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:34:04] d2.utils.events INFO: eta: 4:30:17  iter: 133039  total_loss: 0.583  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:35:06] d2.utils.events INFO: eta: 4:29:17  iter: 133059  total_loss: 0.698  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 15:36:07] d2.utils.events INFO: eta: 4:28:15  iter: 133079  total_loss: 0.760  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.244  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:37:08] d2.utils.events INFO: eta: 4:27:15  iter: 133099  total_loss: 0.749  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.077  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:38:10] d2.utils.events INFO: eta: 4:26:15  iter: 133119  total_loss: 0.666  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:39:12] d2.utils.events INFO: eta: 4:25:15  iter: 133139  total_loss: 0.777  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0619  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 15:40:14] d2.utils.events INFO: eta: 4:24:15  iter: 133159  total_loss: 0.720  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:41:15] d2.utils.events INFO: eta: 4:23:12  iter: 133179  total_loss: 0.500  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 15:42:16] d2.utils.events INFO: eta: 4:22:12  iter: 133199  total_loss: 0.646  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:43:16] d2.utils.events INFO: eta: 4:21:12  iter: 133219  total_loss: 0.838  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:44:18] d2.utils.events INFO: eta: 4:20:12  iter: 133239  total_loss: 0.686  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:45:19] d2.utils.events INFO: eta: 4:19:12  iter: 133259  total_loss: 0.694  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:46:20] d2.utils.events INFO: eta: 4:18:11  iter: 133279  total_loss: 0.853  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.371  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:47:23] d2.utils.events INFO: eta: 4:17:12  iter: 133299  total_loss: 0.833  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:48:24] d2.utils.events INFO: eta: 4:16:10  iter: 133319  total_loss: 0.607  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:49:25] d2.utils.events INFO: eta: 4:15:10  iter: 133339  total_loss: 0.799  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 15:50:26] d2.utils.events INFO: eta: 4:14:09  iter: 133359  total_loss: 0.833  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:51:28] d2.utils.events INFO: eta: 4:13:09  iter: 133379  total_loss: 0.737  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 15:52:29] d2.utils.events INFO: eta: 4:12:07  iter: 133399  total_loss: 0.739  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:53:32] d2.utils.events INFO: eta: 4:11:08  iter: 133419  total_loss: 0.916  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.253  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.343  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0620  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 15:54:34] d2.utils.events INFO: eta: 4:10:07  iter: 133439  total_loss: 0.573  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:55:35] d2.utils.events INFO: eta: 4:09:07  iter: 133459  total_loss: 0.724  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 15:56:36] d2.utils.events INFO: eta: 4:08:05  iter: 133479  total_loss: 0.783  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0620  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 15:57:37] d2.utils.events INFO: eta: 4:07:04  iter: 133499  total_loss: 0.558  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 15:58:37] d2.utils.events INFO: eta: 4:06:02  iter: 133519  total_loss: 0.659  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0035  lr: 0.000100  max_mem: 9284M
[01/05 15:59:36] d2.utils.events INFO: eta: 4:04:56  iter: 133539  total_loss: 0.791  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:00:38] d2.utils.events INFO: eta: 4:03:56  iter: 133559  total_loss: 0.635  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:01:40] d2.utils.events INFO: eta: 4:02:56  iter: 133579  total_loss: 0.847  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:02:41] d2.utils.events INFO: eta: 4:01:58  iter: 133599  total_loss: 0.783  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:03:43] d2.utils.events INFO: eta: 4:00:58  iter: 133619  total_loss: 0.716  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:04:43] d2.utils.events INFO: eta: 3:59:57  iter: 133639  total_loss: 0.852  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:05:45] d2.utils.events INFO: eta: 3:58:56  iter: 133659  total_loss: 0.598  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:06:47] d2.utils.events INFO: eta: 3:57:55  iter: 133679  total_loss: 0.686  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 16:07:48] d2.utils.events INFO: eta: 3:56:54  iter: 133699  total_loss: 0.712  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.005  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 16:08:49] d2.utils.events INFO: eta: 3:55:53  iter: 133719  total_loss: 0.853  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:09:50] d2.utils.events INFO: eta: 3:54:51  iter: 133739  total_loss: 0.651  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:10:53] d2.utils.events INFO: eta: 3:53:49  iter: 133759  total_loss: 0.571  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:11:54] d2.utils.events INFO: eta: 3:52:49  iter: 133779  total_loss: 0.787  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:12:53] d2.utils.events INFO: eta: 3:51:46  iter: 133799  total_loss: 0.644  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 16:13:54] d2.utils.events INFO: eta: 3:50:45  iter: 133819  total_loss: 0.684  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:14:54] d2.utils.events INFO: eta: 3:49:44  iter: 133839  total_loss: 0.811  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 16:15:55] d2.utils.events INFO: eta: 3:48:44  iter: 133859  total_loss: 0.613  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:16:57] d2.utils.events INFO: eta: 3:47:43  iter: 133879  total_loss: 0.677  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:17:57] d2.utils.events INFO: eta: 3:46:41  iter: 133899  total_loss: 0.670  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:18:58] d2.utils.events INFO: eta: 3:45:40  iter: 133919  total_loss: 0.734  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:20:00] d2.utils.events INFO: eta: 3:44:41  iter: 133939  total_loss: 0.803  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:21:01] d2.utils.events INFO: eta: 3:43:40  iter: 133959  total_loss: 0.693  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:22:01] d2.utils.events INFO: eta: 3:42:37  iter: 133979  total_loss: 0.492  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:23:03] d2.utils.events INFO: eta: 3:41:36  iter: 133999  total_loss: 0.765  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:24:03] d2.utils.events INFO: eta: 3:40:36  iter: 134019  total_loss: 0.811  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:25:05] d2.utils.events INFO: eta: 3:39:35  iter: 134039  total_loss: 0.671  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 16:26:06] d2.utils.events INFO: eta: 3:38:34  iter: 134059  total_loss: 0.737  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:27:09] d2.utils.events INFO: eta: 3:37:34  iter: 134079  total_loss: 0.798  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:28:10] d2.utils.events INFO: eta: 3:36:32  iter: 134099  total_loss: 0.892  loss_cls_stage0: 0.079  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:29:12] d2.utils.events INFO: eta: 3:35:32  iter: 134119  total_loss: 1.013  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.117  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.258  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.373  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:30:13] d2.utils.events INFO: eta: 3:34:31  iter: 134139  total_loss: 0.684  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:31:12] d2.utils.events INFO: eta: 3:33:30  iter: 134159  total_loss: 0.690  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0034  lr: 0.000100  max_mem: 9284M
[01/05 16:32:12] d2.utils.events INFO: eta: 3:32:29  iter: 134179  total_loss: 0.480  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.046  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0027  lr: 0.000100  max_mem: 9284M
[01/05 16:33:13] d2.utils.events INFO: eta: 3:31:27  iter: 134199  total_loss: 0.616  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:34:14] d2.utils.events INFO: eta: 3:30:26  iter: 134219  total_loss: 0.665  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:35:16] d2.utils.events INFO: eta: 3:29:25  iter: 134239  total_loss: 0.654  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:36:16] d2.utils.events INFO: eta: 3:28:24  iter: 134259  total_loss: 0.754  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 16:37:18] d2.utils.events INFO: eta: 3:27:23  iter: 134279  total_loss: 0.956  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.376  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0616  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:38:21] d2.utils.events INFO: eta: 3:26:22  iter: 134299  total_loss: 0.820  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0616  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:39:22] d2.utils.events INFO: eta: 3:25:21  iter: 134319  total_loss: 0.695  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0616  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:40:23] d2.utils.events INFO: eta: 3:24:21  iter: 134339  total_loss: 0.560  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0616  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:41:25] d2.utils.events INFO: eta: 3:23:20  iter: 134359  total_loss: 0.794  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.111  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.259  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:42:27] d2.utils.events INFO: eta: 3:22:20  iter: 134379  total_loss: 0.848  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:43:29] d2.utils.events INFO: eta: 3:21:20  iter: 134399  total_loss: 0.665  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:44:31] d2.utils.events INFO: eta: 3:20:19  iter: 134419  total_loss: 0.826  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:45:32] d2.utils.events INFO: eta: 3:19:17  iter: 134439  total_loss: 0.946  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:46:35] d2.utils.events INFO: eta: 3:18:18  iter: 134459  total_loss: 0.734  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:47:37] d2.utils.events INFO: eta: 3:17:17  iter: 134479  total_loss: 0.620  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 16:48:38] d2.utils.events INFO: eta: 3:16:17  iter: 134499  total_loss: 0.696  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:49:39] d2.utils.events INFO: eta: 3:15:16  iter: 134519  total_loss: 0.594  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:50:41] d2.utils.events INFO: eta: 3:14:16  iter: 134539  total_loss: 0.696  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 16:51:42] d2.utils.events INFO: eta: 3:13:15  iter: 134559  total_loss: 0.832  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:52:42] d2.utils.events INFO: eta: 3:12:13  iter: 134579  total_loss: 0.753  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 16:53:43] d2.utils.events INFO: eta: 3:11:13  iter: 134599  total_loss: 0.673  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 16:54:45] d2.utils.events INFO: eta: 3:10:12  iter: 134619  total_loss: 0.738  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:55:47] d2.utils.events INFO: eta: 3:09:11  iter: 134639  total_loss: 0.583  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 16:56:48] d2.utils.events INFO: eta: 3:08:10  iter: 134659  total_loss: 0.579  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 16:57:49] d2.utils.events INFO: eta: 3:07:09  iter: 134679  total_loss: 0.642  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:58:49] d2.utils.events INFO: eta: 3:06:07  iter: 134699  total_loss: 0.582  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 16:59:50] d2.utils.events INFO: eta: 3:05:07  iter: 134719  total_loss: 0.670  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:00:53] d2.utils.events INFO: eta: 3:04:07  iter: 134739  total_loss: 0.427  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:01:55] d2.utils.events INFO: eta: 3:03:06  iter: 134759  total_loss: 0.599  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:02:56] d2.utils.events INFO: eta: 3:02:05  iter: 134779  total_loss: 0.716  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 17:03:58] d2.utils.events INFO: eta: 3:01:05  iter: 134799  total_loss: 0.658  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 17:04:58] d2.utils.events INFO: eta: 3:00:04  iter: 134819  total_loss: 0.565  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.170  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:05:59] d2.utils.events INFO: eta: 2:59:03  iter: 134839  total_loss: 0.705  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 17:07:00] d2.utils.events INFO: eta: 2:58:02  iter: 134859  total_loss: 0.759  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.346  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0618  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 17:08:00] d2.utils.events INFO: eta: 2:57:00  iter: 134879  total_loss: 0.709  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 17:09:02] d2.utils.events INFO: eta: 2:56:00  iter: 134899  total_loss: 0.701  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:10:03] d2.utils.events INFO: eta: 2:54:59  iter: 134919  total_loss: 0.791  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.361  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 17:11:04] d2.utils.events INFO: eta: 2:53:58  iter: 134939  total_loss: 0.748  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 17:12:06] d2.utils.events INFO: eta: 2:52:57  iter: 134959  total_loss: 0.677  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 17:13:07] d2.utils.events INFO: eta: 2:51:56  iter: 134979  total_loss: 0.947  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.257  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.366  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 17:14:09] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/05 17:14:14] d2.data.datasets.coco INFO: Loaded 1200 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small.json
[01/05 17:14:14] d2.evaluation.evaluator INFO: Start inference on 600 images
[01/05 17:15:19] d2.evaluation.evaluator INFO: Inference done 50/600. 0.4798 s / img. ETA=0:04:23
[01/05 17:15:43] d2.evaluation.evaluator INFO: Inference done 100/600. 0.4800 s / img. ETA=0:04:00
[01/05 17:16:07] d2.evaluation.evaluator INFO: Inference done 150/600. 0.4798 s / img. ETA=0:03:35
[01/05 17:16:30] d2.evaluation.evaluator INFO: Inference done 200/600. 0.4797 s / img. ETA=0:03:11
[01/05 17:16:54] d2.evaluation.evaluator INFO: Inference done 250/600. 0.4795 s / img. ETA=0:02:47
[01/05 17:17:18] d2.evaluation.evaluator INFO: Inference done 300/600. 0.4795 s / img. ETA=0:02:23
[01/05 17:17:42] d2.evaluation.evaluator INFO: Inference done 350/600. 0.4796 s / img. ETA=0:01:59
[01/05 17:18:06] d2.evaluation.evaluator INFO: Inference done 400/600. 0.4795 s / img. ETA=0:01:35
[01/05 17:18:30] d2.evaluation.evaluator INFO: Inference done 450/600. 0.4795 s / img. ETA=0:01:11
[01/05 17:18:54] d2.evaluation.evaluator INFO: Inference done 500/600. 0.4796 s / img. ETA=0:00:47
[01/05 17:19:18] d2.evaluation.evaluator INFO: Inference done 550/600. 0.4796 s / img. ETA=0:00:23
[01/05 17:19:42] d2.evaluation.evaluator INFO: Inference done 600/600. 0.4796 s / img. ETA=0:00:00
[01/05 17:19:43] d2.evaluation.evaluator INFO: Total inference time: 0:04:45 (0.478992 s / img per device, on 2 devices)
[01/05 17:19:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:43 (0.476550 s / img per device, on 2 devices)
[01/05 17:19:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/05 17:19:43] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small.json
[01/05 17:19:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/05 17:19:46] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 57.061 | 78.696 | 65.292 | 41.845 | 50.526 | 58.578 |
[01/05 17:19:46] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 58.827 | ASC-US     | 58.768 | HSIL        | 72.703 |
| LSIL       | 71.203 | Candida    | 53.315 | Trichomonas | 27.550 |
[01/05 17:19:46] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small in csv format:
[01/05 17:19:46] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/05 17:19:46] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/05 17:19:46] d2.evaluation.testing INFO: copypaste: 57.0612,78.6961,65.2921,41.8454,50.5262,58.5783
[01/05 17:19:46] d2.utils.events INFO: eta: 2:50:55  iter: 134999  total_loss: 0.741  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:20:46] d2.utils.events INFO: eta: 2:49:54  iter: 135019  total_loss: 0.502  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.135  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 17:21:47] d2.utils.events INFO: eta: 2:48:53  iter: 135039  total_loss: 0.725  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:22:48] d2.utils.events INFO: eta: 2:47:52  iter: 135059  total_loss: 0.481  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.042  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 17:23:50] d2.utils.events INFO: eta: 2:46:51  iter: 135079  total_loss: 0.749  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 17:24:52] d2.utils.events INFO: eta: 2:45:50  iter: 135099  total_loss: 0.742  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:25:53] d2.utils.events INFO: eta: 2:44:49  iter: 135119  total_loss: 0.727  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 17:26:55] d2.utils.events INFO: eta: 2:43:48  iter: 135139  total_loss: 0.639  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:27:56] d2.utils.events INFO: eta: 2:42:48  iter: 135159  total_loss: 0.687  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:28:58] d2.utils.events INFO: eta: 2:41:47  iter: 135179  total_loss: 0.607  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:29:58] d2.utils.events INFO: eta: 2:40:46  iter: 135199  total_loss: 0.681  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:30:59] d2.utils.events INFO: eta: 2:39:46  iter: 135219  total_loss: 0.820  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:32:00] d2.utils.events INFO: eta: 2:38:45  iter: 135239  total_loss: 0.581  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:33:01] d2.utils.events INFO: eta: 2:37:44  iter: 135259  total_loss: 0.937  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.261  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.348  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 17:34:01] d2.utils.events INFO: eta: 2:36:43  iter: 135279  total_loss: 0.827  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:35:04] d2.utils.events INFO: eta: 2:35:42  iter: 135299  total_loss: 0.520  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:36:05] d2.utils.events INFO: eta: 2:34:41  iter: 135319  total_loss: 0.765  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 17:37:05] d2.utils.events INFO: eta: 2:33:39  iter: 135339  total_loss: 0.725  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:38:06] d2.utils.events INFO: eta: 2:32:38  iter: 135359  total_loss: 0.684  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 17:39:07] d2.utils.events INFO: eta: 2:31:37  iter: 135379  total_loss: 0.571  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:40:08] d2.utils.events INFO: eta: 2:30:35  iter: 135399  total_loss: 0.822  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 17:41:09] d2.utils.events INFO: eta: 2:29:34  iter: 135419  total_loss: 0.591  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 17:42:10] d2.utils.events INFO: eta: 2:28:33  iter: 135439  total_loss: 0.647  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 17:43:13] d2.utils.events INFO: eta: 2:27:33  iter: 135459  total_loss: 0.837  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.356  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:44:14] d2.utils.events INFO: eta: 2:26:31  iter: 135479  total_loss: 0.611  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:45:16] d2.utils.events INFO: eta: 2:25:30  iter: 135499  total_loss: 0.696  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:46:17] d2.utils.events INFO: eta: 2:24:30  iter: 135519  total_loss: 0.827  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.333  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:47:18] d2.utils.events INFO: eta: 2:23:29  iter: 135539  total_loss: 0.892  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.351  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:48:18] d2.utils.events INFO: eta: 2:22:28  iter: 135559  total_loss: 0.514  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0616  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:49:20] d2.utils.events INFO: eta: 2:21:27  iter: 135579  total_loss: 0.818  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:50:21] d2.utils.events INFO: eta: 2:20:26  iter: 135599  total_loss: 0.598  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:51:24] d2.utils.events INFO: eta: 2:19:26  iter: 135619  total_loss: 0.710  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 17:52:25] d2.utils.events INFO: eta: 2:18:25  iter: 135639  total_loss: 0.812  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 17:53:28] d2.utils.events INFO: eta: 2:17:24  iter: 135659  total_loss: 0.693  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:54:29] d2.utils.events INFO: eta: 2:16:24  iter: 135679  total_loss: 0.558  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:55:31] d2.utils.events INFO: eta: 2:15:24  iter: 135699  total_loss: 0.536  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 17:56:33] d2.utils.events INFO: eta: 2:14:24  iter: 135719  total_loss: 0.884  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 17:57:34] d2.utils.events INFO: eta: 2:13:22  iter: 135739  total_loss: 0.757  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 17:58:35] d2.utils.events INFO: eta: 2:12:21  iter: 135759  total_loss: 0.625  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 17:59:36] d2.utils.events INFO: eta: 2:11:20  iter: 135779  total_loss: 0.493  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0618  data_time: 0.0027  lr: 0.000100  max_mem: 9284M
[01/05 18:00:37] d2.utils.events INFO: eta: 2:10:19  iter: 135799  total_loss: 0.637  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:01:40] d2.utils.events INFO: eta: 2:09:19  iter: 135819  total_loss: 0.736  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:02:41] d2.utils.events INFO: eta: 2:08:18  iter: 135839  total_loss: 0.594  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:03:43] d2.utils.events INFO: eta: 2:07:17  iter: 135859  total_loss: 0.836  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:04:43] d2.utils.events INFO: eta: 2:06:17  iter: 135879  total_loss: 0.820  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.341  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:05:44] d2.utils.events INFO: eta: 2:05:15  iter: 135899  total_loss: 0.652  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 18:06:45] d2.utils.events INFO: eta: 2:04:14  iter: 135919  total_loss: 0.698  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:07:47] d2.utils.events INFO: eta: 2:03:13  iter: 135939  total_loss: 0.821  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:08:48] d2.utils.events INFO: eta: 2:02:12  iter: 135959  total_loss: 0.760  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:09:48] d2.utils.events INFO: eta: 2:01:11  iter: 135979  total_loss: 0.613  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 18:10:50] d2.utils.events INFO: eta: 2:00:11  iter: 135999  total_loss: 0.559  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 18:11:52] d2.utils.events INFO: eta: 1:59:10  iter: 136019  total_loss: 0.645  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 18:12:53] d2.utils.events INFO: eta: 1:58:09  iter: 136039  total_loss: 0.705  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:13:54] d2.utils.events INFO: eta: 1:57:09  iter: 136059  total_loss: 0.659  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:14:56] d2.utils.events INFO: eta: 1:56:08  iter: 136079  total_loss: 0.585  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:15:57] d2.utils.events INFO: eta: 1:55:07  iter: 136099  total_loss: 0.812  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:16:59] d2.utils.events INFO: eta: 1:54:06  iter: 136119  total_loss: 0.784  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:18:00] d2.utils.events INFO: eta: 1:53:05  iter: 136139  total_loss: 0.733  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:19:01] d2.utils.events INFO: eta: 1:52:04  iter: 136159  total_loss: 0.846  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.347  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:20:03] d2.utils.events INFO: eta: 1:51:03  iter: 136179  total_loss: 0.627  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:21:03] d2.utils.events INFO: eta: 1:50:02  iter: 136199  total_loss: 0.788  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:22:05] d2.utils.events INFO: eta: 1:49:01  iter: 136219  total_loss: 0.428  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.041  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.106  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.175  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:23:07] d2.utils.events INFO: eta: 1:48:01  iter: 136239  total_loss: 0.720  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0030  lr: 0.000100  max_mem: 9284M
[01/05 18:24:08] d2.utils.events INFO: eta: 1:47:00  iter: 136259  total_loss: 0.624  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0028  lr: 0.000100  max_mem: 9284M
[01/05 18:25:10] d2.utils.events INFO: eta: 1:45:59  iter: 136279  total_loss: 0.797  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:26:12] d2.utils.events INFO: eta: 1:44:58  iter: 136299  total_loss: 0.763  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 18:27:12] d2.utils.events INFO: eta: 1:43:57  iter: 136319  total_loss: 0.634  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:28:14] d2.utils.events INFO: eta: 1:42:56  iter: 136339  total_loss: 0.796  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:29:17] d2.utils.events INFO: eta: 1:41:56  iter: 136359  total_loss: 0.601  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:30:20] d2.utils.events INFO: eta: 1:40:56  iter: 136379  total_loss: 0.729  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:31:22] d2.utils.events INFO: eta: 1:39:55  iter: 136399  total_loss: 0.695  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0621  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:32:21] d2.utils.events INFO: eta: 1:38:54  iter: 136419  total_loss: 0.861  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 18:33:23] d2.utils.events INFO: eta: 1:37:53  iter: 136439  total_loss: 0.697  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0621  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:34:24] d2.utils.events INFO: eta: 1:36:51  iter: 136459  total_loss: 0.802  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0621  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:35:26] d2.utils.events INFO: eta: 1:35:50  iter: 136479  total_loss: 0.703  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0621  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 18:36:26] d2.utils.events INFO: eta: 1:34:49  iter: 136499  total_loss: 0.663  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0621  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:37:26] d2.utils.events INFO: eta: 1:33:48  iter: 136519  total_loss: 0.677  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0620  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:38:28] d2.utils.events INFO: eta: 1:32:47  iter: 136539  total_loss: 0.604  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:39:29] d2.utils.events INFO: eta: 1:31:47  iter: 136559  total_loss: 0.769  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:40:29] d2.utils.events INFO: eta: 1:30:45  iter: 136579  total_loss: 0.747  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:41:31] d2.utils.events INFO: eta: 1:29:45  iter: 136599  total_loss: 0.535  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0620  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:42:31] d2.utils.events INFO: eta: 1:28:43  iter: 136619  total_loss: 0.840  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:43:33] d2.utils.events INFO: eta: 1:27:42  iter: 136639  total_loss: 0.702  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 18:44:33] d2.utils.events INFO: eta: 1:26:41  iter: 136659  total_loss: 0.889  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:45:33] d2.utils.events INFO: eta: 1:25:39  iter: 136679  total_loss: 0.633  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0618  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:46:35] d2.utils.events INFO: eta: 1:24:38  iter: 136699  total_loss: 0.824  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 18:47:36] d2.utils.events INFO: eta: 1:23:37  iter: 136719  total_loss: 0.647  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:48:36] d2.utils.events INFO: eta: 1:22:36  iter: 136739  total_loss: 0.672  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 18:49:37] d2.utils.events INFO: eta: 1:21:35  iter: 136759  total_loss: 0.707  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:50:37] d2.utils.events INFO: eta: 1:20:33  iter: 136779  total_loss: 0.639  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 18:51:38] d2.utils.events INFO: eta: 1:19:33  iter: 136799  total_loss: 0.806  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0617  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 18:52:40] d2.utils.events INFO: eta: 1:18:32  iter: 136819  total_loss: 0.766  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:53:42] d2.utils.events INFO: eta: 1:17:31  iter: 136839  total_loss: 0.800  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:54:43] d2.utils.events INFO: eta: 1:16:30  iter: 136859  total_loss: 0.529  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:55:46] d2.utils.events INFO: eta: 1:15:29  iter: 136879  total_loss: 0.786  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:56:48] d2.utils.events INFO: eta: 1:14:29  iter: 136899  total_loss: 0.718  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:57:49] d2.utils.events INFO: eta: 1:13:28  iter: 136919  total_loss: 0.795  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 18:58:50] d2.utils.events INFO: eta: 1:12:27  iter: 136939  total_loss: 0.722  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 18:59:52] d2.utils.events INFO: eta: 1:11:27  iter: 136959  total_loss: 0.925  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.235  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:00:54] d2.utils.events INFO: eta: 1:10:26  iter: 136979  total_loss: 0.538  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.118  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.163  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0619  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:01:54] d2.utils.events INFO: eta: 1:09:24  iter: 136999  total_loss: 0.696  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:02:55] d2.utils.events INFO: eta: 1:08:24  iter: 137019  total_loss: 0.518  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 19:03:56] d2.utils.events INFO: eta: 1:07:23  iter: 137039  total_loss: 0.955  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.253  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:04:56] d2.utils.events INFO: eta: 1:06:21  iter: 137059  total_loss: 0.616  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0032  lr: 0.000100  max_mem: 9284M
[01/05 19:05:57] d2.utils.events INFO: eta: 1:05:20  iter: 137079  total_loss: 0.610  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:06:58] d2.utils.events INFO: eta: 1:04:19  iter: 137099  total_loss: 0.830  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:07:59] d2.utils.events INFO: eta: 1:03:18  iter: 137119  total_loss: 0.803  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:09:00] d2.utils.events INFO: eta: 1:02:18  iter: 137139  total_loss: 0.737  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0618  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 19:10:02] d2.utils.events INFO: eta: 1:01:17  iter: 137159  total_loss: 0.774  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0618  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:11:03] d2.utils.events INFO: eta: 1:00:16  iter: 137179  total_loss: 0.600  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 19:12:05] d2.utils.events INFO: eta: 0:59:16  iter: 137199  total_loss: 0.655  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:13:08] d2.utils.events INFO: eta: 0:58:15  iter: 137219  total_loss: 0.860  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:14:09] d2.utils.events INFO: eta: 0:57:14  iter: 137239  total_loss: 0.793  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:15:10] d2.utils.events INFO: eta: 0:56:13  iter: 137259  total_loss: 0.667  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:16:12] d2.utils.events INFO: eta: 0:55:12  iter: 137279  total_loss: 0.750  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:17:12] d2.utils.events INFO: eta: 0:54:11  iter: 137299  total_loss: 0.631  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:18:14] d2.utils.events INFO: eta: 0:53:10  iter: 137319  total_loss: 0.677  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:19:16] d2.utils.events INFO: eta: 0:52:10  iter: 137339  total_loss: 0.853  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.109  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:20:17] d2.utils.events INFO: eta: 0:51:09  iter: 137359  total_loss: 0.588  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0619  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 19:21:18] d2.utils.events INFO: eta: 0:50:07  iter: 137379  total_loss: 0.883  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.324  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0619  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:22:19] d2.utils.events INFO: eta: 0:49:06  iter: 137399  total_loss: 0.729  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0619  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:23:19] d2.utils.events INFO: eta: 0:48:06  iter: 137419  total_loss: 0.720  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:24:19] d2.utils.events INFO: eta: 0:47:05  iter: 137439  total_loss: 0.654  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0618  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:25:20] d2.utils.events INFO: eta: 0:46:04  iter: 137459  total_loss: 0.936  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0617  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:26:21] d2.utils.events INFO: eta: 0:45:03  iter: 137479  total_loss: 0.578  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 19:27:21] d2.utils.events INFO: eta: 0:44:02  iter: 137499  total_loss: 0.690  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:28:22] d2.utils.events INFO: eta: 0:43:01  iter: 137519  total_loss: 0.569  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:29:24] d2.utils.events INFO: eta: 0:42:00  iter: 137539  total_loss: 0.557  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0617  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 19:30:24] d2.utils.events INFO: eta: 0:41:00  iter: 137559  total_loss: 0.518  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:31:25] d2.utils.events INFO: eta: 0:39:59  iter: 137579  total_loss: 0.807  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:32:27] d2.utils.events INFO: eta: 0:38:58  iter: 137599  total_loss: 0.562  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:33:29] d2.utils.events INFO: eta: 0:37:58  iter: 137619  total_loss: 0.864  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0617  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:34:30] d2.utils.events INFO: eta: 0:36:57  iter: 137639  total_loss: 1.045  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.117  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.289  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.343  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0617  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 19:35:31] d2.utils.events INFO: eta: 0:35:56  iter: 137659  total_loss: 0.614  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0617  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:36:32] d2.utils.events INFO: eta: 0:34:55  iter: 137679  total_loss: 0.560  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:37:33] d2.utils.events INFO: eta: 0:33:54  iter: 137699  total_loss: 0.910  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:38:34] d2.utils.events INFO: eta: 0:32:54  iter: 137719  total_loss: 0.760  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.333  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0616  data_time: 0.0036  lr: 0.000100  max_mem: 9284M
[01/05 19:39:36] d2.utils.events INFO: eta: 0:31:53  iter: 137739  total_loss: 0.623  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0616  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 19:40:36] d2.utils.events INFO: eta: 0:30:52  iter: 137759  total_loss: 0.760  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:41:36] d2.utils.events INFO: eta: 0:29:52  iter: 137779  total_loss: 0.806  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0616  data_time: 0.0019  lr: 0.000100  max_mem: 9284M
[01/05 19:42:38] d2.utils.events INFO: eta: 0:28:51  iter: 137799  total_loss: 0.740  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0616  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:43:39] d2.utils.events INFO: eta: 0:27:50  iter: 137819  total_loss: 0.685  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:44:39] d2.utils.events INFO: eta: 0:26:49  iter: 137839  total_loss: 0.645  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:45:40] d2.utils.events INFO: eta: 0:25:48  iter: 137859  total_loss: 0.604  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:46:42] d2.utils.events INFO: eta: 0:24:48  iter: 137879  total_loss: 0.633  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:47:42] d2.utils.events INFO: eta: 0:23:46  iter: 137899  total_loss: 0.903  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:48:44] d2.utils.events INFO: eta: 0:22:46  iter: 137919  total_loss: 0.752  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0615  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 19:49:45] d2.utils.events INFO: eta: 0:21:45  iter: 137939  total_loss: 0.814  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0615  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:50:46] d2.utils.events INFO: eta: 0:20:44  iter: 137959  total_loss: 0.894  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.244  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  time: 3.0615  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:51:47] d2.utils.events INFO: eta: 0:19:43  iter: 137979  total_loss: 0.866  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0615  data_time: 0.0025  lr: 0.000100  max_mem: 9284M
[01/05 19:52:49] d2.utils.events INFO: eta: 0:18:42  iter: 137999  total_loss: 0.475  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.044  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.111  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 19:53:51] d2.utils.events INFO: eta: 0:17:42  iter: 138019  total_loss: 0.614  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0615  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:54:52] d2.utils.events INFO: eta: 0:16:41  iter: 138039  total_loss: 0.625  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:55:56] d2.utils.events INFO: eta: 0:15:40  iter: 138059  total_loss: 0.818  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 3.0616  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:56:57] d2.utils.events INFO: eta: 0:14:39  iter: 138079  total_loss: 0.770  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0616  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 19:57:59] d2.utils.events INFO: eta: 0:13:38  iter: 138099  total_loss: 0.778  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 19:58:58] d2.utils.events INFO: eta: 0:12:37  iter: 138119  total_loss: 0.718  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.338  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 20:00:00] d2.utils.events INFO: eta: 0:11:36  iter: 138139  total_loss: 0.611  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0616  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 20:01:01] d2.utils.events INFO: eta: 0:10:35  iter: 138159  total_loss: 0.595  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0616  data_time: 0.0026  lr: 0.000100  max_mem: 9284M
[01/05 20:02:02] d2.utils.events INFO: eta: 0:09:35  iter: 138179  total_loss: 0.625  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0616  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 20:03:02] d2.utils.events INFO: eta: 0:08:34  iter: 138199  total_loss: 0.511  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 20:04:03] d2.utils.events INFO: eta: 0:07:33  iter: 138219  total_loss: 0.717  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0615  data_time: 0.0023  lr: 0.000100  max_mem: 9284M
[01/05 20:05:05] d2.utils.events INFO: eta: 0:06:32  iter: 138239  total_loss: 0.763  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 20:06:06] d2.utils.events INFO: eta: 0:05:31  iter: 138259  total_loss: 0.743  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0615  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 20:07:07] d2.utils.events INFO: eta: 0:04:30  iter: 138279  total_loss: 0.603  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0615  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 20:08:08] d2.utils.events INFO: eta: 0:03:29  iter: 138299  total_loss: 0.611  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.187  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0027  lr: 0.000100  max_mem: 9284M
[01/05 20:09:08] d2.utils.events INFO: eta: 0:02:29  iter: 138319  total_loss: 0.671  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0615  data_time: 0.0022  lr: 0.000100  max_mem: 9284M
[01/05 20:10:10] d2.utils.events INFO: eta: 0:01:28  iter: 138339  total_loss: 0.914  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0615  data_time: 0.0024  lr: 0.000100  max_mem: 9284M
[01/05 20:11:12] d2.utils.events INFO: eta: 0:00:27  iter: 138359  total_loss: 0.839  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0020  lr: 0.000100  max_mem: 9284M
[01/05 20:11:36] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_final.pth
[01/05 20:11:42] d2.data.datasets.coco INFO: Loaded 1200 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small.json
[01/05 20:11:42] d2.evaluation.evaluator INFO: Start inference on 600 images
[01/05 20:12:46] d2.evaluation.evaluator INFO: Inference done 50/600. 0.4792 s / img. ETA=0:04:23
[01/05 20:13:10] d2.evaluation.evaluator INFO: Inference done 100/600. 0.4794 s / img. ETA=0:03:59
[01/05 20:13:34] d2.evaluation.evaluator INFO: Inference done 150/600. 0.4796 s / img. ETA=0:03:35
[01/05 20:13:58] d2.evaluation.evaluator INFO: Inference done 200/600. 0.4798 s / img. ETA=0:03:11
[01/05 20:14:22] d2.evaluation.evaluator INFO: Inference done 250/600. 0.4804 s / img. ETA=0:02:48
[01/05 20:14:46] d2.evaluation.evaluator INFO: Inference done 300/600. 0.4803 s / img. ETA=0:02:24
[01/05 20:15:10] d2.evaluation.evaluator INFO: Inference done 350/600. 0.4802 s / img. ETA=0:02:00
[01/05 20:15:34] d2.evaluation.evaluator INFO: Inference done 400/600. 0.4801 s / img. ETA=0:01:36
[01/05 20:15:58] d2.evaluation.evaluator INFO: Inference done 450/600. 0.4801 s / img. ETA=0:01:12
[01/05 20:16:22] d2.evaluation.evaluator INFO: Inference done 500/600. 0.4801 s / img. ETA=0:00:48
[01/05 20:16:46] d2.evaluation.evaluator INFO: Inference done 550/600. 0.4801 s / img. ETA=0:00:24
[01/05 20:17:10] d2.evaluation.evaluator INFO: Inference done 600/600. 0.4800 s / img. ETA=0:00:00
[01/05 20:17:10] d2.evaluation.evaluator INFO: Total inference time: 0:04:45 (0.478992 s / img per device, on 2 devices)
[01/05 20:17:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:04:43 (0.476970 s / img per device, on 2 devices)
[01/05 20:17:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/05 20:17:10] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small.json
[01/05 20:17:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/05 20:17:13] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 55.424 | 77.521 | 62.983 | 43.421 | 48.752 | 57.287 |
[01/05 20:17:13] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 55.955 | ASC-US     | 58.657 | HSIL        | 70.644 |
| LSIL       | 69.610 | Candida    | 50.747 | Trichomonas | 26.931 |
[01/05 20:17:13] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small in csv format:
[01/05 20:17:13] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/05 20:17:13] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/05 20:17:13] d2.evaluation.testing INFO: copypaste: 55.4239,77.5212,62.9831,43.4206,48.7524,57.2869
[01/05 20:17:13] d2.utils.events INFO: eta: 0:00:03  iter: 138367  total_loss: 0.801  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0615  data_time: 0.0021  lr: 0.000100  max_mem: 9284M
[01/05 20:17:13] d2.trainer INFO: Running inference with test-time augmentation ...
[01/05 20:17:13] d2.data.datasets.coco INFO: Loaded 1200 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small.json
[01/05 20:17:14] d2.evaluation.evaluator INFO: Start inference on 600 images
[01/05 20:20:31] d2.evaluation.evaluator INFO: Inference done 50/600. 3.3272 s / img. ETA=0:30:29
[01/05 20:23:17] d2.evaluation.evaluator INFO: Inference done 100/600. 3.3282 s / img. ETA=0:27:44
[01/05 20:26:03] d2.evaluation.evaluator INFO: Inference done 150/600. 3.3270 s / img. ETA=0:24:57
[01/05 20:28:49] d2.evaluation.evaluator INFO: Inference done 200/600. 3.3227 s / img. ETA=0:22:09
[01/05 20:31:34] d2.evaluation.evaluator INFO: Inference done 250/600. 3.3190 s / img. ETA=0:19:21
[01/05 20:34:19] d2.evaluation.evaluator INFO: Inference done 300/600. 3.3167 s / img. ETA=0:16:35
[01/05 20:37:04] d2.evaluation.evaluator INFO: Inference done 350/600. 3.3149 s / img. ETA=0:13:48
[01/05 20:39:50] d2.evaluation.evaluator INFO: Inference done 400/600. 3.3134 s / img. ETA=0:11:02
[01/05 20:42:36] d2.evaluation.evaluator INFO: Inference done 450/600. 3.3143 s / img. ETA=0:08:17
[01/05 20:45:22] d2.evaluation.evaluator INFO: Inference done 500/600. 3.3146 s / img. ETA=0:05:31
[01/05 20:48:07] d2.evaluation.evaluator INFO: Inference done 550/600. 3.3134 s / img. ETA=0:02:45
[01/05 20:50:52] d2.evaluation.evaluator INFO: Inference done 600/600. 3.3128 s / img. ETA=0:00:00
[01/05 20:50:52] d2.evaluation.evaluator INFO: Total inference time: 0:32:51 (3.312605 s / img per device, on 2 devices)
[01/05 20:50:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:32:49 (3.309877 s / img per device, on 2 devices)
[01/05 20:50:57] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/05 20:50:57] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference_TTA/my_dataset_val_small.json
[01/05 20:50:57] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/05 20:51:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 59.624 | 82.293 | 67.672 | 36.793 | 54.157 | 61.640 |
[01/05 20:51:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 61.277 | ASC-US     | 63.633 | HSIL        | 73.613 |
| LSIL       | 74.512 | Candida    | 54.801 | Trichomonas | 29.907 |
[01/05 20:51:01] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small in csv format:
[01/05 20:51:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/05 20:51:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/05 20:51:01] d2.evaluation.testing INFO: copypaste: 59.6237,82.2933,67.6723,36.7934,54.1568,61.6402
[01/05 20:51:01] d2.engine.hooks INFO: Overall training speed: 23365 iterations in 19:52:16 (3.0617 s / it)
[01/05 20:51:01] d2.engine.hooks INFO: Total training time: 20:54:51 (1:02:35 on hooks)
[01/05 23:01:25] detectron2 INFO: Rank of current process: 0. World size: 2
[01/05 23:01:29] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/05 23:01:29] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/05 23:01:29] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test  my_dataset_val_small
SOLVER:
  MAX_ITER: 138368  ## 46368 74368(70000 最好) 96368(8500)  116368 138368
  BASE_LR: 0.01     ### 
  STEPS: (138068, 138268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/05 23:01:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 138368
  MOMENTUM: 0.9
  STEPS: (138068, 138268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/05 23:01:30] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/05 23:01:30] d2.utils.env INFO: Using a generated random seed 30102870
[01/05 23:01:33] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/05 23:01:33] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_final.pth
[01/05 23:01:34] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[01/05 23:01:34] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[01/05 23:01:35] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[01/05 23:01:36] d2.evaluation.evaluator INFO: Start inference on 16850 images
[01/05 23:02:29] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4794 s / img. ETA=2:14:13
[01/05 23:02:53] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4803 s / img. ETA=2:14:04
[01/05 23:03:18] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4811 s / img. ETA=2:13:54
[01/05 23:03:42] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4810 s / img. ETA=2:13:28
[01/05 23:04:06] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4810 s / img. ETA=2:13:04
[01/05 23:04:30] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4810 s / img. ETA=2:12:40
[01/05 23:04:54] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4810 s / img. ETA=2:12:16
[01/05 23:05:18] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4811 s / img. ETA=2:11:54
[01/05 23:05:42] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4812 s / img. ETA=2:11:31
[01/05 23:06:06] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4813 s / img. ETA=2:11:08
[01/05 23:06:30] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4815 s / img. ETA=2:10:48
[01/05 23:06:54] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4815 s / img. ETA=2:10:24
[01/05 23:07:18] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4814 s / img. ETA=2:09:59
[01/05 23:07:42] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4814 s / img. ETA=2:09:34
[01/05 23:08:07] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4814 s / img. ETA=2:09:10
[01/05 23:08:31] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4813 s / img. ETA=2:08:45
[01/05 23:08:55] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4813 s / img. ETA=2:08:21
[01/05 23:09:19] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4813 s / img. ETA=2:07:57
[01/05 23:09:43] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4813 s / img. ETA=2:07:32
[01/05 23:10:07] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4813 s / img. ETA=2:07:08
[01/05 23:10:31] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4813 s / img. ETA=2:06:44
[01/05 23:10:55] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4813 s / img. ETA=2:06:20
[01/05 23:11:19] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4813 s / img. ETA=2:05:56
[01/05 23:11:43] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4813 s / img. ETA=2:05:32
[01/05 23:12:07] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4813 s / img. ETA=2:05:07
[01/05 23:12:31] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4812 s / img. ETA=2:04:42
[01/05 23:12:55] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4812 s / img. ETA=2:04:18
[01/05 23:13:19] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4812 s / img. ETA=2:03:55
[01/05 23:13:43] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4812 s / img. ETA=2:03:30
[01/05 23:14:07] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4811 s / img. ETA=2:03:05
[01/05 23:14:31] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4811 s / img. ETA=2:02:41
[01/05 23:14:55] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4811 s / img. ETA=2:02:16
[01/05 23:15:19] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4811 s / img. ETA=2:01:53
[01/05 23:15:43] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4812 s / img. ETA=2:01:29
[01/05 23:16:08] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4812 s / img. ETA=2:01:05
[01/05 23:16:32] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4812 s / img. ETA=2:00:41
[01/05 23:16:56] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4812 s / img. ETA=2:00:17
[01/05 23:17:20] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4811 s / img. ETA=1:59:52
[01/05 23:17:44] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4812 s / img. ETA=1:59:29
[01/05 23:18:08] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4811 s / img. ETA=1:59:05
[01/05 23:18:32] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4811 s / img. ETA=1:58:40
[01/05 23:18:56] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4811 s / img. ETA=1:58:16
[01/05 23:19:20] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4811 s / img. ETA=1:57:52
[01/05 23:19:44] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4812 s / img. ETA=1:57:28
[01/05 23:20:08] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4812 s / img. ETA=1:57:05
[01/05 23:20:32] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4812 s / img. ETA=1:56:41
[01/05 23:20:56] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4812 s / img. ETA=1:56:16
[01/05 23:21:20] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4812 s / img. ETA=1:55:52
[01/05 23:21:44] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4812 s / img. ETA=1:55:28
[01/05 23:22:08] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4812 s / img. ETA=1:55:04
[01/05 23:22:32] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4812 s / img. ETA=1:54:40
[01/05 23:22:57] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4812 s / img. ETA=1:54:17
[01/05 23:23:21] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4812 s / img. ETA=1:53:53
[01/05 23:23:45] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4812 s / img. ETA=1:53:29
[01/05 23:24:09] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4812 s / img. ETA=1:53:05
[01/05 23:24:33] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4812 s / img. ETA=1:52:41
[01/05 23:24:57] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4812 s / img. ETA=1:52:17
[01/05 23:25:21] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4812 s / img. ETA=1:51:53
[01/05 23:25:45] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4812 s / img. ETA=1:51:29
[01/05 23:26:09] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4812 s / img. ETA=1:51:04
[01/05 23:26:33] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4812 s / img. ETA=1:50:40
[01/05 23:26:57] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4812 s / img. ETA=1:50:16
[01/05 23:27:21] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4812 s / img. ETA=1:49:52
[01/05 23:27:45] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4812 s / img. ETA=1:49:28
[01/05 23:28:09] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4812 s / img. ETA=1:49:04
[01/05 23:28:33] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4812 s / img. ETA=1:48:40
[01/05 23:28:58] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4812 s / img. ETA=1:48:16
[01/05 23:29:22] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4812 s / img. ETA=1:47:52
[01/05 23:29:46] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4812 s / img. ETA=1:47:28
[01/05 23:30:10] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4812 s / img. ETA=1:47:03
[01/05 23:30:33] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4811 s / img. ETA=1:46:38
[01/05 23:30:57] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4811 s / img. ETA=1:46:14
[01/05 23:31:21] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4811 s / img. ETA=1:45:50
[01/05 23:31:45] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4811 s / img. ETA=1:45:25
[01/05 23:32:09] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4810 s / img. ETA=1:45:01
[01/05 23:32:33] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4810 s / img. ETA=1:44:36
[01/05 23:32:57] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4810 s / img. ETA=1:44:12
[01/05 23:33:21] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4810 s / img. ETA=1:43:48
[01/05 23:33:45] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4810 s / img. ETA=1:43:24
[01/05 23:34:09] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4810 s / img. ETA=1:43:00
[01/05 23:34:34] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4810 s / img. ETA=1:42:37
[01/05 23:34:58] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4810 s / img. ETA=1:42:13
[01/05 23:35:22] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4810 s / img. ETA=1:41:48
[01/05 23:35:46] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4810 s / img. ETA=1:41:24
[01/05 23:36:10] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4810 s / img. ETA=1:41:00
[01/05 23:36:34] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4810 s / img. ETA=1:40:36
[01/05 23:36:58] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4810 s / img. ETA=1:40:12
[01/05 23:37:22] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4809 s / img. ETA=1:39:47
[01/05 23:37:46] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4810 s / img. ETA=1:39:23
[01/05 23:38:10] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4810 s / img. ETA=1:38:59
[01/05 23:38:34] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4809 s / img. ETA=1:38:35
[01/05 23:38:58] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4809 s / img. ETA=1:38:11
[01/05 23:39:22] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4810 s / img. ETA=1:37:47
[01/05 23:39:46] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4810 s / img. ETA=1:37:24
[01/05 23:40:10] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4810 s / img. ETA=1:36:59
[01/05 23:40:34] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4810 s / img. ETA=1:36:35
[01/05 23:40:58] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4810 s / img. ETA=1:36:11
[01/05 23:41:22] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4810 s / img. ETA=1:35:47
[01/05 23:41:46] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4810 s / img. ETA=1:35:23
[01/05 23:42:10] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4809 s / img. ETA=1:34:59
[01/05 23:42:34] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4809 s / img. ETA=1:34:35
[01/05 23:42:58] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4809 s / img. ETA=1:34:11
[01/05 23:43:22] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4809 s / img. ETA=1:33:47
[01/05 23:43:46] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4809 s / img. ETA=1:33:22
[01/05 23:44:10] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4809 s / img. ETA=1:32:58
[01/05 23:44:34] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4809 s / img. ETA=1:32:34
[01/05 23:44:58] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4809 s / img. ETA=1:32:10
[01/05 23:45:22] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4809 s / img. ETA=1:31:46
[01/05 23:45:46] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4809 s / img. ETA=1:31:22
[01/05 23:46:10] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4809 s / img. ETA=1:30:57
[01/05 23:46:34] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4809 s / img. ETA=1:30:33
[01/05 23:46:58] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4809 s / img. ETA=1:30:09
[01/05 23:47:22] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4809 s / img. ETA=1:29:45
[01/05 23:47:46] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4809 s / img. ETA=1:29:21
[01/05 23:48:10] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4809 s / img. ETA=1:28:57
[01/05 23:48:34] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4809 s / img. ETA=1:28:33
[01/05 23:48:58] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4809 s / img. ETA=1:28:09
[01/05 23:49:22] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4808 s / img. ETA=1:27:45
[01/05 23:49:47] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4809 s / img. ETA=1:27:21
[01/05 23:50:11] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4809 s / img. ETA=1:26:57
[01/05 23:50:34] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4808 s / img. ETA=1:26:32
[01/05 23:50:58] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4808 s / img. ETA=1:26:08
[01/05 23:51:22] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4808 s / img. ETA=1:25:44
[01/05 23:51:46] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4808 s / img. ETA=1:25:20
[01/05 23:52:11] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4808 s / img. ETA=1:24:56
[01/05 23:52:35] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4808 s / img. ETA=1:24:32
[01/05 23:52:59] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4808 s / img. ETA=1:24:08
[01/05 23:53:23] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4808 s / img. ETA=1:23:44
[01/05 23:53:47] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4808 s / img. ETA=1:23:20
[01/05 23:54:11] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4808 s / img. ETA=1:22:56
[01/05 23:54:35] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4808 s / img. ETA=1:22:32
[01/05 23:54:59] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4808 s / img. ETA=1:22:08
[01/05 23:55:23] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4808 s / img. ETA=1:21:44
[01/05 23:55:49] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4811 s / img. ETA=1:21:23
[01/05 23:56:13] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4811 s / img. ETA=1:20:59
[01/05 23:56:37] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4811 s / img. ETA=1:20:35
[01/05 23:57:01] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4811 s / img. ETA=1:20:11
[01/05 23:57:25] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4811 s / img. ETA=1:19:47
[01/05 23:57:49] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4811 s / img. ETA=1:19:22
[01/05 23:58:13] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4811 s / img. ETA=1:18:58
[01/05 23:58:37] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4811 s / img. ETA=1:18:34
[01/05 23:59:01] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4811 s / img. ETA=1:18:10
[01/05 23:59:25] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4811 s / img. ETA=1:17:46
[01/05 23:59:49] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4811 s / img. ETA=1:17:22
[01/06 00:00:13] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4811 s / img. ETA=1:16:58
[01/06 00:00:37] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4811 s / img. ETA=1:16:34
[01/06 00:01:01] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4811 s / img. ETA=1:16:10
[01/06 00:01:25] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4811 s / img. ETA=1:15:46
[01/06 00:01:49] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4811 s / img. ETA=1:15:21
[01/06 00:02:13] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4811 s / img. ETA=1:14:57
[01/06 00:02:37] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4810 s / img. ETA=1:14:33
[01/06 00:03:01] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4810 s / img. ETA=1:14:09
[01/06 00:03:25] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4810 s / img. ETA=1:13:45
[01/06 00:03:49] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4810 s / img. ETA=1:13:21
[01/06 00:04:14] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4810 s / img. ETA=1:12:57
[01/06 00:04:38] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4810 s / img. ETA=1:12:33
[01/06 00:05:02] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4810 s / img. ETA=1:12:09
[01/06 00:05:26] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4810 s / img. ETA=1:11:45
[01/06 00:05:50] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4810 s / img. ETA=1:11:21
[01/06 00:06:14] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4810 s / img. ETA=1:10:56
[01/06 00:06:38] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4810 s / img. ETA=1:10:32
[01/06 00:07:01] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4810 s / img. ETA=1:10:08
[01/06 00:07:25] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4810 s / img. ETA=1:09:44
[01/06 00:07:49] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4810 s / img. ETA=1:09:20
[01/06 00:08:13] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4809 s / img. ETA=1:08:56
[01/06 00:08:37] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4809 s / img. ETA=1:08:32
[01/06 00:09:01] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4809 s / img. ETA=1:08:07
[01/06 00:09:25] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4809 s / img. ETA=1:07:43
[01/06 00:09:49] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4809 s / img. ETA=1:07:19
[01/06 00:10:13] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4809 s / img. ETA=1:06:55
[01/06 00:10:37] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4809 s / img. ETA=1:06:31
[01/06 00:11:01] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4809 s / img. ETA=1:06:07
[01/06 00:11:25] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4809 s / img. ETA=1:05:43
[01/06 00:11:49] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4809 s / img. ETA=1:05:19
[01/06 00:12:13] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4809 s / img. ETA=1:04:55
[01/06 00:12:37] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4809 s / img. ETA=1:04:31
[01/06 00:13:01] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4809 s / img. ETA=1:04:07
[01/06 00:13:25] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4809 s / img. ETA=1:03:43
[01/06 00:13:49] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4809 s / img. ETA=1:03:18
[01/06 00:14:13] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4809 s / img. ETA=1:02:54
[01/06 00:14:37] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4809 s / img. ETA=1:02:30
[01/06 00:15:01] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4809 s / img. ETA=1:02:06
[01/06 00:15:25] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4809 s / img. ETA=1:01:42
[01/06 00:15:49] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4809 s / img. ETA=1:01:18
[01/06 00:16:13] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4808 s / img. ETA=1:00:54
[01/06 00:16:37] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4808 s / img. ETA=1:00:30
[01/06 00:17:01] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4808 s / img. ETA=1:00:06
[01/06 00:17:25] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4808 s / img. ETA=0:59:42
[01/06 00:17:49] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4808 s / img. ETA=0:59:18
[01/06 00:18:13] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4808 s / img. ETA=0:58:54
[01/06 00:18:38] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4809 s / img. ETA=0:58:30
[01/06 00:19:02] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4809 s / img. ETA=0:58:06
[01/06 00:19:26] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4809 s / img. ETA=0:57:42
[01/06 00:19:50] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4809 s / img. ETA=0:57:18
[01/06 00:20:14] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4809 s / img. ETA=0:56:54
[01/06 00:20:38] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4809 s / img. ETA=0:56:30
[01/06 00:21:02] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4808 s / img. ETA=0:56:05
[01/06 00:21:26] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4808 s / img. ETA=0:55:41
[01/06 00:21:50] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4808 s / img. ETA=0:55:17
[01/06 00:22:13] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4808 s / img. ETA=0:54:53
[01/06 00:22:37] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4808 s / img. ETA=0:54:29
[01/06 00:23:01] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4808 s / img. ETA=0:54:05
[01/06 00:23:25] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4808 s / img. ETA=0:53:41
[01/06 00:23:49] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4808 s / img. ETA=0:53:17
[01/06 00:24:13] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4808 s / img. ETA=0:52:53
[01/06 00:24:38] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4808 s / img. ETA=0:52:29
[01/06 00:25:01] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4808 s / img. ETA=0:52:05
[01/06 00:25:25] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4808 s / img. ETA=0:51:40
[01/06 00:25:49] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4808 s / img. ETA=0:51:16
[01/06 00:26:14] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4808 s / img. ETA=0:50:52
[01/06 00:26:38] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4808 s / img. ETA=0:50:28
[01/06 00:27:02] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4808 s / img. ETA=0:50:04
[01/06 00:27:26] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4808 s / img. ETA=0:49:40
[01/06 00:27:50] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4808 s / img. ETA=0:49:16
[01/06 00:28:14] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4808 s / img. ETA=0:48:52
[01/06 00:28:38] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4808 s / img. ETA=0:48:28
[01/06 00:29:02] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4808 s / img. ETA=0:48:04
[01/06 00:29:26] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4808 s / img. ETA=0:47:40
[01/06 00:29:50] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4807 s / img. ETA=0:47:16
[01/06 00:30:14] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4807 s / img. ETA=0:46:52
[01/06 00:30:38] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4807 s / img. ETA=0:46:28
[01/06 00:31:02] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4807 s / img. ETA=0:46:04
[01/06 00:31:26] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4807 s / img. ETA=0:45:40
[01/06 00:31:50] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4807 s / img. ETA=0:45:16
[01/06 00:32:14] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4807 s / img. ETA=0:44:52
[01/06 00:32:38] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4807 s / img. ETA=0:44:28
[01/06 00:33:02] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4807 s / img. ETA=0:44:04
[01/06 00:33:26] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4807 s / img. ETA=0:43:39
[01/06 00:33:50] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4807 s / img. ETA=0:43:15
[01/06 00:34:14] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4807 s / img. ETA=0:42:51
[01/06 00:34:38] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4807 s / img. ETA=0:42:27
[01/06 00:35:02] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4807 s / img. ETA=0:42:03
[01/06 00:35:26] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4807 s / img. ETA=0:41:39
[01/06 00:35:50] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4807 s / img. ETA=0:41:15
[01/06 00:36:14] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4807 s / img. ETA=0:40:51
[01/06 00:36:38] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4807 s / img. ETA=0:40:27
[01/06 00:37:02] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4807 s / img. ETA=0:40:03
[01/06 00:37:26] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4807 s / img. ETA=0:39:39
[01/06 00:37:50] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4807 s / img. ETA=0:39:15
[01/06 00:38:14] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4807 s / img. ETA=0:38:51
[01/06 00:38:38] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4807 s / img. ETA=0:38:27
[01/06 00:39:02] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4807 s / img. ETA=0:38:03
[01/06 00:39:26] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4807 s / img. ETA=0:37:39
[01/06 00:39:50] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4807 s / img. ETA=0:37:15
[01/06 00:40:14] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4807 s / img. ETA=0:36:51
[01/06 00:40:38] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4807 s / img. ETA=0:36:27
[01/06 00:41:02] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4807 s / img. ETA=0:36:03
[01/06 00:41:26] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4807 s / img. ETA=0:35:39
[01/06 00:41:50] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4807 s / img. ETA=0:35:15
[01/06 00:42:14] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4807 s / img. ETA=0:34:50
[01/06 00:42:38] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4807 s / img. ETA=0:34:26
[01/06 00:43:02] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4807 s / img. ETA=0:34:02
[01/06 00:43:26] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4807 s / img. ETA=0:33:38
[01/06 00:43:50] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4807 s / img. ETA=0:33:14
[01/06 00:44:14] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4807 s / img. ETA=0:32:50
[01/06 00:44:38] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4807 s / img. ETA=0:32:26
[01/06 00:45:02] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4807 s / img. ETA=0:32:02
[01/06 00:45:26] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4807 s / img. ETA=0:31:38
[01/06 00:45:50] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4806 s / img. ETA=0:31:14
[01/06 00:46:14] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4806 s / img. ETA=0:30:50
[01/06 00:46:38] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4806 s / img. ETA=0:30:26
[01/06 00:47:02] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4806 s / img. ETA=0:30:02
[01/06 00:47:26] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4806 s / img. ETA=0:29:38
[01/06 00:47:50] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4806 s / img. ETA=0:29:14
[01/06 00:48:14] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4806 s / img. ETA=0:28:50
[01/06 00:48:38] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4806 s / img. ETA=0:28:26
[01/06 00:49:02] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4806 s / img. ETA=0:28:02
[01/06 00:49:26] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4806 s / img. ETA=0:27:38
[01/06 00:49:50] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4806 s / img. ETA=0:27:14
[01/06 00:50:14] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4806 s / img. ETA=0:26:50
[01/06 00:50:38] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4806 s / img. ETA=0:26:26
[01/06 00:51:02] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4806 s / img. ETA=0:26:02
[01/06 00:51:26] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4806 s / img. ETA=0:25:37
[01/06 00:51:50] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4806 s / img. ETA=0:25:13
[01/06 00:52:14] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4806 s / img. ETA=0:24:49
[01/06 00:52:38] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4806 s / img. ETA=0:24:25
[01/06 00:53:02] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4806 s / img. ETA=0:24:01
[01/06 00:53:26] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4806 s / img. ETA=0:23:37
[01/06 00:53:50] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4806 s / img. ETA=0:23:13
[01/06 00:54:14] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4806 s / img. ETA=0:22:49
[01/06 00:54:38] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4806 s / img. ETA=0:22:25
[01/06 00:55:02] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4806 s / img. ETA=0:22:01
[01/06 00:55:26] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4806 s / img. ETA=0:21:37
[01/06 00:55:52] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4807 s / img. ETA=0:21:13
[01/06 00:56:16] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4807 s / img. ETA=0:20:49
[01/06 00:56:40] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4807 s / img. ETA=0:20:25
[01/06 00:57:04] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4807 s / img. ETA=0:20:01
[01/06 00:57:28] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4807 s / img. ETA=0:19:37
[01/06 00:57:52] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4807 s / img. ETA=0:19:13
[01/06 00:58:16] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4807 s / img. ETA=0:18:49
[01/06 00:58:40] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4807 s / img. ETA=0:18:25
[01/06 00:59:04] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4807 s / img. ETA=0:18:01
[01/06 00:59:28] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4807 s / img. ETA=0:17:37
[01/06 00:59:52] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4807 s / img. ETA=0:17:13
[01/06 01:00:16] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4807 s / img. ETA=0:16:49
[01/06 01:00:40] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4807 s / img. ETA=0:16:25
[01/06 01:01:04] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4807 s / img. ETA=0:16:01
[01/06 01:01:28] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4807 s / img. ETA=0:15:37
[01/06 01:01:52] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4807 s / img. ETA=0:15:13
[01/06 01:02:16] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4807 s / img. ETA=0:14:49
[01/06 01:02:40] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4807 s / img. ETA=0:14:25
[01/06 01:03:04] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4807 s / img. ETA=0:14:01
[01/06 01:03:28] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4807 s / img. ETA=0:13:37
[01/06 01:03:52] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4807 s / img. ETA=0:13:13
[01/06 01:04:16] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4807 s / img. ETA=0:12:49
[01/06 01:04:40] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4807 s / img. ETA=0:12:25
[01/06 01:05:04] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4807 s / img. ETA=0:12:01
[01/06 01:05:28] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4807 s / img. ETA=0:11:36
[01/06 01:05:52] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4807 s / img. ETA=0:11:12
[01/06 01:06:16] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4807 s / img. ETA=0:10:48
[01/06 01:06:40] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4807 s / img. ETA=0:10:24
[01/06 01:07:04] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4807 s / img. ETA=0:10:00
[01/06 01:07:28] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4807 s / img. ETA=0:09:36
[01/06 01:07:52] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4807 s / img. ETA=0:09:12
[01/06 01:08:16] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4807 s / img. ETA=0:08:48
[01/06 01:08:40] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4807 s / img. ETA=0:08:24
[01/06 01:09:04] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4807 s / img. ETA=0:08:00
[01/06 01:09:28] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4807 s / img. ETA=0:07:36
[01/06 01:09:52] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4807 s / img. ETA=0:07:12
[01/06 01:10:16] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4806 s / img. ETA=0:06:48
[01/06 01:10:40] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4806 s / img. ETA=0:06:24
[01/06 01:11:04] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4806 s / img. ETA=0:06:00
[01/06 01:11:28] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4806 s / img. ETA=0:05:36
[01/06 01:11:52] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4806 s / img. ETA=0:05:12
[01/06 01:12:16] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4806 s / img. ETA=0:04:48
[01/06 01:12:40] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4806 s / img. ETA=0:04:24
[01/06 01:13:04] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4807 s / img. ETA=0:04:00
[01/06 01:13:28] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4807 s / img. ETA=0:03:36
[01/06 01:13:52] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4807 s / img. ETA=0:03:12
[01/06 01:14:16] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4807 s / img. ETA=0:02:48
[01/06 01:14:40] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4807 s / img. ETA=0:02:24
[01/06 01:15:05] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4807 s / img. ETA=0:02:00
[01/06 01:15:29] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4807 s / img. ETA=0:01:36
[01/06 01:15:53] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4807 s / img. ETA=0:01:12
[01/06 01:16:17] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4807 s / img. ETA=0:00:48
[01/06 01:16:41] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4807 s / img. ETA=0:00:24
[01/06 01:17:05] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4807 s / img. ETA=0:00:00
[01/06 01:17:05] d2.evaluation.evaluator INFO: Total inference time: 2:14:57 (0.480677 s / img per device, on 2 devices)
[01/06 01:17:05] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:08 (0.477791 s / img per device, on 2 devices)
[01/06 01:17:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/06 01:17:14] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[01/06 01:17:15] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/06 01:17:42] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[01/06 01:17:42] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[01/06 01:17:42] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[01/06 01:17:42] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/06 01:17:42] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/06 01:17:42] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
[01/06 10:42:57] detectron2 INFO: Rank of current process: 0. World size: 2
[01/06 10:43:02] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/06 10:43:02] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/06 10:43:02] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small_small",)
  TEST: ("my_dataset_val_small_small",)  # my_dataset_val_light my_dataset_test  my_dataset_val_small my_dataset_val_small_small
SOLVER:
  MAX_ITER: 154368  ## 46368 74368(70000 最好) 96368(85000)  116368 138368 154368
  BASE_LR: 0.01     ### 
  STEPS: (154068, 154268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/06 10:43:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_small_small',)
  TRAIN: ('my_dataset_train_small_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 154368
  MOMENTUM: 0.9
  STEPS: (154068, 154268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/06 10:43:02] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/06 10:43:02] d2.utils.env INFO: Using a generated random seed 2980804
[01/06 10:43:06] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/06 10:43:09] d2.data.datasets.coco INFO: Loading /home/admin/jupyter/Demo/DataSets/Data/train_small_small.json takes 2.79 seconds.
[01/06 10:43:09] d2.data.datasets.coco INFO: Loaded 5555 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_small_small.json
[01/06 10:43:09] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 1843         |   ASC-US   | 1480         |    HSIL     | 2043         |
|    LSIL    | 2248         |  Candida   | 1181         | Trichomonas | 4459         |
|            |              |            |              |             |              |
|   total    | 13254        |            |              |             |              |[0m
[01/06 10:43:09] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[01/06 10:43:09] d2.data.build INFO: Using training sampler TrainingSampler
[01/06 10:45:02] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/06 10:45:11] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/06 10:45:12] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/06 10:45:12] d2.engine.train_loop INFO: Starting training from iteration 135000
[01/06 10:46:13] d2.utils.events INFO: eta: 16:24:46  iter: 135019  total_loss: 0.611  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0663  data_time: 0.0026  lr: 0.000100  max_mem: 8578M
[01/06 10:47:15] d2.utils.events INFO: eta: 16:24:24  iter: 135039  total_loss: 1.204  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.141  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.294  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.437  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0737  data_time: 0.0028  lr: 0.000100  max_mem: 8578M
[01/06 10:48:17] d2.utils.events INFO: eta: 16:23:59  iter: 135059  total_loss: 0.970  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.235  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.369  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0821  data_time: 0.0026  lr: 0.000100  max_mem: 8578M
[01/06 10:49:19] d2.utils.events INFO: eta: 16:23:45  iter: 135079  total_loss: 0.836  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0904  data_time: 0.0025  lr: 0.000100  max_mem: 8578M
[01/06 10:50:38] detectron2 INFO: Rank of current process: 0. World size: 2
[01/06 10:50:42] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/06 10:50:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=False, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/06 10:50:42] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small_small",)
  TEST: ("my_dataset_val_small_small",)  # my_dataset_val_light my_dataset_test  my_dataset_val_small my_dataset_val_small_small
SOLVER:
  MAX_ITER: 161368  ## 46368 74368(70000 最好) 96368(85000)  116368 138368 161368 
  BASE_LR: 0.01     ### 
  STEPS: (160068, 160268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 2      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/06 10:50:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_val_small_small',)
  TRAIN: ('my_dataset_train_small_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 161368
  MOMENTUM: 0.9
  STEPS: (160068, 160268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/06 10:50:42] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/06 10:50:42] d2.utils.env INFO: Using a generated random seed 42208855
[01/06 10:50:45] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/06 10:50:45] d2.data.datasets.coco INFO: Loaded 5555 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/train_small_small.json
[01/06 10:50:46] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 1843         |   ASC-US   | 1480         |    HSIL     | 2043         |
|    LSIL    | 2248         |  Candida   | 1181         | Trichomonas | 4459         |
|            |              |            |              |             |              |
|   total    | 13254        |            |              |             |              |[0m
[01/06 10:50:46] d2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(1000, 1200), max_size=1440, sample_style='range'), RandomContrast(intensity_min=0.5, intensity_max=1.5), RandomBrightness(intensity_min=0.5, intensity_max=1.5), RandomSaturation(intensity_min=0.5, intensity_max=1.5), RandomHFlip(), RandomVFlip()]
[01/06 10:50:46] d2.data.build INFO: Using training sampler TrainingSampler
[01/06 10:51:43] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/06 10:51:45] fvcore.common.checkpoint INFO: Loading optimizer from ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/06 10:51:45] fvcore.common.checkpoint INFO: Loading scheduler from ./outs/out_cascade_mask_rcnn_X_152/model_0134999.pth
[01/06 10:51:45] d2.engine.train_loop INFO: Starting training from iteration 135000
[01/06 10:52:47] d2.utils.events INFO: eta: 22:20:56  iter: 135019  total_loss: 0.685  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0802  data_time: 0.0029  lr: 0.000100  max_mem: 8349M
[01/06 10:53:49] d2.utils.events INFO: eta: 22:21:09  iter: 135039  total_loss: 0.672  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0920  data_time: 0.0022  lr: 0.000100  max_mem: 8578M
[01/06 10:54:49] d2.utils.events INFO: eta: 22:18:54  iter: 135059  total_loss: 0.667  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0668  data_time: 0.0026  lr: 0.000100  max_mem: 8578M
[01/06 10:55:53] d2.utils.events INFO: eta: 22:18:02  iter: 135079  total_loss: 0.709  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0929  data_time: 0.0412  lr: 0.000100  max_mem: 8578M
[01/06 10:56:55] d2.utils.events INFO: eta: 22:17:49  iter: 135099  total_loss: 0.787  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0930  data_time: 0.0025  lr: 0.000100  max_mem: 8578M
[01/06 10:57:57] d2.utils.events INFO: eta: 22:16:48  iter: 135119  total_loss: 0.679  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0968  data_time: 0.0030  lr: 0.000100  max_mem: 8578M
[01/06 10:58:59] d2.utils.events INFO: eta: 22:15:47  iter: 135139  total_loss: 0.875  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0953  data_time: 0.0024  lr: 0.000100  max_mem: 8578M
[01/06 11:00:00] d2.utils.events INFO: eta: 22:13:58  iter: 135159  total_loss: 0.777  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0895  data_time: 0.0025  lr: 0.000100  max_mem: 8578M
[01/06 11:01:02] d2.utils.events INFO: eta: 22:12:50  iter: 135179  total_loss: 0.944  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0905  data_time: 0.0024  lr: 0.000100  max_mem: 8578M
[01/06 11:02:03] d2.utils.events INFO: eta: 22:11:36  iter: 135199  total_loss: 0.690  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0877  data_time: 0.0026  lr: 0.000100  max_mem: 8578M
[01/06 11:03:04] d2.utils.events INFO: eta: 22:10:35  iter: 135219  total_loss: 1.035  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.123  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.254  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 3.0850  data_time: 0.0020  lr: 0.000100  max_mem: 8578M
[01/06 11:04:06] d2.utils.events INFO: eta: 22:09:27  iter: 135239  total_loss: 0.655  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.003  time: 3.0851  data_time: 0.0026  lr: 0.000100  max_mem: 8578M
[01/06 11:05:09] d2.utils.events INFO: eta: 22:08:46  iter: 135259  total_loss: 0.774  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0882  data_time: 0.0028  lr: 0.000100  max_mem: 8578M
[01/06 11:06:09] d2.utils.events INFO: eta: 22:07:06  iter: 135279  total_loss: 1.058  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.252  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0830  data_time: 0.0021  lr: 0.000100  max_mem: 8578M
[01/06 11:07:10] d2.utils.events INFO: eta: 22:05:48  iter: 135299  total_loss: 0.863  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0819  data_time: 0.0022  lr: 0.000100  max_mem: 8578M
[01/06 11:08:11] d2.utils.events INFO: eta: 22:04:51  iter: 135319  total_loss: 0.722  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0798  data_time: 0.0024  lr: 0.000100  max_mem: 8578M
[01/06 11:09:14] d2.utils.events INFO: eta: 22:04:05  iter: 135339  total_loss: 0.746  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0820  data_time: 0.0022  lr: 0.000100  max_mem: 8578M
[01/06 11:10:16] d2.utils.events INFO: eta: 22:03:14  iter: 135359  total_loss: 0.717  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0825  data_time: 0.0029  lr: 0.000100  max_mem: 8578M
[01/06 11:11:18] d2.utils.events INFO: eta: 22:02:13  iter: 135379  total_loss: 0.821  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0844  data_time: 0.0022  lr: 0.000100  max_mem: 8578M
[01/06 11:12:20] d2.utils.events INFO: eta: 22:01:07  iter: 135399  total_loss: 0.647  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0862  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:13:21] d2.utils.events INFO: eta: 21:59:50  iter: 135419  total_loss: 0.642  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0832  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:14:22] d2.utils.events INFO: eta: 21:58:48  iter: 135439  total_loss: 0.804  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0828  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:15:23] d2.utils.events INFO: eta: 21:57:38  iter: 135459  total_loss: 0.996  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0798  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:16:22] d2.utils.events INFO: eta: 21:56:10  iter: 135479  total_loss: 0.703  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:17:24] d2.utils.events INFO: eta: 21:55:09  iter: 135499  total_loss: 0.724  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 11:18:25] d2.utils.events INFO: eta: 21:54:09  iter: 135519  total_loss: 0.782  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0742  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:19:27] d2.utils.events INFO: eta: 21:53:13  iter: 135539  total_loss: 0.662  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0761  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 11:20:29] d2.utils.events INFO: eta: 21:52:07  iter: 135559  total_loss: 0.621  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 11:21:30] d2.utils.events INFO: eta: 21:51:00  iter: 135579  total_loss: 0.608  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:22:33] d2.utils.events INFO: eta: 21:50:09  iter: 135599  total_loss: 0.646  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0783  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:23:35] d2.utils.events INFO: eta: 21:49:15  iter: 135619  total_loss: 0.822  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0791  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:24:37] d2.utils.events INFO: eta: 21:48:21  iter: 135639  total_loss: 0.659  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0798  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:25:38] d2.utils.events INFO: eta: 21:47:07  iter: 135659  total_loss: 0.769  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0782  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:26:40] d2.utils.events INFO: eta: 21:46:06  iter: 135679  total_loss: 0.703  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0794  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 11:27:41] d2.utils.events INFO: eta: 21:45:04  iter: 135699  total_loss: 0.766  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0787  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 11:28:43] d2.utils.events INFO: eta: 21:44:00  iter: 135719  total_loss: 0.681  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0786  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 11:29:44] d2.utils.events INFO: eta: 21:42:55  iter: 135739  total_loss: 0.879  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0782  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:30:46] d2.utils.events INFO: eta: 21:41:53  iter: 135759  total_loss: 0.768  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0779  data_time: 0.0031  lr: 0.000100  max_mem: 9402M
[01/06 11:31:47] d2.utils.events INFO: eta: 21:40:51  iter: 135779  total_loss: 0.925  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0780  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:32:49] d2.utils.events INFO: eta: 21:39:52  iter: 135799  total_loss: 0.792  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0786  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 11:33:52] d2.utils.events INFO: eta: 21:38:55  iter: 135819  total_loss: 0.846  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0801  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 11:34:55] d2.utils.events INFO: eta: 21:38:09  iter: 135839  total_loss: 0.834  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0813  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:35:57] d2.utils.events INFO: eta: 21:37:15  iter: 135859  total_loss: 0.801  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0821  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 11:36:58] d2.utils.events INFO: eta: 21:36:01  iter: 135879  total_loss: 0.731  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0814  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:37:59] d2.utils.events INFO: eta: 21:34:55  iter: 135899  total_loss: 0.740  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0804  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 11:39:02] d2.utils.events INFO: eta: 21:34:08  iter: 135919  total_loss: 0.885  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0819  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:40:04] d2.utils.events INFO: eta: 21:33:03  iter: 135939  total_loss: 0.712  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0818  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:41:05] d2.utils.events INFO: eta: 21:31:57  iter: 135959  total_loss: 0.670  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0815  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:42:07] d2.utils.events INFO: eta: 21:31:01  iter: 135979  total_loss: 0.661  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0818  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 11:43:07] d2.utils.events INFO: eta: 21:29:55  iter: 135999  total_loss: 0.745  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0804  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 11:44:09] d2.utils.events INFO: eta: 21:28:49  iter: 136019  total_loss: 0.783  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0807  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:45:10] d2.utils.events INFO: eta: 21:27:39  iter: 136039  total_loss: 0.898  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0798  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:46:11] d2.utils.events INFO: eta: 21:26:39  iter: 136059  total_loss: 0.657  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0797  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 11:47:14] d2.utils.events INFO: eta: 21:25:44  iter: 136079  total_loss: 1.018  loss_cls_stage0: 0.076  loss_box_reg_stage0: 0.127  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.265  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.349  loss_rpn_cls: 0.006  loss_rpn_loc: 0.009  time: 3.0807  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:48:16] d2.utils.events INFO: eta: 21:24:36  iter: 136099  total_loss: 0.937  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.244  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0811  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 11:49:18] d2.utils.events INFO: eta: 21:23:32  iter: 136119  total_loss: 0.629  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0808  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 11:50:18] d2.utils.events INFO: eta: 21:22:21  iter: 136139  total_loss: 0.930  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0795  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 11:51:20] d2.utils.events INFO: eta: 21:21:31  iter: 136159  total_loss: 0.731  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0803  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 11:52:21] d2.utils.events INFO: eta: 21:20:19  iter: 136179  total_loss: 0.412  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.104  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.182  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0795  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:53:24] d2.utils.events INFO: eta: 21:19:32  iter: 136199  total_loss: 0.772  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0808  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 11:54:25] d2.utils.events INFO: eta: 21:18:29  iter: 136219  total_loss: 0.727  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0805  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 11:55:26] d2.utils.events INFO: eta: 21:17:19  iter: 136239  total_loss: 0.693  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0794  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:56:29] d2.utils.events INFO: eta: 21:16:12  iter: 136259  total_loss: 0.779  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.093  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0809  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:57:31] d2.utils.events INFO: eta: 21:15:18  iter: 136279  total_loss: 0.707  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0809  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 11:58:32] d2.utils.events INFO: eta: 21:14:16  iter: 136299  total_loss: 0.866  loss_cls_stage0: 0.081  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.092  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.006  loss_rpn_loc: 0.013  time: 3.0808  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 11:59:34] d2.utils.events INFO: eta: 21:13:13  iter: 136319  total_loss: 0.780  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0807  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:00:34] d2.utils.events INFO: eta: 21:12:01  iter: 136339  total_loss: 0.644  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0798  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 12:01:35] d2.utils.events INFO: eta: 21:10:55  iter: 136359  total_loss: 0.866  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0793  data_time: 0.0030  lr: 0.000100  max_mem: 9402M
[01/06 12:02:37] d2.utils.events INFO: eta: 21:09:52  iter: 136379  total_loss: 0.820  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0794  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:03:38] d2.utils.events INFO: eta: 21:08:49  iter: 136399  total_loss: 0.751  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0792  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:04:40] d2.utils.events INFO: eta: 21:07:50  iter: 136419  total_loss: 0.670  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0790  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:05:41] d2.utils.events INFO: eta: 21:06:55  iter: 136439  total_loss: 0.998  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.252  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.388  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0788  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 12:06:42] d2.utils.events INFO: eta: 21:05:57  iter: 136459  total_loss: 0.876  loss_cls_stage0: 0.082  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0784  data_time: 0.0038  lr: 0.000100  max_mem: 9402M
[01/06 12:07:44] d2.utils.events INFO: eta: 21:05:05  iter: 136479  total_loss: 0.807  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0788  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 12:08:47] d2.utils.events INFO: eta: 21:04:07  iter: 136499  total_loss: 0.718  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0793  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 12:09:48] d2.utils.events INFO: eta: 21:03:01  iter: 136519  total_loss: 0.871  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0794  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 12:10:49] d2.utils.events INFO: eta: 21:01:55  iter: 136539  total_loss: 0.773  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0787  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:11:49] d2.utils.events INFO: eta: 21:00:53  iter: 136559  total_loss: 0.733  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0779  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 12:12:51] d2.utils.events INFO: eta: 20:59:52  iter: 136579  total_loss: 0.990  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.253  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 12:13:52] d2.utils.events INFO: eta: 20:58:48  iter: 136599  total_loss: 1.133  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.126  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.301  loss_cls_stage2: 0.081  loss_box_reg_stage2: 0.443  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0778  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:14:53] d2.utils.events INFO: eta: 20:57:43  iter: 136619  total_loss: 0.919  loss_cls_stage0: 0.070  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.089  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.089  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0773  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:15:53] d2.utils.events INFO: eta: 20:56:36  iter: 136639  total_loss: 0.848  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:16:55] d2.utils.events INFO: eta: 20:55:35  iter: 136659  total_loss: 0.772  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0763  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:17:56] d2.utils.events INFO: eta: 20:54:32  iter: 136679  total_loss: 0.660  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 12:18:57] d2.utils.events INFO: eta: 20:53:27  iter: 136699  total_loss: 0.714  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0762  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 12:19:59] d2.utils.events INFO: eta: 20:52:24  iter: 136719  total_loss: 0.718  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0032  lr: 0.000100  max_mem: 9402M
[01/06 12:21:00] d2.utils.events INFO: eta: 20:51:23  iter: 136739  total_loss: 0.679  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 12:22:02] d2.utils.events INFO: eta: 20:50:29  iter: 136759  total_loss: 0.717  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0762  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:23:03] d2.utils.events INFO: eta: 20:49:26  iter: 136779  total_loss: 0.657  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0756  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:24:04] d2.utils.events INFO: eta: 20:48:25  iter: 136799  total_loss: 0.903  loss_cls_stage0: 0.074  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.332  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0030  lr: 0.000100  max_mem: 9402M
[01/06 12:25:05] d2.utils.events INFO: eta: 20:47:18  iter: 136819  total_loss: 0.709  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.076  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.087  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0032  lr: 0.000100  max_mem: 9402M
[01/06 12:26:05] d2.utils.events INFO: eta: 20:46:09  iter: 136839  total_loss: 0.773  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0746  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:27:07] d2.utils.events INFO: eta: 20:45:05  iter: 136859  total_loss: 0.781  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0744  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:28:08] d2.utils.events INFO: eta: 20:44:07  iter: 136879  total_loss: 0.849  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0741  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 12:29:08] d2.utils.events INFO: eta: 20:43:03  iter: 136899  total_loss: 0.648  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0735  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:30:08] d2.utils.events INFO: eta: 20:41:51  iter: 136919  total_loss: 0.893  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0730  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:31:11] d2.utils.events INFO: eta: 20:40:57  iter: 136939  total_loss: 0.673  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0737  data_time: 0.0034  lr: 0.000100  max_mem: 9402M
[01/06 12:32:13] d2.utils.events INFO: eta: 20:39:56  iter: 136959  total_loss: 0.721  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0739  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 12:33:15] d2.utils.events INFO: eta: 20:38:53  iter: 136979  total_loss: 0.819  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.324  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0740  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:34:17] d2.utils.events INFO: eta: 20:37:53  iter: 136999  total_loss: 0.813  loss_cls_stage0: 0.077  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.332  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0741  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 12:35:19] d2.utils.events INFO: eta: 20:36:53  iter: 137019  total_loss: 0.682  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0744  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:36:21] d2.utils.events INFO: eta: 20:35:54  iter: 137039  total_loss: 0.733  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:37:23] d2.utils.events INFO: eta: 20:34:51  iter: 137059  total_loss: 0.802  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0750  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:38:25] d2.utils.events INFO: eta: 20:33:50  iter: 137079  total_loss: 0.899  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0753  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:39:28] d2.utils.events INFO: eta: 20:32:56  iter: 137099  total_loss: 0.674  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0761  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 12:40:31] d2.utils.events INFO: eta: 20:31:57  iter: 137119  total_loss: 0.881  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.368  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0034  lr: 0.000100  max_mem: 9402M
[01/06 12:41:31] d2.utils.events INFO: eta: 20:30:56  iter: 137139  total_loss: 0.751  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:42:32] d2.utils.events INFO: eta: 20:29:48  iter: 137159  total_loss: 0.845  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.348  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:43:32] d2.utils.events INFO: eta: 20:28:46  iter: 137179  total_loss: 0.862  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 12:44:34] d2.utils.events INFO: eta: 20:27:40  iter: 137199  total_loss: 0.744  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 12:45:37] d2.utils.events INFO: eta: 20:26:44  iter: 137219  total_loss: 0.770  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 12:46:37] d2.utils.events INFO: eta: 20:25:48  iter: 137239  total_loss: 0.899  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.244  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.393  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:47:38] d2.utils.events INFO: eta: 20:24:43  iter: 137259  total_loss: 0.784  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:48:39] d2.utils.events INFO: eta: 20:23:39  iter: 137279  total_loss: 0.550  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0746  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:49:41] d2.utils.events INFO: eta: 20:22:39  iter: 137299  total_loss: 0.768  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0031  lr: 0.000100  max_mem: 9402M
[01/06 12:50:43] d2.utils.events INFO: eta: 20:21:38  iter: 137319  total_loss: 0.934  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.110  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.005  loss_rpn_loc: 0.011  time: 3.0749  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:51:44] d2.utils.events INFO: eta: 20:20:48  iter: 137339  total_loss: 0.782  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:52:46] d2.utils.events INFO: eta: 20:19:47  iter: 137359  total_loss: 0.890  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.356  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 12:53:47] d2.utils.events INFO: eta: 20:18:40  iter: 137379  total_loss: 0.647  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0748  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 12:54:49] d2.utils.events INFO: eta: 20:17:43  iter: 137399  total_loss: 0.928  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0750  data_time: 0.0031  lr: 0.000100  max_mem: 9402M
[01/06 12:55:52] d2.utils.events INFO: eta: 20:16:40  iter: 137419  total_loss: 0.818  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.076  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 12:56:53] d2.utils.events INFO: eta: 20:15:32  iter: 137439  total_loss: 0.691  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 12:57:55] d2.utils.events INFO: eta: 20:14:30  iter: 137459  total_loss: 0.875  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.263  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.369  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 12:58:56] d2.utils.events INFO: eta: 20:13:26  iter: 137479  total_loss: 1.020  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.117  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.279  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.368  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0753  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 12:59:57] d2.utils.events INFO: eta: 20:12:20  iter: 137499  total_loss: 0.691  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:00:57] d2.utils.events INFO: eta: 20:11:15  iter: 137519  total_loss: 0.787  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0746  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:01:58] d2.utils.events INFO: eta: 20:10:11  iter: 137539  total_loss: 1.090  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.107  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.271  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0745  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:02:59] d2.utils.events INFO: eta: 20:09:13  iter: 137559  total_loss: 0.573  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0743  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:04:01] d2.utils.events INFO: eta: 20:08:15  iter: 137579  total_loss: 0.775  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0744  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:05:03] d2.utils.events INFO: eta: 20:07:14  iter: 137599  total_loss: 0.716  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0744  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 13:06:05] d2.utils.events INFO: eta: 20:06:18  iter: 137619  total_loss: 0.714  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  time: 3.0746  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 13:07:07] d2.utils.events INFO: eta: 20:05:30  iter: 137639  total_loss: 0.702  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.086  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0030  lr: 0.000100  max_mem: 9402M
[01/06 13:08:09] d2.utils.events INFO: eta: 20:04:28  iter: 137659  total_loss: 0.568  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0748  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 13:09:11] d2.utils.events INFO: eta: 20:03:31  iter: 137679  total_loss: 0.733  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:10:12] d2.utils.events INFO: eta: 20:02:31  iter: 137699  total_loss: 0.787  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.079  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:11:14] d2.utils.events INFO: eta: 20:01:27  iter: 137719  total_loss: 0.893  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 3.0750  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:12:16] d2.utils.events INFO: eta: 20:00:29  iter: 137739  total_loss: 0.478  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 13:13:18] d2.utils.events INFO: eta: 19:59:25  iter: 137759  total_loss: 0.755  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0030  lr: 0.000100  max_mem: 9402M
[01/06 13:14:18] d2.utils.events INFO: eta: 19:58:24  iter: 137779  total_loss: 0.868  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:15:21] d2.utils.events INFO: eta: 19:57:23  iter: 137799  total_loss: 0.636  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 13:16:22] d2.utils.events INFO: eta: 19:56:29  iter: 137819  total_loss: 0.788  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0755  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 13:17:25] d2.utils.events INFO: eta: 19:55:31  iter: 137839  total_loss: 0.862  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:18:25] d2.utils.events INFO: eta: 19:54:28  iter: 137859  total_loss: 0.762  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:19:26] d2.utils.events INFO: eta: 19:53:28  iter: 137879  total_loss: 0.605  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 13:20:27] d2.utils.events INFO: eta: 19:52:31  iter: 137899  total_loss: 0.860  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.378  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0748  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:21:28] d2.utils.events INFO: eta: 19:51:32  iter: 137919  total_loss: 0.827  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0747  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:22:30] d2.utils.events INFO: eta: 19:50:27  iter: 137939  total_loss: 0.719  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0750  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:23:32] d2.utils.events INFO: eta: 19:49:30  iter: 137959  total_loss: 0.774  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:24:35] d2.utils.events INFO: eta: 19:48:33  iter: 137979  total_loss: 0.627  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0754  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:25:38] d2.utils.events INFO: eta: 19:47:34  iter: 137999  total_loss: 0.797  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:26:40] d2.utils.events INFO: eta: 19:46:33  iter: 138019  total_loss: 0.749  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0763  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:27:42] d2.utils.events INFO: eta: 19:45:27  iter: 138039  total_loss: 0.649  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:28:43] d2.utils.events INFO: eta: 19:44:25  iter: 138059  total_loss: 0.688  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0761  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:29:44] d2.utils.events INFO: eta: 19:43:19  iter: 138079  total_loss: 0.737  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 13:30:46] d2.utils.events INFO: eta: 19:42:15  iter: 138099  total_loss: 0.752  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:31:48] d2.utils.events INFO: eta: 19:41:15  iter: 138119  total_loss: 0.848  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0762  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:32:49] d2.utils.events INFO: eta: 19:40:16  iter: 138139  total_loss: 0.806  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0762  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 13:33:51] d2.utils.events INFO: eta: 19:39:16  iter: 138159  total_loss: 0.661  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:34:54] d2.utils.events INFO: eta: 19:38:26  iter: 138179  total_loss: 0.866  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0768  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 13:35:56] d2.utils.events INFO: eta: 19:37:25  iter: 138199  total_loss: 0.648  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0767  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:36:56] d2.utils.events INFO: eta: 19:36:17  iter: 138219  total_loss: 0.563  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0764  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:37:59] d2.utils.events INFO: eta: 19:35:16  iter: 138239  total_loss: 0.628  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0766  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:39:01] d2.utils.events INFO: eta: 19:34:15  iter: 138259  total_loss: 0.670  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:40:02] d2.utils.events INFO: eta: 19:33:16  iter: 138279  total_loss: 0.846  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.370  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 13:41:04] d2.utils.events INFO: eta: 19:32:19  iter: 138299  total_loss: 0.672  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0769  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:42:06] d2.utils.events INFO: eta: 19:31:19  iter: 138319  total_loss: 0.700  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:43:07] d2.utils.events INFO: eta: 19:30:11  iter: 138339  total_loss: 0.752  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.332  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0768  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 13:44:10] d2.utils.events INFO: eta: 19:29:18  iter: 138359  total_loss: 0.931  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.113  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.251  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.371  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0771  data_time: 0.0031  lr: 0.000100  max_mem: 9402M
[01/06 13:45:13] d2.utils.events INFO: eta: 19:28:31  iter: 138379  total_loss: 0.750  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0776  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:46:15] d2.utils.events INFO: eta: 19:27:29  iter: 138399  total_loss: 0.770  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0777  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:47:16] d2.utils.events INFO: eta: 19:26:24  iter: 138419  total_loss: 0.595  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0775  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 13:48:19] d2.utils.events INFO: eta: 19:25:32  iter: 138439  total_loss: 0.674  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0779  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 13:49:19] d2.utils.events INFO: eta: 19:24:31  iter: 138459  total_loss: 0.788  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0776  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:50:21] d2.utils.events INFO: eta: 19:23:30  iter: 138479  total_loss: 0.796  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 13:51:22] d2.utils.events INFO: eta: 19:22:24  iter: 138499  total_loss: 0.952  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.109  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 13:52:24] d2.utils.events INFO: eta: 19:21:19  iter: 138519  total_loss: 0.894  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0775  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:53:25] d2.utils.events INFO: eta: 19:20:23  iter: 138539  total_loss: 0.639  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 13:54:27] d2.utils.events INFO: eta: 19:19:24  iter: 138559  total_loss: 0.686  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0776  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:55:28] d2.utils.events INFO: eta: 19:18:16  iter: 138579  total_loss: 0.811  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0774  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 13:56:31] d2.utils.events INFO: eta: 19:17:20  iter: 138599  total_loss: 0.684  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.193  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0777  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 13:57:31] d2.utils.events INFO: eta: 19:16:14  iter: 138619  total_loss: 0.842  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 13:58:32] d2.utils.events INFO: eta: 19:15:04  iter: 138639  total_loss: 0.986  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 13:59:34] d2.utils.events INFO: eta: 19:14:04  iter: 138659  total_loss: 0.980  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.249  loss_cls_stage2: 0.080  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.006  loss_rpn_loc: 0.013  time: 3.0774  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:00:35] d2.utils.events INFO: eta: 19:13:00  iter: 138679  total_loss: 0.723  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0033  lr: 0.000100  max_mem: 9402M
[01/06 14:01:37] d2.utils.events INFO: eta: 19:12:01  iter: 138699  total_loss: 0.777  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0773  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:02:39] d2.utils.events INFO: eta: 19:11:04  iter: 138719  total_loss: 0.693  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:03:41] d2.utils.events INFO: eta: 19:10:07  iter: 138739  total_loss: 0.793  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0774  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 14:04:42] d2.utils.events INFO: eta: 19:09:02  iter: 138759  total_loss: 0.761  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0774  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:05:44] d2.utils.events INFO: eta: 19:08:05  iter: 138779  total_loss: 0.942  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.341  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0774  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:06:45] d2.utils.events INFO: eta: 19:06:56  iter: 138799  total_loss: 0.693  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:07:47] d2.utils.events INFO: eta: 19:05:57  iter: 138819  total_loss: 0.825  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0774  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 14:08:48] d2.utils.events INFO: eta: 19:04:54  iter: 138839  total_loss: 0.874  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.341  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0774  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:09:49] d2.utils.events INFO: eta: 19:03:59  iter: 138859  total_loss: 0.738  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0770  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 14:10:51] d2.utils.events INFO: eta: 19:03:03  iter: 138879  total_loss: 0.617  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:11:52] d2.utils.events INFO: eta: 19:02:02  iter: 138899  total_loss: 0.784  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.085  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 14:12:52] d2.utils.events INFO: eta: 19:00:55  iter: 138919  total_loss: 0.607  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0766  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 14:13:53] d2.utils.events INFO: eta: 18:59:54  iter: 138939  total_loss: 0.628  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 14:14:54] d2.utils.events INFO: eta: 18:58:49  iter: 138959  total_loss: 0.672  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:15:55] d2.utils.events INFO: eta: 18:57:41  iter: 138979  total_loss: 0.831  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:16:57] d2.utils.events INFO: eta: 18:56:36  iter: 138999  total_loss: 0.669  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0763  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 14:17:58] d2.utils.events INFO: eta: 18:55:34  iter: 139019  total_loss: 0.609  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0763  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:19:01] d2.utils.events INFO: eta: 18:54:35  iter: 139039  total_loss: 0.657  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0766  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 14:20:02] d2.utils.events INFO: eta: 18:53:34  iter: 139059  total_loss: 0.728  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.357  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:21:04] d2.utils.events INFO: eta: 18:52:37  iter: 139079  total_loss: 0.832  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.241  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0766  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 14:22:06] d2.utils.events INFO: eta: 18:51:36  iter: 139099  total_loss: 0.563  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0767  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 14:23:07] d2.utils.events INFO: eta: 18:50:31  iter: 139119  total_loss: 0.737  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:24:08] d2.utils.events INFO: eta: 18:49:29  iter: 139139  total_loss: 0.863  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0765  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:25:12] d2.utils.events INFO: eta: 18:48:30  iter: 139159  total_loss: 0.886  loss_cls_stage0: 0.066  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.086  loss_box_reg_stage1: 0.253  loss_cls_stage2: 0.092  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 14:26:13] d2.utils.events INFO: eta: 18:47:25  iter: 139179  total_loss: 0.647  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0769  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:27:15] d2.utils.events INFO: eta: 18:46:24  iter: 139199  total_loss: 0.681  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0769  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:28:16] d2.utils.events INFO: eta: 18:45:31  iter: 139219  total_loss: 0.677  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:29:18] d2.utils.events INFO: eta: 18:44:31  iter: 139239  total_loss: 0.895  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0770  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 14:30:19] d2.utils.events INFO: eta: 18:43:28  iter: 139259  total_loss: 0.787  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0769  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:31:21] d2.utils.events INFO: eta: 18:42:31  iter: 139279  total_loss: 0.661  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0769  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 14:32:23] d2.utils.events INFO: eta: 18:41:32  iter: 139299  total_loss: 0.536  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.196  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0031  lr: 0.000100  max_mem: 9402M
[01/06 14:33:26] d2.utils.events INFO: eta: 18:40:30  iter: 139319  total_loss: 0.673  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0772  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 14:34:27] d2.utils.events INFO: eta: 18:39:32  iter: 139339  total_loss: 0.641  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:35:27] d2.utils.events INFO: eta: 18:38:22  iter: 139359  total_loss: 0.840  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0768  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 14:36:28] d2.utils.events INFO: eta: 18:37:06  iter: 139379  total_loss: 0.730  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:37:30] d2.utils.events INFO: eta: 18:36:08  iter: 139399  total_loss: 0.426  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.115  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0768  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:38:31] d2.utils.events INFO: eta: 18:35:04  iter: 139419  total_loss: 0.900  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0766  data_time: 0.0037  lr: 0.000100  max_mem: 9402M
[01/06 14:39:33] d2.utils.events INFO: eta: 18:33:58  iter: 139439  total_loss: 0.515  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0767  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:40:35] d2.utils.events INFO: eta: 18:33:02  iter: 139459  total_loss: 0.937  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.073  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.075  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.006  loss_rpn_loc: 0.008  time: 3.0770  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 14:41:36] d2.utils.events INFO: eta: 18:31:57  iter: 139479  total_loss: 0.634  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0767  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:42:36] d2.utils.events INFO: eta: 18:30:55  iter: 139499  total_loss: 0.926  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.257  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.356  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0763  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:43:36] d2.utils.events INFO: eta: 18:29:54  iter: 139519  total_loss: 0.611  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0761  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:44:38] d2.utils.events INFO: eta: 18:28:53  iter: 139539  total_loss: 0.948  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.250  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.394  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0761  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:45:39] d2.utils.events INFO: eta: 18:27:54  iter: 139559  total_loss: 0.730  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:46:41] d2.utils.events INFO: eta: 18:26:57  iter: 139579  total_loss: 0.814  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0761  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 14:47:42] d2.utils.events INFO: eta: 18:25:51  iter: 139599  total_loss: 0.742  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0761  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:48:43] d2.utils.events INFO: eta: 18:24:57  iter: 139619  total_loss: 0.709  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:49:44] d2.utils.events INFO: eta: 18:23:59  iter: 139639  total_loss: 0.691  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:50:46] d2.utils.events INFO: eta: 18:22:50  iter: 139659  total_loss: 0.754  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:51:48] d2.utils.events INFO: eta: 18:21:58  iter: 139679  total_loss: 0.668  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0032  lr: 0.000100  max_mem: 9402M
[01/06 14:52:49] d2.utils.events INFO: eta: 18:20:45  iter: 139699  total_loss: 0.939  loss_cls_stage0: 0.072  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.079  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.090  loss_box_reg_stage2: 0.366  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:53:52] d2.utils.events INFO: eta: 18:19:47  iter: 139719  total_loss: 0.870  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 14:54:52] d2.utils.events INFO: eta: 18:18:41  iter: 139739  total_loss: 0.671  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0758  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 14:55:55] d2.utils.events INFO: eta: 18:17:42  iter: 139759  total_loss: 0.782  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0761  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 14:56:56] d2.utils.events INFO: eta: 18:16:41  iter: 139779  total_loss: 0.678  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 14:57:57] d2.utils.events INFO: eta: 18:15:42  iter: 139799  total_loss: 0.422  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.103  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.183  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0760  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 14:58:58] d2.utils.events INFO: eta: 18:14:35  iter: 139819  total_loss: 0.908  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 15:00:00] d2.utils.events INFO: eta: 18:13:35  iter: 139839  total_loss: 0.650  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:01:02] d2.utils.events INFO: eta: 18:12:35  iter: 139859  total_loss: 0.798  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0760  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 15:02:04] d2.utils.events INFO: eta: 18:11:30  iter: 139879  total_loss: 0.668  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:03:06] d2.utils.events INFO: eta: 18:10:30  iter: 139899  total_loss: 0.928  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.084  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0761  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:04:06] d2.utils.events INFO: eta: 18:09:31  iter: 139919  total_loss: 0.735  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:05:08] d2.utils.events INFO: eta: 18:08:30  iter: 139939  total_loss: 0.790  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0760  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:06:10] d2.utils.events INFO: eta: 18:07:34  iter: 139959  total_loss: 0.667  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:07:11] d2.utils.events INFO: eta: 18:06:34  iter: 139979  total_loss: 0.801  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 15:08:14] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0139999.pth
[01/06 15:08:20] d2.data.datasets.coco INFO: Loaded 1000 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small_small.json
[01/06 15:08:20] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 348          |   ASC-US   | 270          |    HSIL     | 339          |
|    LSIL    | 435          |  Candida   | 222          | Trichomonas | 970          |
|            |              |            |              |             |              |
|   total    | 2584         |            |              |             |              |[0m
[01/06 15:08:20] d2.evaluation.evaluator INFO: Start inference on 500 images
[01/06 15:09:24] d2.evaluation.evaluator INFO: Inference done 50/500. 0.4812 s / img. ETA=0:03:36
[01/06 15:09:48] d2.evaluation.evaluator INFO: Inference done 100/500. 0.4810 s / img. ETA=0:03:12
[01/06 15:10:12] d2.evaluation.evaluator INFO: Inference done 150/500. 0.4808 s / img. ETA=0:02:48
[01/06 15:10:36] d2.evaluation.evaluator INFO: Inference done 200/500. 0.4807 s / img. ETA=0:02:24
[01/06 15:11:00] d2.evaluation.evaluator INFO: Inference done 250/500. 0.4809 s / img. ETA=0:02:00
[01/06 15:11:24] d2.evaluation.evaluator INFO: Inference done 300/500. 0.4813 s / img. ETA=0:01:36
[01/06 15:11:49] d2.evaluation.evaluator INFO: Inference done 350/500. 0.4815 s / img. ETA=0:01:12
[01/06 15:12:13] d2.evaluation.evaluator INFO: Inference done 400/500. 0.4814 s / img. ETA=0:00:48
[01/06 15:12:37] d2.evaluation.evaluator INFO: Inference done 450/500. 0.4814 s / img. ETA=0:00:24
[01/06 15:13:01] d2.evaluation.evaluator INFO: Inference done 500/500. 0.4814 s / img. ETA=0:00:00
[01/06 15:13:01] d2.evaluation.evaluator INFO: Total inference time: 0:03:58 (0.480808 s / img per device, on 2 devices)
[01/06 15:13:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:56 (0.478379 s / img per device, on 2 devices)
[01/06 15:13:01] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/06 15:13:01] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small_small.json
[01/06 15:13:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/06 15:13:05] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 60.592 | 82.880 | 68.764 | 49.611 | 55.411 | 71.618 |
[01/06 15:13:05] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 67.076 | ASC-US     | 65.941 | HSIL        | 76.242 |
| LSIL       | 72.966 | Candida    | 54.685 | Trichomonas | 26.645 |
[01/06 15:13:05] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small_small in csv format:
[01/06 15:13:05] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/06 15:13:05] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/06 15:13:05] d2.evaluation.testing INFO: copypaste: 60.5924,82.8799,68.7635,49.6115,55.4107,71.6185
[01/06 15:13:05] d2.utils.events INFO: eta: 18:05:42  iter: 139999  total_loss: 0.619  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/06 15:14:06] d2.utils.events INFO: eta: 18:04:35  iter: 140019  total_loss: 0.784  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0762  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:15:09] d2.utils.events INFO: eta: 18:03:32  iter: 140039  total_loss: 0.696  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0764  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:16:09] d2.utils.events INFO: eta: 18:02:31  iter: 140059  total_loss: 0.713  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.065  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0762  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:17:12] d2.utils.events INFO: eta: 18:01:30  iter: 140079  total_loss: 0.566  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 15:18:14] d2.utils.events INFO: eta: 18:00:29  iter: 140099  total_loss: 0.762  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0765  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:19:14] d2.utils.events INFO: eta: 17:59:24  iter: 140119  total_loss: 0.695  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0763  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:20:17] d2.utils.events INFO: eta: 17:58:27  iter: 140139  total_loss: 0.637  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:21:19] d2.utils.events INFO: eta: 17:57:24  iter: 140159  total_loss: 0.912  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0766  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 15:22:21] d2.utils.events INFO: eta: 17:56:24  iter: 140179  total_loss: 0.872  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.069  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.082  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  time: 3.0767  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:23:23] d2.utils.events INFO: eta: 17:55:27  iter: 140199  total_loss: 0.640  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0767  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:24:23] d2.utils.events INFO: eta: 17:54:19  iter: 140219  total_loss: 0.681  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0765  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:25:24] d2.utils.events INFO: eta: 17:53:13  iter: 140239  total_loss: 0.706  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0763  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:26:24] d2.utils.events INFO: eta: 17:52:11  iter: 140259  total_loss: 0.568  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0761  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:27:26] d2.utils.events INFO: eta: 17:51:11  iter: 140279  total_loss: 0.711  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:28:29] d2.utils.events INFO: eta: 17:50:06  iter: 140299  total_loss: 0.883  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 3.0764  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:29:30] d2.utils.events INFO: eta: 17:49:03  iter: 140319  total_loss: 0.722  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0763  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:30:31] d2.utils.events INFO: eta: 17:48:02  iter: 140339  total_loss: 0.743  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0762  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 15:31:34] d2.utils.events INFO: eta: 17:47:04  iter: 140359  total_loss: 0.599  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:32:37] d2.utils.events INFO: eta: 17:46:09  iter: 140379  total_loss: 0.911  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.352  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0767  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 15:33:40] d2.utils.events INFO: eta: 17:45:11  iter: 140399  total_loss: 0.900  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:34:42] d2.utils.events INFO: eta: 17:44:14  iter: 140419  total_loss: 0.616  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:35:42] d2.utils.events INFO: eta: 17:43:12  iter: 140439  total_loss: 0.804  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0769  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:36:43] d2.utils.events INFO: eta: 17:42:03  iter: 140459  total_loss: 0.731  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0767  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:37:45] d2.utils.events INFO: eta: 17:41:08  iter: 140479  total_loss: 0.642  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:38:47] d2.utils.events INFO: eta: 17:40:10  iter: 140499  total_loss: 0.720  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.008  loss_rpn_loc: 0.008  time: 3.0769  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:39:49] d2.utils.events INFO: eta: 17:39:08  iter: 140519  total_loss: 0.748  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0769  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:40:51] d2.utils.events INFO: eta: 17:38:10  iter: 140539  total_loss: 0.703  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:41:54] d2.utils.events INFO: eta: 17:37:14  iter: 140559  total_loss: 0.850  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:42:55] d2.utils.events INFO: eta: 17:36:17  iter: 140579  total_loss: 0.836  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:43:56] d2.utils.events INFO: eta: 17:35:11  iter: 140599  total_loss: 0.659  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 15:44:59] d2.utils.events INFO: eta: 17:34:10  iter: 140619  total_loss: 0.726  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:46:01] d2.utils.events INFO: eta: 17:33:11  iter: 140639  total_loss: 0.659  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.210  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0774  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 15:47:02] d2.utils.events INFO: eta: 17:32:10  iter: 140659  total_loss: 0.773  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0774  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 15:48:04] d2.utils.events INFO: eta: 17:31:14  iter: 140679  total_loss: 0.894  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.223  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.344  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:49:06] d2.utils.events INFO: eta: 17:30:18  iter: 140699  total_loss: 0.517  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:50:07] d2.utils.events INFO: eta: 17:29:05  iter: 140719  total_loss: 0.642  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 15:51:09] d2.utils.events INFO: eta: 17:28:07  iter: 140739  total_loss: 0.880  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:52:10] d2.utils.events INFO: eta: 17:26:59  iter: 140759  total_loss: 0.718  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0774  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:53:12] d2.utils.events INFO: eta: 17:25:58  iter: 140779  total_loss: 0.858  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0774  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:54:15] d2.utils.events INFO: eta: 17:25:11  iter: 140799  total_loss: 0.462  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.179  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0776  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:55:16] d2.utils.events INFO: eta: 17:24:13  iter: 140819  total_loss: 0.753  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0776  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 15:56:21] d2.utils.events INFO: eta: 17:23:14  iter: 140839  total_loss: 0.696  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  time: 3.0781  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 15:57:23] d2.utils.events INFO: eta: 17:22:08  iter: 140859  total_loss: 0.700  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.006  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 15:58:24] d2.utils.events INFO: eta: 17:20:59  iter: 140879  total_loss: 0.778  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0780  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 15:59:25] d2.utils.events INFO: eta: 17:19:54  iter: 140899  total_loss: 0.608  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0780  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 16:00:27] d2.utils.events INFO: eta: 17:18:57  iter: 140919  total_loss: 0.518  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0781  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:01:29] d2.utils.events INFO: eta: 17:17:56  iter: 140939  total_loss: 0.652  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 16:02:30] d2.utils.events INFO: eta: 17:16:51  iter: 140959  total_loss: 0.548  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.178  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0781  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:03:32] d2.utils.events INFO: eta: 17:15:50  iter: 140979  total_loss: 0.697  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0780  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:04:33] d2.utils.events INFO: eta: 17:14:45  iter: 140999  total_loss: 0.713  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 16:05:35] d2.utils.events INFO: eta: 17:13:48  iter: 141019  total_loss: 0.683  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0780  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:06:35] d2.utils.events INFO: eta: 17:12:43  iter: 141039  total_loss: 0.531  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0778  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:07:37] d2.utils.events INFO: eta: 17:11:50  iter: 141059  total_loss: 0.484  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.127  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0779  data_time: 0.0042  lr: 0.000100  max_mem: 9402M
[01/06 16:08:39] d2.utils.events INFO: eta: 17:10:45  iter: 141079  total_loss: 0.668  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0779  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:09:41] d2.utils.events INFO: eta: 17:09:44  iter: 141099  total_loss: 0.774  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0779  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:10:44] d2.utils.events INFO: eta: 17:08:52  iter: 141119  total_loss: 0.891  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.255  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.378  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0782  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:11:45] d2.utils.events INFO: eta: 17:07:47  iter: 141139  total_loss: 0.798  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 16:12:47] d2.utils.events INFO: eta: 17:06:46  iter: 141159  total_loss: 0.906  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.266  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.348  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0782  data_time: 0.0019  lr: 0.000100  max_mem: 9402M
[01/06 16:13:50] d2.utils.events INFO: eta: 17:05:54  iter: 141179  total_loss: 0.835  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.253  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0784  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:14:50] d2.utils.events INFO: eta: 17:04:29  iter: 141199  total_loss: 0.824  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.073  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.007  loss_rpn_loc: 0.012  time: 3.0782  data_time: 0.0046  lr: 0.000100  max_mem: 9402M
[01/06 16:15:52] d2.utils.events INFO: eta: 17:03:34  iter: 141219  total_loss: 0.529  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0782  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 16:16:53] d2.utils.events INFO: eta: 17:02:33  iter: 141239  total_loss: 0.704  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:17:55] d2.utils.events INFO: eta: 17:01:32  iter: 141259  total_loss: 0.747  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:18:57] d2.utils.events INFO: eta: 17:00:31  iter: 141279  total_loss: 0.601  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0783  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:19:59] d2.utils.events INFO: eta: 16:59:30  iter: 141299  total_loss: 0.775  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0783  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 16:21:01] d2.utils.events INFO: eta: 16:58:38  iter: 141319  total_loss: 0.861  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.321  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0785  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:22:03] d2.utils.events INFO: eta: 16:57:37  iter: 141339  total_loss: 0.558  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0784  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 16:23:03] d2.utils.events INFO: eta: 16:56:30  iter: 141359  total_loss: 0.537  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0782  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 16:24:04] d2.utils.events INFO: eta: 16:55:18  iter: 141379  total_loss: 0.685  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0782  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:25:06] d2.utils.events INFO: eta: 16:54:05  iter: 141399  total_loss: 0.836  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0782  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:26:09] d2.utils.events INFO: eta: 16:53:06  iter: 141419  total_loss: 0.603  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0784  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:27:10] d2.utils.events INFO: eta: 16:52:02  iter: 141439  total_loss: 0.691  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0783  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:28:12] d2.utils.events INFO: eta: 16:51:10  iter: 141459  total_loss: 0.691  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0784  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:29:13] d2.utils.events INFO: eta: 16:50:01  iter: 141479  total_loss: 0.698  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0783  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:30:15] d2.utils.events INFO: eta: 16:49:08  iter: 141499  total_loss: 0.780  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0784  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:31:17] d2.utils.events INFO: eta: 16:48:03  iter: 141519  total_loss: 0.775  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0784  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 16:32:18] d2.utils.events INFO: eta: 16:46:57  iter: 141539  total_loss: 0.822  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0783  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:33:20] d2.utils.events INFO: eta: 16:45:56  iter: 141559  total_loss: 0.568  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0783  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:34:21] d2.utils.events INFO: eta: 16:44:51  iter: 141579  total_loss: 0.603  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0782  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:35:21] d2.utils.events INFO: eta: 16:43:50  iter: 141599  total_loss: 0.402  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.109  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0781  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 16:36:22] d2.utils.events INFO: eta: 16:42:49  iter: 141619  total_loss: 0.903  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.349  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0780  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:37:25] d2.utils.events INFO: eta: 16:41:49  iter: 141639  total_loss: 0.899  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.115  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.240  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0781  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 16:38:26] d2.utils.events INFO: eta: 16:40:48  iter: 141659  total_loss: 0.664  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0781  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:39:27] d2.utils.events INFO: eta: 16:39:44  iter: 141679  total_loss: 1.061  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.113  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.308  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.433  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0780  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 16:40:28] d2.utils.events INFO: eta: 16:38:42  iter: 141699  total_loss: 0.865  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0779  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:41:29] d2.utils.events INFO: eta: 16:37:44  iter: 141719  total_loss: 0.776  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0778  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:42:31] d2.utils.events INFO: eta: 16:36:41  iter: 141739  total_loss: 0.571  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0779  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:43:33] d2.utils.events INFO: eta: 16:35:45  iter: 141759  total_loss: 0.756  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0779  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:44:33] d2.utils.events INFO: eta: 16:34:41  iter: 141779  total_loss: 0.805  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 16:45:36] d2.utils.events INFO: eta: 16:33:37  iter: 141799  total_loss: 0.686  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0778  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:46:36] d2.utils.events INFO: eta: 16:32:35  iter: 141819  total_loss: 0.950  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.281  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0777  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:47:38] d2.utils.events INFO: eta: 16:31:31  iter: 141839  total_loss: 0.863  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0777  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 16:48:40] d2.utils.events INFO: eta: 16:30:31  iter: 141859  total_loss: 0.587  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0778  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:49:41] d2.utils.events INFO: eta: 16:29:32  iter: 141879  total_loss: 0.842  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0777  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:50:44] d2.utils.events INFO: eta: 16:28:32  iter: 141899  total_loss: 0.723  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0779  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:51:44] d2.utils.events INFO: eta: 16:27:28  iter: 141919  total_loss: 0.878  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:52:46] d2.utils.events INFO: eta: 16:26:25  iter: 141939  total_loss: 0.737  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 16:53:47] d2.utils.events INFO: eta: 16:25:24  iter: 141959  total_loss: 0.763  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:54:49] d2.utils.events INFO: eta: 16:24:26  iter: 141979  total_loss: 0.858  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:55:52] d2.utils.events INFO: eta: 16:23:23  iter: 141999  total_loss: 0.796  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0779  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:56:52] d2.utils.events INFO: eta: 16:22:21  iter: 142019  total_loss: 0.904  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.374  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0777  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 16:57:54] d2.utils.events INFO: eta: 16:21:22  iter: 142039  total_loss: 0.634  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0777  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 16:58:55] d2.utils.events INFO: eta: 16:20:19  iter: 142059  total_loss: 0.674  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0776  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 16:59:55] d2.utils.events INFO: eta: 16:19:16  iter: 142079  total_loss: 0.715  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:00:56] d2.utils.events INFO: eta: 16:18:12  iter: 142099  total_loss: 0.730  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 17:01:56] d2.utils.events INFO: eta: 16:17:02  iter: 142119  total_loss: 0.611  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:02:58] d2.utils.events INFO: eta: 16:16:02  iter: 142139  total_loss: 0.826  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.084  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:04:01] d2.utils.events INFO: eta: 16:15:01  iter: 142159  total_loss: 0.673  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:05:01] d2.utils.events INFO: eta: 16:13:44  iter: 142179  total_loss: 0.671  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:06:01] d2.utils.events INFO: eta: 16:12:49  iter: 142199  total_loss: 0.787  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 17:07:03] d2.utils.events INFO: eta: 16:11:52  iter: 142219  total_loss: 0.640  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:08:05] d2.utils.events INFO: eta: 16:10:55  iter: 142239  total_loss: 0.473  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.117  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 17:09:06] d2.utils.events INFO: eta: 16:09:48  iter: 142259  total_loss: 0.833  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:10:08] d2.utils.events INFO: eta: 16:08:43  iter: 142279  total_loss: 0.999  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.259  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.369  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:11:08] d2.utils.events INFO: eta: 16:07:35  iter: 142299  total_loss: 0.804  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0769  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:12:10] d2.utils.events INFO: eta: 16:06:31  iter: 142319  total_loss: 0.608  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0769  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:13:12] d2.utils.events INFO: eta: 16:05:32  iter: 142339  total_loss: 0.829  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.356  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0769  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:14:14] d2.utils.events INFO: eta: 16:04:33  iter: 142359  total_loss: 0.661  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 17:15:17] d2.utils.events INFO: eta: 16:03:38  iter: 142379  total_loss: 0.710  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 17:16:19] d2.utils.events INFO: eta: 16:02:37  iter: 142399  total_loss: 0.803  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0773  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:17:20] d2.utils.events INFO: eta: 16:01:30  iter: 142419  total_loss: 0.774  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:18:21] d2.utils.events INFO: eta: 16:00:31  iter: 142439  total_loss: 0.705  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0770  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 17:19:21] d2.utils.events INFO: eta: 15:59:31  iter: 142459  total_loss: 0.712  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:20:22] d2.utils.events INFO: eta: 15:58:30  iter: 142479  total_loss: 0.702  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0768  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:21:24] d2.utils.events INFO: eta: 15:57:27  iter: 142499  total_loss: 0.628  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0769  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:22:27] d2.utils.events INFO: eta: 15:56:31  iter: 142519  total_loss: 0.724  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.064  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:23:28] d2.utils.events INFO: eta: 15:55:30  iter: 142539  total_loss: 0.973  loss_cls_stage0: 0.069  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.355  loss_rpn_cls: 0.005  loss_rpn_loc: 0.009  time: 3.0770  data_time: 0.0019  lr: 0.000100  max_mem: 9402M
[01/06 17:24:30] d2.utils.events INFO: eta: 15:54:31  iter: 142559  total_loss: 0.752  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0771  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:25:32] d2.utils.events INFO: eta: 15:53:33  iter: 142579  total_loss: 0.739  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 17:26:33] d2.utils.events INFO: eta: 15:52:38  iter: 142599  total_loss: 0.606  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0771  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:27:36] d2.utils.events INFO: eta: 15:51:40  iter: 142619  total_loss: 0.605  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:28:38] d2.utils.events INFO: eta: 15:50:40  iter: 142639  total_loss: 0.865  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.068  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.083  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0773  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:29:40] d2.utils.events INFO: eta: 15:49:40  iter: 142659  total_loss: 0.776  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0774  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:30:43] d2.utils.events INFO: eta: 15:48:38  iter: 142679  total_loss: 0.982  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.113  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.262  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0775  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:31:44] d2.utils.events INFO: eta: 15:47:39  iter: 142699  total_loss: 0.770  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0775  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:32:46] d2.utils.events INFO: eta: 15:46:37  iter: 142719  total_loss: 0.639  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0775  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:33:47] d2.utils.events INFO: eta: 15:45:36  iter: 142739  total_loss: 0.750  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0775  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:34:48] d2.utils.events INFO: eta: 15:44:36  iter: 142759  total_loss: 0.620  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:35:49] d2.utils.events INFO: eta: 15:43:36  iter: 142779  total_loss: 0.709  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:36:51] d2.utils.events INFO: eta: 15:42:34  iter: 142799  total_loss: 0.763  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0773  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:37:52] d2.utils.events INFO: eta: 15:41:34  iter: 142819  total_loss: 0.739  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.338  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:38:54] d2.utils.events INFO: eta: 15:40:35  iter: 142839  total_loss: 0.770  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.101  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0773  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:39:56] d2.utils.events INFO: eta: 15:39:35  iter: 142859  total_loss: 0.898  loss_cls_stage0: 0.064  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.074  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.077  loss_box_reg_stage2: 0.377  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0773  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:40:56] d2.utils.events INFO: eta: 15:38:34  iter: 142879  total_loss: 0.510  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:41:57] d2.utils.events INFO: eta: 15:37:30  iter: 142899  total_loss: 0.597  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:42:58] d2.utils.events INFO: eta: 15:36:37  iter: 142919  total_loss: 0.839  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.332  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0771  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:43:59] d2.utils.events INFO: eta: 15:35:37  iter: 142939  total_loss: 0.671  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:45:00] d2.utils.events INFO: eta: 15:34:36  iter: 142959  total_loss: 0.817  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.328  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0769  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:46:00] d2.utils.events INFO: eta: 15:33:30  iter: 142979  total_loss: 0.594  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0767  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 17:47:01] d2.utils.events INFO: eta: 15:32:28  iter: 142999  total_loss: 0.567  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:48:02] d2.utils.events INFO: eta: 15:31:27  iter: 143019  total_loss: 0.785  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0765  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:49:03] d2.utils.events INFO: eta: 15:30:26  iter: 143039  total_loss: 0.695  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 17:50:04] d2.utils.events INFO: eta: 15:29:25  iter: 143059  total_loss: 0.815  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0763  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:51:05] d2.utils.events INFO: eta: 15:28:25  iter: 143079  total_loss: 0.685  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0763  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:52:06] d2.utils.events INFO: eta: 15:27:23  iter: 143099  total_loss: 0.570  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0762  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 17:53:07] d2.utils.events INFO: eta: 15:26:23  iter: 143119  total_loss: 0.672  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.005  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:54:09] d2.utils.events INFO: eta: 15:25:22  iter: 143139  total_loss: 1.014  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.281  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.348  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0762  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 17:55:11] d2.utils.events INFO: eta: 15:24:21  iter: 143159  total_loss: 0.743  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:56:15] d2.utils.events INFO: eta: 15:23:34  iter: 143179  total_loss: 0.718  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0766  data_time: 0.0030  lr: 0.000100  max_mem: 9402M
[01/06 17:57:17] d2.utils.events INFO: eta: 15:22:34  iter: 143199  total_loss: 0.550  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.204  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0767  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 17:58:20] d2.utils.events INFO: eta: 15:21:34  iter: 143219  total_loss: 0.899  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0768  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 17:59:22] d2.utils.events INFO: eta: 15:20:35  iter: 143239  total_loss: 0.759  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0768  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:00:23] d2.utils.events INFO: eta: 15:19:39  iter: 143259  total_loss: 0.695  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.221  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 3.0768  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:01:23] d2.utils.events INFO: eta: 15:18:31  iter: 143279  total_loss: 0.702  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0766  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 18:02:25] d2.utils.events INFO: eta: 15:17:35  iter: 143299  total_loss: 0.709  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0767  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 18:03:27] d2.utils.events INFO: eta: 15:16:36  iter: 143319  total_loss: 0.779  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0767  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:04:28] d2.utils.events INFO: eta: 15:15:32  iter: 143339  total_loss: 0.699  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.309  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0766  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:05:29] d2.utils.events INFO: eta: 15:14:28  iter: 143359  total_loss: 0.816  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:06:31] d2.utils.events INFO: eta: 15:13:26  iter: 143379  total_loss: 0.700  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0766  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:07:33] d2.utils.events INFO: eta: 15:12:26  iter: 143399  total_loss: 0.899  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0767  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:08:35] d2.utils.events INFO: eta: 15:11:29  iter: 143419  total_loss: 0.882  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.376  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0767  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:09:37] d2.utils.events INFO: eta: 15:10:33  iter: 143439  total_loss: 0.989  loss_cls_stage0: 0.073  loss_box_reg_stage0: 0.121  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.278  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.382  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0768  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 18:10:38] d2.utils.events INFO: eta: 15:09:34  iter: 143459  total_loss: 0.869  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0767  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:11:39] d2.utils.events INFO: eta: 15:08:31  iter: 143479  total_loss: 0.654  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0767  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 18:12:41] d2.utils.events INFO: eta: 15:07:28  iter: 143499  total_loss: 0.624  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0767  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:13:42] d2.utils.events INFO: eta: 15:06:24  iter: 143519  total_loss: 0.593  loss_cls_stage0: 0.071  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:14:41] d2.utils.events INFO: eta: 15:05:23  iter: 143539  total_loss: 0.609  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0764  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:15:43] d2.utils.events INFO: eta: 15:04:17  iter: 143559  total_loss: 0.637  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:16:43] d2.utils.events INFO: eta: 15:03:14  iter: 143579  total_loss: 0.629  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0762  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:17:44] d2.utils.events INFO: eta: 15:02:11  iter: 143599  total_loss: 0.713  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 18:18:44] d2.utils.events INFO: eta: 15:00:57  iter: 143619  total_loss: 0.597  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:19:45] d2.utils.events INFO: eta: 14:59:52  iter: 143639  total_loss: 0.821  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 18:20:47] d2.utils.events INFO: eta: 14:58:55  iter: 143659  total_loss: 0.643  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 18:21:49] d2.utils.events INFO: eta: 14:57:54  iter: 143679  total_loss: 0.565  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 18:22:50] d2.utils.events INFO: eta: 14:56:48  iter: 143699  total_loss: 0.652  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:23:52] d2.utils.events INFO: eta: 14:55:51  iter: 143719  total_loss: 0.680  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:24:52] d2.utils.events INFO: eta: 14:54:47  iter: 143739  total_loss: 0.805  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.221  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:25:53] d2.utils.events INFO: eta: 14:53:40  iter: 143759  total_loss: 0.657  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 18:26:56] d2.utils.events INFO: eta: 14:52:48  iter: 143779  total_loss: 0.676  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0034  lr: 0.000100  max_mem: 9402M
[01/06 18:27:57] d2.utils.events INFO: eta: 14:51:45  iter: 143799  total_loss: 0.628  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:28:59] d2.utils.events INFO: eta: 14:50:47  iter: 143819  total_loss: 0.702  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:30:00] d2.utils.events INFO: eta: 14:49:43  iter: 143839  total_loss: 0.746  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:31:01] d2.utils.events INFO: eta: 14:48:39  iter: 143859  total_loss: 0.459  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0757  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 18:32:02] d2.utils.events INFO: eta: 14:47:37  iter: 143879  total_loss: 0.600  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:33:05] d2.utils.events INFO: eta: 14:46:44  iter: 143899  total_loss: 0.906  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.110  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.351  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:34:05] d2.utils.events INFO: eta: 14:45:43  iter: 143919  total_loss: 0.730  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.287  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:35:08] d2.utils.events INFO: eta: 14:44:45  iter: 143939  total_loss: 0.891  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.369  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:36:09] d2.utils.events INFO: eta: 14:43:43  iter: 143959  total_loss: 0.697  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:37:11] d2.utils.events INFO: eta: 14:42:50  iter: 143979  total_loss: 0.674  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:38:12] d2.utils.events INFO: eta: 14:41:51  iter: 143999  total_loss: 0.699  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 18:39:14] d2.utils.events INFO: eta: 14:40:54  iter: 144019  total_loss: 0.666  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.217  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 18:40:15] d2.utils.events INFO: eta: 14:39:49  iter: 144039  total_loss: 0.523  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:41:18] d2.utils.events INFO: eta: 14:38:53  iter: 144059  total_loss: 0.737  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.331  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:42:18] d2.utils.events INFO: eta: 14:37:52  iter: 144079  total_loss: 0.887  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.069  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:43:20] d2.utils.events INFO: eta: 14:36:57  iter: 144099  total_loss: 0.665  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:44:21] d2.utils.events INFO: eta: 14:35:52  iter: 144119  total_loss: 0.656  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:45:22] d2.utils.events INFO: eta: 14:34:49  iter: 144139  total_loss: 0.558  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:46:25] d2.utils.events INFO: eta: 14:33:50  iter: 144159  total_loss: 0.794  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:47:27] d2.utils.events INFO: eta: 14:32:42  iter: 144179  total_loss: 0.839  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.347  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:48:29] d2.utils.events INFO: eta: 14:31:41  iter: 144199  total_loss: 0.659  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0760  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:49:31] d2.utils.events INFO: eta: 14:30:36  iter: 144219  total_loss: 0.596  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 18:50:33] d2.utils.events INFO: eta: 14:29:34  iter: 144239  total_loss: 0.780  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:51:34] d2.utils.events INFO: eta: 14:28:33  iter: 144259  total_loss: 0.504  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.131  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 18:52:37] d2.utils.events INFO: eta: 14:27:37  iter: 144279  total_loss: 0.643  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0761  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 18:53:40] d2.utils.events INFO: eta: 14:26:38  iter: 144299  total_loss: 0.931  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.338  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0763  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:54:41] d2.utils.events INFO: eta: 14:25:36  iter: 144319  total_loss: 0.704  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0763  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:55:44] d2.utils.events INFO: eta: 14:24:37  iter: 144339  total_loss: 0.700  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 18:56:45] d2.utils.events INFO: eta: 14:23:38  iter: 144359  total_loss: 0.875  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.232  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.357  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0764  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 18:57:47] d2.utils.events INFO: eta: 14:22:38  iter: 144379  total_loss: 0.599  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0764  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:58:50] d2.utils.events INFO: eta: 14:21:36  iter: 144399  total_loss: 0.654  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 18:59:52] d2.utils.events INFO: eta: 14:20:37  iter: 144419  total_loss: 0.582  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0766  data_time: 0.0019  lr: 0.000100  max_mem: 9402M
[01/06 19:00:55] d2.utils.events INFO: eta: 14:19:36  iter: 144439  total_loss: 0.725  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0767  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 19:01:57] d2.utils.events INFO: eta: 14:18:36  iter: 144459  total_loss: 0.749  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0768  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 19:03:00] d2.utils.events INFO: eta: 14:17:42  iter: 144479  total_loss: 0.745  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0769  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 19:04:02] d2.utils.events INFO: eta: 14:16:43  iter: 144499  total_loss: 0.809  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:05:04] d2.utils.events INFO: eta: 14:15:43  iter: 144519  total_loss: 0.494  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:06:05] d2.utils.events INFO: eta: 14:14:43  iter: 144539  total_loss: 0.638  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:07:08] d2.utils.events INFO: eta: 14:13:52  iter: 144559  total_loss: 0.620  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:08:11] d2.utils.events INFO: eta: 14:12:57  iter: 144579  total_loss: 0.825  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.352  loss_rpn_cls: 0.006  loss_rpn_loc: 0.008  time: 3.0772  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 19:09:12] d2.utils.events INFO: eta: 14:11:56  iter: 144599  total_loss: 0.599  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 19:10:14] d2.utils.events INFO: eta: 14:11:00  iter: 144619  total_loss: 0.893  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 19:11:15] d2.utils.events INFO: eta: 14:10:01  iter: 144639  total_loss: 0.663  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0772  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 19:12:17] d2.utils.events INFO: eta: 14:08:58  iter: 144659  total_loss: 0.705  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:13:17] d2.utils.events INFO: eta: 14:07:57  iter: 144679  total_loss: 0.524  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 19:14:20] d2.utils.events INFO: eta: 14:07:02  iter: 144699  total_loss: 0.648  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:15:21] d2.utils.events INFO: eta: 14:05:58  iter: 144719  total_loss: 0.822  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:16:23] d2.utils.events INFO: eta: 14:05:00  iter: 144739  total_loss: 1.023  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.287  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.432  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0772  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 19:17:24] d2.utils.events INFO: eta: 14:04:03  iter: 144759  total_loss: 0.823  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:18:26] d2.utils.events INFO: eta: 14:02:57  iter: 144779  total_loss: 0.591  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.184  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:19:27] d2.utils.events INFO: eta: 14:01:58  iter: 144799  total_loss: 0.729  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:20:30] d2.utils.events INFO: eta: 14:00:58  iter: 144819  total_loss: 0.989  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.242  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.385  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0773  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 19:21:32] d2.utils.events INFO: eta: 13:59:58  iter: 144839  total_loss: 0.713  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0773  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:22:32] d2.utils.events INFO: eta: 13:58:54  iter: 144859  total_loss: 0.807  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:23:33] d2.utils.events INFO: eta: 13:57:51  iter: 144879  total_loss: 0.605  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0771  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:24:34] d2.utils.events INFO: eta: 13:56:48  iter: 144899  total_loss: 0.669  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.218  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:25:35] d2.utils.events INFO: eta: 13:55:49  iter: 144919  total_loss: 0.775  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:26:36] d2.utils.events INFO: eta: 13:54:46  iter: 144939  total_loss: 0.697  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:27:39] d2.utils.events INFO: eta: 13:53:47  iter: 144959  total_loss: 0.784  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:28:40] d2.utils.events INFO: eta: 13:52:44  iter: 144979  total_loss: 0.772  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.009  loss_rpn_loc: 0.006  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:29:42] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0144999.pth
[01/06 19:29:47] d2.data.datasets.coco INFO: Loaded 1000 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small_small.json
[01/06 19:29:48] d2.evaluation.evaluator INFO: Start inference on 500 images
[01/06 19:30:52] d2.evaluation.evaluator INFO: Inference done 50/500. 0.4795 s / img. ETA=0:03:35
[01/06 19:31:16] d2.evaluation.evaluator INFO: Inference done 100/500. 0.4800 s / img. ETA=0:03:12
[01/06 19:31:40] d2.evaluation.evaluator INFO: Inference done 150/500. 0.4797 s / img. ETA=0:02:47
[01/06 19:32:04] d2.evaluation.evaluator INFO: Inference done 200/500. 0.4797 s / img. ETA=0:02:23
[01/06 19:32:28] d2.evaluation.evaluator INFO: Inference done 250/500. 0.4796 s / img. ETA=0:01:59
[01/06 19:32:52] d2.evaluation.evaluator INFO: Inference done 300/500. 0.4798 s / img. ETA=0:01:35
[01/06 19:33:16] d2.evaluation.evaluator INFO: Inference done 350/500. 0.4799 s / img. ETA=0:01:11
[01/06 19:33:40] d2.evaluation.evaluator INFO: Inference done 400/500. 0.4798 s / img. ETA=0:00:47
[01/06 19:34:04] d2.evaluation.evaluator INFO: Inference done 450/500. 0.4799 s / img. ETA=0:00:23
[01/06 19:34:28] d2.evaluation.evaluator INFO: Inference done 500/500. 0.4799 s / img. ETA=0:00:00
[01/06 19:34:28] d2.evaluation.evaluator INFO: Total inference time: 0:03:57 (0.478788 s / img per device, on 2 devices)
[01/06 19:34:28] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:56 (0.476881 s / img per device, on 2 devices)
[01/06 19:34:28] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/06 19:34:28] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small_small.json
[01/06 19:34:28] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/06 19:34:32] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 59.093 | 81.497 | 67.322 | 51.287 | 54.097 | 70.502 |
[01/06 19:34:32] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 66.162 | ASC-US     | 63.750 | HSIL        | 75.396 |
| LSIL       | 72.266 | Candida    | 51.088 | Trichomonas | 25.898 |
[01/06 19:34:32] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small_small in csv format:
[01/06 19:34:32] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/06 19:34:32] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/06 19:34:32] d2.evaluation.testing INFO: copypaste: 59.0932,81.4968,67.3222,51.2870,54.0971,70.5024
[01/06 19:34:32] d2.utils.events INFO: eta: 13:51:43  iter: 144999  total_loss: 0.816  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0771  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 19:35:33] d2.utils.events INFO: eta: 13:50:41  iter: 145019  total_loss: 0.652  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0770  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 19:36:36] d2.utils.events INFO: eta: 13:49:45  iter: 145039  total_loss: 0.686  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0771  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:37:38] d2.utils.events INFO: eta: 13:48:44  iter: 145059  total_loss: 0.649  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:38:41] d2.utils.events INFO: eta: 13:47:49  iter: 145079  total_loss: 0.810  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.071  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0773  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:39:44] d2.utils.events INFO: eta: 13:46:50  iter: 145099  total_loss: 0.634  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0775  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:40:44] d2.utils.events INFO: eta: 13:45:49  iter: 145119  total_loss: 0.812  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0774  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 19:41:46] d2.utils.events INFO: eta: 13:44:49  iter: 145139  total_loss: 0.658  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:42:47] d2.utils.events INFO: eta: 13:43:45  iter: 145159  total_loss: 0.574  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0774  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:43:48] d2.utils.events INFO: eta: 13:42:46  iter: 145179  total_loss: 0.488  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0773  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:44:49] d2.utils.events INFO: eta: 13:41:45  iter: 145199  total_loss: 0.762  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:45:51] d2.utils.events INFO: eta: 13:40:45  iter: 145219  total_loss: 0.840  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.068  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0773  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 19:46:52] d2.utils.events INFO: eta: 13:39:44  iter: 145239  total_loss: 0.626  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0772  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 19:47:52] d2.utils.events INFO: eta: 13:38:43  iter: 145259  total_loss: 0.664  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0771  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:48:54] d2.utils.events INFO: eta: 13:37:41  iter: 145279  total_loss: 0.721  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:49:57] d2.utils.events INFO: eta: 13:36:39  iter: 145299  total_loss: 0.828  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0773  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:50:59] d2.utils.events INFO: eta: 13:35:39  iter: 145319  total_loss: 0.749  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0773  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 19:52:02] d2.utils.events INFO: eta: 13:34:38  iter: 145339  total_loss: 0.762  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0775  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 19:53:04] d2.utils.events INFO: eta: 13:33:38  iter: 145359  total_loss: 0.556  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.235  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0775  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:54:05] d2.utils.events INFO: eta: 13:32:36  iter: 145379  total_loss: 0.656  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.202  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0775  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 19:55:07] d2.utils.events INFO: eta: 13:31:33  iter: 145399  total_loss: 0.595  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0775  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 19:56:10] d2.utils.events INFO: eta: 13:30:30  iter: 145419  total_loss: 0.703  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0776  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 19:57:11] d2.utils.events INFO: eta: 13:29:30  iter: 145439  total_loss: 0.980  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.122  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.250  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.411  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 19:58:13] d2.utils.events INFO: eta: 13:28:29  iter: 145459  total_loss: 0.704  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 19:59:15] d2.utils.events INFO: eta: 13:27:28  iter: 145479  total_loss: 0.791  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:00:16] d2.utils.events INFO: eta: 13:26:25  iter: 145499  total_loss: 0.765  loss_cls_stage0: 0.067  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.072  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:01:18] d2.utils.events INFO: eta: 13:25:23  iter: 145519  total_loss: 0.809  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:02:20] d2.utils.events INFO: eta: 13:24:23  iter: 145539  total_loss: 0.670  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:03:20] d2.utils.events INFO: eta: 13:23:19  iter: 145559  total_loss: 0.670  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0775  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 20:04:23] d2.utils.events INFO: eta: 13:22:15  iter: 145579  total_loss: 0.703  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0776  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:05:24] d2.utils.events INFO: eta: 13:21:15  iter: 145599  total_loss: 0.695  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0776  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:06:25] d2.utils.events INFO: eta: 13:20:13  iter: 145619  total_loss: 0.818  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0775  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:07:27] d2.utils.events INFO: eta: 13:19:12  iter: 145639  total_loss: 1.052  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.108  loss_cls_stage1: 0.070  loss_box_reg_stage1: 0.263  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.390  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0776  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:08:29] d2.utils.events INFO: eta: 13:18:11  iter: 145659  total_loss: 0.583  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0776  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:09:30] d2.utils.events INFO: eta: 13:17:07  iter: 145679  total_loss: 0.644  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0776  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:10:31] d2.utils.events INFO: eta: 13:15:59  iter: 145699  total_loss: 0.648  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0775  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 20:11:33] d2.utils.events INFO: eta: 13:14:59  iter: 145719  total_loss: 0.600  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0775  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 20:12:33] d2.utils.events INFO: eta: 13:13:55  iter: 145739  total_loss: 0.688  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0774  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:13:33] d2.utils.events INFO: eta: 13:12:51  iter: 145759  total_loss: 0.714  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0772  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:14:33] d2.utils.events INFO: eta: 13:11:49  iter: 145779  total_loss: 0.893  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.361  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0771  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:15:36] d2.utils.events INFO: eta: 13:10:51  iter: 145799  total_loss: 0.779  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:16:38] d2.utils.events INFO: eta: 13:09:48  iter: 145819  total_loss: 0.744  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:17:38] d2.utils.events INFO: eta: 13:08:45  iter: 145839  total_loss: 0.601  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0771  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:18:38] d2.utils.events INFO: eta: 13:07:44  iter: 145859  total_loss: 0.754  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0770  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:19:41] d2.utils.events INFO: eta: 13:06:46  iter: 145879  total_loss: 0.690  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0771  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:20:43] d2.utils.events INFO: eta: 13:05:46  iter: 145899  total_loss: 0.648  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.006  loss_rpn_loc: 0.005  time: 3.0772  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:21:45] d2.utils.events INFO: eta: 13:04:44  iter: 145919  total_loss: 0.911  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0771  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:22:47] d2.utils.events INFO: eta: 13:03:43  iter: 145939  total_loss: 0.713  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0772  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:23:48] d2.utils.events INFO: eta: 13:02:41  iter: 145959  total_loss: 0.722  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0772  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:24:49] d2.utils.events INFO: eta: 13:01:41  iter: 145979  total_loss: 0.753  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0771  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:25:49] d2.utils.events INFO: eta: 13:00:37  iter: 145999  total_loss: 0.893  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.381  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0770  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:26:50] d2.utils.events INFO: eta: 12:59:36  iter: 146019  total_loss: 0.812  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.054  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.331  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0769  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:27:52] d2.utils.events INFO: eta: 12:58:34  iter: 146039  total_loss: 0.840  loss_cls_stage0: 0.065  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0769  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:28:52] d2.utils.events INFO: eta: 12:57:31  iter: 146059  total_loss: 0.832  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0768  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:29:53] d2.utils.events INFO: eta: 12:56:23  iter: 146079  total_loss: 0.718  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0767  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:30:54] d2.utils.events INFO: eta: 12:55:14  iter: 146099  total_loss: 0.849  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0767  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:31:56] d2.utils.events INFO: eta: 12:54:17  iter: 146119  total_loss: 0.797  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.234  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0767  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:32:58] d2.utils.events INFO: eta: 12:53:17  iter: 146139  total_loss: 0.744  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0768  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:34:00] d2.utils.events INFO: eta: 12:52:17  iter: 146159  total_loss: 0.690  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:35:02] d2.utils.events INFO: eta: 12:51:18  iter: 146179  total_loss: 0.777  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0768  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:36:03] d2.utils.events INFO: eta: 12:50:17  iter: 146199  total_loss: 0.592  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 20:37:05] d2.utils.events INFO: eta: 12:49:11  iter: 146219  total_loss: 0.726  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:38:07] d2.utils.events INFO: eta: 12:48:15  iter: 146239  total_loss: 0.780  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.064  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0769  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:39:09] d2.utils.events INFO: eta: 12:47:15  iter: 146259  total_loss: 0.807  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0769  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:40:09] d2.utils.events INFO: eta: 12:46:13  iter: 146279  total_loss: 0.699  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:41:10] d2.utils.events INFO: eta: 12:45:09  iter: 146299  total_loss: 0.470  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.047  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0768  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 20:42:12] d2.utils.events INFO: eta: 12:44:07  iter: 146319  total_loss: 0.673  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0768  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:43:13] d2.utils.events INFO: eta: 12:43:04  iter: 146339  total_loss: 0.612  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0767  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:44:14] d2.utils.events INFO: eta: 12:41:59  iter: 146359  total_loss: 0.639  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0767  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 20:45:14] d2.utils.events INFO: eta: 12:40:53  iter: 146379  total_loss: 0.869  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.367  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0766  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:46:15] d2.utils.events INFO: eta: 12:39:49  iter: 146399  total_loss: 0.691  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0765  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:47:18] d2.utils.events INFO: eta: 12:38:55  iter: 146419  total_loss: 0.680  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0766  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:48:20] d2.utils.events INFO: eta: 12:37:53  iter: 146439  total_loss: 0.629  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0766  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:49:21] d2.utils.events INFO: eta: 12:36:51  iter: 146459  total_loss: 0.712  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0766  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:50:24] d2.utils.events INFO: eta: 12:35:44  iter: 146479  total_loss: 0.735  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.330  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0767  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:51:25] d2.utils.events INFO: eta: 12:34:43  iter: 146499  total_loss: 0.557  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.061  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0766  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 20:52:26] d2.utils.events INFO: eta: 12:33:42  iter: 146519  total_loss: 0.776  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0766  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:53:27] d2.utils.events INFO: eta: 12:32:41  iter: 146539  total_loss: 0.811  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.217  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0766  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/06 20:54:28] d2.utils.events INFO: eta: 12:31:40  iter: 146559  total_loss: 0.654  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0765  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 20:55:29] d2.utils.events INFO: eta: 12:30:38  iter: 146579  total_loss: 0.711  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0765  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 20:56:31] d2.utils.events INFO: eta: 12:29:35  iter: 146599  total_loss: 0.673  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0765  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:57:32] d2.utils.events INFO: eta: 12:28:36  iter: 146619  total_loss: 0.628  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 20:58:34] d2.utils.events INFO: eta: 12:27:36  iter: 146639  total_loss: 0.826  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.348  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0765  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 20:59:35] d2.utils.events INFO: eta: 12:26:35  iter: 146659  total_loss: 0.595  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0765  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:00:37] d2.utils.events INFO: eta: 12:25:34  iter: 146679  total_loss: 0.726  loss_cls_stage0: 0.056  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.066  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0765  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 21:01:38] d2.utils.events INFO: eta: 12:24:34  iter: 146699  total_loss: 0.803  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0765  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 21:02:39] d2.utils.events INFO: eta: 12:23:32  iter: 146719  total_loss: 0.647  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:03:41] d2.utils.events INFO: eta: 12:22:32  iter: 146739  total_loss: 0.761  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0764  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:04:42] d2.utils.events INFO: eta: 12:21:33  iter: 146759  total_loss: 0.519  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0764  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:05:44] d2.utils.events INFO: eta: 12:20:39  iter: 146779  total_loss: 0.693  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0764  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:06:45] d2.utils.events INFO: eta: 12:19:32  iter: 146799  total_loss: 0.837  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0764  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:07:47] d2.utils.events INFO: eta: 12:18:34  iter: 146819  total_loss: 0.644  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0764  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:08:47] d2.utils.events INFO: eta: 12:17:36  iter: 146839  total_loss: 0.778  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0763  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:09:48] d2.utils.events INFO: eta: 12:16:35  iter: 146859  total_loss: 0.647  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.062  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 3.0762  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:10:50] d2.utils.events INFO: eta: 12:15:31  iter: 146879  total_loss: 0.705  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0763  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 21:11:51] d2.utils.events INFO: eta: 12:14:26  iter: 146899  total_loss: 0.790  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 21:12:51] d2.utils.events INFO: eta: 12:13:24  iter: 146919  total_loss: 0.744  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.351  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0761  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:13:53] d2.utils.events INFO: eta: 12:12:22  iter: 146939  total_loss: 0.768  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0761  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:14:54] d2.utils.events INFO: eta: 12:11:22  iter: 146959  total_loss: 0.593  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.133  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0761  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 21:15:56] d2.utils.events INFO: eta: 12:10:22  iter: 146979  total_loss: 0.881  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.110  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.313  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0762  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:16:58] d2.utils.events INFO: eta: 12:09:25  iter: 146999  total_loss: 0.539  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0762  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:17:58] d2.utils.events INFO: eta: 12:08:24  iter: 147019  total_loss: 0.589  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0761  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:19:00] d2.utils.events INFO: eta: 12:07:20  iter: 147039  total_loss: 0.692  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 21:20:01] d2.utils.events INFO: eta: 12:06:19  iter: 147059  total_loss: 0.618  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 21:21:03] d2.utils.events INFO: eta: 12:05:23  iter: 147079  total_loss: 0.870  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.319  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:22:05] d2.utils.events INFO: eta: 12:04:23  iter: 147099  total_loss: 0.600  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0761  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:23:06] d2.utils.events INFO: eta: 12:03:20  iter: 147119  total_loss: 0.710  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0761  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:24:08] d2.utils.events INFO: eta: 12:02:15  iter: 147139  total_loss: 0.671  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0761  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 21:25:08] d2.utils.events INFO: eta: 12:01:13  iter: 147159  total_loss: 0.784  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.000  loss_rpn_loc: 0.010  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:26:10] d2.utils.events INFO: eta: 12:00:14  iter: 147179  total_loss: 0.493  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0760  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 21:27:12] d2.utils.events INFO: eta: 11:59:16  iter: 147199  total_loss: 0.803  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.336  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:28:12] d2.utils.events INFO: eta: 11:58:12  iter: 147219  total_loss: 0.579  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 21:29:13] d2.utils.events INFO: eta: 11:57:10  iter: 147239  total_loss: 0.707  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.346  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:30:16] d2.utils.events INFO: eta: 11:56:09  iter: 147259  total_loss: 0.628  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:31:17] d2.utils.events INFO: eta: 11:55:08  iter: 147279  total_loss: 0.603  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:32:19] d2.utils.events INFO: eta: 11:54:07  iter: 147299  total_loss: 0.613  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:33:20] d2.utils.events INFO: eta: 11:53:05  iter: 147319  total_loss: 0.699  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:34:22] d2.utils.events INFO: eta: 11:52:03  iter: 147339  total_loss: 0.628  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 21:35:23] d2.utils.events INFO: eta: 11:51:03  iter: 147359  total_loss: 0.647  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0019  lr: 0.000100  max_mem: 9402M
[01/06 21:36:26] d2.utils.events INFO: eta: 11:50:04  iter: 147379  total_loss: 0.770  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 21:37:28] d2.utils.events INFO: eta: 11:49:09  iter: 147399  total_loss: 0.648  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0761  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:38:28] d2.utils.events INFO: eta: 11:48:02  iter: 147419  total_loss: 0.712  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:39:30] d2.utils.events INFO: eta: 11:47:01  iter: 147439  total_loss: 0.637  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:40:33] d2.utils.events INFO: eta: 11:46:01  iter: 147459  total_loss: 0.614  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0761  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 21:41:33] d2.utils.events INFO: eta: 11:45:02  iter: 147479  total_loss: 0.516  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 21:42:35] d2.utils.events INFO: eta: 11:44:05  iter: 147499  total_loss: 0.692  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0760  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 21:43:37] d2.utils.events INFO: eta: 11:43:04  iter: 147519  total_loss: 0.527  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0760  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:44:37] d2.utils.events INFO: eta: 11:42:02  iter: 147539  total_loss: 0.763  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:45:38] d2.utils.events INFO: eta: 11:40:59  iter: 147559  total_loss: 0.447  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.185  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:46:38] d2.utils.events INFO: eta: 11:39:55  iter: 147579  total_loss: 0.605  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:47:39] d2.utils.events INFO: eta: 11:38:54  iter: 147599  total_loss: 0.687  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:48:41] d2.utils.events INFO: eta: 11:37:53  iter: 147619  total_loss: 0.725  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:49:41] d2.utils.events INFO: eta: 11:36:52  iter: 147639  total_loss: 0.719  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:50:42] d2.utils.events INFO: eta: 11:35:51  iter: 147659  total_loss: 0.739  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:51:43] d2.utils.events INFO: eta: 11:34:51  iter: 147679  total_loss: 0.699  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:52:44] d2.utils.events INFO: eta: 11:33:50  iter: 147699  total_loss: 0.934  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.239  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.406  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:53:46] d2.utils.events INFO: eta: 11:32:53  iter: 147719  total_loss: 0.569  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:54:47] d2.utils.events INFO: eta: 11:31:49  iter: 147739  total_loss: 0.789  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.355  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:55:51] d2.utils.events INFO: eta: 11:30:50  iter: 147759  total_loss: 0.700  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 21:56:53] d2.utils.events INFO: eta: 11:29:49  iter: 147779  total_loss: 0.806  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.378  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 21:57:55] d2.utils.events INFO: eta: 11:28:51  iter: 147799  total_loss: 0.740  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 21:58:57] d2.utils.events INFO: eta: 11:27:49  iter: 147819  total_loss: 0.831  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 21:59:57] d2.utils.events INFO: eta: 11:26:45  iter: 147839  total_loss: 0.791  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:00:59] d2.utils.events INFO: eta: 11:25:48  iter: 147859  total_loss: 0.637  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:02:01] d2.utils.events INFO: eta: 11:24:48  iter: 147879  total_loss: 0.653  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:03:02] d2.utils.events INFO: eta: 11:23:47  iter: 147899  total_loss: 0.653  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 22:04:04] d2.utils.events INFO: eta: 11:22:50  iter: 147919  total_loss: 0.806  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 22:05:05] d2.utils.events INFO: eta: 11:21:48  iter: 147939  total_loss: 0.727  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:06:05] d2.utils.events INFO: eta: 11:20:45  iter: 147959  total_loss: 0.658  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:07:07] d2.utils.events INFO: eta: 11:19:43  iter: 147979  total_loss: 0.747  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.006  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:08:10] d2.utils.events INFO: eta: 11:18:43  iter: 147999  total_loss: 0.611  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:09:12] d2.utils.events INFO: eta: 11:17:44  iter: 148019  total_loss: 0.632  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:10:12] d2.utils.events INFO: eta: 11:16:41  iter: 148039  total_loss: 0.564  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0756  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 22:11:13] d2.utils.events INFO: eta: 11:15:39  iter: 148059  total_loss: 0.645  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:12:14] d2.utils.events INFO: eta: 11:14:39  iter: 148079  total_loss: 0.689  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:13:15] d2.utils.events INFO: eta: 11:13:37  iter: 148099  total_loss: 0.862  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 22:14:16] d2.utils.events INFO: eta: 11:12:37  iter: 148119  total_loss: 0.766  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:15:16] d2.utils.events INFO: eta: 11:11:34  iter: 148139  total_loss: 0.588  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:16:18] d2.utils.events INFO: eta: 11:10:35  iter: 148159  total_loss: 0.702  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:17:21] d2.utils.events INFO: eta: 11:09:35  iter: 148179  total_loss: 0.626  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:18:23] d2.utils.events INFO: eta: 11:08:34  iter: 148199  total_loss: 0.979  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.267  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.428  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:19:24] d2.utils.events INFO: eta: 11:07:35  iter: 148219  total_loss: 0.538  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.048  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:20:27] d2.utils.events INFO: eta: 11:06:36  iter: 148239  total_loss: 0.929  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.251  loss_cls_stage2: 0.072  loss_box_reg_stage2: 0.340  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:21:28] d2.utils.events INFO: eta: 11:05:35  iter: 148259  total_loss: 0.706  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:22:30] d2.utils.events INFO: eta: 11:04:34  iter: 148279  total_loss: 0.622  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:23:30] d2.utils.events INFO: eta: 11:03:34  iter: 148299  total_loss: 0.524  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 22:24:33] d2.utils.events INFO: eta: 11:02:33  iter: 148319  total_loss: 0.608  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:25:32] d2.utils.events INFO: eta: 11:01:32  iter: 148339  total_loss: 0.687  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:26:33] d2.utils.events INFO: eta: 11:00:28  iter: 148359  total_loss: 0.661  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:27:35] d2.utils.events INFO: eta: 10:59:25  iter: 148379  total_loss: 0.562  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 22:28:35] d2.utils.events INFO: eta: 10:58:24  iter: 148399  total_loss: 0.863  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.105  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0753  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 22:29:37] d2.utils.events INFO: eta: 10:57:26  iter: 148419  total_loss: 0.768  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.356  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 22:30:38] d2.utils.events INFO: eta: 10:56:23  iter: 148439  total_loss: 0.714  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 3.0753  data_time: 0.0019  lr: 0.000100  max_mem: 9402M
[01/06 22:31:39] d2.utils.events INFO: eta: 10:55:21  iter: 148459  total_loss: 0.701  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:32:39] d2.utils.events INFO: eta: 10:54:15  iter: 148479  total_loss: 0.653  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:33:41] d2.utils.events INFO: eta: 10:53:14  iter: 148499  total_loss: 0.680  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:34:42] d2.utils.events INFO: eta: 10:52:12  iter: 148519  total_loss: 0.584  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:35:45] d2.utils.events INFO: eta: 10:51:12  iter: 148539  total_loss: 0.687  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 22:36:46] d2.utils.events INFO: eta: 10:50:12  iter: 148559  total_loss: 0.713  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0030  lr: 0.000100  max_mem: 9402M
[01/06 22:37:49] d2.utils.events INFO: eta: 10:49:16  iter: 148579  total_loss: 0.641  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:38:51] d2.utils.events INFO: eta: 10:48:15  iter: 148599  total_loss: 1.011  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.106  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.274  loss_cls_stage2: 0.074  loss_box_reg_stage2: 0.388  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0753  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:39:52] d2.utils.events INFO: eta: 10:47:13  iter: 148619  total_loss: 0.697  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.006  loss_rpn_loc: 0.013  time: 3.0753  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 22:40:53] d2.utils.events INFO: eta: 10:46:12  iter: 148639  total_loss: 0.735  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0753  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:41:56] d2.utils.events INFO: eta: 10:45:13  iter: 148659  total_loss: 0.834  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.326  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:42:58] d2.utils.events INFO: eta: 10:44:13  iter: 148679  total_loss: 0.805  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.320  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 22:44:00] d2.utils.events INFO: eta: 10:43:15  iter: 148699  total_loss: 0.664  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:45:02] d2.utils.events INFO: eta: 10:42:12  iter: 148719  total_loss: 0.543  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:46:03] d2.utils.events INFO: eta: 10:41:11  iter: 148739  total_loss: 0.505  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:47:05] d2.utils.events INFO: eta: 10:40:08  iter: 148759  total_loss: 0.726  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.204  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:48:07] d2.utils.events INFO: eta: 10:39:07  iter: 148779  total_loss: 0.729  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:49:08] d2.utils.events INFO: eta: 10:38:05  iter: 148799  total_loss: 0.898  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.246  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.371  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 22:50:11] d2.utils.events INFO: eta: 10:37:04  iter: 148819  total_loss: 0.779  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0755  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/06 22:51:12] d2.utils.events INFO: eta: 10:36:05  iter: 148839  total_loss: 0.640  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:52:14] d2.utils.events INFO: eta: 10:35:05  iter: 148859  total_loss: 0.768  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0755  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 22:53:15] d2.utils.events INFO: eta: 10:34:02  iter: 148879  total_loss: 0.563  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.190  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:54:18] d2.utils.events INFO: eta: 10:33:02  iter: 148899  total_loss: 0.598  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0756  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 22:55:19] d2.utils.events INFO: eta: 10:31:58  iter: 148919  total_loss: 0.797  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0755  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:56:21] d2.utils.events INFO: eta: 10:30:58  iter: 148939  total_loss: 0.730  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 22:57:22] d2.utils.events INFO: eta: 10:29:57  iter: 148959  total_loss: 0.633  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 22:58:23] d2.utils.events INFO: eta: 10:28:57  iter: 148979  total_loss: 0.849  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.324  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 22:59:25] d2.utils.events INFO: eta: 10:27:55  iter: 148999  total_loss: 0.736  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 3.0756  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:00:28] d2.utils.events INFO: eta: 10:26:54  iter: 149019  total_loss: 0.497  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.023  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:01:29] d2.utils.events INFO: eta: 10:25:54  iter: 149039  total_loss: 0.696  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.194  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.009  loss_rpn_loc: 0.008  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:02:32] d2.utils.events INFO: eta: 10:24:58  iter: 149059  total_loss: 0.665  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:03:33] d2.utils.events INFO: eta: 10:23:55  iter: 149079  total_loss: 0.697  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:04:35] d2.utils.events INFO: eta: 10:22:55  iter: 149099  total_loss: 0.616  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:05:36] d2.utils.events INFO: eta: 10:21:54  iter: 149119  total_loss: 0.774  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.104  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.226  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:06:38] d2.utils.events INFO: eta: 10:20:55  iter: 149139  total_loss: 0.657  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:07:39] d2.utils.events INFO: eta: 10:19:52  iter: 149159  total_loss: 0.639  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:08:41] d2.utils.events INFO: eta: 10:18:50  iter: 149179  total_loss: 0.697  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 23:09:43] d2.utils.events INFO: eta: 10:17:50  iter: 149199  total_loss: 0.789  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.278  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:10:46] d2.utils.events INFO: eta: 10:16:50  iter: 149219  total_loss: 0.608  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:11:47] d2.utils.events INFO: eta: 10:15:48  iter: 149239  total_loss: 0.854  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.391  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:12:49] d2.utils.events INFO: eta: 10:14:45  iter: 149259  total_loss: 0.678  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:13:50] d2.utils.events INFO: eta: 10:13:46  iter: 149279  total_loss: 0.751  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:14:51] d2.utils.events INFO: eta: 10:12:46  iter: 149299  total_loss: 0.677  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:15:53] d2.utils.events INFO: eta: 10:11:45  iter: 149319  total_loss: 0.550  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:16:54] d2.utils.events INFO: eta: 10:10:44  iter: 149339  total_loss: 0.759  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.288  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:17:55] d2.utils.events INFO: eta: 10:09:45  iter: 149359  total_loss: 0.916  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.338  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:18:56] d2.utils.events INFO: eta: 10:08:42  iter: 149379  total_loss: 0.489  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.172  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 23:19:57] d2.utils.events INFO: eta: 10:07:39  iter: 149399  total_loss: 0.734  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:20:56] d2.utils.events INFO: eta: 10:06:35  iter: 149419  total_loss: 0.487  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0754  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:21:56] d2.utils.events INFO: eta: 10:05:34  iter: 149439  total_loss: 0.753  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.329  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 23:22:58] d2.utils.events INFO: eta: 10:04:34  iter: 149459  total_loss: 0.676  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 23:24:00] d2.utils.events INFO: eta: 10:03:38  iter: 149479  total_loss: 0.813  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:25:00] d2.utils.events INFO: eta: 10:02:36  iter: 149499  total_loss: 0.487  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.195  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0753  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:26:01] d2.utils.events INFO: eta: 10:01:35  iter: 149519  total_loss: 0.599  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:27:03] d2.utils.events INFO: eta: 10:00:34  iter: 149539  total_loss: 0.626  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:28:06] d2.utils.events INFO: eta: 9:59:34  iter: 149559  total_loss: 0.624  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.275  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:29:06] d2.utils.events INFO: eta: 9:58:29  iter: 149579  total_loss: 0.735  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:30:08] d2.utils.events INFO: eta: 9:57:28  iter: 149599  total_loss: 0.698  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:31:08] d2.utils.events INFO: eta: 9:56:31  iter: 149619  total_loss: 0.808  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/06 23:32:09] d2.utils.events INFO: eta: 9:55:30  iter: 149639  total_loss: 0.574  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/06 23:33:10] d2.utils.events INFO: eta: 9:54:25  iter: 149659  total_loss: 0.866  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.350  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:34:11] d2.utils.events INFO: eta: 9:53:23  iter: 149679  total_loss: 0.577  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:35:12] d2.utils.events INFO: eta: 9:52:21  iter: 149699  total_loss: 0.677  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:36:15] d2.utils.events INFO: eta: 9:51:22  iter: 149719  total_loss: 0.805  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:37:18] d2.utils.events INFO: eta: 9:50:25  iter: 149739  total_loss: 0.514  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0753  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:38:20] d2.utils.events INFO: eta: 9:49:25  iter: 149759  total_loss: 0.704  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 23:39:22] d2.utils.events INFO: eta: 9:48:24  iter: 149779  total_loss: 0.660  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.181  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:40:24] d2.utils.events INFO: eta: 9:47:23  iter: 149799  total_loss: 0.771  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:41:27] d2.utils.events INFO: eta: 9:46:23  iter: 149819  total_loss: 0.611  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.003  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:42:29] d2.utils.events INFO: eta: 9:45:22  iter: 149839  total_loss: 0.610  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:43:29] d2.utils.events INFO: eta: 9:44:20  iter: 149859  total_loss: 0.763  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 23:44:31] d2.utils.events INFO: eta: 9:43:17  iter: 149879  total_loss: 0.554  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.153  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:45:32] d2.utils.events INFO: eta: 9:42:14  iter: 149899  total_loss: 0.774  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.349  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:46:34] d2.utils.events INFO: eta: 9:41:17  iter: 149919  total_loss: 0.561  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:47:36] d2.utils.events INFO: eta: 9:40:17  iter: 149939  total_loss: 0.767  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:48:37] d2.utils.events INFO: eta: 9:39:16  iter: 149959  total_loss: 0.490  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.162  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/06 23:49:38] d2.utils.events INFO: eta: 9:38:15  iter: 149979  total_loss: 0.713  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/06 23:50:38] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0149999.pth
[01/06 23:50:44] d2.data.datasets.coco INFO: Loaded 1000 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small_small.json
[01/06 23:50:44] d2.evaluation.evaluator INFO: Start inference on 500 images
[01/06 23:51:47] d2.evaluation.evaluator INFO: Inference done 50/500. 0.4790 s / img. ETA=0:03:35
[01/06 23:52:11] d2.evaluation.evaluator INFO: Inference done 100/500. 0.4791 s / img. ETA=0:03:11
[01/06 23:52:35] d2.evaluation.evaluator INFO: Inference done 150/500. 0.4791 s / img. ETA=0:02:47
[01/06 23:52:59] d2.evaluation.evaluator INFO: Inference done 200/500. 0.4791 s / img. ETA=0:02:23
[01/06 23:53:23] d2.evaluation.evaluator INFO: Inference done 250/500. 0.4792 s / img. ETA=0:01:59
[01/06 23:53:47] d2.evaluation.evaluator INFO: Inference done 300/500. 0.4794 s / img. ETA=0:01:35
[01/06 23:54:11] d2.evaluation.evaluator INFO: Inference done 350/500. 0.4795 s / img. ETA=0:01:11
[01/06 23:54:35] d2.evaluation.evaluator INFO: Inference done 400/500. 0.4795 s / img. ETA=0:00:47
[01/06 23:54:59] d2.evaluation.evaluator INFO: Inference done 450/500. 0.4795 s / img. ETA=0:00:23
[01/06 23:55:23] d2.evaluation.evaluator INFO: Inference done 500/500. 0.4795 s / img. ETA=0:00:00
[01/06 23:55:24] d2.evaluation.evaluator INFO: Total inference time: 0:03:57 (0.478788 s / img per device, on 2 devices)
[01/06 23:55:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:55 (0.476535 s / img per device, on 2 devices)
[01/06 23:55:24] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/06 23:55:24] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small_small.json
[01/06 23:55:24] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/06 23:55:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.462 | 80.597 | 66.781 | 50.190 | 53.308 | 69.422 |
[01/06 23:55:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 65.403 | ASC-US     | 61.481 | HSIL        | 74.534 |
| LSIL       | 70.290 | Candida    | 52.800 | Trichomonas | 26.265 |
[01/06 23:55:27] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small_small in csv format:
[01/06 23:55:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/06 23:55:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/06 23:55:27] d2.evaluation.testing INFO: copypaste: 58.4623,80.5970,66.7815,50.1897,53.3076,69.4216
[01/06 23:55:27] d2.utils.events INFO: eta: 9:37:14  iter: 149999  total_loss: 0.536  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.206  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0753  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/06 23:56:30] d2.utils.events INFO: eta: 9:36:13  iter: 150019  total_loss: 0.625  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:57:32] d2.utils.events INFO: eta: 9:35:13  iter: 150039  total_loss: 0.869  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/06 23:58:32] d2.utils.events INFO: eta: 9:34:05  iter: 150059  total_loss: 0.758  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/06 23:59:34] d2.utils.events INFO: eta: 9:33:06  iter: 150079  total_loss: 0.600  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.201  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0754  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:00:34] d2.utils.events INFO: eta: 9:32:03  iter: 150099  total_loss: 0.602  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0753  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:01:35] d2.utils.events INFO: eta: 9:31:03  iter: 150119  total_loss: 0.762  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:02:37] d2.utils.events INFO: eta: 9:30:02  iter: 150139  total_loss: 0.633  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:03:38] d2.utils.events INFO: eta: 9:29:02  iter: 150159  total_loss: 0.904  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.057  loss_box_reg_stage1: 0.248  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.381  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:04:40] d2.utils.events INFO: eta: 9:28:01  iter: 150179  total_loss: 0.812  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0753  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/07 00:05:41] d2.utils.events INFO: eta: 9:26:59  iter: 150199  total_loss: 0.557  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:06:44] d2.utils.events INFO: eta: 9:25:58  iter: 150219  total_loss: 0.610  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:07:46] d2.utils.events INFO: eta: 9:25:02  iter: 150239  total_loss: 0.573  loss_cls_stage0: 0.025  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:08:47] d2.utils.events INFO: eta: 9:24:01  iter: 150259  total_loss: 0.992  loss_cls_stage0: 0.063  loss_box_reg_stage0: 0.119  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.277  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.373  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0753  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 00:09:47] d2.utils.events INFO: eta: 9:22:54  iter: 150279  total_loss: 0.579  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:10:48] d2.utils.events INFO: eta: 9:21:54  iter: 150299  total_loss: 0.437  loss_cls_stage0: 0.022  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.017  loss_box_reg_stage1: 0.112  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:11:48] d2.utils.events INFO: eta: 9:20:51  iter: 150319  total_loss: 0.645  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:12:49] d2.utils.events INFO: eta: 9:19:53  iter: 150339  total_loss: 0.656  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.291  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:13:50] d2.utils.events INFO: eta: 9:18:52  iter: 150359  total_loss: 0.773  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.348  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0750  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:14:52] d2.utils.events INFO: eta: 9:17:52  iter: 150379  total_loss: 0.582  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:15:54] d2.utils.events INFO: eta: 9:16:55  iter: 150399  total_loss: 0.839  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.337  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:16:57] d2.utils.events INFO: eta: 9:15:57  iter: 150419  total_loss: 0.731  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:17:59] d2.utils.events INFO: eta: 9:14:57  iter: 150439  total_loss: 0.485  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:19:00] d2.utils.events INFO: eta: 9:13:55  iter: 150459  total_loss: 0.749  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:20:01] d2.utils.events INFO: eta: 9:12:54  iter: 150479  total_loss: 0.859  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:21:03] d2.utils.events INFO: eta: 9:11:56  iter: 150499  total_loss: 0.644  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 00:22:04] d2.utils.events INFO: eta: 9:10:56  iter: 150519  total_loss: 0.707  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:23:06] d2.utils.events INFO: eta: 9:09:57  iter: 150539  total_loss: 0.805  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.059  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:24:08] d2.utils.events INFO: eta: 9:08:54  iter: 150559  total_loss: 0.594  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:25:10] d2.utils.events INFO: eta: 9:07:56  iter: 150579  total_loss: 0.704  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:26:10] d2.utils.events INFO: eta: 9:06:52  iter: 150599  total_loss: 0.840  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 00:27:11] d2.utils.events INFO: eta: 9:05:49  iter: 150619  total_loss: 0.520  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.126  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.192  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:28:12] d2.utils.events INFO: eta: 9:04:49  iter: 150639  total_loss: 0.702  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:29:14] d2.utils.events INFO: eta: 9:03:49  iter: 150659  total_loss: 0.768  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:30:15] d2.utils.events INFO: eta: 9:02:48  iter: 150679  total_loss: 0.602  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 00:31:18] d2.utils.events INFO: eta: 9:01:48  iter: 150699  total_loss: 0.810  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.387  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:32:19] d2.utils.events INFO: eta: 9:00:47  iter: 150719  total_loss: 0.743  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:33:22] d2.utils.events INFO: eta: 8:59:45  iter: 150739  total_loss: 0.853  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.351  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:34:22] d2.utils.events INFO: eta: 8:58:41  iter: 150759  total_loss: 0.482  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.186  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:35:23] d2.utils.events INFO: eta: 8:57:38  iter: 150779  total_loss: 0.628  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:36:25] d2.utils.events INFO: eta: 8:56:37  iter: 150799  total_loss: 0.904  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.247  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.377  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:37:28] d2.utils.events INFO: eta: 8:55:35  iter: 150819  total_loss: 0.780  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 3.0752  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 00:38:31] d2.utils.events INFO: eta: 8:54:36  iter: 150839  total_loss: 0.645  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 00:39:33] d2.utils.events INFO: eta: 8:53:37  iter: 150859  total_loss: 0.622  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0753  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:40:35] d2.utils.events INFO: eta: 8:52:38  iter: 150879  total_loss: 0.540  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 00:41:36] d2.utils.events INFO: eta: 8:51:37  iter: 150899  total_loss: 0.837  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.257  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.311  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:42:38] d2.utils.events INFO: eta: 8:50:34  iter: 150919  total_loss: 0.743  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:43:41] d2.utils.events INFO: eta: 8:49:36  iter: 150939  total_loss: 0.741  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 00:44:43] d2.utils.events INFO: eta: 8:48:39  iter: 150959  total_loss: 0.651  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:45:45] d2.utils.events INFO: eta: 8:47:39  iter: 150979  total_loss: 0.753  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.005  loss_rpn_loc: 0.007  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:46:46] d2.utils.events INFO: eta: 8:46:38  iter: 150999  total_loss: 0.714  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 00:47:47] d2.utils.events INFO: eta: 8:45:36  iter: 151019  total_loss: 0.721  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.283  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0754  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:48:49] d2.utils.events INFO: eta: 8:44:34  iter: 151039  total_loss: 0.649  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 00:49:52] d2.utils.events INFO: eta: 8:43:35  iter: 151059  total_loss: 0.608  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:50:53] d2.utils.events INFO: eta: 8:42:34  iter: 151079  total_loss: 0.788  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.005  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:51:55] d2.utils.events INFO: eta: 8:41:34  iter: 151099  total_loss: 0.866  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.238  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.358  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0756  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 00:52:56] d2.utils.events INFO: eta: 8:40:32  iter: 151119  total_loss: 0.759  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:53:59] d2.utils.events INFO: eta: 8:39:32  iter: 151139  total_loss: 0.725  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:55:01] d2.utils.events INFO: eta: 8:38:32  iter: 151159  total_loss: 0.563  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 00:56:05] d2.utils.events INFO: eta: 8:37:30  iter: 151179  total_loss: 0.734  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:57:07] d2.utils.events INFO: eta: 8:36:32  iter: 151199  total_loss: 0.669  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:58:08] d2.utils.events INFO: eta: 8:35:28  iter: 151219  total_loss: 0.808  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 00:59:10] d2.utils.events INFO: eta: 8:34:25  iter: 151239  total_loss: 0.750  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.091  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:00:12] d2.utils.events INFO: eta: 8:33:25  iter: 151259  total_loss: 0.735  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.251  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:01:14] d2.utils.events INFO: eta: 8:32:26  iter: 151279  total_loss: 0.619  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.075  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.078  loss_box_reg_stage2: 0.188  loss_rpn_cls: 0.006  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:02:16] d2.utils.events INFO: eta: 8:31:27  iter: 151299  total_loss: 1.011  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.116  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.264  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.388  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:03:19] d2.utils.events INFO: eta: 8:30:27  iter: 151319  total_loss: 0.798  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.222  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0760  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:04:20] d2.utils.events INFO: eta: 8:29:25  iter: 151339  total_loss: 0.558  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:05:22] d2.utils.events INFO: eta: 8:28:24  iter: 151359  total_loss: 0.741  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:06:23] d2.utils.events INFO: eta: 8:27:21  iter: 151379  total_loss: 0.821  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.212  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:07:25] d2.utils.events INFO: eta: 8:26:19  iter: 151399  total_loss: 0.686  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:08:25] d2.utils.events INFO: eta: 8:25:17  iter: 151419  total_loss: 0.728  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:09:26] d2.utils.events INFO: eta: 8:24:14  iter: 151439  total_loss: 0.533  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:10:27] d2.utils.events INFO: eta: 8:23:13  iter: 151459  total_loss: 0.658  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.268  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:11:28] d2.utils.events INFO: eta: 8:22:11  iter: 151479  total_loss: 0.577  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0758  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/07 01:12:30] d2.utils.events INFO: eta: 8:21:10  iter: 151499  total_loss: 0.777  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:13:30] d2.utils.events INFO: eta: 8:20:07  iter: 151519  total_loss: 0.704  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.205  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/07 01:14:32] d2.utils.events INFO: eta: 8:19:04  iter: 151539  total_loss: 0.798  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.318  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:15:33] d2.utils.events INFO: eta: 8:18:04  iter: 151559  total_loss: 0.789  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.051  loss_box_reg_stage2: 0.297  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:16:35] d2.utils.events INFO: eta: 8:17:05  iter: 151579  total_loss: 0.908  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0757  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/07 01:17:36] d2.utils.events INFO: eta: 8:16:07  iter: 151599  total_loss: 0.585  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:18:37] d2.utils.events INFO: eta: 8:15:06  iter: 151619  total_loss: 0.691  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.049  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:19:40] d2.utils.events INFO: eta: 8:14:05  iter: 151639  total_loss: 0.844  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.354  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:20:41] d2.utils.events INFO: eta: 8:13:04  iter: 151659  total_loss: 0.629  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 01:21:43] d2.utils.events INFO: eta: 8:12:03  iter: 151679  total_loss: 0.601  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.281  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:22:46] d2.utils.events INFO: eta: 8:11:02  iter: 151699  total_loss: 0.785  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.058  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:23:49] d2.utils.events INFO: eta: 8:10:02  iter: 151719  total_loss: 0.642  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:24:51] d2.utils.events INFO: eta: 8:09:00  iter: 151739  total_loss: 0.781  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.335  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 01:25:52] d2.utils.events INFO: eta: 8:08:00  iter: 151759  total_loss: 0.780  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.200  loss_cls_stage2: 0.057  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:26:54] d2.utils.events INFO: eta: 8:07:00  iter: 151779  total_loss: 0.631  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.207  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:27:56] d2.utils.events INFO: eta: 8:06:00  iter: 151799  total_loss: 0.593  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.155  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.214  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/07 01:28:56] d2.utils.events INFO: eta: 8:04:57  iter: 151819  total_loss: 0.567  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.160  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.233  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 01:29:57] d2.utils.events INFO: eta: 8:03:53  iter: 151839  total_loss: 0.723  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:30:58] d2.utils.events INFO: eta: 8:02:53  iter: 151859  total_loss: 0.546  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.110  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.165  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:31:59] d2.utils.events INFO: eta: 8:01:51  iter: 151879  total_loss: 0.566  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 01:33:00] d2.utils.events INFO: eta: 8:00:51  iter: 151899  total_loss: 0.686  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.272  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:34:02] d2.utils.events INFO: eta: 7:59:52  iter: 151919  total_loss: 0.660  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:35:04] d2.utils.events INFO: eta: 7:58:50  iter: 151939  total_loss: 0.554  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.158  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:36:06] d2.utils.events INFO: eta: 7:57:48  iter: 151959  total_loss: 0.633  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:37:07] d2.utils.events INFO: eta: 7:56:47  iter: 151979  total_loss: 0.644  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:38:09] d2.utils.events INFO: eta: 7:55:47  iter: 151999  total_loss: 0.626  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:39:10] d2.utils.events INFO: eta: 7:54:47  iter: 152019  total_loss: 0.611  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:40:10] d2.utils.events INFO: eta: 7:53:44  iter: 152039  total_loss: 0.513  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.238  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 01:41:10] d2.utils.events INFO: eta: 7:52:42  iter: 152059  total_loss: 0.802  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.229  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.359  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 01:42:11] d2.utils.events INFO: eta: 7:51:40  iter: 152079  total_loss: 0.638  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:43:12] d2.utils.events INFO: eta: 7:50:37  iter: 152099  total_loss: 0.563  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:44:13] d2.utils.events INFO: eta: 7:49:36  iter: 152119  total_loss: 0.817  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.207  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 01:45:16] d2.utils.events INFO: eta: 7:48:36  iter: 152139  total_loss: 0.566  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:46:18] d2.utils.events INFO: eta: 7:47:34  iter: 152159  total_loss: 0.547  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.138  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0756  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 01:47:21] d2.utils.events INFO: eta: 7:46:36  iter: 152179  total_loss: 0.733  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.325  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:48:22] d2.utils.events INFO: eta: 7:45:32  iter: 152199  total_loss: 0.786  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.224  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.333  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 01:49:24] d2.utils.events INFO: eta: 7:44:32  iter: 152219  total_loss: 0.653  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:50:27] d2.utils.events INFO: eta: 7:43:32  iter: 152239  total_loss: 0.790  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:51:30] d2.utils.events INFO: eta: 7:42:32  iter: 152259  total_loss: 0.647  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 01:52:32] d2.utils.events INFO: eta: 7:41:31  iter: 152279  total_loss: 0.628  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.285  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 01:53:35] d2.utils.events INFO: eta: 7:40:31  iter: 152299  total_loss: 0.556  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.169  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 01:54:36] d2.utils.events INFO: eta: 7:39:28  iter: 152319  total_loss: 0.645  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.180  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:55:40] d2.utils.events INFO: eta: 7:38:32  iter: 152339  total_loss: 0.696  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.223  loss_rpn_cls: 0.004  loss_rpn_loc: 0.011  time: 3.0761  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 01:56:40] d2.utils.events INFO: eta: 7:37:30  iter: 152359  total_loss: 0.773  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.258  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0019  lr: 0.000100  max_mem: 9402M
[01/07 01:57:42] d2.utils.events INFO: eta: 7:36:31  iter: 152379  total_loss: 0.656  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 01:58:43] d2.utils.events INFO: eta: 7:35:29  iter: 152399  total_loss: 0.685  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 01:59:44] d2.utils.events INFO: eta: 7:34:31  iter: 152419  total_loss: 0.619  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:00:44] d2.utils.events INFO: eta: 7:33:30  iter: 152439  total_loss: 0.629  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:01:46] d2.utils.events INFO: eta: 7:32:29  iter: 152459  total_loss: 0.727  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:02:47] d2.utils.events INFO: eta: 7:31:27  iter: 152479  total_loss: 0.691  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:03:49] d2.utils.events INFO: eta: 7:30:27  iter: 152499  total_loss: 0.639  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:04:51] d2.utils.events INFO: eta: 7:29:30  iter: 152519  total_loss: 0.703  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.089  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0759  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 02:05:52] d2.utils.events INFO: eta: 7:28:28  iter: 152539  total_loss: 0.691  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:06:54] d2.utils.events INFO: eta: 7:27:28  iter: 152559  total_loss: 0.768  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:07:56] d2.utils.events INFO: eta: 7:26:27  iter: 152579  total_loss: 0.577  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:08:59] d2.utils.events INFO: eta: 7:25:27  iter: 152599  total_loss: 0.796  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.237  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0760  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:10:01] d2.utils.events INFO: eta: 7:24:26  iter: 152619  total_loss: 0.658  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0760  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:11:01] d2.utils.events INFO: eta: 7:23:23  iter: 152639  total_loss: 0.644  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:12:03] d2.utils.events INFO: eta: 7:22:24  iter: 152659  total_loss: 0.656  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0759  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 02:13:04] d2.utils.events INFO: eta: 7:21:23  iter: 152679  total_loss: 0.841  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.249  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.368  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 02:14:05] d2.utils.events INFO: eta: 7:20:18  iter: 152699  total_loss: 0.656  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.292  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0759  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:15:06] d2.utils.events INFO: eta: 7:19:15  iter: 152719  total_loss: 0.664  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0759  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 02:16:07] d2.utils.events INFO: eta: 7:18:12  iter: 152739  total_loss: 0.688  loss_cls_stage0: 0.058  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.067  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.066  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:17:07] d2.utils.events INFO: eta: 7:17:12  iter: 152759  total_loss: 0.668  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.241  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0758  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:18:09] d2.utils.events INFO: eta: 7:16:11  iter: 152779  total_loss: 0.682  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0758  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:19:10] d2.utils.events INFO: eta: 7:15:07  iter: 152799  total_loss: 0.838  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.225  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 02:20:12] d2.utils.events INFO: eta: 7:14:09  iter: 152819  total_loss: 0.908  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.364  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0758  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:21:13] d2.utils.events INFO: eta: 7:13:08  iter: 152839  total_loss: 0.614  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0757  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:22:14] d2.utils.events INFO: eta: 7:12:07  iter: 152859  total_loss: 0.544  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0757  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:23:16] d2.utils.events INFO: eta: 7:11:07  iter: 152879  total_loss: 0.651  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.229  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0757  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 02:24:16] d2.utils.events INFO: eta: 7:10:06  iter: 152899  total_loss: 0.692  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:25:17] d2.utils.events INFO: eta: 7:09:02  iter: 152919  total_loss: 0.564  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0756  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 02:26:19] d2.utils.events INFO: eta: 7:08:00  iter: 152939  total_loss: 0.692  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.062  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.239  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 02:27:21] d2.utils.events INFO: eta: 7:06:59  iter: 152959  total_loss: 0.512  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.135  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0757  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:28:22] d2.utils.events INFO: eta: 7:05:57  iter: 152979  total_loss: 0.660  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:29:21] d2.utils.events INFO: eta: 7:04:54  iter: 152999  total_loss: 0.612  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:30:22] d2.utils.events INFO: eta: 7:03:52  iter: 153019  total_loss: 0.594  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.236  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:31:25] d2.utils.events INFO: eta: 7:02:55  iter: 153039  total_loss: 0.677  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 02:32:27] d2.utils.events INFO: eta: 7:01:57  iter: 153059  total_loss: 0.582  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.017  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:33:30] d2.utils.events INFO: eta: 7:00:58  iter: 153079  total_loss: 0.682  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.183  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:34:31] d2.utils.events INFO: eta: 6:59:57  iter: 153099  total_loss: 0.894  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.063  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:35:32] d2.utils.events INFO: eta: 6:58:57  iter: 153119  total_loss: 0.658  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.156  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:36:33] d2.utils.events INFO: eta: 6:57:57  iter: 153139  total_loss: 0.676  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:37:33] d2.utils.events INFO: eta: 6:56:54  iter: 153159  total_loss: 0.802  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.314  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 02:38:34] d2.utils.events INFO: eta: 6:55:52  iter: 153179  total_loss: 0.490  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.124  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.198  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 3.0755  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:39:36] d2.utils.events INFO: eta: 6:54:52  iter: 153199  total_loss: 0.862  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.243  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:40:39] d2.utils.events INFO: eta: 6:53:51  iter: 153219  total_loss: 0.775  loss_cls_stage0: 0.061  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.300  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:41:40] d2.utils.events INFO: eta: 6:52:50  iter: 153239  total_loss: 0.704  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.249  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:42:42] d2.utils.events INFO: eta: 6:51:49  iter: 153259  total_loss: 0.610  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:43:44] d2.utils.events INFO: eta: 6:50:48  iter: 153279  total_loss: 0.778  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:44:46] d2.utils.events INFO: eta: 6:49:47  iter: 153299  total_loss: 0.720  loss_cls_stage0: 0.060  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.197  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:45:47] d2.utils.events INFO: eta: 6:48:45  iter: 153319  total_loss: 0.771  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:46:49] d2.utils.events INFO: eta: 6:47:43  iter: 153339  total_loss: 0.762  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0756  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:47:51] d2.utils.events INFO: eta: 6:46:44  iter: 153359  total_loss: 0.776  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.050  loss_box_reg_stage2: 0.344  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0756  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:48:51] d2.utils.events INFO: eta: 6:45:42  iter: 153379  total_loss: 0.596  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.061  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.008  loss_rpn_loc: 0.011  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:49:52] d2.utils.events INFO: eta: 6:44:41  iter: 153399  total_loss: 0.427  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.022  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.191  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:50:53] d2.utils.events INFO: eta: 6:43:40  iter: 153419  total_loss: 0.683  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.051  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 02:51:54] d2.utils.events INFO: eta: 6:42:39  iter: 153439  total_loss: 0.717  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.284  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:52:55] d2.utils.events INFO: eta: 6:41:39  iter: 153459  total_loss: 0.713  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.352  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 02:53:56] d2.utils.events INFO: eta: 6:40:37  iter: 153479  total_loss: 0.715  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.046  loss_box_reg_stage2: 0.262  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0754  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 02:54:59] d2.utils.events INFO: eta: 6:39:36  iter: 153499  total_loss: 0.672  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.070  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.178  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.259  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:56:01] d2.utils.events INFO: eta: 6:38:33  iter: 153519  total_loss: 0.913  loss_cls_stage0: 0.062  loss_box_reg_stage0: 0.099  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.247  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.392  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 02:57:02] d2.utils.events INFO: eta: 6:37:32  iter: 153539  total_loss: 0.568  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 02:58:04] d2.utils.events INFO: eta: 6:36:31  iter: 153559  total_loss: 0.740  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.041  loss_box_reg_stage2: 0.333  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 02:59:05] d2.utils.events INFO: eta: 6:35:29  iter: 153579  total_loss: 0.666  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 03:00:06] d2.utils.events INFO: eta: 6:34:26  iter: 153599  total_loss: 0.480  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:01:08] d2.utils.events INFO: eta: 6:33:23  iter: 153619  total_loss: 0.754  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:02:11] d2.utils.events INFO: eta: 6:32:27  iter: 153639  total_loss: 0.537  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.231  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 03:03:13] d2.utils.events INFO: eta: 6:31:28  iter: 153659  total_loss: 0.608  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:04:15] d2.utils.events INFO: eta: 6:30:26  iter: 153679  total_loss: 0.800  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.301  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 03:05:17] d2.utils.events INFO: eta: 6:29:26  iter: 153699  total_loss: 0.652  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:06:18] d2.utils.events INFO: eta: 6:28:25  iter: 153719  total_loss: 0.835  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.094  loss_cls_stage1: 0.056  loss_box_reg_stage1: 0.208  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0756  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:07:19] d2.utils.events INFO: eta: 6:27:25  iter: 153739  total_loss: 0.525  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:08:20] d2.utils.events INFO: eta: 6:26:24  iter: 153759  total_loss: 0.623  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.245  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:09:21] d2.utils.events INFO: eta: 6:25:23  iter: 153779  total_loss: 0.426  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.045  loss_cls_stage1: 0.017  loss_box_reg_stage1: 0.108  loss_cls_stage2: 0.019  loss_box_reg_stage2: 0.194  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0755  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 03:10:22] d2.utils.events INFO: eta: 6:24:22  iter: 153799  total_loss: 0.749  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.199  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0755  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:11:24] d2.utils.events INFO: eta: 6:23:21  iter: 153819  total_loss: 0.664  loss_cls_stage0: 0.044  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0755  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 03:12:25] d2.utils.events INFO: eta: 6:22:20  iter: 153839  total_loss: 0.658  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.305  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0755  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 03:13:26] d2.utils.events INFO: eta: 6:21:19  iter: 153859  total_loss: 0.848  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.233  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:14:27] d2.utils.events INFO: eta: 6:20:17  iter: 153879  total_loss: 0.904  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.102  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.269  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.390  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0754  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:15:28] d2.utils.events INFO: eta: 6:19:16  iter: 153899  total_loss: 0.668  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.055  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:16:30] d2.utils.events INFO: eta: 6:18:16  iter: 153919  total_loss: 0.707  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.164  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.244  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0754  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:17:30] d2.utils.events INFO: eta: 6:17:15  iter: 153939  total_loss: 0.552  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.130  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0753  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 03:18:30] d2.utils.events INFO: eta: 6:16:12  iter: 153959  total_loss: 0.541  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.051  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.018  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0752  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 03:19:31] d2.utils.events INFO: eta: 6:15:12  iter: 153979  total_loss: 0.759  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.215  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.317  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:20:32] d2.utils.events INFO: eta: 6:14:12  iter: 153999  total_loss: 0.640  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.182  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.009  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:21:33] d2.utils.events INFO: eta: 6:13:10  iter: 154019  total_loss: 0.770  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.195  loss_cls_stage2: 0.070  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:22:35] d2.utils.events INFO: eta: 6:12:08  iter: 154039  total_loss: 0.516  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:23:37] d2.utils.events INFO: eta: 6:11:06  iter: 154059  total_loss: 0.751  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:24:38] d2.utils.events INFO: eta: 6:10:00  iter: 154079  total_loss: 0.744  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.310  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:25:39] d2.utils.events INFO: eta: 6:08:58  iter: 154099  total_loss: 0.780  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.293  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:26:42] d2.utils.events INFO: eta: 6:07:59  iter: 154119  total_loss: 0.521  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:27:44] d2.utils.events INFO: eta: 6:06:57  iter: 154139  total_loss: 0.786  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.218  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.334  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:28:45] d2.utils.events INFO: eta: 6:05:56  iter: 154159  total_loss: 0.451  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.208  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:29:46] d2.utils.events INFO: eta: 6:04:55  iter: 154179  total_loss: 0.534  loss_cls_stage0: 0.031  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 03:30:47] d2.utils.events INFO: eta: 6:03:53  iter: 154199  total_loss: 0.615  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.150  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:31:49] d2.utils.events INFO: eta: 6:02:53  iter: 154219  total_loss: 0.877  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.227  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.374  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:32:51] d2.utils.events INFO: eta: 6:01:52  iter: 154239  total_loss: 0.751  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 03:33:52] d2.utils.events INFO: eta: 6:00:48  iter: 154259  total_loss: 0.780  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.273  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 03:34:52] d2.utils.events INFO: eta: 5:59:43  iter: 154279  total_loss: 0.810  loss_cls_stage0: 0.049  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.196  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.265  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:35:55] d2.utils.events INFO: eta: 5:58:41  iter: 154299  total_loss: 0.713  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.290  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:36:56] d2.utils.events INFO: eta: 5:57:40  iter: 154319  total_loss: 0.518  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.136  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.232  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:37:58] d2.utils.events INFO: eta: 5:56:37  iter: 154339  total_loss: 0.809  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.236  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:38:59] d2.utils.events INFO: eta: 5:55:32  iter: 154359  total_loss: 0.915  loss_cls_stage0: 0.059  loss_box_reg_stage0: 0.096  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.257  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.345  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:39:58] d2.utils.events INFO: eta: 5:54:31  iter: 154379  total_loss: 0.651  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.322  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 03:41:00] d2.utils.events INFO: eta: 5:53:30  iter: 154399  total_loss: 0.703  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0750  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:42:02] d2.utils.events INFO: eta: 5:52:30  iter: 154419  total_loss: 0.598  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.149  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.220  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:43:04] d2.utils.events INFO: eta: 5:51:31  iter: 154439  total_loss: 0.887  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.117  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.263  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.315  loss_rpn_cls: 0.003  loss_rpn_loc: 0.008  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 03:44:06] d2.utils.events INFO: eta: 5:50:30  iter: 154459  total_loss: 0.613  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.302  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:45:07] d2.utils.events INFO: eta: 5:49:31  iter: 154479  total_loss: 0.707  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.216  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:46:08] d2.utils.events INFO: eta: 5:48:28  iter: 154499  total_loss: 0.605  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.240  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:47:09] d2.utils.events INFO: eta: 5:47:28  iter: 154519  total_loss: 0.771  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 03:48:11] d2.utils.events INFO: eta: 5:46:28  iter: 154539  total_loss: 0.592  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 03:49:12] d2.utils.events INFO: eta: 5:45:27  iter: 154559  total_loss: 0.645  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0750  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:50:14] d2.utils.events INFO: eta: 5:44:24  iter: 154579  total_loss: 0.580  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.065  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.145  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.219  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:51:16] d2.utils.events INFO: eta: 5:43:26  iter: 154599  total_loss: 0.797  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.214  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.010  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 03:52:17] d2.utils.events INFO: eta: 5:42:25  iter: 154619  total_loss: 0.820  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.086  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.220  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.342  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 03:53:19] d2.utils.events INFO: eta: 5:41:24  iter: 154639  total_loss: 0.595  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.143  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 03:54:21] d2.utils.events INFO: eta: 5:40:23  iter: 154659  total_loss: 0.833  loss_cls_stage0: 0.055  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.231  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.353  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:55:22] d2.utils.events INFO: eta: 5:39:22  iter: 154679  total_loss: 0.622  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.162  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.246  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:56:25] d2.utils.events INFO: eta: 5:38:21  iter: 154699  total_loss: 0.650  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.296  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:57:26] d2.utils.events INFO: eta: 5:37:21  iter: 154719  total_loss: 0.717  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.046  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 03:58:26] d2.utils.events INFO: eta: 5:36:20  iter: 154739  total_loss: 0.721  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0750  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/07 03:59:28] d2.utils.events INFO: eta: 5:35:18  iter: 154759  total_loss: 0.697  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0750  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:00:30] d2.utils.events INFO: eta: 5:34:17  iter: 154779  total_loss: 0.691  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.303  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 04:01:30] d2.utils.events INFO: eta: 5:33:17  iter: 154799  total_loss: 0.616  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.029  loss_box_reg_stage2: 0.261  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:02:33] d2.utils.events INFO: eta: 5:32:16  iter: 154819  total_loss: 0.575  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.147  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:03:34] d2.utils.events INFO: eta: 5:31:15  iter: 154839  total_loss: 0.630  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.174  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/07 04:04:36] d2.utils.events INFO: eta: 5:30:14  iter: 154859  total_loss: 0.933  loss_cls_stage0: 0.057  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.249  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.390  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:05:37] d2.utils.events INFO: eta: 5:29:13  iter: 154879  total_loss: 0.656  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.312  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:06:39] d2.utils.events INFO: eta: 5:28:14  iter: 154899  total_loss: 0.841  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.364  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:07:41] d2.utils.events INFO: eta: 5:27:13  iter: 154919  total_loss: 0.455  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.119  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.174  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0751  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 04:08:42] d2.utils.events INFO: eta: 5:26:12  iter: 154939  total_loss: 0.552  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.142  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:09:44] d2.utils.events INFO: eta: 5:25:13  iter: 154959  total_loss: 0.662  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.159  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.266  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 04:10:46] d2.utils.events INFO: eta: 5:24:14  iter: 154979  total_loss: 0.486  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.137  loss_cls_stage2: 0.017  loss_box_reg_stage2: 0.212  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:11:46] fvcore.common.checkpoint INFO: Saving checkpoint to ./outs/out_cascade_mask_rcnn_X_152/model_0154999.pth
[01/07 04:11:51] d2.data.datasets.coco INFO: Loaded 1000 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/val_small_small.json
[01/07 04:11:51] d2.evaluation.evaluator INFO: Start inference on 500 images
[01/07 04:12:54] d2.evaluation.evaluator INFO: Inference done 50/500. 0.4799 s / img. ETA=0:03:35
[01/07 04:13:18] d2.evaluation.evaluator INFO: Inference done 100/500. 0.4799 s / img. ETA=0:03:11
[01/07 04:13:43] d2.evaluation.evaluator INFO: Inference done 150/500. 0.4801 s / img. ETA=0:02:48
[01/07 04:14:07] d2.evaluation.evaluator INFO: Inference done 200/500. 0.4805 s / img. ETA=0:02:24
[01/07 04:14:31] d2.evaluation.evaluator INFO: Inference done 250/500. 0.4805 s / img. ETA=0:02:00
[01/07 04:14:55] d2.evaluation.evaluator INFO: Inference done 300/500. 0.4804 s / img. ETA=0:01:36
[01/07 04:15:19] d2.evaluation.evaluator INFO: Inference done 350/500. 0.4804 s / img. ETA=0:01:12
[01/07 04:15:43] d2.evaluation.evaluator INFO: Inference done 400/500. 0.4803 s / img. ETA=0:00:48
[01/07 04:16:07] d2.evaluation.evaluator INFO: Inference done 450/500. 0.4804 s / img. ETA=0:00:24
[01/07 04:16:31] d2.evaluation.evaluator INFO: Inference done 500/500. 0.4804 s / img. ETA=0:00:00
[01/07 04:16:31] d2.evaluation.evaluator INFO: Total inference time: 0:03:58 (0.480808 s / img per device, on 2 devices)
[01/07 04:16:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:03:56 (0.477291 s / img per device, on 2 devices)
[01/07 04:16:31] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/07 04:16:31] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_val_small_small.json
[01/07 04:16:31] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/07 04:16:34] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.682 | 81.195 | 66.951 | 47.797 | 53.302 | 70.035 |
[01/07 04:16:34] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP     | category   | AP     | category    | AP     |
|:-----------|:-------|:-----------|:-------|:------------|:-------|
| ASC-H      | 64.560 | ASC-US     | 62.883 | HSIL        | 75.547 |
| LSIL       | 70.118 | Candida    | 53.105 | Trichomonas | 25.876 |
[01/07 04:16:34] d2.engine.defaults INFO: Evaluation results for my_dataset_val_small_small in csv format:
[01/07 04:16:34] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/07 04:16:34] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/07 04:16:34] d2.evaluation.testing INFO: copypaste: 58.6815,81.1945,66.9514,47.7974,53.3016,70.0347
[01/07 04:16:34] d2.utils.events INFO: eta: 5:23:12  iter: 154999  total_loss: 0.581  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.151  loss_cls_stage2: 0.020  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.004  loss_rpn_loc: 0.004  time: 3.0750  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:17:35] d2.utils.events INFO: eta: 5:22:12  iter: 155019  total_loss: 0.835  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.306  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:18:36] d2.utils.events INFO: eta: 5:21:11  iter: 155039  total_loss: 0.636  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.260  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:19:38] d2.utils.events INFO: eta: 5:20:10  iter: 155059  total_loss: 0.777  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.088  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.211  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.341  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:20:38] d2.utils.events INFO: eta: 5:19:11  iter: 155079  total_loss: 0.708  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.004  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/07 04:21:40] d2.utils.events INFO: eta: 5:18:10  iter: 155099  total_loss: 0.835  loss_cls_stage0: 0.054  loss_box_reg_stage0: 0.090  loss_cls_stage1: 0.053  loss_box_reg_stage1: 0.206  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0749  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:22:42] d2.utils.events INFO: eta: 5:17:08  iter: 155119  total_loss: 0.566  loss_cls_stage0: 0.026  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.157  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:23:43] d2.utils.events INFO: eta: 5:16:07  iter: 155139  total_loss: 0.634  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.170  loss_cls_stage2: 0.022  loss_box_reg_stage2: 0.277  loss_rpn_cls: 0.004  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:24:44] d2.utils.events INFO: eta: 5:15:07  iter: 155159  total_loss: 0.633  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.040  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:25:46] d2.utils.events INFO: eta: 5:14:07  iter: 155179  total_loss: 0.949  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.112  loss_cls_stage1: 0.042  loss_box_reg_stage1: 0.265  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.371  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 04:26:48] d2.utils.events INFO: eta: 5:13:09  iter: 155199  total_loss: 0.641  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.066  loss_cls_stage1: 0.041  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.052  loss_box_reg_stage2: 0.226  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:27:49] d2.utils.events INFO: eta: 5:12:07  iter: 155219  total_loss: 0.730  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.056  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0749  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:28:52] d2.utils.events INFO: eta: 5:11:07  iter: 155239  total_loss: 0.802  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.093  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.235  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.371  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:29:53] d2.utils.events INFO: eta: 5:10:09  iter: 155259  total_loss: 0.596  loss_cls_stage0: 0.027  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.027  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 3.0750  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/07 04:30:54] d2.utils.events INFO: eta: 5:09:09  iter: 155279  total_loss: 0.803  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.385  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:31:54] d2.utils.events INFO: eta: 5:08:07  iter: 155299  total_loss: 0.604  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.171  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.270  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:32:55] d2.utils.events INFO: eta: 5:07:07  iter: 155319  total_loss: 0.565  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.058  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.237  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0748  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:33:57] d2.utils.events INFO: eta: 5:06:07  iter: 155339  total_loss: 0.799  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.092  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.044  loss_box_reg_stage2: 0.294  loss_rpn_cls: 0.001  loss_rpn_loc: 0.008  time: 3.0749  data_time: 0.0029  lr: 0.000100  max_mem: 9402M
[01/07 04:34:59] d2.utils.events INFO: eta: 5:05:10  iter: 155359  total_loss: 0.827  loss_cls_stage0: 0.047  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.216  loss_cls_stage2: 0.048  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:36:01] d2.utils.events INFO: eta: 5:04:13  iter: 155379  total_loss: 0.769  loss_cls_stage0: 0.042  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.043  loss_box_reg_stage2: 0.323  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:37:03] d2.utils.events INFO: eta: 5:03:12  iter: 155399  total_loss: 0.706  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.176  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.267  loss_rpn_cls: 0.004  loss_rpn_loc: 0.009  time: 3.0749  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:38:05] d2.utils.events INFO: eta: 5:02:10  iter: 155419  total_loss: 0.716  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.193  loss_cls_stage2: 0.045  loss_box_reg_stage2: 0.282  loss_rpn_cls: 0.002  loss_rpn_loc: 0.004  time: 3.0749  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 04:39:05] d2.utils.events INFO: eta: 5:01:07  iter: 155439  total_loss: 0.505  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.024  loss_box_reg_stage2: 0.222  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:40:07] d2.utils.events INFO: eta: 5:00:06  iter: 155459  total_loss: 0.550  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.057  loss_cls_stage1: 0.020  loss_box_reg_stage1: 0.132  loss_cls_stage2: 0.019  loss_box_reg_stage2: 0.247  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 04:41:09] d2.utils.events INFO: eta: 4:59:05  iter: 155479  total_loss: 0.503  loss_cls_stage0: 0.023  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.017  loss_box_reg_stage1: 0.144  loss_cls_stage2: 0.017  loss_box_reg_stage2: 0.234  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0749  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:42:09] d2.utils.events INFO: eta: 4:58:04  iter: 155499  total_loss: 0.610  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.185  loss_cls_stage2: 0.038  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0748  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:43:10] d2.utils.events INFO: eta: 4:57:04  iter: 155519  total_loss: 0.573  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.069  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.165  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0748  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:44:13] d2.utils.events INFO: eta: 4:56:04  iter: 155539  total_loss: 0.687  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.044  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.243  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:45:14] d2.utils.events INFO: eta: 4:55:02  iter: 155559  total_loss: 0.568  loss_cls_stage0: 0.024  loss_box_reg_stage0: 0.068  loss_cls_stage1: 0.017  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.013  loss_box_reg_stage2: 0.230  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0749  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:46:16] d2.utils.events INFO: eta: 4:54:02  iter: 155579  total_loss: 0.813  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.098  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.228  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.356  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 04:47:18] d2.utils.events INFO: eta: 4:53:01  iter: 155599  total_loss: 0.496  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.060  loss_cls_stage1: 0.024  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.019  loss_box_reg_stage2: 0.227  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0749  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:48:20] d2.utils.events INFO: eta: 4:52:00  iter: 155619  total_loss: 0.665  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.172  loss_cls_stage2: 0.053  loss_box_reg_stage2: 0.253  loss_rpn_cls: 0.000  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:49:21] d2.utils.events INFO: eta: 4:50:58  iter: 155639  total_loss: 0.668  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.188  loss_cls_stage2: 0.054  loss_box_reg_stage2: 0.316  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0749  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:50:22] d2.utils.events INFO: eta: 4:49:56  iter: 155659  total_loss: 0.696  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.081  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.175  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0027  lr: 0.000100  max_mem: 9402M
[01/07 04:51:23] d2.utils.events INFO: eta: 4:48:55  iter: 155679  total_loss: 0.699  loss_cls_stage0: 0.037  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.161  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0748  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:52:26] d2.utils.events INFO: eta: 4:47:54  iter: 155699  total_loss: 0.565  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.050  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.139  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.295  loss_rpn_cls: 0.001  loss_rpn_loc: 0.007  time: 3.0749  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:53:27] d2.utils.events INFO: eta: 4:46:53  iter: 155719  total_loss: 0.513  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.064  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.140  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.199  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0749  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 04:54:30] d2.utils.events INFO: eta: 4:45:53  iter: 155739  total_loss: 0.627  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.061  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.152  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.256  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 04:55:32] d2.utils.events INFO: eta: 4:44:54  iter: 155759  total_loss: 0.591  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.146  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0750  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 04:56:35] d2.utils.events INFO: eta: 4:43:53  iter: 155779  total_loss: 0.452  loss_cls_stage0: 0.021  loss_box_reg_stage0: 0.043  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.116  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.189  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 04:57:37] d2.utils.events INFO: eta: 4:42:51  iter: 155799  total_loss: 0.857  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.097  loss_cls_stage1: 0.060  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.060  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.003  loss_rpn_loc: 0.009  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 04:58:39] d2.utils.events INFO: eta: 4:41:50  iter: 155819  total_loss: 0.653  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.063  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.263  loss_rpn_cls: 0.004  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 04:59:40] d2.utils.events INFO: eta: 4:40:49  iter: 155839  total_loss: 0.651  loss_cls_stage0: 0.043  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.040  loss_box_reg_stage1: 0.163  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.269  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:00:43] d2.utils.events INFO: eta: 4:39:50  iter: 155859  total_loss: 0.888  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.241  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.358  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:01:44] d2.utils.events INFO: eta: 4:38:48  iter: 155879  total_loss: 0.697  loss_cls_stage0: 0.039  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.038  loss_box_reg_stage1: 0.191  loss_cls_stage2: 0.037  loss_box_reg_stage2: 0.327  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:02:45] d2.utils.events INFO: eta: 4:37:46  iter: 155899  total_loss: 0.654  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.190  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:03:47] d2.utils.events INFO: eta: 4:36:45  iter: 155919  total_loss: 0.875  loss_cls_stage0: 0.051  loss_box_reg_stage0: 0.100  loss_cls_stage1: 0.048  loss_box_reg_stage1: 0.245  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.331  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:04:47] d2.utils.events INFO: eta: 4:35:44  iter: 155939  total_loss: 0.693  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.186  loss_cls_stage2: 0.039  loss_box_reg_stage2: 0.298  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:05:48] d2.utils.events INFO: eta: 4:34:42  iter: 155959  total_loss: 0.649  loss_cls_stage0: 0.050  loss_box_reg_stage0: 0.084  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.187  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.005  time: 3.0750  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 05:06:50] d2.utils.events INFO: eta: 4:33:41  iter: 155979  total_loss: 0.625  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.257  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 05:07:52] d2.utils.events INFO: eta: 4:32:40  iter: 155999  total_loss: 0.806  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.050  loss_box_reg_stage1: 0.205  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.255  loss_rpn_cls: 0.005  loss_rpn_loc: 0.008  time: 3.0750  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:08:53] d2.utils.events INFO: eta: 4:31:39  iter: 156019  total_loss: 0.640  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.032  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.252  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0750  data_time: 0.0028  lr: 0.000100  max_mem: 9402M
[01/07 05:09:55] d2.utils.events INFO: eta: 4:30:38  iter: 156039  total_loss: 0.517  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.052  loss_cls_stage1: 0.035  loss_box_reg_stage1: 0.123  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.228  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:10:57] d2.utils.events INFO: eta: 4:29:38  iter: 156059  total_loss: 0.667  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.082  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.168  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:11:58] d2.utils.events INFO: eta: 4:28:38  iter: 156079  total_loss: 0.541  loss_cls_stage0: 0.032  loss_box_reg_stage0: 0.056  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.134  loss_cls_stage2: 0.021  loss_box_reg_stage2: 0.242  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:13:01] d2.utils.events INFO: eta: 4:27:38  iter: 156099  total_loss: 0.576  loss_cls_stage0: 0.030  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.167  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.004  loss_rpn_loc: 0.008  time: 3.0751  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 05:14:04] d2.utils.events INFO: eta: 4:26:37  iter: 156119  total_loss: 0.718  loss_cls_stage0: 0.029  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.219  loss_cls_stage2: 0.031  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:15:05] d2.utils.events INFO: eta: 4:25:36  iter: 156139  total_loss: 0.624  loss_cls_stage0: 0.052  loss_box_reg_stage0: 0.071  loss_cls_stage1: 0.045  loss_box_reg_stage1: 0.173  loss_cls_stage2: 0.047  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:16:06] d2.utils.events INFO: eta: 4:24:36  iter: 156159  total_loss: 0.637  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.039  loss_box_reg_stage1: 0.166  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.271  loss_rpn_cls: 0.003  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 05:17:08] d2.utils.events INFO: eta: 4:23:34  iter: 156179  total_loss: 0.690  loss_cls_stage0: 0.048  loss_box_reg_stage0: 0.074  loss_cls_stage1: 0.043  loss_box_reg_stage1: 0.179  loss_cls_stage2: 0.049  loss_box_reg_stage2: 0.224  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 05:18:09] d2.utils.events INFO: eta: 4:22:33  iter: 156199  total_loss: 0.564  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.062  loss_cls_stage1: 0.029  loss_box_reg_stage1: 0.154  loss_cls_stage2: 0.030  loss_box_reg_stage2: 0.248  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:19:11] d2.utils.events INFO: eta: 4:21:32  iter: 156219  total_loss: 0.518  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.054  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.128  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.215  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:20:12] d2.utils.events INFO: eta: 4:20:29  iter: 156239  total_loss: 0.695  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.026  loss_box_reg_stage1: 0.189  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.286  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:21:14] d2.utils.events INFO: eta: 4:19:30  iter: 156259  total_loss: 0.639  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.080  loss_cls_stage1: 0.028  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.308  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:22:15] d2.utils.events INFO: eta: 4:18:29  iter: 156279  total_loss: 0.701  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.091  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.280  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:23:17] d2.utils.events INFO: eta: 4:17:28  iter: 156299  total_loss: 0.728  loss_cls_stage0: 0.040  loss_box_reg_stage0: 0.073  loss_cls_stage1: 0.036  loss_box_reg_stage1: 0.184  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.307  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 05:24:19] d2.utils.events INFO: eta: 4:16:28  iter: 156319  total_loss: 0.651  loss_cls_stage0: 0.034  loss_box_reg_stage0: 0.067  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.169  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:25:20] d2.utils.events INFO: eta: 4:15:27  iter: 156339  total_loss: 0.788  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.103  loss_cls_stage1: 0.055  loss_box_reg_stage1: 0.213  loss_cls_stage2: 0.065  loss_box_reg_stage2: 0.225  loss_rpn_cls: 0.008  loss_rpn_loc: 0.009  time: 3.0752  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 05:26:22] d2.utils.events INFO: eta: 4:14:26  iter: 156359  total_loss: 0.854  loss_cls_stage0: 0.045  loss_box_reg_stage0: 0.087  loss_cls_stage1: 0.037  loss_box_reg_stage1: 0.230  loss_cls_stage2: 0.036  loss_box_reg_stage2: 0.299  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 3.0752  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:27:24] d2.utils.events INFO: eta: 4:13:25  iter: 156379  total_loss: 0.447  loss_cls_stage0: 0.020  loss_box_reg_stage0: 0.049  loss_cls_stage1: 0.017  loss_box_reg_stage1: 0.125  loss_cls_stage2: 0.017  loss_box_reg_stage2: 0.203  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:28:25] d2.utils.events INFO: eta: 4:12:23  iter: 156399  total_loss: 0.737  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.076  loss_cls_stage1: 0.021  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.339  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:29:27] d2.utils.events INFO: eta: 4:11:22  iter: 156419  total_loss: 0.510  loss_cls_stage0: 0.033  loss_box_reg_stage0: 0.053  loss_cls_stage1: 0.025  loss_box_reg_stage1: 0.129  loss_cls_stage2: 0.028  loss_box_reg_stage2: 0.213  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 3.0752  data_time: 0.0021  lr: 0.000100  max_mem: 9402M
[01/07 05:30:29] d2.utils.events INFO: eta: 4:10:22  iter: 156439  total_loss: 0.596  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.059  loss_cls_stage1: 0.030  loss_box_reg_stage1: 0.148  loss_cls_stage2: 0.035  loss_box_reg_stage2: 0.254  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0025  lr: 0.000100  max_mem: 9402M
[01/07 05:31:30] d2.utils.events INFO: eta: 4:09:20  iter: 156459  total_loss: 0.630  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.078  loss_cls_stage1: 0.052  loss_box_reg_stage1: 0.198  loss_cls_stage2: 0.042  loss_box_reg_stage2: 0.211  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0752  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 05:32:30] d2.utils.events INFO: eta: 4:08:19  iter: 156479  total_loss: 0.561  loss_cls_stage0: 0.036  loss_box_reg_stage0: 0.063  loss_cls_stage1: 0.034  loss_box_reg_stage1: 0.141  loss_cls_stage2: 0.033  loss_box_reg_stage2: 0.197  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:33:32] d2.utils.events INFO: eta: 4:07:19  iter: 156499  total_loss: 0.759  loss_cls_stage0: 0.068  loss_box_reg_stage0: 0.095  loss_cls_stage1: 0.071  loss_box_reg_stage1: 0.202  loss_cls_stage2: 0.067  loss_box_reg_stage2: 0.279  loss_rpn_cls: 0.003  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0026  lr: 0.000100  max_mem: 9402M
[01/07 05:34:32] d2.utils.events INFO: eta: 4:06:17  iter: 156519  total_loss: 0.770  loss_cls_stage0: 0.046  loss_box_reg_stage0: 0.085  loss_cls_stage1: 0.047  loss_box_reg_stage1: 0.210  loss_cls_stage2: 0.055  loss_box_reg_stage2: 0.250  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0020  lr: 0.000100  max_mem: 9402M
[01/07 05:35:34] d2.utils.events INFO: eta: 4:05:14  iter: 156539  total_loss: 0.717  loss_cls_stage0: 0.028  loss_box_reg_stage0: 0.072  loss_cls_stage1: 0.033  loss_box_reg_stage1: 0.209  loss_cls_stage2: 0.034  loss_box_reg_stage2: 0.304  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0024  lr: 0.000100  max_mem: 9402M
[01/07 05:36:36] d2.utils.events INFO: eta: 4:04:14  iter: 156559  total_loss: 0.784  loss_cls_stage0: 0.053  loss_box_reg_stage0: 0.083  loss_cls_stage1: 0.059  loss_box_reg_stage1: 0.203  loss_cls_stage2: 0.058  loss_box_reg_stage2: 0.264  loss_rpn_cls: 0.002  loss_rpn_loc: 0.007  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:37:37] d2.utils.events INFO: eta: 4:03:12  iter: 156579  total_loss: 0.725  loss_cls_stage0: 0.038  loss_box_reg_stage0: 0.079  loss_cls_stage1: 0.031  loss_box_reg_stage1: 0.201  loss_cls_stage2: 0.032  loss_box_reg_stage2: 0.289  loss_rpn_cls: 0.002  loss_rpn_loc: 0.005  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:38:39] d2.utils.events INFO: eta: 4:02:11  iter: 156599  total_loss: 0.617  loss_cls_stage0: 0.035  loss_box_reg_stage0: 0.075  loss_cls_stage1: 0.023  loss_box_reg_stage1: 0.177  loss_cls_stage2: 0.026  loss_box_reg_stage2: 0.274  loss_rpn_cls: 0.002  loss_rpn_loc: 0.006  time: 3.0751  data_time: 0.0022  lr: 0.000100  max_mem: 9402M
[01/07 05:39:41] d2.utils.events INFO: eta: 4:01:10  iter: 156619  total_loss: 0.650  loss_cls_stage0: 0.041  loss_box_reg_stage0: 0.077  loss_cls_stage1: 0.027  loss_box_reg_stage1: 0.192  loss_cls_stage2: 0.025  loss_box_reg_stage2: 0.276  loss_rpn_cls: 0.001  loss_rpn_loc: 0.006  time: 3.0752  data_time: 0.0023  lr: 0.000100  max_mem: 9402M
[01/07 05:41:58] detectron2 INFO: Rank of current process: 0. World size: 2
[01/07 05:42:03] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/07 05:42:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/07 05:42:03] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small_small",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test  my_dataset_val_small my_dataset_val_small_small
SOLVER:
  MAX_ITER: 161368  ## 46368 74368(70000 最好) 96368(85000)  116368 138368 161368 
  BASE_LR: 0.01     ### 
  STEPS: (160068, 160268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/07 05:42:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_small_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 161368
  MOMENTUM: 0.9
  STEPS: (160068, 160268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/07 05:42:03] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/07 05:42:03] d2.utils.env INFO: Using a generated random seed 3385043
[01/07 05:42:06] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/07 05:42:06] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0154999.pth
[01/07 05:47:00] d2.data.datasets.coco INFO: Loading /home/admin/jupyter/Demo/DataSets/Data/test.json takes 25.96 seconds.
[01/07 05:47:00] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[01/07 05:47:00] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[01/07 05:47:01] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[01/07 05:47:01] d2.evaluation.evaluator INFO: Start inference on 16850 images
[01/07 05:47:38] detectron2 INFO: Rank of current process: 0. World size: 2
[01/07 05:47:42] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) [GCC 7.2.0]
Numpy                     1.16.0
Detectron2 Compiler       GCC 5.3
Detectron2 CUDA Compiler  10.0
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.3.1+cu100
PyTorch Debug Build       False
torchvision               0.4.2+cu100
CUDA available            True
GPU 0,1                   Tesla P100-PCIE-16GB
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.0, V10.0.130
Pillow                    6.2.1
cv2                       4.1.2
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[01/07 05:47:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml', dist_url='tcp://127.0.0.1:49657', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=[], resume=True)
[01/07 05:47:42] detectron2 INFO: Contents of args.config_file=./configs/gongjing/cascade_mask_rcnn_X_152_FPN.yaml:
_BASE_: "../Base-RCNN-FPN.yaml"
MODEL:
  MASK_ON: False
  WEIGHTS: "catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k"
  RESNETS:
    STRIDE_IN_1X1: False  # this is a C2 model
    NUM_GROUPS: 32
    WIDTH_PER_GROUP: 8
    DEPTH: 152
    DEFORM_ON_PER_STAGE: [False, True, True, True]
  ROI_HEADS:
    NAME: "CascadeROIHeads"
    NUM_CLASSES: 6  #### num_class
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_CONV: 4
    NUM_FC: 1
    NORM: "GN"
    CLS_AGNOSTIC_BBOX_REG: True
  ROI_MASK_HEAD:
    NUM_CONV: 8
    NORM: "GN"
  RPN:
    POST_NMS_TOPK_TRAIN: 2000
INPUT:
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: "range"  ####测试改 输入尺寸，测试数据集，batch大小。
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000 ########## 
  MAX_SIZE_TEST: 1440 
  CROP:
    ENABLED: False
    TYPE: "relative_range"
    SIZE: [0.9, 0.9]
TEST:
  EVAL_PERIOD: 5000
  AUG:
    ENABLED: False   ###  TTA
    MIN_SIZES: (1000,1100,1200 )
    MAX_SIZE: 1440 
    FLIP: True
DATASETS:
  TRAIN: ("my_dataset_train_small_small",)
  TEST: ("my_dataset_test",)  # my_dataset_val_light my_dataset_test  my_dataset_val_small my_dataset_val_small_small
SOLVER:
  MAX_ITER: 161368  ## 46368 74368(70000 最好) 96368(85000)  116368 138368 161368 
  BASE_LR: 0.01     ### 
  STEPS: (160068, 160268)
  CHECKPOINT_PERIOD: 5000  #### save models
  IMS_PER_BATCH: 4      ####batchsize
OUTPUT_DIR: "./outs/out_cascade_mask_rcnn_X_152"
[01/07 05:47:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('my_dataset_test',)
  TRAIN: ('my_dataset_train_small_small',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1440
  MAX_SIZE_TRAIN: 1440
  MIN_SIZE_TEST: 1000
  MIN_SIZE_TRAIN: (1000, 1200)
  MIN_SIZE_TRAIN_SAMPLING: range
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, True, True, True]
    DEPTH: 152
    NORM: FrozenBN
    NUM_GROUPS: 32
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    WIDTH_PER_GROUP: 8
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: True
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: GN
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: CascadeROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: GN
    NUM_CONV: 8
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: catalog://ImageNetPretrained/FAIR/X-152-32x8d-IN5k
OUTPUT_DIR: ./outs/out_cascade_mask_rcnn_X_152
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 161368
  MOMENTUM: 0.9
  STEPS: (160068, 160268)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 1440
    MIN_SIZES: (1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
[01/07 05:47:43] detectron2 INFO: Full config saved to /data/nas/workspace/jupyter/Demo/Models/detectron2_bai/outs/out_cascade_mask_rcnn_X_152/config.yaml
[01/07 05:47:43] d2.utils.env INFO: Using a generated random seed 43071685
[01/07 05:47:46] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2_offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (6): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (7): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (8): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (9): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (10): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (11): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (12): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (13): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (14): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (15): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (16): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (17): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (18): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (19): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (20): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (21): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (22): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (23): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (24): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (25): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (26): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (27): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (28): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (29): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (30): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (31): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (32): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (33): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (34): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (35): DeformBottleneckBlock(
          (conv1): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv2_offset): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=1024, out_channels=1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv3): Conv2d(
            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): DeformBottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): DeformBottleneckBlock(
          (conv1): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv2_offset): Conv2d(2048, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (conv2): DeformConv(
            in_channels=2048, out_channels=2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), groups=32, deformable_groups=1, bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv3): Conv2d(
            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (1): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
      (2): FastRCNNConvFCHead(
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv3): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (conv4): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      )
    )
    (box_predictor): ModuleList(
      (0): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (1): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
      (2): FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=7, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
  )
)
[01/07 05:47:46] fvcore.common.checkpoint INFO: Loading checkpoint from ./outs/out_cascade_mask_rcnn_X_152/model_0154999.pth
[01/07 05:47:47] d2.data.datasets.coco INFO: Loaded 33700 images in COCO format from /home/admin/jupyter/Demo/DataSets/Data/test.json
[01/07 05:47:47] d2.data.datasets.coco WARNING: Filtered out 33700 instances without valid segmentation. There might be issues in your dataset generation process.
[01/07 05:47:48] d2.data.build INFO: Distribution of training instances among all 6 categories:
[36m|  category  | #instances   |  category  | #instances   |  category   | #instances   |
|:----------:|:-------------|:----------:|:-------------|:-----------:|:-------------|
|   ASC-H    | 0            |   ASC-US   | 0            |    HSIL     | 0            |
|    LSIL    | 0            |  Candida   | 0            | Trichomonas | 0            |
|            |              |            |              |             |              |
|   total    | 0            |            |              |             |              |[0m
[01/07 05:47:49] d2.evaluation.evaluator INFO: Start inference on 16850 images
[01/07 05:48:41] d2.evaluation.evaluator INFO: Inference done 50/16850. 0.4803 s / img. ETA=2:14:28
[01/07 05:49:05] d2.evaluation.evaluator INFO: Inference done 100/16850. 0.4814 s / img. ETA=2:14:24
[01/07 05:49:29] d2.evaluation.evaluator INFO: Inference done 150/16850. 0.4816 s / img. ETA=2:14:02
[01/07 05:49:53] d2.evaluation.evaluator INFO: Inference done 200/16850. 0.4814 s / img. ETA=2:13:35
[01/07 05:50:17] d2.evaluation.evaluator INFO: Inference done 250/16850. 0.4812 s / img. ETA=2:13:08
[01/07 05:50:41] d2.evaluation.evaluator INFO: Inference done 300/16850. 0.4815 s / img. ETA=2:12:49
[01/07 05:51:05] d2.evaluation.evaluator INFO: Inference done 350/16850. 0.4819 s / img. ETA=2:12:31
[01/07 05:51:30] d2.evaluation.evaluator INFO: Inference done 400/16850. 0.4822 s / img. ETA=2:12:11
[01/07 05:51:54] d2.evaluation.evaluator INFO: Inference done 450/16850. 0.4825 s / img. ETA=2:11:52
[01/07 05:52:18] d2.evaluation.evaluator INFO: Inference done 500/16850. 0.4825 s / img. ETA=2:11:28
[01/07 05:52:42] d2.evaluation.evaluator INFO: Inference done 550/16850. 0.4826 s / img. ETA=2:11:06
[01/07 05:53:06] d2.evaluation.evaluator INFO: Inference done 600/16850. 0.4827 s / img. ETA=2:10:43
[01/07 05:53:31] d2.evaluation.evaluator INFO: Inference done 650/16850. 0.4827 s / img. ETA=2:10:20
[01/07 05:53:55] d2.evaluation.evaluator INFO: Inference done 700/16850. 0.4828 s / img. ETA=2:09:57
[01/07 05:54:19] d2.evaluation.evaluator INFO: Inference done 750/16850. 0.4829 s / img. ETA=2:09:34
[01/07 05:54:43] d2.evaluation.evaluator INFO: Inference done 800/16850. 0.4828 s / img. ETA=2:09:09
[01/07 05:55:07] d2.evaluation.evaluator INFO: Inference done 850/16850. 0.4828 s / img. ETA=2:08:44
[01/07 05:55:31] d2.evaluation.evaluator INFO: Inference done 900/16850. 0.4827 s / img. ETA=2:08:19
[01/07 05:55:58] d2.evaluation.evaluator INFO: Inference done 950/16850. 0.4850 s / img. ETA=2:08:31
[01/07 05:56:22] d2.evaluation.evaluator INFO: Inference done 1000/16850. 0.4848 s / img. ETA=2:08:03
[01/07 05:56:46] d2.evaluation.evaluator INFO: Inference done 1050/16850. 0.4846 s / img. ETA=2:07:37
[01/07 05:57:10] d2.evaluation.evaluator INFO: Inference done 1100/16850. 0.4846 s / img. ETA=2:07:11
[01/07 05:57:34] d2.evaluation.evaluator INFO: Inference done 1150/16850. 0.4844 s / img. ETA=2:06:45
[01/07 05:57:58] d2.evaluation.evaluator INFO: Inference done 1200/16850. 0.4844 s / img. ETA=2:06:20
[01/07 05:58:22] d2.evaluation.evaluator INFO: Inference done 1250/16850. 0.4843 s / img. ETA=2:05:55
[01/07 05:58:46] d2.evaluation.evaluator INFO: Inference done 1300/16850. 0.4842 s / img. ETA=2:05:30
[01/07 05:59:10] d2.evaluation.evaluator INFO: Inference done 1350/16850. 0.4842 s / img. ETA=2:05:04
[01/07 05:59:35] d2.evaluation.evaluator INFO: Inference done 1400/16850. 0.4841 s / img. ETA=2:04:40
[01/07 05:59:59] d2.evaluation.evaluator INFO: Inference done 1450/16850. 0.4841 s / img. ETA=2:04:14
[01/07 06:00:23] d2.evaluation.evaluator INFO: Inference done 1500/16850. 0.4840 s / img. ETA=2:03:49
[01/07 06:00:47] d2.evaluation.evaluator INFO: Inference done 1550/16850. 0.4840 s / img. ETA=2:03:24
[01/07 06:01:11] d2.evaluation.evaluator INFO: Inference done 1600/16850. 0.4839 s / img. ETA=2:03:00
[01/07 06:01:35] d2.evaluation.evaluator INFO: Inference done 1650/16850. 0.4839 s / img. ETA=2:02:35
[01/07 06:01:59] d2.evaluation.evaluator INFO: Inference done 1700/16850. 0.4839 s / img. ETA=2:02:11
[01/07 06:02:24] d2.evaluation.evaluator INFO: Inference done 1750/16850. 0.4839 s / img. ETA=2:01:46
[01/07 06:02:48] d2.evaluation.evaluator INFO: Inference done 1800/16850. 0.4838 s / img. ETA=2:01:21
[01/07 06:03:12] d2.evaluation.evaluator INFO: Inference done 1850/16850. 0.4838 s / img. ETA=2:00:56
[01/07 06:03:36] d2.evaluation.evaluator INFO: Inference done 1900/16850. 0.4837 s / img. ETA=2:00:31
[01/07 06:04:00] d2.evaluation.evaluator INFO: Inference done 1950/16850. 0.4837 s / img. ETA=2:00:06
[01/07 06:04:24] d2.evaluation.evaluator INFO: Inference done 2000/16850. 0.4836 s / img. ETA=1:59:41
[01/07 06:04:48] d2.evaluation.evaluator INFO: Inference done 2050/16850. 0.4835 s / img. ETA=1:59:16
[01/07 06:05:12] d2.evaluation.evaluator INFO: Inference done 2100/16850. 0.4835 s / img. ETA=1:58:51
[01/07 06:05:36] d2.evaluation.evaluator INFO: Inference done 2150/16850. 0.4835 s / img. ETA=1:58:27
[01/07 06:06:01] d2.evaluation.evaluator INFO: Inference done 2200/16850. 0.4835 s / img. ETA=1:58:03
[01/07 06:06:25] d2.evaluation.evaluator INFO: Inference done 2250/16850. 0.4835 s / img. ETA=1:57:39
[01/07 06:06:49] d2.evaluation.evaluator INFO: Inference done 2300/16850. 0.4836 s / img. ETA=1:57:15
[01/07 06:07:13] d2.evaluation.evaluator INFO: Inference done 2350/16850. 0.4835 s / img. ETA=1:56:51
[01/07 06:07:37] d2.evaluation.evaluator INFO: Inference done 2400/16850. 0.4835 s / img. ETA=1:56:26
[01/07 06:08:01] d2.evaluation.evaluator INFO: Inference done 2450/16850. 0.4834 s / img. ETA=1:56:01
[01/07 06:08:25] d2.evaluation.evaluator INFO: Inference done 2500/16850. 0.4834 s / img. ETA=1:55:36
[01/07 06:08:49] d2.evaluation.evaluator INFO: Inference done 2550/16850. 0.4834 s / img. ETA=1:55:12
[01/07 06:09:14] d2.evaluation.evaluator INFO: Inference done 2600/16850. 0.4834 s / img. ETA=1:54:47
[01/07 06:09:38] d2.evaluation.evaluator INFO: Inference done 2650/16850. 0.4834 s / img. ETA=1:54:23
[01/07 06:10:02] d2.evaluation.evaluator INFO: Inference done 2700/16850. 0.4834 s / img. ETA=1:53:59
[01/07 06:10:26] d2.evaluation.evaluator INFO: Inference done 2750/16850. 0.4833 s / img. ETA=1:53:35
[01/07 06:10:50] d2.evaluation.evaluator INFO: Inference done 2800/16850. 0.4833 s / img. ETA=1:53:10
[01/07 06:11:14] d2.evaluation.evaluator INFO: Inference done 2850/16850. 0.4833 s / img. ETA=1:52:46
[01/07 06:11:38] d2.evaluation.evaluator INFO: Inference done 2900/16850. 0.4833 s / img. ETA=1:52:22
[01/07 06:12:03] d2.evaluation.evaluator INFO: Inference done 2950/16850. 0.4833 s / img. ETA=1:51:57
[01/07 06:12:27] d2.evaluation.evaluator INFO: Inference done 3000/16850. 0.4833 s / img. ETA=1:51:33
[01/07 06:12:51] d2.evaluation.evaluator INFO: Inference done 3050/16850. 0.4833 s / img. ETA=1:51:09
[01/07 06:13:15] d2.evaluation.evaluator INFO: Inference done 3100/16850. 0.4833 s / img. ETA=1:50:45
[01/07 06:13:39] d2.evaluation.evaluator INFO: Inference done 3150/16850. 0.4833 s / img. ETA=1:50:20
[01/07 06:14:03] d2.evaluation.evaluator INFO: Inference done 3200/16850. 0.4833 s / img. ETA=1:49:56
[01/07 06:14:28] d2.evaluation.evaluator INFO: Inference done 3250/16850. 0.4833 s / img. ETA=1:49:33
[01/07 06:14:52] d2.evaluation.evaluator INFO: Inference done 3300/16850. 0.4834 s / img. ETA=1:49:09
[01/07 06:15:16] d2.evaluation.evaluator INFO: Inference done 3350/16850. 0.4834 s / img. ETA=1:48:45
[01/07 06:15:40] d2.evaluation.evaluator INFO: Inference done 3400/16850. 0.4834 s / img. ETA=1:48:21
[01/07 06:16:04] d2.evaluation.evaluator INFO: Inference done 3450/16850. 0.4833 s / img. ETA=1:47:56
[01/07 06:16:28] d2.evaluation.evaluator INFO: Inference done 3500/16850. 0.4833 s / img. ETA=1:47:31
[01/07 06:16:52] d2.evaluation.evaluator INFO: Inference done 3550/16850. 0.4832 s / img. ETA=1:47:06
[01/07 06:17:16] d2.evaluation.evaluator INFO: Inference done 3600/16850. 0.4832 s / img. ETA=1:46:41
[01/07 06:17:40] d2.evaluation.evaluator INFO: Inference done 3650/16850. 0.4831 s / img. ETA=1:46:17
[01/07 06:18:04] d2.evaluation.evaluator INFO: Inference done 3700/16850. 0.4831 s / img. ETA=1:45:52
[01/07 06:18:28] d2.evaluation.evaluator INFO: Inference done 3750/16850. 0.4831 s / img. ETA=1:45:28
[01/07 06:18:53] d2.evaluation.evaluator INFO: Inference done 3800/16850. 0.4831 s / img. ETA=1:45:04
[01/07 06:19:17] d2.evaluation.evaluator INFO: Inference done 3850/16850. 0.4831 s / img. ETA=1:44:39
[01/07 06:19:41] d2.evaluation.evaluator INFO: Inference done 3900/16850. 0.4830 s / img. ETA=1:44:15
[01/07 06:20:05] d2.evaluation.evaluator INFO: Inference done 3950/16850. 0.4830 s / img. ETA=1:43:51
[01/07 06:20:29] d2.evaluation.evaluator INFO: Inference done 4000/16850. 0.4830 s / img. ETA=1:43:27
[01/07 06:20:53] d2.evaluation.evaluator INFO: Inference done 4050/16850. 0.4830 s / img. ETA=1:43:02
[01/07 06:21:17] d2.evaluation.evaluator INFO: Inference done 4100/16850. 0.4831 s / img. ETA=1:42:39
[01/07 06:21:42] d2.evaluation.evaluator INFO: Inference done 4150/16850. 0.4831 s / img. ETA=1:42:15
[01/07 06:22:06] d2.evaluation.evaluator INFO: Inference done 4200/16850. 0.4832 s / img. ETA=1:41:52
[01/07 06:22:30] d2.evaluation.evaluator INFO: Inference done 4250/16850. 0.4831 s / img. ETA=1:41:27
[01/07 06:22:54] d2.evaluation.evaluator INFO: Inference done 4300/16850. 0.4831 s / img. ETA=1:41:03
[01/07 06:23:18] d2.evaluation.evaluator INFO: Inference done 4350/16850. 0.4831 s / img. ETA=1:40:38
[01/07 06:23:42] d2.evaluation.evaluator INFO: Inference done 4400/16850. 0.4831 s / img. ETA=1:40:14
[01/07 06:24:07] d2.evaluation.evaluator INFO: Inference done 4450/16850. 0.4831 s / img. ETA=1:39:50
[01/07 06:24:31] d2.evaluation.evaluator INFO: Inference done 4500/16850. 0.4831 s / img. ETA=1:39:25
[01/07 06:24:55] d2.evaluation.evaluator INFO: Inference done 4550/16850. 0.4830 s / img. ETA=1:39:01
[01/07 06:25:19] d2.evaluation.evaluator INFO: Inference done 4600/16850. 0.4830 s / img. ETA=1:38:37
[01/07 06:25:43] d2.evaluation.evaluator INFO: Inference done 4650/16850. 0.4830 s / img. ETA=1:38:12
[01/07 06:26:07] d2.evaluation.evaluator INFO: Inference done 4700/16850. 0.4830 s / img. ETA=1:37:48
[01/07 06:26:31] d2.evaluation.evaluator INFO: Inference done 4750/16850. 0.4830 s / img. ETA=1:37:24
[01/07 06:26:55] d2.evaluation.evaluator INFO: Inference done 4800/16850. 0.4830 s / img. ETA=1:37:00
[01/07 06:27:19] d2.evaluation.evaluator INFO: Inference done 4850/16850. 0.4830 s / img. ETA=1:36:36
[01/07 06:27:44] d2.evaluation.evaluator INFO: Inference done 4900/16850. 0.4830 s / img. ETA=1:36:12
[01/07 06:28:08] d2.evaluation.evaluator INFO: Inference done 4950/16850. 0.4830 s / img. ETA=1:35:47
[01/07 06:28:32] d2.evaluation.evaluator INFO: Inference done 5000/16850. 0.4830 s / img. ETA=1:35:23
[01/07 06:28:56] d2.evaluation.evaluator INFO: Inference done 5050/16850. 0.4830 s / img. ETA=1:34:59
[01/07 06:29:20] d2.evaluation.evaluator INFO: Inference done 5100/16850. 0.4830 s / img. ETA=1:34:34
[01/07 06:29:44] d2.evaluation.evaluator INFO: Inference done 5150/16850. 0.4830 s / img. ETA=1:34:10
[01/07 06:30:08] d2.evaluation.evaluator INFO: Inference done 5200/16850. 0.4830 s / img. ETA=1:33:46
[01/07 06:30:32] d2.evaluation.evaluator INFO: Inference done 5250/16850. 0.4829 s / img. ETA=1:33:22
[01/07 06:30:56] d2.evaluation.evaluator INFO: Inference done 5300/16850. 0.4829 s / img. ETA=1:32:57
[01/07 06:31:20] d2.evaluation.evaluator INFO: Inference done 5350/16850. 0.4829 s / img. ETA=1:32:33
[01/07 06:31:44] d2.evaluation.evaluator INFO: Inference done 5400/16850. 0.4829 s / img. ETA=1:32:09
[01/07 06:32:08] d2.evaluation.evaluator INFO: Inference done 5450/16850. 0.4829 s / img. ETA=1:31:44
[01/07 06:32:33] d2.evaluation.evaluator INFO: Inference done 5500/16850. 0.4829 s / img. ETA=1:31:20
[01/07 06:32:57] d2.evaluation.evaluator INFO: Inference done 5550/16850. 0.4828 s / img. ETA=1:30:56
[01/07 06:33:21] d2.evaluation.evaluator INFO: Inference done 5600/16850. 0.4828 s / img. ETA=1:30:31
[01/07 06:33:45] d2.evaluation.evaluator INFO: Inference done 5650/16850. 0.4828 s / img. ETA=1:30:07
[01/07 06:34:09] d2.evaluation.evaluator INFO: Inference done 5700/16850. 0.4828 s / img. ETA=1:29:43
[01/07 06:34:33] d2.evaluation.evaluator INFO: Inference done 5750/16850. 0.4828 s / img. ETA=1:29:18
[01/07 06:34:57] d2.evaluation.evaluator INFO: Inference done 5800/16850. 0.4828 s / img. ETA=1:28:54
[01/07 06:35:21] d2.evaluation.evaluator INFO: Inference done 5850/16850. 0.4828 s / img. ETA=1:28:30
[01/07 06:35:45] d2.evaluation.evaluator INFO: Inference done 5900/16850. 0.4828 s / img. ETA=1:28:06
[01/07 06:36:09] d2.evaluation.evaluator INFO: Inference done 5950/16850. 0.4828 s / img. ETA=1:27:42
[01/07 06:36:33] d2.evaluation.evaluator INFO: Inference done 6000/16850. 0.4827 s / img. ETA=1:27:17
[01/07 06:36:57] d2.evaluation.evaluator INFO: Inference done 6050/16850. 0.4827 s / img. ETA=1:26:53
[01/07 06:37:21] d2.evaluation.evaluator INFO: Inference done 6100/16850. 0.4827 s / img. ETA=1:26:28
[01/07 06:37:45] d2.evaluation.evaluator INFO: Inference done 6150/16850. 0.4827 s / img. ETA=1:26:04
[01/07 06:38:09] d2.evaluation.evaluator INFO: Inference done 6200/16850. 0.4827 s / img. ETA=1:25:40
[01/07 06:38:33] d2.evaluation.evaluator INFO: Inference done 6250/16850. 0.4827 s / img. ETA=1:25:16
[01/07 06:38:57] d2.evaluation.evaluator INFO: Inference done 6300/16850. 0.4826 s / img. ETA=1:24:51
[01/07 06:39:21] d2.evaluation.evaluator INFO: Inference done 6350/16850. 0.4826 s / img. ETA=1:24:27
[01/07 06:39:45] d2.evaluation.evaluator INFO: Inference done 6400/16850. 0.4826 s / img. ETA=1:24:03
[01/07 06:40:09] d2.evaluation.evaluator INFO: Inference done 6450/16850. 0.4826 s / img. ETA=1:23:38
[01/07 06:40:34] d2.evaluation.evaluator INFO: Inference done 6500/16850. 0.4826 s / img. ETA=1:23:14
[01/07 06:40:58] d2.evaluation.evaluator INFO: Inference done 6550/16850. 0.4826 s / img. ETA=1:22:50
[01/07 06:41:22] d2.evaluation.evaluator INFO: Inference done 6600/16850. 0.4826 s / img. ETA=1:22:26
[01/07 06:41:46] d2.evaluation.evaluator INFO: Inference done 6650/16850. 0.4826 s / img. ETA=1:22:02
[01/07 06:42:10] d2.evaluation.evaluator INFO: Inference done 6700/16850. 0.4826 s / img. ETA=1:21:38
[01/07 06:42:34] d2.evaluation.evaluator INFO: Inference done 6750/16850. 0.4826 s / img. ETA=1:21:14
[01/07 06:42:58] d2.evaluation.evaluator INFO: Inference done 6800/16850. 0.4826 s / img. ETA=1:20:49
[01/07 06:43:22] d2.evaluation.evaluator INFO: Inference done 6850/16850. 0.4826 s / img. ETA=1:20:25
[01/07 06:43:47] d2.evaluation.evaluator INFO: Inference done 6900/16850. 0.4826 s / img. ETA=1:20:01
[01/07 06:44:11] d2.evaluation.evaluator INFO: Inference done 6950/16850. 0.4826 s / img. ETA=1:19:37
[01/07 06:44:35] d2.evaluation.evaluator INFO: Inference done 7000/16850. 0.4826 s / img. ETA=1:19:13
[01/07 06:44:59] d2.evaluation.evaluator INFO: Inference done 7050/16850. 0.4825 s / img. ETA=1:18:48
[01/07 06:45:23] d2.evaluation.evaluator INFO: Inference done 7100/16850. 0.4825 s / img. ETA=1:18:24
[01/07 06:45:47] d2.evaluation.evaluator INFO: Inference done 7150/16850. 0.4825 s / img. ETA=1:18:00
[01/07 06:46:11] d2.evaluation.evaluator INFO: Inference done 7200/16850. 0.4825 s / img. ETA=1:17:36
[01/07 06:46:35] d2.evaluation.evaluator INFO: Inference done 7250/16850. 0.4825 s / img. ETA=1:17:12
[01/07 06:46:59] d2.evaluation.evaluator INFO: Inference done 7300/16850. 0.4825 s / img. ETA=1:16:48
[01/07 06:47:23] d2.evaluation.evaluator INFO: Inference done 7350/16850. 0.4825 s / img. ETA=1:16:23
[01/07 06:47:47] d2.evaluation.evaluator INFO: Inference done 7400/16850. 0.4825 s / img. ETA=1:15:59
[01/07 06:48:11] d2.evaluation.evaluator INFO: Inference done 7450/16850. 0.4825 s / img. ETA=1:15:35
[01/07 06:48:35] d2.evaluation.evaluator INFO: Inference done 7500/16850. 0.4825 s / img. ETA=1:15:11
[01/07 06:49:00] d2.evaluation.evaluator INFO: Inference done 7550/16850. 0.4825 s / img. ETA=1:14:47
[01/07 06:49:24] d2.evaluation.evaluator INFO: Inference done 7600/16850. 0.4825 s / img. ETA=1:14:23
[01/07 06:49:48] d2.evaluation.evaluator INFO: Inference done 7650/16850. 0.4825 s / img. ETA=1:13:58
[01/07 06:50:12] d2.evaluation.evaluator INFO: Inference done 7700/16850. 0.4825 s / img. ETA=1:13:34
[01/07 06:50:36] d2.evaluation.evaluator INFO: Inference done 7750/16850. 0.4824 s / img. ETA=1:13:10
[01/07 06:51:00] d2.evaluation.evaluator INFO: Inference done 7800/16850. 0.4824 s / img. ETA=1:12:46
[01/07 06:51:24] d2.evaluation.evaluator INFO: Inference done 7850/16850. 0.4824 s / img. ETA=1:12:21
[01/07 06:51:48] d2.evaluation.evaluator INFO: Inference done 7900/16850. 0.4824 s / img. ETA=1:11:57
[01/07 06:52:12] d2.evaluation.evaluator INFO: Inference done 7950/16850. 0.4825 s / img. ETA=1:11:33
[01/07 06:52:36] d2.evaluation.evaluator INFO: Inference done 8000/16850. 0.4824 s / img. ETA=1:11:09
[01/07 06:53:00] d2.evaluation.evaluator INFO: Inference done 8050/16850. 0.4824 s / img. ETA=1:10:45
[01/07 06:53:24] d2.evaluation.evaluator INFO: Inference done 8100/16850. 0.4824 s / img. ETA=1:10:21
[01/07 06:53:48] d2.evaluation.evaluator INFO: Inference done 8150/16850. 0.4824 s / img. ETA=1:09:56
[01/07 06:54:12] d2.evaluation.evaluator INFO: Inference done 8200/16850. 0.4824 s / img. ETA=1:09:32
[01/07 06:54:36] d2.evaluation.evaluator INFO: Inference done 8250/16850. 0.4824 s / img. ETA=1:09:08
[01/07 06:55:00] d2.evaluation.evaluator INFO: Inference done 8300/16850. 0.4824 s / img. ETA=1:08:44
[01/07 06:55:24] d2.evaluation.evaluator INFO: Inference done 8350/16850. 0.4824 s / img. ETA=1:08:20
[01/07 06:55:50] d2.evaluation.evaluator INFO: Inference done 8400/16850. 0.4825 s / img. ETA=1:07:57
[01/07 06:56:14] d2.evaluation.evaluator INFO: Inference done 8450/16850. 0.4825 s / img. ETA=1:07:33
[01/07 06:56:38] d2.evaluation.evaluator INFO: Inference done 8500/16850. 0.4825 s / img. ETA=1:07:08
[01/07 06:57:02] d2.evaluation.evaluator INFO: Inference done 8550/16850. 0.4825 s / img. ETA=1:06:44
[01/07 06:57:26] d2.evaluation.evaluator INFO: Inference done 8600/16850. 0.4825 s / img. ETA=1:06:20
[01/07 06:57:50] d2.evaluation.evaluator INFO: Inference done 8650/16850. 0.4825 s / img. ETA=1:05:56
[01/07 06:58:14] d2.evaluation.evaluator INFO: Inference done 8700/16850. 0.4825 s / img. ETA=1:05:32
[01/07 06:58:38] d2.evaluation.evaluator INFO: Inference done 8750/16850. 0.4825 s / img. ETA=1:05:07
[01/07 06:59:02] d2.evaluation.evaluator INFO: Inference done 8800/16850. 0.4825 s / img. ETA=1:04:43
[01/07 06:59:26] d2.evaluation.evaluator INFO: Inference done 8850/16850. 0.4824 s / img. ETA=1:04:19
[01/07 06:59:50] d2.evaluation.evaluator INFO: Inference done 8900/16850. 0.4824 s / img. ETA=1:03:55
[01/07 07:00:15] d2.evaluation.evaluator INFO: Inference done 8950/16850. 0.4824 s / img. ETA=1:03:31
[01/07 07:00:39] d2.evaluation.evaluator INFO: Inference done 9000/16850. 0.4824 s / img. ETA=1:03:07
[01/07 07:01:03] d2.evaluation.evaluator INFO: Inference done 9050/16850. 0.4824 s / img. ETA=1:02:43
[01/07 07:01:27] d2.evaluation.evaluator INFO: Inference done 9100/16850. 0.4824 s / img. ETA=1:02:18
[01/07 07:01:51] d2.evaluation.evaluator INFO: Inference done 9150/16850. 0.4824 s / img. ETA=1:01:54
[01/07 07:02:15] d2.evaluation.evaluator INFO: Inference done 9200/16850. 0.4824 s / img. ETA=1:01:30
[01/07 07:02:39] d2.evaluation.evaluator INFO: Inference done 9250/16850. 0.4824 s / img. ETA=1:01:06
[01/07 07:03:03] d2.evaluation.evaluator INFO: Inference done 9300/16850. 0.4824 s / img. ETA=1:00:42
[01/07 07:03:27] d2.evaluation.evaluator INFO: Inference done 9350/16850. 0.4824 s / img. ETA=1:00:17
[01/07 07:03:51] d2.evaluation.evaluator INFO: Inference done 9400/16850. 0.4824 s / img. ETA=0:59:53
[01/07 07:04:15] d2.evaluation.evaluator INFO: Inference done 9450/16850. 0.4824 s / img. ETA=0:59:29
[01/07 07:04:39] d2.evaluation.evaluator INFO: Inference done 9500/16850. 0.4824 s / img. ETA=0:59:05
[01/07 07:05:04] d2.evaluation.evaluator INFO: Inference done 9550/16850. 0.4824 s / img. ETA=0:58:41
[01/07 07:05:28] d2.evaluation.evaluator INFO: Inference done 9600/16850. 0.4824 s / img. ETA=0:58:17
[01/07 07:05:52] d2.evaluation.evaluator INFO: Inference done 9650/16850. 0.4824 s / img. ETA=0:57:53
[01/07 07:06:16] d2.evaluation.evaluator INFO: Inference done 9700/16850. 0.4824 s / img. ETA=0:57:29
[01/07 07:06:40] d2.evaluation.evaluator INFO: Inference done 9750/16850. 0.4824 s / img. ETA=0:57:04
[01/07 07:07:04] d2.evaluation.evaluator INFO: Inference done 9800/16850. 0.4824 s / img. ETA=0:56:40
[01/07 07:07:28] d2.evaluation.evaluator INFO: Inference done 9850/16850. 0.4823 s / img. ETA=0:56:16
[01/07 07:07:52] d2.evaluation.evaluator INFO: Inference done 9900/16850. 0.4824 s / img. ETA=0:55:52
[01/07 07:08:16] d2.evaluation.evaluator INFO: Inference done 9950/16850. 0.4824 s / img. ETA=0:55:28
[01/07 07:08:40] d2.evaluation.evaluator INFO: Inference done 10000/16850. 0.4824 s / img. ETA=0:55:04
[01/07 07:09:04] d2.evaluation.evaluator INFO: Inference done 10050/16850. 0.4824 s / img. ETA=0:54:39
[01/07 07:09:28] d2.evaluation.evaluator INFO: Inference done 10100/16850. 0.4823 s / img. ETA=0:54:15
[01/07 07:09:53] d2.evaluation.evaluator INFO: Inference done 10150/16850. 0.4823 s / img. ETA=0:53:51
[01/07 07:10:17] d2.evaluation.evaluator INFO: Inference done 10200/16850. 0.4823 s / img. ETA=0:53:27
[01/07 07:10:41] d2.evaluation.evaluator INFO: Inference done 10250/16850. 0.4823 s / img. ETA=0:53:03
[01/07 07:11:05] d2.evaluation.evaluator INFO: Inference done 10300/16850. 0.4823 s / img. ETA=0:52:39
[01/07 07:11:29] d2.evaluation.evaluator INFO: Inference done 10350/16850. 0.4823 s / img. ETA=0:52:14
[01/07 07:11:53] d2.evaluation.evaluator INFO: Inference done 10400/16850. 0.4823 s / img. ETA=0:51:50
[01/07 07:12:17] d2.evaluation.evaluator INFO: Inference done 10450/16850. 0.4823 s / img. ETA=0:51:26
[01/07 07:12:41] d2.evaluation.evaluator INFO: Inference done 10500/16850. 0.4823 s / img. ETA=0:51:02
[01/07 07:13:05] d2.evaluation.evaluator INFO: Inference done 10550/16850. 0.4823 s / img. ETA=0:50:38
[01/07 07:13:29] d2.evaluation.evaluator INFO: Inference done 10600/16850. 0.4823 s / img. ETA=0:50:14
[01/07 07:13:53] d2.evaluation.evaluator INFO: Inference done 10650/16850. 0.4823 s / img. ETA=0:49:50
[01/07 07:14:18] d2.evaluation.evaluator INFO: Inference done 10700/16850. 0.4823 s / img. ETA=0:49:26
[01/07 07:14:42] d2.evaluation.evaluator INFO: Inference done 10750/16850. 0.4823 s / img. ETA=0:49:02
[01/07 07:15:06] d2.evaluation.evaluator INFO: Inference done 10800/16850. 0.4823 s / img. ETA=0:48:37
[01/07 07:15:30] d2.evaluation.evaluator INFO: Inference done 10850/16850. 0.4823 s / img. ETA=0:48:13
[01/07 07:15:54] d2.evaluation.evaluator INFO: Inference done 10900/16850. 0.4823 s / img. ETA=0:47:49
[01/07 07:16:18] d2.evaluation.evaluator INFO: Inference done 10950/16850. 0.4823 s / img. ETA=0:47:25
[01/07 07:16:42] d2.evaluation.evaluator INFO: Inference done 11000/16850. 0.4823 s / img. ETA=0:47:01
[01/07 07:17:06] d2.evaluation.evaluator INFO: Inference done 11050/16850. 0.4823 s / img. ETA=0:46:37
[01/07 07:17:30] d2.evaluation.evaluator INFO: Inference done 11100/16850. 0.4823 s / img. ETA=0:46:13
[01/07 07:17:54] d2.evaluation.evaluator INFO: Inference done 11150/16850. 0.4823 s / img. ETA=0:45:48
[01/07 07:18:18] d2.evaluation.evaluator INFO: Inference done 11200/16850. 0.4823 s / img. ETA=0:45:24
[01/07 07:18:42] d2.evaluation.evaluator INFO: Inference done 11250/16850. 0.4823 s / img. ETA=0:45:00
[01/07 07:19:06] d2.evaluation.evaluator INFO: Inference done 11300/16850. 0.4823 s / img. ETA=0:44:36
[01/07 07:19:31] d2.evaluation.evaluator INFO: Inference done 11350/16850. 0.4823 s / img. ETA=0:44:12
[01/07 07:19:55] d2.evaluation.evaluator INFO: Inference done 11400/16850. 0.4823 s / img. ETA=0:43:48
[01/07 07:20:19] d2.evaluation.evaluator INFO: Inference done 11450/16850. 0.4822 s / img. ETA=0:43:24
[01/07 07:20:43] d2.evaluation.evaluator INFO: Inference done 11500/16850. 0.4822 s / img. ETA=0:42:59
[01/07 07:21:07] d2.evaluation.evaluator INFO: Inference done 11550/16850. 0.4822 s / img. ETA=0:42:35
[01/07 07:21:31] d2.evaluation.evaluator INFO: Inference done 11600/16850. 0.4822 s / img. ETA=0:42:11
[01/07 07:21:55] d2.evaluation.evaluator INFO: Inference done 11650/16850. 0.4822 s / img. ETA=0:41:47
[01/07 07:22:19] d2.evaluation.evaluator INFO: Inference done 11700/16850. 0.4822 s / img. ETA=0:41:23
[01/07 07:22:43] d2.evaluation.evaluator INFO: Inference done 11750/16850. 0.4822 s / img. ETA=0:40:59
[01/07 07:23:07] d2.evaluation.evaluator INFO: Inference done 11800/16850. 0.4822 s / img. ETA=0:40:35
[01/07 07:23:31] d2.evaluation.evaluator INFO: Inference done 11850/16850. 0.4822 s / img. ETA=0:40:11
[01/07 07:23:55] d2.evaluation.evaluator INFO: Inference done 11900/16850. 0.4822 s / img. ETA=0:39:46
[01/07 07:24:19] d2.evaluation.evaluator INFO: Inference done 11950/16850. 0.4822 s / img. ETA=0:39:22
[01/07 07:24:43] d2.evaluation.evaluator INFO: Inference done 12000/16850. 0.4822 s / img. ETA=0:38:58
[01/07 07:25:07] d2.evaluation.evaluator INFO: Inference done 12050/16850. 0.4822 s / img. ETA=0:38:34
[01/07 07:25:31] d2.evaluation.evaluator INFO: Inference done 12100/16850. 0.4822 s / img. ETA=0:38:10
[01/07 07:25:55] d2.evaluation.evaluator INFO: Inference done 12150/16850. 0.4822 s / img. ETA=0:37:46
[01/07 07:26:20] d2.evaluation.evaluator INFO: Inference done 12200/16850. 0.4822 s / img. ETA=0:37:22
[01/07 07:26:44] d2.evaluation.evaluator INFO: Inference done 12250/16850. 0.4822 s / img. ETA=0:36:58
[01/07 07:27:08] d2.evaluation.evaluator INFO: Inference done 12300/16850. 0.4822 s / img. ETA=0:36:33
[01/07 07:27:31] d2.evaluation.evaluator INFO: Inference done 12350/16850. 0.4822 s / img. ETA=0:36:09
[01/07 07:27:55] d2.evaluation.evaluator INFO: Inference done 12400/16850. 0.4822 s / img. ETA=0:35:45
[01/07 07:28:20] d2.evaluation.evaluator INFO: Inference done 12450/16850. 0.4821 s / img. ETA=0:35:21
[01/07 07:28:44] d2.evaluation.evaluator INFO: Inference done 12500/16850. 0.4821 s / img. ETA=0:34:57
[01/07 07:29:08] d2.evaluation.evaluator INFO: Inference done 12550/16850. 0.4821 s / img. ETA=0:34:33
[01/07 07:29:32] d2.evaluation.evaluator INFO: Inference done 12600/16850. 0.4821 s / img. ETA=0:34:09
[01/07 07:29:56] d2.evaluation.evaluator INFO: Inference done 12650/16850. 0.4821 s / img. ETA=0:33:44
[01/07 07:30:20] d2.evaluation.evaluator INFO: Inference done 12700/16850. 0.4821 s / img. ETA=0:33:20
[01/07 07:30:44] d2.evaluation.evaluator INFO: Inference done 12750/16850. 0.4821 s / img. ETA=0:32:56
[01/07 07:31:08] d2.evaluation.evaluator INFO: Inference done 12800/16850. 0.4821 s / img. ETA=0:32:32
[01/07 07:31:32] d2.evaluation.evaluator INFO: Inference done 12850/16850. 0.4821 s / img. ETA=0:32:08
[01/07 07:31:56] d2.evaluation.evaluator INFO: Inference done 12900/16850. 0.4821 s / img. ETA=0:31:44
[01/07 07:32:20] d2.evaluation.evaluator INFO: Inference done 12950/16850. 0.4821 s / img. ETA=0:31:20
[01/07 07:32:44] d2.evaluation.evaluator INFO: Inference done 13000/16850. 0.4821 s / img. ETA=0:30:55
[01/07 07:33:08] d2.evaluation.evaluator INFO: Inference done 13050/16850. 0.4821 s / img. ETA=0:30:31
[01/07 07:33:32] d2.evaluation.evaluator INFO: Inference done 13100/16850. 0.4821 s / img. ETA=0:30:07
[01/07 07:33:56] d2.evaluation.evaluator INFO: Inference done 13150/16850. 0.4821 s / img. ETA=0:29:43
[01/07 07:34:20] d2.evaluation.evaluator INFO: Inference done 13200/16850. 0.4821 s / img. ETA=0:29:19
[01/07 07:34:44] d2.evaluation.evaluator INFO: Inference done 13250/16850. 0.4821 s / img. ETA=0:28:55
[01/07 07:35:08] d2.evaluation.evaluator INFO: Inference done 13300/16850. 0.4821 s / img. ETA=0:28:31
[01/07 07:35:32] d2.evaluation.evaluator INFO: Inference done 13350/16850. 0.4820 s / img. ETA=0:28:07
[01/07 07:35:56] d2.evaluation.evaluator INFO: Inference done 13400/16850. 0.4820 s / img. ETA=0:27:43
[01/07 07:36:20] d2.evaluation.evaluator INFO: Inference done 13450/16850. 0.4820 s / img. ETA=0:27:18
[01/07 07:36:44] d2.evaluation.evaluator INFO: Inference done 13500/16850. 0.4820 s / img. ETA=0:26:54
[01/07 07:37:08] d2.evaluation.evaluator INFO: Inference done 13550/16850. 0.4820 s / img. ETA=0:26:30
[01/07 07:37:32] d2.evaluation.evaluator INFO: Inference done 13600/16850. 0.4820 s / img. ETA=0:26:06
[01/07 07:37:56] d2.evaluation.evaluator INFO: Inference done 13650/16850. 0.4820 s / img. ETA=0:25:42
[01/07 07:38:20] d2.evaluation.evaluator INFO: Inference done 13700/16850. 0.4820 s / img. ETA=0:25:18
[01/07 07:38:44] d2.evaluation.evaluator INFO: Inference done 13750/16850. 0.4820 s / img. ETA=0:24:54
[01/07 07:39:08] d2.evaluation.evaluator INFO: Inference done 13800/16850. 0.4820 s / img. ETA=0:24:30
[01/07 07:39:32] d2.evaluation.evaluator INFO: Inference done 13850/16850. 0.4820 s / img. ETA=0:24:05
[01/07 07:39:56] d2.evaluation.evaluator INFO: Inference done 13900/16850. 0.4820 s / img. ETA=0:23:41
[01/07 07:40:20] d2.evaluation.evaluator INFO: Inference done 13950/16850. 0.4820 s / img. ETA=0:23:17
[01/07 07:40:44] d2.evaluation.evaluator INFO: Inference done 14000/16850. 0.4820 s / img. ETA=0:22:53
[01/07 07:41:09] d2.evaluation.evaluator INFO: Inference done 14050/16850. 0.4820 s / img. ETA=0:22:29
[01/07 07:41:33] d2.evaluation.evaluator INFO: Inference done 14100/16850. 0.4820 s / img. ETA=0:22:05
[01/07 07:41:57] d2.evaluation.evaluator INFO: Inference done 14150/16850. 0.4820 s / img. ETA=0:21:41
[01/07 07:42:21] d2.evaluation.evaluator INFO: Inference done 14200/16850. 0.4820 s / img. ETA=0:21:17
[01/07 07:42:45] d2.evaluation.evaluator INFO: Inference done 14250/16850. 0.4819 s / img. ETA=0:20:53
[01/07 07:43:09] d2.evaluation.evaluator INFO: Inference done 14300/16850. 0.4819 s / img. ETA=0:20:28
[01/07 07:43:33] d2.evaluation.evaluator INFO: Inference done 14350/16850. 0.4820 s / img. ETA=0:20:04
[01/07 07:43:57] d2.evaluation.evaluator INFO: Inference done 14400/16850. 0.4820 s / img. ETA=0:19:40
[01/07 07:44:21] d2.evaluation.evaluator INFO: Inference done 14450/16850. 0.4820 s / img. ETA=0:19:16
[01/07 07:44:45] d2.evaluation.evaluator INFO: Inference done 14500/16850. 0.4820 s / img. ETA=0:18:52
[01/07 07:45:10] d2.evaluation.evaluator INFO: Inference done 14550/16850. 0.4820 s / img. ETA=0:18:28
[01/07 07:45:34] d2.evaluation.evaluator INFO: Inference done 14600/16850. 0.4820 s / img. ETA=0:18:04
[01/07 07:45:58] d2.evaluation.evaluator INFO: Inference done 14650/16850. 0.4820 s / img. ETA=0:17:40
[01/07 07:46:22] d2.evaluation.evaluator INFO: Inference done 14700/16850. 0.4820 s / img. ETA=0:17:16
[01/07 07:46:46] d2.evaluation.evaluator INFO: Inference done 14750/16850. 0.4820 s / img. ETA=0:16:52
[01/07 07:47:10] d2.evaluation.evaluator INFO: Inference done 14800/16850. 0.4820 s / img. ETA=0:16:28
[01/07 07:47:34] d2.evaluation.evaluator INFO: Inference done 14850/16850. 0.4819 s / img. ETA=0:16:03
[01/07 07:47:58] d2.evaluation.evaluator INFO: Inference done 14900/16850. 0.4819 s / img. ETA=0:15:39
[01/07 07:48:22] d2.evaluation.evaluator INFO: Inference done 14950/16850. 0.4819 s / img. ETA=0:15:15
[01/07 07:48:46] d2.evaluation.evaluator INFO: Inference done 15000/16850. 0.4819 s / img. ETA=0:14:51
[01/07 07:49:10] d2.evaluation.evaluator INFO: Inference done 15050/16850. 0.4819 s / img. ETA=0:14:27
[01/07 07:49:34] d2.evaluation.evaluator INFO: Inference done 15100/16850. 0.4819 s / img. ETA=0:14:03
[01/07 07:49:58] d2.evaluation.evaluator INFO: Inference done 15150/16850. 0.4819 s / img. ETA=0:13:39
[01/07 07:50:22] d2.evaluation.evaluator INFO: Inference done 15200/16850. 0.4819 s / img. ETA=0:13:15
[01/07 07:50:46] d2.evaluation.evaluator INFO: Inference done 15250/16850. 0.4819 s / img. ETA=0:12:51
[01/07 07:51:10] d2.evaluation.evaluator INFO: Inference done 15300/16850. 0.4819 s / img. ETA=0:12:26
[01/07 07:51:34] d2.evaluation.evaluator INFO: Inference done 15350/16850. 0.4819 s / img. ETA=0:12:02
[01/07 07:51:58] d2.evaluation.evaluator INFO: Inference done 15400/16850. 0.4819 s / img. ETA=0:11:38
[01/07 07:52:22] d2.evaluation.evaluator INFO: Inference done 15450/16850. 0.4819 s / img. ETA=0:11:14
[01/07 07:52:46] d2.evaluation.evaluator INFO: Inference done 15500/16850. 0.4819 s / img. ETA=0:10:50
[01/07 07:53:10] d2.evaluation.evaluator INFO: Inference done 15550/16850. 0.4819 s / img. ETA=0:10:26
[01/07 07:53:34] d2.evaluation.evaluator INFO: Inference done 15600/16850. 0.4819 s / img. ETA=0:10:02
[01/07 07:53:58] d2.evaluation.evaluator INFO: Inference done 15650/16850. 0.4819 s / img. ETA=0:09:38
[01/07 07:54:22] d2.evaluation.evaluator INFO: Inference done 15700/16850. 0.4819 s / img. ETA=0:09:14
[01/07 07:54:46] d2.evaluation.evaluator INFO: Inference done 15750/16850. 0.4819 s / img. ETA=0:08:50
[01/07 07:55:10] d2.evaluation.evaluator INFO: Inference done 15800/16850. 0.4819 s / img. ETA=0:08:25
[01/07 07:55:35] d2.evaluation.evaluator INFO: Inference done 15850/16850. 0.4819 s / img. ETA=0:08:01
[01/07 07:56:00] d2.evaluation.evaluator INFO: Inference done 15900/16850. 0.4820 s / img. ETA=0:07:37
[01/07 07:56:24] d2.evaluation.evaluator INFO: Inference done 15950/16850. 0.4820 s / img. ETA=0:07:13
[01/07 07:56:48] d2.evaluation.evaluator INFO: Inference done 16000/16850. 0.4820 s / img. ETA=0:06:49
[01/07 07:57:12] d2.evaluation.evaluator INFO: Inference done 16050/16850. 0.4820 s / img. ETA=0:06:25
[01/07 07:57:37] d2.evaluation.evaluator INFO: Inference done 16100/16850. 0.4820 s / img. ETA=0:06:01
[01/07 07:58:01] d2.evaluation.evaluator INFO: Inference done 16150/16850. 0.4820 s / img. ETA=0:05:37
[01/07 07:58:25] d2.evaluation.evaluator INFO: Inference done 16200/16850. 0.4820 s / img. ETA=0:05:13
[01/07 07:58:49] d2.evaluation.evaluator INFO: Inference done 16250/16850. 0.4820 s / img. ETA=0:04:49
[01/07 07:59:13] d2.evaluation.evaluator INFO: Inference done 16300/16850. 0.4820 s / img. ETA=0:04:25
[01/07 07:59:37] d2.evaluation.evaluator INFO: Inference done 16350/16850. 0.4820 s / img. ETA=0:04:00
[01/07 08:00:01] d2.evaluation.evaluator INFO: Inference done 16400/16850. 0.4820 s / img. ETA=0:03:36
[01/07 08:00:25] d2.evaluation.evaluator INFO: Inference done 16450/16850. 0.4820 s / img. ETA=0:03:12
[01/07 08:00:49] d2.evaluation.evaluator INFO: Inference done 16500/16850. 0.4820 s / img. ETA=0:02:48
[01/07 08:01:13] d2.evaluation.evaluator INFO: Inference done 16550/16850. 0.4819 s / img. ETA=0:02:24
[01/07 08:01:37] d2.evaluation.evaluator INFO: Inference done 16600/16850. 0.4819 s / img. ETA=0:02:00
[01/07 08:02:01] d2.evaluation.evaluator INFO: Inference done 16650/16850. 0.4819 s / img. ETA=0:01:36
[01/07 08:02:25] d2.evaluation.evaluator INFO: Inference done 16700/16850. 0.4819 s / img. ETA=0:01:12
[01/07 08:02:49] d2.evaluation.evaluator INFO: Inference done 16750/16850. 0.4819 s / img. ETA=0:00:48
[01/07 08:03:14] d2.evaluation.evaluator INFO: Inference done 16800/16850. 0.4819 s / img. ETA=0:00:24
[01/07 08:03:38] d2.evaluation.evaluator INFO: Inference done 16850/16850. 0.4819 s / img. ETA=0:00:00
[01/07 08:03:38] d2.evaluation.evaluator INFO: Total inference time: 2:15:18 (0.481923 s / img per device, on 2 devices)
[01/07 08:03:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 2:14:29 (0.479049 s / img per device, on 2 devices)
[01/07 08:03:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[01/07 08:03:40] d2.evaluation.coco_evaluation INFO: Saving results to ./outs/out_cascade_mask_rcnn_X_152/inference/my_dataset_test.json
[01/07 08:03:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions ...
[01/07 08:04:06] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |   APm    |   APl    |
|:-----:|:------:|:------:|:-----:|:--------:|:--------:|
| 0.000 | 0.000  | 0.000  | 0.000 | -100.000 | -100.000 |
[01/07 08:04:06] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP   | category    | AP   |
|:-----------|:------|:-----------|:-----|:------------|:-----|
| ASC-H      | 0.000 | ASC-US     | nan  | HSIL        | nan  |
| LSIL       | nan   | Candida    | nan  | Trichomonas | nan  |
[01/07 08:04:07] d2.engine.defaults INFO: Evaluation results for my_dataset_test in csv format:
[01/07 08:04:07] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/07 08:04:07] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[01/07 08:04:07] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,-100.0000,-100.0000
